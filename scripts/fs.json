{
	"tokens": 155688,
	"articles": [
		{
			"title": "Chesterton’s Fence: A Lesson in Second Order Thinking",
			"url": "https://fs.blog/chestertons-fence/",
			"content": "A core component of making great decisions is understanding the rationale behind previous decisions. If we don’t understand how we got “here,” we run the risk of making things much worse.  When we seek to intervene in any system created by someone, it’s not enough to view their decisions and choices simply as the consequences of first-order thinking because we can inadvertently create serious problems. Before changing anything, we should wonder whether they were using second-order thinking. Their reasons for making certain choices might be more complex than they seem at first. It’s best to assume they knew things we don’t or had experience we can’t fathom, so we don’t go for quick fixes and end up making things worse. Second-order thinking is the practice of not just considering the consequences of our decisions but also the consequences of those consequences. Everyone can manage first-order thinking, which is just considering the immediate anticipated result of an action. It’s simple and quick, usually requiring little effort. By comparison, second-order thinking is more complex and time-consuming. The fact that it is difficult and unusual is what makes the ability to do it such a powerful advantage. Second-order thinking will get you extraordinary results, and so will learning to recognize when other people are using second-order thinking. To understand exactly why this is the case, let’s consider Chesterton’s Fence, described by G. K. Chesterton himself as follows: There exists in such a case a certain institution or law; let us say, for the sake of simplicity, a fence or gate erected across a road. The more modern type of reformer goes gaily up to it and says, “I don’t see the use of this; let us clear it away.” To which the more intelligent type of reformer will do well to answer: “If you don’t see the use of it, I certainly won’t let you clear it away. Go away and think. Then, when you can come back and tell me that you do see the use of it, I may allow you to destroy it.”  Chesterton’s Fence is a heuristic inspired by a quote from the writer and polymath G. K. Chesterton’s 1929 book, The Thing. It’s best known as being one of John F. Kennedy’s favored sayings, as well as a principle Wikipedia encourages its editors to follow. In the book, Chesterton describes the classic case of the reformer who notices something, such as a fence, and fails to see the reason for its existence. However, before they decide to remove it, they must figure out why it exists in the first place. If they do not do this, they are likely to do more harm than good with its removal. In its most concise version, Chesterton’s Fence states the following: Do not remove a fence until you know why it was put up in the first place. Chesterton went on to explain why this principle holds true, writing that fences don’t grow out of the ground, nor do people build them in their sleep or during a fit of madness. He explained that fences are built by people who carefully planned them out and “had some reason for thinking the fence would be a good thing for somebody.” Until we establish that reason, we have no business taking an ax to it. The reason might not be a good or relevant one; we just need to be aware of what the reason is. Otherwise, we may end up with unintended consequences: second- and third-order effects we don’t want, spreading like ripples on a pond and causing damage for years. Elsewhere, in his essay collection Heretics, Chesterton makes a similar point, detailed here: Suppose that a great commotion arises in the street about something, let us say a lamp-post, which many influential persons desire to pull down. A grey-clad monk, who is the spirit of the Middle Ages, is approached upon the matter, and begins to say, in the arid manner of the Schoolmen, “Let us first of all consider, my brethren, the value of Light. If Light be in itself good” At this point he is somewhat excusably knocked down. All the people make a rush for the lamp-post, the lamp-post is down in ten minutes, and they go about congratulating each other on their un-mediaeval practicality. But as things go on they do not work out so easily. Some people have pulled the lamp-post down because they wanted the electric light; some because they wanted old iron; some because they wanted darkness, because their deeds were evil. Some thought it not enough of a lamp-post, some too much; some acted because they wanted to smash municipal machinery; some because they wanted to smash something. And there is war in the night, no man knowing whom he strikes. So, gradually and inevitably, to-day, to-morrow, or the next day, there comes back the conviction that the monk was right after all, and that all depends on what is the philosophy of Light. Only what we might have discussed under the gas-lamp, we now must discuss in the dark. As simple as Chesterton’s Fence is as a principle, it teaches us an important lesson. Many of the problems we face in life occur when we intervene with systems without an awareness of what the consequences could be. We can easily forget that this applies to subtraction as much as to addition. If a fence exists, there is likely a reason for it. It may be an illogical or inconsequential reason, but it is a reason nonetheless.  “Before I built a wall I’d ask to know What I was walling in or walling out, And to whom I was like to give offence.”  Robert Frost, “Mending Wall” Chesterton also alluded to the all-too-common belief that previous generations were bumbling fools, stumbling around, constructing fences wherever they fancied. Should we fail to respect their judgement and not try to understand it, we run the risk of creating new, unexpected problems. By and large, people do not do things for no reason. We’re all lazy at heart. We don’t like to waste time and resources on useless fences. Not understanding something does not mean it must be pointless. Take the case of supposedly hierarchy-free companies. Someone came along and figured that having management and an overall hierarchy is an imperfect system. It places additional stress on those at the bottom and can even be damaging to their health. It leaves room for abuse of power and manipulative company politics. It makes it unlikely that good ideas from those at the bottom will get listened to. However, despite the numerous problems inherent in hierarchical companies, doing away with this structure altogether belies a lack of awareness of the reasons why it is so ubiquitous. Someone needs to make decisions and be held responsible for their consequences. During times of stress or disorganization, people naturally tend to look to leaders for direction. Without a formal hierarchy, people often form an invisible one, which is far more complex to navigate and can lead to the most charismatic or domineering individual taking control, rather than the most qualified. It is certainly admirable that hierarchy-free companies are taking the enormous risk inherent in breaking the mold and trying something new. However, their approach ignores Chesterton’s Fence and doesn’t address why hierarchies exist within companies in the first place. Removing them does not necessarily lead to a fairer, more productive system. Yes, doing things the way they’ve always been done means getting what we’ve always got. There’s certainly nothing positive about being resistant to any change. Things become out of date and redundant with time. Sometimes an outside perspective is ideal for shaking things up and finding new ways. Even so, we can’t let ourselves be too overconfident about the redundancy of things we see as pointless. Or, to paraphrase Rory Sutherland, the peacock’s tail is not about efficiency. In fact, its whole value lies in its inefficiency. It signals a bird is healthy enough to waste energy growing it and has the strength to carry it around. Peahens use the tails of peacocks as guidance for choosing which mates are likely to have the best genes to pass on to their offspring. If an outside observer were to somehow swoop in and give peacocks regular, functional tails, it would be more energy efficient and practical, but it would deprive them of the ability to advertise their genetic potential.  All of us, at one point or another, make some attempt to change a habit to improve our lives. If you’re engaging in a bad habit, it’s admirable to try to eliminate itexcept part of why many attempts to do so fail is that bad habits do not appear out of nowhere. No one wakes up one day and decides they want to start smoking or drinking every night or watching television until the early hours of the morning. Bad habits generally evolve to serve an unfulfilled need: connection, comfort, distraction, take your pick. Attempting to remove the habit and leave everything else untouched does not eliminate the need and can simply lead to a replacement habit that might be just as harmful or even worse. Because of this, more successful approaches often involve replacing a bad habit with a good, benign, or less harmful oneor dealing with the underlying need. In other words, that fence went up for a reason, and it can’t come down without something either taking its place or removing the need for it to be there in the first place. To give a further example, in a classic post from 2009 on his website, serial entrepreneur Steve Blank gives an example of a decision he has repeatedly seen in startups. They grow to the point where it makes sense to hire a Chief Financial Officer. Eager to make an immediate difference, the new CFO starts looking for ways to cut costs so they can point to how they’re saving the company money. They take a look at the free snacks and sodas offered to employees and calculate how much they cost per yearperhaps a few thousand dollars. It seems like a waste of money, so they decide to do away with free sodas or start charging a few cents for them. After all, they’re paying people enough. They can buy their own sodas. Blank writes that, in his experience, the outcome is always the same. The original employees who helped the company grow initially notice the change and realize things are not how they were before. Of course they can afford to buy their own sodas. But suddenly having to is just an unmissable sign that the company’s culture is changing, which can be enough to prompt the most talented people to jump ship. Attempting to save a relatively small amount of money ends up costing far more in employee turnover. The new CFO didn’t consider why that fence was up in the first place.  Chesterton’s Fence is not an admonishment of anyone who tries to make improvements; it is a call to be aware of second-order thinking before intervening. It reminds us that we don’t always know better than those who made decisions before us, and we can’t see all the nuances to a situation until we’re intimate with it. Unless we know why someone made a decision, we can’t safely change it or conclude that they were wrong.  The first step before modifying an aspect of a system is to understand it. Observe it in full. Note how it interconnects with other aspects, including ones that might not be linked to you personally. Learn how it works, and then propose your change. ",
			"tokens": 2463,
			"chunks": [
				{
					"article_title": "Chesterton’s Fence: A Lesson in Second Order Thinking",
					"article_url": "https://fs.blog/chestertons-fence/",
					"content": "A core component of making great decisions is understanding the rationale behind previous decisions. If we don’t understand how we got “here,” we run the risk of making things much worse.  When we seek to intervene in any system created by someone, it’s not enough to view their decisions and choices simply as the consequences of first-order thinking because we can inadvertently create serious problems. Before changing anything, we should wonder whether they were using second-order thinking. Their reasons for making certain choices might be more complex than they seem at first. It’s best to assume they knew things we don’t or had experience we can’t fathom, so we don’t go for quick fixes and end up making things worse. Second-order thinking is the practice of not just considering the consequences of our decisions but also the consequences of those consequences. ",
					"content_token": 183,
					"embedding": []
				},
				{
					"article_title": "Chesterton’s Fence: A Lesson in Second Order Thinking",
					"article_url": "https://fs.blog/chestertons-fence/",
					"content": "Everyone can manage first-order thinking, which is just considering the immediate anticipated result of an action. It’s simple and quick, usually requiring little effort. By comparison, second-order thinking is more complex and time-consuming. The fact that it is difficult and unusual is what makes the ability to do it such a powerful advantage. Second-order thinking will get you extraordinary results, and so will learning to recognize when other people are using second-order thinking. To understand exactly why this is the case, let’s consider Chesterton’s Fence, described by G. K. Chesterton himself as follows: There exists in such a case a certain institution or law; let us say, for the sake of simplicity, a fence or gate erected across a road. ",
					"content_token": 161,
					"embedding": []
				},
				{
					"article_title": "Chesterton’s Fence: A Lesson in Second Order Thinking",
					"article_url": "https://fs.blog/chestertons-fence/",
					"content": "The more modern type of reformer goes gaily up to it and says, “I don’t see the use of this; let us clear it away.” To which the more intelligent type of reformer will do well to answer: “If you don’t see the use of it, I certainly won’t let you clear it away. Go away and think. Then, when you can come back and tell me that you do see the use of it, I may allow you to destroy it.”  Chesterton’s Fence is a heuristic inspired by a quote from the writer and polymath G. K. Chesterton’s 1929 book, The Thing. It’s best known as being one of John F. Kennedy’s favored sayings, as well as a principle Wikipedia encourages its editors to follow. ",
					"content_token": 183,
					"embedding": []
				},
				{
					"article_title": "Chesterton’s Fence: A Lesson in Second Order Thinking",
					"article_url": "https://fs.blog/chestertons-fence/",
					"content": "In the book, Chesterton describes the classic case of the reformer who notices something, such as a fence, and fails to see the reason for its existence. However, before they decide to remove it, they must figure out why it exists in the first place. If they do not do this, they are likely to do more harm than good with its removal. In its most concise version, Chesterton’s Fence states the following: Do not remove a fence until you know why it was put up in the first place. Chesterton went on to explain why this principle holds true, writing that fences don’t grow out of the ground, nor do people build them in their sleep or during a fit of madness. He explained that fences are built by people who carefully planned them out and “had some reason for thinking the fence would be a good thing for somebody.” Until we establish that reason, we have no business taking an ax to it. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "Chesterton’s Fence: A Lesson in Second Order Thinking",
					"article_url": "https://fs.blog/chestertons-fence/",
					"content": "The reason might not be a good or relevant one; we just need to be aware of what the reason is. Otherwise, we may end up with unintended consequences: second- and third-order effects we don’t want, spreading like ripples on a pond and causing damage for years. Elsewhere, in his essay collection Heretics, Chesterton makes a similar point, detailed here: Suppose that a great commotion arises in the street about something, let us say a lamp-post, which many influential persons desire to pull down. A grey-clad monk, who is the spirit of the Middle Ages, is approached upon the matter, and begins to say, in the arid manner of the Schoolmen, “Let us first of all consider, my brethren, the value of Light. If Light be in itself good” At this point he is somewhat excusably knocked down. ",
					"content_token": 184,
					"embedding": []
				},
				{
					"article_title": "Chesterton’s Fence: A Lesson in Second Order Thinking",
					"article_url": "https://fs.blog/chestertons-fence/",
					"content": "All the people make a rush for the lamp-post, the lamp-post is down in ten minutes, and they go about congratulating each other on their un-mediaeval practicality. But as things go on they do not work out so easily. Some people have pulled the lamp-post down because they wanted the electric light; some because they wanted old iron; some because they wanted darkness, because their deeds were evil. Some thought it not enough of a lamp-post, some too much; some acted because they wanted to smash municipal machinery; some because they wanted to smash something. And there is war in the night, no man knowing whom he strikes. So, gradually and inevitably, to-day, to-morrow, or the next day, there comes back the conviction that the monk was right after all, and that all depends on what is the philosophy of Light. Only what we might have discussed under the gas-lamp, we now must discuss in the dark. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "Chesterton’s Fence: A Lesson in Second Order Thinking",
					"article_url": "https://fs.blog/chestertons-fence/",
					"content": "As simple as Chesterton’s Fence is as a principle, it teaches us an important lesson. Many of the problems we face in life occur when we intervene with systems without an awareness of what the consequences could be. We can easily forget that this applies to subtraction as much as to addition. If a fence exists, there is likely a reason for it. It may be an illogical or inconsequential reason, but it is a reason nonetheless.  “Before I built a wall I’d ask to know What I was walling in or walling out, And to whom I was like to give offence.”  Robert Frost, “Mending Wall” Chesterton also alluded to the all-too-common belief that previous generations were bumbling fools, stumbling around, constructing fences wherever they fancied. Should we fail to respect their judgement and not try to understand it, we run the risk of creating new, unexpected problems. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "Chesterton’s Fence: A Lesson in Second Order Thinking",
					"article_url": "https://fs.blog/chestertons-fence/",
					"content": "By and large, people do not do things for no reason. We’re all lazy at heart. We don’t like to waste time and resources on useless fences. Not understanding something does not mean it must be pointless. Take the case of supposedly hierarchy-free companies. Someone came along and figured that having management and an overall hierarchy is an imperfect system. It places additional stress on those at the bottom and can even be damaging to their health. It leaves room for abuse of power and manipulative company politics. It makes it unlikely that good ideas from those at the bottom will get listened to. However, despite the numerous problems inherent in hierarchical companies, doing away with this structure altogether belies a lack of awareness of the reasons why it is so ubiquitous. Someone needs to make decisions and be held responsible for their consequences. During times of stress or disorganization, people naturally tend to look to leaders for direction. ",
					"content_token": 187,
					"embedding": []
				},
				{
					"article_title": "Chesterton’s Fence: A Lesson in Second Order Thinking",
					"article_url": "https://fs.blog/chestertons-fence/",
					"content": "Without a formal hierarchy, people often form an invisible one, which is far more complex to navigate and can lead to the most charismatic or domineering individual taking control, rather than the most qualified. It is certainly admirable that hierarchy-free companies are taking the enormous risk inherent in breaking the mold and trying something new. However, their approach ignores Chesterton’s Fence and doesn’t address why hierarchies exist within companies in the first place. Removing them does not necessarily lead to a fairer, more productive system. Yes, doing things the way they’ve always been done means getting what we’ve always got. There’s certainly nothing positive about being resistant to any change. Things become out of date and redundant with time. Sometimes an outside perspective is ideal for shaking things up and finding new ways. Even so, we can’t let ourselves be too overconfident about the redundancy of things we see as pointless. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "Chesterton’s Fence: A Lesson in Second Order Thinking",
					"article_url": "https://fs.blog/chestertons-fence/",
					"content": "Or, to paraphrase Rory Sutherland, the peacock’s tail is not about efficiency. In fact, its whole value lies in its inefficiency. It signals a bird is healthy enough to waste energy growing it and has the strength to carry it around. Peahens use the tails of peacocks as guidance for choosing which mates are likely to have the best genes to pass on to their offspring. If an outside observer were to somehow swoop in and give peacocks regular, functional tails, it would be more energy efficient and practical, but it would deprive them of the ability to advertise their genetic potential.  All of us, at one point or another, make some attempt to change a habit to improve our lives. If you’re engaging in a bad habit, it’s admirable to try to eliminate itexcept part of why many attempts to do so fail is that bad habits do not appear out of nowhere. ",
					"content_token": 189,
					"embedding": []
				},
				{
					"article_title": "Chesterton’s Fence: A Lesson in Second Order Thinking",
					"article_url": "https://fs.blog/chestertons-fence/",
					"content": "No one wakes up one day and decides they want to start smoking or drinking every night or watching television until the early hours of the morning. Bad habits generally evolve to serve an unfulfilled need: connection, comfort, distraction, take your pick. Attempting to remove the habit and leave everything else untouched does not eliminate the need and can simply lead to a replacement habit that might be just as harmful or even worse. Because of this, more successful approaches often involve replacing a bad habit with a good, benign, or less harmful oneor dealing with the underlying need. In other words, that fence went up for a reason, and it can’t come down without something either taking its place or removing the need for it to be there in the first place. To give a further example, in a classic post from 2009 on his website, serial entrepreneur Steve Blank gives an example of a decision he has repeatedly seen in startups. ",
					"content_token": 188,
					"embedding": []
				},
				{
					"article_title": "Chesterton’s Fence: A Lesson in Second Order Thinking",
					"article_url": "https://fs.blog/chestertons-fence/",
					"content": "They grow to the point where it makes sense to hire a Chief Financial Officer. Eager to make an immediate difference, the new CFO starts looking for ways to cut costs so they can point to how they’re saving the company money. They take a look at the free snacks and sodas offered to employees and calculate how much they cost per yearperhaps a few thousand dollars. It seems like a waste of money, so they decide to do away with free sodas or start charging a few cents for them. After all, they’re paying people enough. They can buy their own sodas. Blank writes that, in his experience, the outcome is always the same. The original employees who helped the company grow initially notice the change and realize things are not how they were before. Of course they can afford to buy their own sodas. ",
					"content_token": 174,
					"embedding": []
				},
				{
					"article_title": "Chesterton’s Fence: A Lesson in Second Order Thinking",
					"article_url": "https://fs.blog/chestertons-fence/",
					"content": "But suddenly having to is just an unmissable sign that the company’s culture is changing, which can be enough to prompt the most talented people to jump ship. Attempting to save a relatively small amount of money ends up costing far more in employee turnover. The new CFO didn’t consider why that fence was up in the first place.  Chesterton’s Fence is not an admonishment of anyone who tries to make improvements; it is a call to be aware of second-order thinking before intervening. It reminds us that we don’t always know better than those who made decisions before us, and we can’t see all the nuances to a situation until we’re intimate with it. Unless we know why someone made a decision, we can’t safely change it or conclude that they were wrong.  The first step before modifying an aspect of a system is to understand it. Observe it in full. ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "Chesterton’s Fence: A Lesson in Second Order Thinking",
					"article_url": "https://fs.blog/chestertons-fence/",
					"content": "Note how it interconnects with other aspects, including ones that might not be linked to you personally. Learn how it works, and then propose your change.",
					"content_token": 32,
					"embedding": []
				}
			]
		},
		{
			"title": "The Availability Bias: How to Overcome a Common Cognitive Distortion",
			"url": "https://fs.blog/availability-bias-cognitive-distortion/",
			"content": "“The attention which we lend to an experience is proportional to its vivid or interesting character, and it is a notorious fact that what interests us most vividly at the time is, other things equal, what we remember best.”William James    The availability heuristic explains why winning an award makes you more likely to win another award. It explains why we sometimes avoid one thing out of fear and end up doing something else that’s objectively riskier. It explains why governments spend enormous amounts of money mitigating risks we’ve already faced. It explains why the five people closest to you have a big impact on your worldview. It explains why mountains of data indicating something is harmful don’t necessarily convince everyone to avoid it. It explains why it can seem as if everything is going well when the stock market is up. And it explains why bad publicity can still be beneficial in the long run.    Here’s how the availability heuristic works, how to overcome it, and how to use it to your advantage.        How the availability heuristic works    Before we explain the availability heuristic, let’s quickly recap the field it comes from.    Behavioral economics is a field of study bringing together knowledge from psychology and economics to reveal how real people behave in the real world. This is in contrast to the traditional economic view of human behavior, which assumed people always behave in accordance with rational, stable interests. The field largely began in the 1960s and 1970s with the work of psychologists Amos Tversky and Daniel Kahneman.    Behavioral economics posits that people often make decisions and judgments under uncertainty using imperfect heuristics, rather than by weighing up all of the relevant factors. Quick heuristics enable us to make rapid decisions without taking the time and mental energy to think through all the details.    Most of the time, they lead to satisfactory outcomes. However, they can bias us towards certain consistently irrational decisions that contradict what economics would tell us is the best choice. We usually don’t realize we’re using heuristics, and they’re hard to change even if we’re actively trying to be more rational.    One such cognitive shortcut is the availability heuristic, first studied by Tversky and Kahneman in 1973. We tend to judge the likelihood and significance of things based on how easily they come to mind. The more “available” a piece of information is to us, the more important it seems. The result is that we give greater weight to information we learned recently because a news article you read last night comes to mind easier than a science class you took years ago. It’s too much work to try to comb through every piece of information that might be in our heads.    We also give greater weight to information that is shocking or unusual. Shark attacks and plane crashes strike us more than an accidental drowning or car accidents, so we overestimate their odds.    If we’re presented with a set of similar things with one that differs from the rest, we’ll find it easier to remember. For example, of the sequence of characters “RTASDT9RTGS,” the most common character remembered would be the “9” because it stands out from the letters.    In Behavioural Law and Economics, Timur Kuran and Cass Sunstein write:    “Additional examples from recent years include mass outcries over Agent Orange, asbestos in schools, breast implants, and automobile airbags that endanger children. Their common thread is that people tended to form their risk judgments largely, if not entirely, on the basis of information produced through a social process, rather than personal experience or investigation. In each case, a public upheaval occurred as vast numbers of players reacted to each other’s actions and statements. In each, moreover, the demand for swift, extensive, and costly government action came to be considered morally necessary and socially desirableeven though, in most or all cases, the resulting regulations may well have produced little good, and perhaps even relatively more harm.”    Narratives are more memorable than disjointed facts. There’s a reason why cultures around the world teach important life lessons and values through fables, fairy tales, myths, proverbs, and stories.    Personal experience can also make information more salient. If you’ve recently been in a car accident, you may well view car accidents as more common in general than you did before. The base rates haven’t changed; you just have an unpleasant, vivid memory coming to mind whenever you get in a car. We too easily assume that our recollections are representative and true and discount events that are outside of our immediate memory. To give another example, you may be more likely to buy insurance against a natural disaster if you’ve just been impacted by one than you are before it happens.    Anything that makes something easier to remember increases its impact on us. In an early study, Tversky and Kahneman asked subjects whether a random English word is more likely to begin with “K” or have “K” as the third letter. Seeing as it’s typically easier to recall words beginning with a particular letter, people tended to assume the former was more common. The opposite is true.    In Judgment Under Uncertainty: Heuristics and Biases, Tversky and Kahneman write:    “one may estimate probability by assessing availability, or associative distance. Lifelong experience has taught us that instances of large classes are recalled better and faster than instances of less frequent classes, that likely occurrences are easier to imagine than unlikely ones, and that associative connections are strengthened when two events frequently co-occur.For example, one may assess the divorce rate in a given community by recalling divorces among one’s acquaintances; one may evaluate the probability that a politician will lose an election by considering various ways in which he may lose support; and one may estimate the probability that a violent person will see’ beasts of prey in a Rorschach card by assessing the strength of association between violence and beasts of prey. In all of these cases, the assessment of the frequency of a class or the probability of an event is mediated by an assessment of availability.”    They go on to write:    “That associative bonds are strengthened by repetition is perhaps the oldest law of memory known to man. The availability heuristic exploits the inverse form of this law, that is, it uses strength of association as a basis for the judgment of frequency. In this theory, availability is a mediating variable, rather than a dependent variable as is typically the case in the study of memory.”        How the availability heuristic misleads us    “People tend to assess the relative importance of issues by the ease with which they are retrieved from memoryand this is largely determined by the extent of coverage in the media.” Daniel Kahneman, Thinking Fast and Slow    To go back to the points made in the introduction of this post, winning an award can make you more likely to win another award because it gives you visibility, making your name come to mind more easily in connection to that kind of accolade. We sometimes avoid one thing in favor of something objectively riskier, like driving instead of taking a plane, because the dangers of the latter are more memorable. The five people closest to you can have a big impact on your worldview because you frequently encounter their attitudes and opinions, bringing them to mind when you make your own judgments. Mountains of data indicating something is harmful don’t always convince people to avoid it if those dangers aren’t salient, such as if they haven’t personally experienced them. It can seem as if things are going well when the stock market is up because it’s a simple, visible, and therefore memorable indicator. Bad publicity can be beneficial in the long run if it means something, such as a controversial book, gets mentioned often and is more likely to be recalled.    These aren’t empirical rules, but they’re logical consequences of the availability heuristic, in the absence of mitigating factors.    We are what we remember, and our memories have a significant impact on our perception of the world. What we end up remembering is influenced by factors such as the following:    Our foundational beliefs about the worldOur expectationsThe emotions a piece of information inspires in usHow many times we’re exposed to a piece of informationThe source of a piece of informationThere is no real link between how memorable something is and how likely it is to happen. In fact, the opposite is often true. Unusual events stand out more and receive more attention than commonplace ones. As a result, the availability heuristic skews our perception of risks in two key ways:    We overestimate the likelihood of unlikely events. And we underestimate the likelihood of likely events.    Overestimating the risk of unlikely events leads us to stay awake at night, turning our hair grey, worrying about things that have almost no chance of happening. We can end up wasting enormous amounts of time, money, and other resources trying to mitigate things that have, on balance, a small impact. Sometimes those mitigation efforts end up backfiring, and sometimes they make us feel safer than they should.    On the flipside, we can overestimate the chance of unusually good things happening to us. Looking at everyone’s highlights on social media, we can end up expecting our own lives to also be a procession of grand achievements and joys. But most people’s lives are mundane most of the time, and the highlights we see tend to be exceptional ones, not routine ones.    Underestimating the risk of likely events leads us to fail to prepare for predictable problems and occurrences. We’re so worn out from worrying about unlikely events, we don’t have the energy to think about what’s in front of us. If you’re stressed and anxious much of the time, you’ll have a hard time paying attention to those signals when they really matter.    All of this is not to say that you shouldn’t prepare for the worst. Or that unlikely things never happen as Littlewood’s Law states, you can expect a one-in-a-million event at least once per month. Rather, we should be careful about only preparing for the extremes because those extremes are more memorable.        How to overcome the availability heuristic    Knowing about a cognitive bias isn’t usually enough to overcome it. Even people like Kahneman who have studied behavioral economics for many years sometimes struggle with the same irrational patterns. But being aware of the availability heuristic is helpful for the times when you need to make an important decision and can step back to make sure it isn’t distorting your view. Here are five ways of mitigating the availability heuristic.    1. Always consider base rates when making judgments about probability.The base rate of something is the average prevalence of it within a particular population. For example, around 10 of the population are left-handed. If you had to guess the likelihood of a random person being left-handed, you would be correct to say 1 in 10 in the absence of other relevant information. When judging the probability of something, look at the base rate whenever possible.    2. Focus on trends and patterns.The mental model of regression to the mean teaches us that extreme events tend to be followed by more moderate ones. Outlier events are often the result of luck and randomness. They’re not necessarily instructive. Whenever possible, base your judgments on trends and patternsthe longer term, the better. Track record is everything, even if outlier events are more memorable.    3. Take the time to think before making a judgment.The whole point of heuristics is that they save the time and effort needed to parse a ton of information and make a judgment. But, as we always say, you can’t make a good decision without taking time to think. There’s no shortcut for that. If you’re making an important decision, the only way to get around the availability heuristic is to stop and go through the relevant information, rather than assuming whatever comes to mind first is correct.    4. Keep track of information you might need to use in a judgment far off in the future.Don’t rely on memory. In Judgment in Managerial Decision-Making, Max Bazerman and Don Moore present the example of workplace annual performance appraisals. Managers tend to base their evaluations more on the prior three months than the nine months before that. It’s much easier than remembering what happened over the course of an entire year. Managers also tend to give substantial weight to unusual one-off behavior, such as a serious mistake or notable success, without considering the overall trend. In this case, noting down observations on someone’s performance throughout the entire year would lead to a more accurate appraisal.    5. Go back and revisit old information.Even if you think you can recall everything important, it’s a good idea to go back and refresh your memory of relevant information before making a decision.    The availability heuristic is part of Farnam Street’s latticework of mental models.",
			"tokens": 2827,
			"chunks": [
				{
					"article_title": "The Availability Bias: How to Overcome a Common Cognitive Distortion",
					"article_url": "https://fs.blog/availability-bias-cognitive-distortion/",
					"content": "“The attention which we lend to an experience is proportional to its vivid or interesting character, and it is a notorious fact that what interests us most vividly at the time is, other things equal, what we remember best.”William James    The availability heuristic explains why winning an award makes you more likely to win another award. It explains why we sometimes avoid one thing out of fear and end up doing something else that’s objectively riskier. It explains why governments spend enormous amounts of money mitigating risks we’ve already faced. It explains why the five people closest to you have a big impact on your worldview. It explains why mountains of data indicating something is harmful don’t necessarily convince everyone to avoid it. It explains why it can seem as if everything is going well when the stock market is up. And it explains why bad publicity can still be beneficial in the long run. ",
					"content_token": 186,
					"embedding": []
				},
				{
					"article_title": "The Availability Bias: How to Overcome a Common Cognitive Distortion",
					"article_url": "https://fs.blog/availability-bias-cognitive-distortion/",
					"content": "   Here’s how the availability heuristic works, how to overcome it, and how to use it to your advantage.        How the availability heuristic works    Before we explain the availability heuristic, let’s quickly recap the field it comes from.    Behavioral economics is a field of study bringing together knowledge from psychology and economics to reveal how real people behave in the real world. This is in contrast to the traditional economic view of human behavior, which assumed people always behave in accordance with rational, stable interests. The field largely began in the 1960s and 1970s with the work of psychologists Amos Tversky and Daniel Kahneman.    Behavioral economics posits that people often make decisions and judgments under uncertainty using imperfect heuristics, rather than by weighing up all of the relevant factors. Quick heuristics enable us to make rapid decisions without taking the time and mental energy to think through all the details. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "The Availability Bias: How to Overcome a Common Cognitive Distortion",
					"article_url": "https://fs.blog/availability-bias-cognitive-distortion/",
					"content": "   Most of the time, they lead to satisfactory outcomes. However, they can bias us towards certain consistently irrational decisions that contradict what economics would tell us is the best choice. We usually don’t realize we’re using heuristics, and they’re hard to change even if we’re actively trying to be more rational.    One such cognitive shortcut is the availability heuristic, first studied by Tversky and Kahneman in 1973. We tend to judge the likelihood and significance of things based on how easily they come to mind. The more “available” a piece of information is to us, the more important it seems. The result is that we give greater weight to information we learned recently because a news article you read last night comes to mind easier than a science class you took years ago. It’s too much work to try to comb through every piece of information that might be in our heads. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "The Availability Bias: How to Overcome a Common Cognitive Distortion",
					"article_url": "https://fs.blog/availability-bias-cognitive-distortion/",
					"content": "   We also give greater weight to information that is shocking or unusual. Shark attacks and plane crashes strike us more than an accidental drowning or car accidents, so we overestimate their odds.    If we’re presented with a set of similar things with one that differs from the rest, we’ll find it easier to remember. For example, of the sequence of characters “RTASDT9RTGS,” the most common character remembered would be the “9” because it stands out from the letters.    In Behavioural Law and Economics, Timur Kuran and Cass Sunstein write:    “Additional examples from recent years include mass outcries over Agent Orange, asbestos in schools, breast implants, and automobile airbags that endanger children. ",
					"content_token": 167,
					"embedding": []
				},
				{
					"article_title": "The Availability Bias: How to Overcome a Common Cognitive Distortion",
					"article_url": "https://fs.blog/availability-bias-cognitive-distortion/",
					"content": "Their common thread is that people tended to form their risk judgments largely, if not entirely, on the basis of information produced through a social process, rather than personal experience or investigation. In each case, a public upheaval occurred as vast numbers of players reacted to each other’s actions and statements. In each, moreover, the demand for swift, extensive, and costly government action came to be considered morally necessary and socially desirableeven though, in most or all cases, the resulting regulations may well have produced little good, and perhaps even relatively more harm.”    Narratives are more memorable than disjointed facts. There’s a reason why cultures around the world teach important life lessons and values through fables, fairy tales, myths, proverbs, and stories.    Personal experience can also make information more salient. If you’ve recently been in a car accident, you may well view car accidents as more common in general than you did before. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "The Availability Bias: How to Overcome a Common Cognitive Distortion",
					"article_url": "https://fs.blog/availability-bias-cognitive-distortion/",
					"content": "The base rates haven’t changed; you just have an unpleasant, vivid memory coming to mind whenever you get in a car. We too easily assume that our recollections are representative and true and discount events that are outside of our immediate memory. To give another example, you may be more likely to buy insurance against a natural disaster if you’ve just been impacted by one than you are before it happens.    Anything that makes something easier to remember increases its impact on us. In an early study, Tversky and Kahneman asked subjects whether a random English word is more likely to begin with “K” or have “K” as the third letter. Seeing as it’s typically easier to recall words beginning with a particular letter, people tended to assume the former was more common. The opposite is true. ",
					"content_token": 174,
					"embedding": []
				},
				{
					"article_title": "The Availability Bias: How to Overcome a Common Cognitive Distortion",
					"article_url": "https://fs.blog/availability-bias-cognitive-distortion/",
					"content": "   In Judgment Under Uncertainty: Heuristics and Biases, Tversky and Kahneman write:    “one may estimate probability by assessing availability, or associative distance. Lifelong experience has taught us that instances of large classes are recalled better and faster than instances of less frequent classes, that likely occurrences are easier to imagine than unlikely ones, and that associative connections are strengthened when two events frequently co-occur.For example, one may assess the divorce rate in a given community by recalling divorces among one’s acquaintances; one may evaluate the probability that a politician will lose an election by considering various ways in which he may lose support; and one may estimate the probability that a violent person will see’ beasts of prey in a Rorschach card by assessing the strength of association between violence and beasts of prey. ",
					"content_token": 177,
					"embedding": []
				},
				{
					"article_title": "The Availability Bias: How to Overcome a Common Cognitive Distortion",
					"article_url": "https://fs.blog/availability-bias-cognitive-distortion/",
					"content": "In all of these cases, the assessment of the frequency of a class or the probability of an event is mediated by an assessment of availability.”    They go on to write:    “That associative bonds are strengthened by repetition is perhaps the oldest law of memory known to man. The availability heuristic exploits the inverse form of this law, that is, it uses strength of association as a basis for the judgment of frequency. ",
					"content_token": 93,
					"embedding": []
				},
				{
					"article_title": "The Availability Bias: How to Overcome a Common Cognitive Distortion",
					"article_url": "https://fs.blog/availability-bias-cognitive-distortion/",
					"content": "In this theory, availability is a mediating variable, rather than a dependent variable as is typically the case in the study of memory.”        How the availability heuristic misleads us    “People tend to assess the relative importance of issues by the ease with which they are retrieved from memoryand this is largely determined by the extent of coverage in the media.” Daniel Kahneman, Thinking Fast and Slow    To go back to the points made in the introduction of this post, winning an award can make you more likely to win another award because it gives you visibility, making your name come to mind more easily in connection to that kind of accolade. We sometimes avoid one thing in favor of something objectively riskier, like driving instead of taking a plane, because the dangers of the latter are more memorable. ",
					"content_token": 177,
					"embedding": []
				},
				{
					"article_title": "The Availability Bias: How to Overcome a Common Cognitive Distortion",
					"article_url": "https://fs.blog/availability-bias-cognitive-distortion/",
					"content": "The five people closest to you can have a big impact on your worldview because you frequently encounter their attitudes and opinions, bringing them to mind when you make your own judgments. Mountains of data indicating something is harmful don’t always convince people to avoid it if those dangers aren’t salient, such as if they haven’t personally experienced them. It can seem as if things are going well when the stock market is up because it’s a simple, visible, and therefore memorable indicator. Bad publicity can be beneficial in the long run if it means something, such as a controversial book, gets mentioned often and is more likely to be recalled.    These aren’t empirical rules, but they’re logical consequences of the availability heuristic, in the absence of mitigating factors.    We are what we remember, and our memories have a significant impact on our perception of the world. ",
					"content_token": 188,
					"embedding": []
				},
				{
					"article_title": "The Availability Bias: How to Overcome a Common Cognitive Distortion",
					"article_url": "https://fs.blog/availability-bias-cognitive-distortion/",
					"content": "What we end up remembering is influenced by factors such as the following:    Our foundational beliefs about the worldOur expectationsThe emotions a piece of information inspires in usHow many times we’re exposed to a piece of informationThe source of a piece of informationThere is no real link between how memorable something is and how likely it is to happen. In fact, the opposite is often true. Unusual events stand out more and receive more attention than commonplace ones. As a result, the availability heuristic skews our perception of risks in two key ways:    We overestimate the likelihood of unlikely events. And we underestimate the likelihood of likely events.    Overestimating the risk of unlikely events leads us to stay awake at night, turning our hair grey, worrying about things that have almost no chance of happening. We can end up wasting enormous amounts of time, money, and other resources trying to mitigate things that have, on balance, a small impact. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "The Availability Bias: How to Overcome a Common Cognitive Distortion",
					"article_url": "https://fs.blog/availability-bias-cognitive-distortion/",
					"content": "Sometimes those mitigation efforts end up backfiring, and sometimes they make us feel safer than they should.    On the flipside, we can overestimate the chance of unusually good things happening to us. Looking at everyone’s highlights on social media, we can end up expecting our own lives to also be a procession of grand achievements and joys. But most people’s lives are mundane most of the time, and the highlights we see tend to be exceptional ones, not routine ones.    Underestimating the risk of likely events leads us to fail to prepare for predictable problems and occurrences. We’re so worn out from worrying about unlikely events, we don’t have the energy to think about what’s in front of us. If you’re stressed and anxious much of the time, you’ll have a hard time paying attention to those signals when they really matter. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "The Availability Bias: How to Overcome a Common Cognitive Distortion",
					"article_url": "https://fs.blog/availability-bias-cognitive-distortion/",
					"content": "   All of this is not to say that you shouldn’t prepare for the worst. Or that unlikely things never happen as Littlewood’s Law states, you can expect a one-in-a-million event at least once per month. Rather, we should be careful about only preparing for the extremes because those extremes are more memorable.        How to overcome the availability heuristic    Knowing about a cognitive bias isn’t usually enough to overcome it. Even people like Kahneman who have studied behavioral economics for many years sometimes struggle with the same irrational patterns. But being aware of the availability heuristic is helpful for the times when you need to make an important decision and can step back to make sure it isn’t distorting your view. Here are five ways of mitigating the availability heuristic.    1. ",
					"content_token": 180,
					"embedding": []
				},
				{
					"article_title": "The Availability Bias: How to Overcome a Common Cognitive Distortion",
					"article_url": "https://fs.blog/availability-bias-cognitive-distortion/",
					"content": "Always consider base rates when making judgments about probability.The base rate of something is the average prevalence of it within a particular population. For example, around 10 of the population are left-handed. If you had to guess the likelihood of a random person being left-handed, you would be correct to say 1 in 10 in the absence of other relevant information. When judging the probability of something, look at the base rate whenever possible.    2. Focus on trends and patterns.The mental model of regression to the mean teaches us that extreme events tend to be followed by more moderate ones. Outlier events are often the result of luck and randomness. They’re not necessarily instructive. Whenever possible, base your judgments on trends and patternsthe longer term, the better. Track record is everything, even if outlier events are more memorable.    3. ",
					"content_token": 180,
					"embedding": []
				},
				{
					"article_title": "The Availability Bias: How to Overcome a Common Cognitive Distortion",
					"article_url": "https://fs.blog/availability-bias-cognitive-distortion/",
					"content": "Take the time to think before making a judgment.The whole point of heuristics is that they save the time and effort needed to parse a ton of information and make a judgment. But, as we always say, you can’t make a good decision without taking time to think. There’s no shortcut for that. If you’re making an important decision, the only way to get around the availability heuristic is to stop and go through the relevant information, rather than assuming whatever comes to mind first is correct.    4. Keep track of information you might need to use in a judgment far off in the future.Don’t rely on memory. In Judgment in Managerial Decision-Making, Max Bazerman and Don Moore present the example of workplace annual performance appraisals. Managers tend to base their evaluations more on the prior three months than the nine months before that. ",
					"content_token": 187,
					"embedding": []
				},
				{
					"article_title": "The Availability Bias: How to Overcome a Common Cognitive Distortion",
					"article_url": "https://fs.blog/availability-bias-cognitive-distortion/",
					"content": "It’s much easier than remembering what happened over the course of an entire year. Managers also tend to give substantial weight to unusual one-off behavior, such as a serious mistake or notable success, without considering the overall trend. In this case, noting down observations on someone’s performance throughout the entire year would lead to a more accurate appraisal.    5. Go back and revisit old information.Even if you think you can recall everything important, it’s a good idea to go back and refresh your memory of relevant information before making a decision.    The availability heuristic is part of Farnam Street’s latticework of mental models.",
					"content_token": 140,
					"embedding": []
				}
			]
		},
		{
			"title": "Efficiency is the Enemy",
			"url": "https://fs.blog/slack/",
			"content": "There’s a good chance most of the problems in your life and work come down to insufficient slack. Here’s how slack works and why you need more of it. Imagine if you, as a budding productivity enthusiast, one day gained access to a time machine and decided to take a trip back several decades to the office of one of your old-timey business heroes. Let’s call him Tony. You disguise yourself as a janitor and figure a few days of observation should be enough to reveal the secret of that CEO’s incredible productivity and shrewd decision-making. You want to learn the habits and methods that enabled him to transform an entire industry for good. Arriving at the no doubt smoke-filled office, you’re a little surprised to find it’s far from a hive of activity. In fact, the people you can see around seem to be doing next to nothing. Outside your hero’s office, his secretary lounges at her desk and let’s face it, the genders wouldn’t have been the other way around. Let’s call her Gloria. She doesn’t appear busy at all. You observe for half an hour as she reads, tidies her desk, and chats with other secretaries who pass by. They don’t seem busy either. Confused as to why Tony would squander money on idle staff, you stick around for a few more hours. With a bit more observation, you realize your initial impression was entirely wrong. Gloria does indeed do nothing much of the time. But every so often, a request, instruction, or alert comes from Tony and she leaps into action. Within minutes, she answers the call, sends the letter, reschedules the appointment, or finds the right document. Any time he has a problem, she solves it right away. There’s no to-do list, no submitting a ticket, no waiting for a reply to an email for either Tony or Gloria. As a result, Tony’s day goes smoothly and efficiently. Every minute of his time goes on the most important part of his workmaking decisionsand not on dealing with trivial inconveniences like waiting in line at the post office. All that time Gloria spends doing nothing isn’t wasted time. It’s slack: excess capacity allowing for responsiveness and flexibility. The slack time is important because it means she never has a backlog of tasks to complete. She can always deal with anything new straight away. Gloria’s job is to ensure Tony is as busy as he needs to be. It’s not to be as busy as possible. If you ever find yourself stressed, overwhelmed, sinking into stasis despite wanting to change, or frustrated when you can’t respond to new opportunities, you need more slack in your life. In Slack: Getting Past Burnout, Busywork, and the Myth of Total Efficiency, Tom DeMarco explains that most people and organizations fail to recognize the value of slack. Although the book is now around twenty years old, its primary message is timeless and worth revisiting.  The enemy of efficiency “You’re efficient when you do something with minimum waste. And you’re effective when you’re doing the right something.” Many organizations are obsessed with efficiency. They want to be sure every resource is utilized to its fullest capacity and everyone is sprinting around every minute of the day doing something. They hire expert consultants to sniff out the faintest whiff of waste. As individuals, many of us are also obsessed with the mirage of total efficiency. We schedule every minute of our day, pride ourselves on forgoing breaks, and berate ourselves for the slightest moment of distraction. We view sleep, sickness, and burnout as unwelcome weaknesses and idolize those who never seem to succumb to them. This view, however, fails to recognize that efficiency and effectiveness are not the same thing. Total efficiency is a myth. Let’s return to Gloria and Tony. Imagine if Tony decided to assign her more work to ensure she spends a full eight hours a day busy. Would that be more efficient? Not really. Slack time enables her to respond to his requests right away, thus being effective at her job. If Gloria is already occupied, Tony will have to wait and whatever he’s doing will get held up. Both of them would be less effective as a result. Any time we eliminate slack, we create a build-up of work. DeMarco writes, “As a practical matter, it is impossible to keep everyone in the organization 100 percent busy unless we allow for some buffering at each employee’s desk. That means there is an inbox where work stacks up.” Many of us have come to expect work to involve no slack time because of the negative way we perceive it. In a world of manic efficiency, slack often comes across as laziness or a lack of initiative. Without slack time, however, we know we won’t be able to get through new tasks straight away, and if someone insists we should, we have to drop whatever we were previously doing. One way or another, something gets delayed. The increase in busyness may well be futile: “It’s possible to make an organization more efficient without making it better. That’s what happens when you drive out slack. It’s also possible to make an organization a little less efficient and improve it enormously. In order to do that, you need to reintroduce enough slack to allow the organization to breathe, reinvent itself, and make necessary change.”  Defining slack DeMarco defines slack as “the degree of freedom required to effect change. Slack is the natural enemy of efficiency and efficiency is the natural enemy of slack.” Elsewhere, he writes: “Slack represents operational capacity sacrificed in the interests of long-term health.” To illustrate the concept, DeMarco asks the reader to imagine one of those puzzle games consisting of eight numbered tiles in a box, with one empty space so you can slide them around one at a time. The objective is to shuffle the tiles into numerical order. That empty space is the equivalent of slack. If you remove it, the game is technically more efficient, but “something else is lost. Without the open space, there is no further possibility of moving tiles at all. The layout is optimal as it is, but if time proves otherwise, there is no way to change it.”  Having a little bit of wiggle room allows us to respond to changing circumstances, to experiment, and to do things that might not work. Slack consists of excess resources. It might be time, money, people on a job, or even expectations. Slack is vital because it prevents us from getting locked into our current state, unable to respond or adapt because we just don’t have the capacity. Not having slack is taxing. Scarcity weighs on our minds and uses up energy that could go toward doing the task at hand better. It amplifies the impact of failures and unintended consequences. Too much slack is bad because resources get wasted and people get bored. But, on the whole, an absence of slack is a problem far more often than an excess of it. If you give yourself too much slack time when scheduling a project that goes smoother than expected, you probably won’t spend the spare time sitting like a lemon. Maybe you’ll recuperate from an earlier project that took more effort than anticipated. Maybe you’ll tinker with some on-hold projects. Maybe you’ll be able to review why this one went well and derive lessons for the future. And maybe slack time is just your reward for doing a good job already! You deserve breathing room. Slack also allows us to handle the inevitable shocks and surprises of life. If every hour in our schedules is accounted for, we can’t slow down to recover from a minor cold, shift a bit of focus to learning a new skill for a while, or absorb a couple of hours of technical difficulties. In general, you need more slack than you expect. Unless you have a lot of practice, your estimations of how long things will take or how difficult they are will almost always be on the low end. Most of us treat best-case scenarios as if they are the most likely scenarios and will inevitably come to pass, but they rarely do. You also need to keep a vigilant eye on how fast you use up your slack so you can replenish it in time. For example, you might want to review your calendar once per week to check it still has white space each day and you haven’t allowed meetings to fill up your slack time. Think of the forms of slack that are more important to you, then check up on them regularly. If you find you’re running out of slack, take action. Once in a while, you might need to forgo slack to reap the benefits of constraints. Lacking slack in the short term or in a particular area can force you to be more inventive. If you find yourself struggling to come up with a creative solution, try consciously reducing your slack. For example, give yourself five-minutes to brainstorm ideas or ask yourself what you might do if your budget were slashed by 90. Most of the time, though, it’s critical to guard your slack with care. It’s best to assume you’ll always tend toward using it upor other people will try to steal it from you. Set clear boundaries in your work and keep an eye on tasks that might inflate.  Slack and change In the past, people and organizations could sometimes get by without much slackat least for a while. Now, even as slack keeps becoming more and more vital for survival, we’re keener than ever to eliminate it in the name of efficiency. Survival requires constant change and reinvention, which “require a commodity that is absent in our time as it has never been before. That commoditythe catalytic ingredient of changeis slack.” DeMarco goes on to write: “Slack is the time when reinvention happens. It is time when you are not 100 percent busy doing the operational business of your firm. Slack is the time when you are 0 percent busy. Slack at all levels is necessary to make the organization work effectively and to grow. It is the lubricant of change. Good companies excel in creative use of slack. And bad ones only obsess about removing it.” Only when we are 0 percent busy can we step back and look at the bigger picture of what we’re doing. Slack allows us to think ahead. To consider whether we’re on the right trajectory. To contemplate unseen problems. To mull over information. To decide if we’re making the right trade-offs. To do things that aren’t scalable or that might not have a chance to prove profitable for a while. To walk away from bad deals.  Slack and productivity The irony is that we achieve far more in the long run when we have slack. We are more productive when we don’t try to be productive all the time. DeMarco explains that the amount of work each person in an organization has is never static: “Things change on a day-to-day basis. This results in new unevenness of the tasks, with some people incurring additional work their buffers build up, while others become less loaded, since someone ahead of them in the work chain is slower to generate their particular kind of work to pass along.” An absence of slack is unsustainable. Inevitably, we end up needing additional resources, which have to come from somewhere. Being comfortable with sometimes being 0 percent busy means we think about whether we’re doing the right thing. This is in contrast to grabbing the first task we see so no one thinks we’re lazy. The expectation of “constant busyness means efficiency” creates pressure to always look occupied and keep a buffer of work on hand. If we see our buffer shrinking and we want to keep busy, the only possible solution is to work slower. Trying to eliminate slack causes work to expand. There’s never any free time because we always fill it. Amos Tversky said the secret to doing good research is to always be a little underemployed; you waste years by not being able to waste hours. Those wasted hours are necessary to figure out if you’re headed in the right direction.",
			"tokens": 2582,
			"chunks": [
				{
					"article_title": "Efficiency is the Enemy",
					"article_url": "https://fs.blog/slack/",
					"content": "There’s a good chance most of the problems in your life and work come down to insufficient slack. Here’s how slack works and why you need more of it. Imagine if you, as a budding productivity enthusiast, one day gained access to a time machine and decided to take a trip back several decades to the office of one of your old-timey business heroes. Let’s call him Tony. You disguise yourself as a janitor and figure a few days of observation should be enough to reveal the secret of that CEO’s incredible productivity and shrewd decision-making. You want to learn the habits and methods that enabled him to transform an entire industry for good. Arriving at the no doubt smoke-filled office, you’re a little surprised to find it’s far from a hive of activity. In fact, the people you can see around seem to be doing next to nothing. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "Efficiency is the Enemy",
					"article_url": "https://fs.blog/slack/",
					"content": "Outside your hero’s office, his secretary lounges at her desk and let’s face it, the genders wouldn’t have been the other way around. Let’s call her Gloria. She doesn’t appear busy at all. You observe for half an hour as she reads, tidies her desk, and chats with other secretaries who pass by. They don’t seem busy either. Confused as to why Tony would squander money on idle staff, you stick around for a few more hours. With a bit more observation, you realize your initial impression was entirely wrong. Gloria does indeed do nothing much of the time. But every so often, a request, instruction, or alert comes from Tony and she leaps into action. Within minutes, she answers the call, sends the letter, reschedules the appointment, or finds the right document. Any time he has a problem, she solves it right away. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "Efficiency is the Enemy",
					"article_url": "https://fs.blog/slack/",
					"content": "There’s no to-do list, no submitting a ticket, no waiting for a reply to an email for either Tony or Gloria. As a result, Tony’s day goes smoothly and efficiently. Every minute of his time goes on the most important part of his workmaking decisionsand not on dealing with trivial inconveniences like waiting in line at the post office. All that time Gloria spends doing nothing isn’t wasted time. It’s slack: excess capacity allowing for responsiveness and flexibility. The slack time is important because it means she never has a backlog of tasks to complete. She can always deal with anything new straight away. Gloria’s job is to ensure Tony is as busy as he needs to be. It’s not to be as busy as possible. ",
					"content_token": 163,
					"embedding": []
				},
				{
					"article_title": "Efficiency is the Enemy",
					"article_url": "https://fs.blog/slack/",
					"content": "If you ever find yourself stressed, overwhelmed, sinking into stasis despite wanting to change, or frustrated when you can’t respond to new opportunities, you need more slack in your life. In Slack: Getting Past Burnout, Busywork, and the Myth of Total Efficiency, Tom DeMarco explains that most people and organizations fail to recognize the value of slack. Although the book is now around twenty years old, its primary message is timeless and worth revisiting.  The enemy of efficiency “You’re efficient when you do something with minimum waste. And you’re effective when you’re doing the right something.” Many organizations are obsessed with efficiency. They want to be sure every resource is utilized to its fullest capacity and everyone is sprinting around every minute of the day doing something. They hire expert consultants to sniff out the faintest whiff of waste. As individuals, many of us are also obsessed with the mirage of total efficiency. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "Efficiency is the Enemy",
					"article_url": "https://fs.blog/slack/",
					"content": "We schedule every minute of our day, pride ourselves on forgoing breaks, and berate ourselves for the slightest moment of distraction. We view sleep, sickness, and burnout as unwelcome weaknesses and idolize those who never seem to succumb to them. This view, however, fails to recognize that efficiency and effectiveness are not the same thing. Total efficiency is a myth. Let’s return to Gloria and Tony. Imagine if Tony decided to assign her more work to ensure she spends a full eight hours a day busy. Would that be more efficient? Not really. Slack time enables her to respond to his requests right away, thus being effective at her job. If Gloria is already occupied, Tony will have to wait and whatever he’s doing will get held up. Both of them would be less effective as a result. Any time we eliminate slack, we create a build-up of work. ",
					"content_token": 183,
					"embedding": []
				},
				{
					"article_title": "Efficiency is the Enemy",
					"article_url": "https://fs.blog/slack/",
					"content": "DeMarco writes, “As a practical matter, it is impossible to keep everyone in the organization 100 percent busy unless we allow for some buffering at each employee’s desk. That means there is an inbox where work stacks up.” Many of us have come to expect work to involve no slack time because of the negative way we perceive it. In a world of manic efficiency, slack often comes across as laziness or a lack of initiative. Without slack time, however, we know we won’t be able to get through new tasks straight away, and if someone insists we should, we have to drop whatever we were previously doing. One way or another, something gets delayed. The increase in busyness may well be futile: “It’s possible to make an organization more efficient without making it better. That’s what happens when you drive out slack. ",
					"content_token": 183,
					"embedding": []
				},
				{
					"article_title": "Efficiency is the Enemy",
					"article_url": "https://fs.blog/slack/",
					"content": "It’s also possible to make an organization a little less efficient and improve it enormously. In order to do that, you need to reintroduce enough slack to allow the organization to breathe, reinvent itself, and make necessary change.”  Defining slack DeMarco defines slack as “the degree of freedom required to effect change. Slack is the natural enemy of efficiency and efficiency is the natural enemy of slack.” Elsewhere, he writes: “Slack represents operational capacity sacrificed in the interests of long-term health.” To illustrate the concept, DeMarco asks the reader to imagine one of those puzzle games consisting of eight numbered tiles in a box, with one empty space so you can slide them around one at a time. The objective is to shuffle the tiles into numerical order. That empty space is the equivalent of slack. If you remove it, the game is technically more efficient, but “something else is lost. ",
					"content_token": 194,
					"embedding": []
				},
				{
					"article_title": "Efficiency is the Enemy",
					"article_url": "https://fs.blog/slack/",
					"content": "Without the open space, there is no further possibility of moving tiles at all. The layout is optimal as it is, but if time proves otherwise, there is no way to change it.”  Having a little bit of wiggle room allows us to respond to changing circumstances, to experiment, and to do things that might not work. Slack consists of excess resources. It might be time, money, people on a job, or even expectations. Slack is vital because it prevents us from getting locked into our current state, unable to respond or adapt because we just don’t have the capacity. Not having slack is taxing. Scarcity weighs on our minds and uses up energy that could go toward doing the task at hand better. It amplifies the impact of failures and unintended consequences. Too much slack is bad because resources get wasted and people get bored. But, on the whole, an absence of slack is a problem far more often than an excess of it. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "Efficiency is the Enemy",
					"article_url": "https://fs.blog/slack/",
					"content": "If you give yourself too much slack time when scheduling a project that goes smoother than expected, you probably won’t spend the spare time sitting like a lemon. Maybe you’ll recuperate from an earlier project that took more effort than anticipated. Maybe you’ll tinker with some on-hold projects. Maybe you’ll be able to review why this one went well and derive lessons for the future. And maybe slack time is just your reward for doing a good job already! You deserve breathing room. Slack also allows us to handle the inevitable shocks and surprises of life. If every hour in our schedules is accounted for, we can’t slow down to recover from a minor cold, shift a bit of focus to learning a new skill for a while, or absorb a couple of hours of technical difficulties. In general, you need more slack than you expect. ",
					"content_token": 181,
					"embedding": []
				},
				{
					"article_title": "Efficiency is the Enemy",
					"article_url": "https://fs.blog/slack/",
					"content": "Unless you have a lot of practice, your estimations of how long things will take or how difficult they are will almost always be on the low end. Most of us treat best-case scenarios as if they are the most likely scenarios and will inevitably come to pass, but they rarely do. You also need to keep a vigilant eye on how fast you use up your slack so you can replenish it in time. For example, you might want to review your calendar once per week to check it still has white space each day and you haven’t allowed meetings to fill up your slack time. Think of the forms of slack that are more important to you, then check up on them regularly. If you find you’re running out of slack, take action. Once in a while, you might need to forgo slack to reap the benefits of constraints. Lacking slack in the short term or in a particular area can force you to be more inventive. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "Efficiency is the Enemy",
					"article_url": "https://fs.blog/slack/",
					"content": "If you find yourself struggling to come up with a creative solution, try consciously reducing your slack. For example, give yourself five-minutes to brainstorm ideas or ask yourself what you might do if your budget were slashed by 90. Most of the time, though, it’s critical to guard your slack with care. It’s best to assume you’ll always tend toward using it upor other people will try to steal it from you. Set clear boundaries in your work and keep an eye on tasks that might inflate.  Slack and change In the past, people and organizations could sometimes get by without much slackat least for a while. Now, even as slack keeps becoming more and more vital for survival, we’re keener than ever to eliminate it in the name of efficiency. Survival requires constant change and reinvention, which “require a commodity that is absent in our time as it has never been before. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "Efficiency is the Enemy",
					"article_url": "https://fs.blog/slack/",
					"content": "That commoditythe catalytic ingredient of changeis slack.” DeMarco goes on to write: “Slack is the time when reinvention happens. It is time when you are not 100 percent busy doing the operational business of your firm. Slack is the time when you are 0 percent busy. Slack at all levels is necessary to make the organization work effectively and to grow. It is the lubricant of change. Good companies excel in creative use of slack. And bad ones only obsess about removing it.” Only when we are 0 percent busy can we step back and look at the bigger picture of what we’re doing. Slack allows us to think ahead. To consider whether we’re on the right trajectory. To contemplate unseen problems. To mull over information. To decide if we’re making the right trade-offs. To do things that aren’t scalable or that might not have a chance to prove profitable for a while. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "Efficiency is the Enemy",
					"article_url": "https://fs.blog/slack/",
					"content": "To walk away from bad deals.  Slack and productivity The irony is that we achieve far more in the long run when we have slack. We are more productive when we don’t try to be productive all the time. DeMarco explains that the amount of work each person in an organization has is never static: “Things change on a day-to-day basis. This results in new unevenness of the tasks, with some people incurring additional work their buffers build up, while others become less loaded, since someone ahead of them in the work chain is slower to generate their particular kind of work to pass along.” An absence of slack is unsustainable. Inevitably, we end up needing additional resources, which have to come from somewhere. Being comfortable with sometimes being 0 percent busy means we think about whether we’re doing the right thing. This is in contrast to grabbing the first task we see so no one thinks we’re lazy. ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "Efficiency is the Enemy",
					"article_url": "https://fs.blog/slack/",
					"content": "The expectation of “constant busyness means efficiency” creates pressure to always look occupied and keep a buffer of work on hand. If we see our buffer shrinking and we want to keep busy, the only possible solution is to work slower. Trying to eliminate slack causes work to expand. There’s never any free time because we always fill it. Amos Tversky said the secret to doing good research is to always be a little underemployed; you waste years by not being able to waste hours. Those wasted hours are necessary to figure out if you’re headed in the right direction.",
					"content_token": 126,
					"embedding": []
				}
			]
		},
		{
			"title": "The OODA Loop: How Fighter Pilots Make Fast and Accurate Decisions",
			"url": "https://fs.blog/ooda-loop/",
			"content": "The OODA Loop is a four-step process for making effective decisions in high-stakes situations. It involves collecting relevant information, recognizing potential biases, deciding, and acting, then repeating the process with new information. Read on to learn how to use the OODA Loop. When we want to learn how to make rational decisions under pressure, it can be helpful to look at the techniques people use in extreme situations. If they work in the most drastic scenarios, they have a good chance of being effective in more typical ones. Because they’re developed and tested in the relentless laboratory of conflict, military mental models have practical applications far beyond their original context. If they didn’t work, they would be quickly replaced by alternatives. Military leaders and strategists invest a great deal of time and resources into developing decision-making processes. One such military mental model is the OODA Loop. Developed by strategist and U.S. Air Force Colonel John Boyd, the OODA Loop is a practical concept designed to function as the foundation of rational thinking in confusing or chaotic situations. “OODA” stands for “Observe, Orient, Decide, and Act.” “What is strategy? A mental tapestry of changing intentions for harmonizing and focusing our efforts as a basis for realizing some aim or purpose in an unfolding and often unforeseen world of many bewildering events and many contending interests.” John Boyd  The four parts of the OODA Loop Let’s break down the four parts of the OODA Loop and see how they fit together. Don’t forget the “Loop” part. The process is intended to be repeated again and again until a conflict finishes. Each repetition provides more information to inform the next one, making it a feedback loop. 1: Observe Step one is to observe the situation with the aim of building the most accurate and comprehensive picture of it possible. For example, a fighter pilot might consider the following factors in a broad, fluid way: What is immediately affecting me? What is affecting my opponent? What could affect either of us later on? Can I make any predictions? How accurate were my prior predictions? Information alone is insufficient. The observation stage requires converting information into an overall picture with overarching meaning that places it in context. A particularly vital skill is the capacity to identify which information is just noise and irrelevant for the current decision. If you want to make good decisions, you need to master the art of observing your environment. For a fighter pilot, that involves factors like the weather conditions and what their opponent is doing. In your workplace, that might include factors like regulations, available resources, relationships with other people, and your current state of mind. To give an example, consider a doctor meeting with a patient in the emergency room for the first time to identify how to treat them. Their first priority is figuring out what information they need to collect, then collecting it. They might check the patient’s records, ask other staff about the admission, ask the patient questions, check vital signs such as blood pressure, and order particular diagnostic tests. Doctors learn to pick up on subtle cues that can be telling of particular conditions, such as a patient’s speech patterns, body language, what they’ve brought with them to the hospital, and even their smell. In some cases, the absence rather than presence of certain cues is also important. At the same time, a doctor needs to discard irrelevant information, then put all the pieces together before they can treat the patient. 2: Orient “Orientation isn’t just a state you’re in; it’s a process. You’re always orienting.” John Boyd The second stage of the OODA Loop, orient, is less intuitive than the other steps. However, it’s worth taking the effort to understand it rather than skipping it. Boyd referred to it as the schwerpunkt, meaning “the main emphasis” in German. To orient yourself is to recognize any barriers that might interfere with the other parts of the OODA Loop. Orientation means connecting yourself with reality and seeing the world as it really is, as free as possible from the influence of cognitive biases and shortcuts. You can give yourself an edge over the competition by making sure you always orient before making a decision, instead of just jumping in. Boyd maintained that properly orienting yourself can be enough to overcome an initial disadvantage, such as fewer resources or less information, to outsmart an opponent. He identified the following four main barriers that impede our view of objective information: Our cultural traditions – we don’t realize how much of what we consider universal behavior is actually culturally prescribed Our genetic heritage – we all have certain constraints Our ability to analyze and synthesize – if we haven’t practiced and developed our thinking skills, we tend to fall back on old habits The influx of new information – it is hard to make sense of observations when the situation keeps changing Prior to Charlie Munger’s popularization of the concept of building a toolbox of mental models, Boyd advocated a similar approach for pilots to help them better navigate the orient stage of the OODA Loop. He recommended a process of “deductive destruction”: paying attention to your own assumptions and biases, then finding fundamental mental models to replace them. Similar to using a decision journal, deductive destruction ensures you always learn from past mistakes and don’t keep on repeating them. In one talk, Boyd employed a brilliant metaphor for developing a latticework of mental models. He compared it to building a snowmobile, a vehicle comprising elements of several different devices, such as the caterpillar treads of a tank, skis, the outboard motor of a boat, and the handlebars of a bike. Individually, each of these items isn’t enough to move you around. But combined they create a functional vehicle. As Boyd put it: A loser is someone individual or group who cannot build snowmobiles when facing uncertainty and unpredictable change; whereas a winner is someone individual or group who can build snowmobiles, and employ them in an appropriate fashion, when facing uncertainty and unpredictable change. To orient yourself, you have to build a metaphorical snowmobile by combining practical concepts from different disciplines. For more on mental models, we literally wrote the book on them. Although Boyd is regarded as a military strategist, he didn’t confine himself to any particular discipline. His theories encompass ideas drawn from various disciplines, including mathematical logic, biology, psychology, thermodynamics, game theory, anthropology, and physics. Boyd described his approach as a “scheme of pulling things apart analysis and putting them back together synthesis in new combinations to find how apparently unrelated ideas and actions can be related to one another.” 3: Decide There are no surprises here. The previous two steps provide the groundwork you need to make an informed decision. If there are multiple options at hand, you need to use your observation and orientation to select one. Boyd cautioned against first-conclusion bias, explaining that we cannot keep making the same decision again and again. This part of the loop needs to be flexible and open to Bayesian updating. In some of his notes, Boyd described this step as the hypothesis stage. The implication is that we should test the decisions we make at this point in the loop, spotting their flaws and including any issues in future observation stages 4: Act There’s a difference between making decisions and enacting decisions. Once you make up your mind, it’s time to take action. By taking action, you test your decision out. The results will hopefully indicate whether it was a good one or not, providing information for when you cycle back to the first part of the OODA Loop and begin observing anew.  Why the OODA Loop works “The ability to operate at a faster tempo or rhythm than an adversary enables one to fold the adversary back inside himself so that he can neither appreciate nor keep up with what is going on. He will become disoriented and confused.” John Boyd We’ve identified three key benefits of using the OODA Loop. 1: Deliberate speed As we’ve established, fighter pilots have to make many decisions in fast succession. They don’t have time to list pros and cons or to consider every available avenue. Once the OODA Loop becomes part of their mental toolboxes, they should be able to cycle through it in a matter of seconds. Speed is a crucial element of military decision-making. Using the OODA Loop in everyday life, we probably have a little more time than a fighter pilot would. But Boyd emphasized the value of being decisive, taking initiative, and staying autonomous. These are universal assets and apply to many situations. 2: Comfort with uncertainty There’s no such thing as total certainty. If you’re making a decision at all, it’s because something is uncertain. But uncertainty does not always have to equate to risk. A fighter pilot is in a precarious situation, one in which where there will be gaps in their knowledge. They cannot read the mind of the opponent and might have incomplete information about the weather conditions and surrounding environment. They can, however, take into account key factors such as the opponent’s type of airplane and what their maneuvers reveal about their intentions and level of training. If the opponent uses an unexpected strategy, is equipped with a new type of weapon or airplane, or behaves in an irrational way, the pilot must accept the accompanying uncertainty. However, Boyd belabored the point that uncertainty is irrelevant if we have the right filters in place. If we can’t cope with uncertainty, we end up stuck in the observation stage. This sometimes happens when we know we need to make a decision, but we’re scared of getting it wrong. So we keep on reading books and articles, asking people for advice, listening to podcasts, and so on. Acting under uncertainty is unavoidable. If we do have the right filters, we can factor uncertainty into the observation stage. We can leave a margin of error. We can recognize the elements that are within our control and those that are not. In presentations, Boyd referred to three key principles to support his ideas: Gdel’s theorems, Heisenberg’s Uncertainty Principle, and the Second Law of Thermodynamics. Of course, we’re using these principles in a different way from their initial purpose and in a simplified, non-literal form. Gdel’s theorems indicate any mental model we have of reality will omit certain information and that Bayesian updating must be used to bring it in line with reality. For fighter pilots, their understanding of what is going on during a battle will always have gaps. Identifying this fundamental uncertainty gives it less power over us. The second concept Boyd referred to is Heisenberg’s Uncertainty Principle. In its simplest form, this principle describes the limit of the precision with which pairs of physical properties can be understood. We cannot know the position and the velocity of a body at the same time. We can know either its location or its speed, but not both. Boyd moved the concept of the Uncertainty Principle from particles to planes. If a pilot focuses too hard on where an enemy plane is, they will lose track of where it is going and vice versa. Trying harder to track the two variables will actually lead to more inaccuracy! Finally, Boyd made use of the Second Law of Thermodynamics. In a closed system, entropy always increases and everything moves towards chaos. Energy spreads out and becomes disorganized. Although Boyd’s notes do not specify the exact applications, his inference appears to be that a fighter pilot must be an open system or they will fail. They must draw “energy” information from outside themselves or the situation will become chaotic. They should also aim to cut their opponent off, forcing them to become a closed system. 3: Unpredictability When you act fast enough, other people view you as unpredictable. They can’t figure out the logic behind your decisions. Boyd recommended making unpredictable changes in speed and direction, writing, “We should operate at a faster tempo than our adversaries or inside our adversaries’ time scales.Such activity will make us appear ambiguous non predictable and thereby generate confusion and disorder among our adversaries.” He even helped design planes that were better equipped to make those unpredictable changes. For the same reason that you can’t run the same play seventy times in a football game, rigid military strategies often become useless after a few uses, or even one iteration, as opponents learn to recognize and counter them. The OODA Loop can be endlessly used because it is a formless strategy, unconnected to any particular maneuvers. We know that Boyd was influenced by Sun Tzu he owned seven thoroughly annotated copies of The Art of War and drew many ideas from the ancient strategist. Sun Tzu depicts war as a game of deception where the best strategy is that which an opponent cannot preempt.  Forty Second Boyd “Let your plans be dark and impenetrable as night, and when you move, fall like a thunderbolt.” Sun Tzu Boyd was no armchair strategist. He developed his ideas through extensive experience as a fighter pilot. His nickname “Forty Second Boyd” speaks to his expertise: Boyd could win any aerial battle in less than forty seconds. In a tribute written after Boyd’s death, General C.C. Krulak described him as “a towering intellect who made unsurpassed contributions to the American art of war. Indeed, he was one of the central architects of the reform of military thought.From John Boyd we learned about competitive decision-making on the battlefieldcompressing time, using time as an ally.” Reflecting Robert Greene’s maxim that everything is material, Boyd spent his career observing people and organizations. How do they adapt to changeable environments in conflicts, business, and other situations? Over time, he deduced that these situations are characterized by uncertainty. Dogmatic, rigid theories are unsuitable for chaotic situations. Rather than trying to rise through the military ranks, Boyd focused on using his position as a colonel to compose a theory of the universal logic of war. Boyd was known to ask his mentees the poignant question, “Do you want to be someone, or do you want to do something?” In his own life, he certainly focused on the latter path and, as a result, left us ideas with tangible value. The OODA Loop is just one of many. Boyd developed the OODA Loop with fighter pilots in mind, but like all good mental models, it works in other fields beyond combat. It’s used in intelligence agencies. It’s used by lawyers, doctors, businesspeople, politicians, law enforcement, marketers, athletes, coaches, and more. If you have to work fast, you might want to learn a thing or two from fighter pilots. For them, a split-second of hesitation can cost them their lives. As anyone who has ever watched Top Gun knows, pilots have a lot of decisions and processes to juggle when they’re in dogfights close-range aerial battles. Pilots move at high speeds and need to avoid enemies while tracking them and keeping a contextual knowledge of objectives, terrains, fuel, and other key variables. And as any pilot who has been in one will tell you, dogfights are nasty. No one wants them to last longer than necessary because every second increases the risk of something going wrong. Pilots have to rely on their decision-making skillsthey can’t just follow a schedule or to-do list to know what to do.  Applying the OODA Loop “We can’t just look at our own personal experiences or use the same mental recipes over and over again; we’ve got to look at other disciplines and activities and relate or connect them to what we know from our experiences and the strategic world we live in.” John Boyd In sports, there is an adage that carries over to business quite well: “Speed kills.” If you are able to be nimble, assess the ever-changing environment, and adapt quickly, you’ll always carry the advantage over any opponents. Start applying the OODA Loop to your day-to-day decisions and watch what happens. You’ll start to notice things that you would have been oblivious to before. Before jumping to your first conclusion, you’ll pause to consider your biases, take in additional information, and be more thoughtful of consequences. As with anything you practice, if you do it right, the more you do it, the better you’ll get. You’ll start making better decisions to your full potential. You’ll see more rapid progress. And as John Boyd would prescribe, you’ll start to do something in your life, and not just be somebody.  We hope you’ve enjoyed our three week exploration of perspectives on decision making. We think there is value in juxtaposing different ideas to help us learn. Stay tuned for more topic specific series in the future.",
			"tokens": 3567,
			"chunks": [
				{
					"article_title": "The OODA Loop: How Fighter Pilots Make Fast and Accurate Decisions",
					"article_url": "https://fs.blog/ooda-loop/",
					"content": "The OODA Loop is a four-step process for making effective decisions in high-stakes situations. It involves collecting relevant information, recognizing potential biases, deciding, and acting, then repeating the process with new information. Read on to learn how to use the OODA Loop. When we want to learn how to make rational decisions under pressure, it can be helpful to look at the techniques people use in extreme situations. If they work in the most drastic scenarios, they have a good chance of being effective in more typical ones. Because they’re developed and tested in the relentless laboratory of conflict, military mental models have practical applications far beyond their original context. If they didn’t work, they would be quickly replaced by alternatives. Military leaders and strategists invest a great deal of time and resources into developing decision-making processes. One such military mental model is the OODA Loop. Developed by strategist and U.S. ",
					"content_token": 192,
					"embedding": []
				},
				{
					"article_title": "The OODA Loop: How Fighter Pilots Make Fast and Accurate Decisions",
					"article_url": "https://fs.blog/ooda-loop/",
					"content": "Air Force Colonel John Boyd, the OODA Loop is a practical concept designed to function as the foundation of rational thinking in confusing or chaotic situations. “OODA” stands for “Observe, Orient, Decide, and Act.” “What is strategy? A mental tapestry of changing intentions for harmonizing and focusing our efforts as a basis for realizing some aim or purpose in an unfolding and often unforeseen world of many bewildering events and many contending interests.” John Boyd  The four parts of the OODA Loop Let’s break down the four parts of the OODA Loop and see how they fit together. Don’t forget the “Loop” part. The process is intended to be repeated again and again until a conflict finishes. Each repetition provides more information to inform the next one, making it a feedback loop. ",
					"content_token": 183,
					"embedding": []
				},
				{
					"article_title": "The OODA Loop: How Fighter Pilots Make Fast and Accurate Decisions",
					"article_url": "https://fs.blog/ooda-loop/",
					"content": "1: Observe Step one is to observe the situation with the aim of building the most accurate and comprehensive picture of it possible. For example, a fighter pilot might consider the following factors in a broad, fluid way: What is immediately affecting me? What is affecting my opponent? What could affect either of us later on? Can I make any predictions? How accurate were my prior predictions? Information alone is insufficient. The observation stage requires converting information into an overall picture with overarching meaning that places it in context. A particularly vital skill is the capacity to identify which information is just noise and irrelevant for the current decision. If you want to make good decisions, you need to master the art of observing your environment. For a fighter pilot, that involves factors like the weather conditions and what their opponent is doing. In your workplace, that might include factors like regulations, available resources, relationships with other people, and your current state of mind. ",
					"content_token": 188,
					"embedding": []
				},
				{
					"article_title": "The OODA Loop: How Fighter Pilots Make Fast and Accurate Decisions",
					"article_url": "https://fs.blog/ooda-loop/",
					"content": "To give an example, consider a doctor meeting with a patient in the emergency room for the first time to identify how to treat them. Their first priority is figuring out what information they need to collect, then collecting it. They might check the patient’s records, ask other staff about the admission, ask the patient questions, check vital signs such as blood pressure, and order particular diagnostic tests. Doctors learn to pick up on subtle cues that can be telling of particular conditions, such as a patient’s speech patterns, body language, what they’ve brought with them to the hospital, and even their smell. In some cases, the absence rather than presence of certain cues is also important. At the same time, a doctor needs to discard irrelevant information, then put all the pieces together before they can treat the patient. 2: Orient “Orientation isn’t just a state you’re in; it’s a process. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "The OODA Loop: How Fighter Pilots Make Fast and Accurate Decisions",
					"article_url": "https://fs.blog/ooda-loop/",
					"content": "You’re always orienting.” John Boyd The second stage of the OODA Loop, orient, is less intuitive than the other steps. However, it’s worth taking the effort to understand it rather than skipping it. Boyd referred to it as the schwerpunkt, meaning “the main emphasis” in German. To orient yourself is to recognize any barriers that might interfere with the other parts of the OODA Loop. Orientation means connecting yourself with reality and seeing the world as it really is, as free as possible from the influence of cognitive biases and shortcuts. You can give yourself an edge over the competition by making sure you always orient before making a decision, instead of just jumping in. Boyd maintained that properly orienting yourself can be enough to overcome an initial disadvantage, such as fewer resources or less information, to outsmart an opponent. ",
					"content_token": 180,
					"embedding": []
				},
				{
					"article_title": "The OODA Loop: How Fighter Pilots Make Fast and Accurate Decisions",
					"article_url": "https://fs.blog/ooda-loop/",
					"content": "He identified the following four main barriers that impede our view of objective information: Our cultural traditions – we don’t realize how much of what we consider universal behavior is actually culturally prescribed Our genetic heritage – we all have certain constraints Our ability to analyze and synthesize – if we haven’t practiced and developed our thinking skills, we tend to fall back on old habits The influx of new information – it is hard to make sense of observations when the situation keeps changing Prior to Charlie Munger’s popularization of the concept of building a toolbox of mental models, Boyd advocated a similar approach for pilots to help them better navigate the orient stage of the OODA Loop. He recommended a process of “deductive destruction”: paying attention to your own assumptions and biases, then finding fundamental mental models to replace them. Similar to using a decision journal, deductive destruction ensures you always learn from past mistakes and don’t keep on repeating them. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "The OODA Loop: How Fighter Pilots Make Fast and Accurate Decisions",
					"article_url": "https://fs.blog/ooda-loop/",
					"content": "In one talk, Boyd employed a brilliant metaphor for developing a latticework of mental models. He compared it to building a snowmobile, a vehicle comprising elements of several different devices, such as the caterpillar treads of a tank, skis, the outboard motor of a boat, and the handlebars of a bike. Individually, each of these items isn’t enough to move you around. But combined they create a functional vehicle. As Boyd put it: A loser is someone individual or group who cannot build snowmobiles when facing uncertainty and unpredictable change; whereas a winner is someone individual or group who can build snowmobiles, and employ them in an appropriate fashion, when facing uncertainty and unpredictable change. To orient yourself, you have to build a metaphorical snowmobile by combining practical concepts from different disciplines. For more on mental models, we literally wrote the book on them. ",
					"content_token": 183,
					"embedding": []
				},
				{
					"article_title": "The OODA Loop: How Fighter Pilots Make Fast and Accurate Decisions",
					"article_url": "https://fs.blog/ooda-loop/",
					"content": "Although Boyd is regarded as a military strategist, he didn’t confine himself to any particular discipline. His theories encompass ideas drawn from various disciplines, including mathematical logic, biology, psychology, thermodynamics, game theory, anthropology, and physics. Boyd described his approach as a “scheme of pulling things apart analysis and putting them back together synthesis in new combinations to find how apparently unrelated ideas and actions can be related to one another.” 3: Decide There are no surprises here. The previous two steps provide the groundwork you need to make an informed decision. If there are multiple options at hand, you need to use your observation and orientation to select one. Boyd cautioned against first-conclusion bias, explaining that we cannot keep making the same decision again and again. This part of the loop needs to be flexible and open to Bayesian updating. In some of his notes, Boyd described this step as the hypothesis stage. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "The OODA Loop: How Fighter Pilots Make Fast and Accurate Decisions",
					"article_url": "https://fs.blog/ooda-loop/",
					"content": "The implication is that we should test the decisions we make at this point in the loop, spotting their flaws and including any issues in future observation stages 4: Act There’s a difference between making decisions and enacting decisions. Once you make up your mind, it’s time to take action. By taking action, you test your decision out. The results will hopefully indicate whether it was a good one or not, providing information for when you cycle back to the first part of the OODA Loop and begin observing anew.  Why the OODA Loop works “The ability to operate at a faster tempo or rhythm than an adversary enables one to fold the adversary back inside himself so that he can neither appreciate nor keep up with what is going on. He will become disoriented and confused.” John Boyd We’ve identified three key benefits of using the OODA Loop. ",
					"content_token": 184,
					"embedding": []
				},
				{
					"article_title": "The OODA Loop: How Fighter Pilots Make Fast and Accurate Decisions",
					"article_url": "https://fs.blog/ooda-loop/",
					"content": "1: Deliberate speed As we’ve established, fighter pilots have to make many decisions in fast succession. They don’t have time to list pros and cons or to consider every available avenue. Once the OODA Loop becomes part of their mental toolboxes, they should be able to cycle through it in a matter of seconds. Speed is a crucial element of military decision-making. Using the OODA Loop in everyday life, we probably have a little more time than a fighter pilot would. But Boyd emphasized the value of being decisive, taking initiative, and staying autonomous. These are universal assets and apply to many situations. 2: Comfort with uncertainty There’s no such thing as total certainty. If you’re making a decision at all, it’s because something is uncertain. But uncertainty does not always have to equate to risk. A fighter pilot is in a precarious situation, one in which where there will be gaps in their knowledge. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "The OODA Loop: How Fighter Pilots Make Fast and Accurate Decisions",
					"article_url": "https://fs.blog/ooda-loop/",
					"content": "They cannot read the mind of the opponent and might have incomplete information about the weather conditions and surrounding environment. They can, however, take into account key factors such as the opponent’s type of airplane and what their maneuvers reveal about their intentions and level of training. If the opponent uses an unexpected strategy, is equipped with a new type of weapon or airplane, or behaves in an irrational way, the pilot must accept the accompanying uncertainty. However, Boyd belabored the point that uncertainty is irrelevant if we have the right filters in place. If we can’t cope with uncertainty, we end up stuck in the observation stage. This sometimes happens when we know we need to make a decision, but we’re scared of getting it wrong. So we keep on reading books and articles, asking people for advice, listening to podcasts, and so on. Acting under uncertainty is unavoidable. If we do have the right filters, we can factor uncertainty into the observation stage. ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "The OODA Loop: How Fighter Pilots Make Fast and Accurate Decisions",
					"article_url": "https://fs.blog/ooda-loop/",
					"content": "We can leave a margin of error. We can recognize the elements that are within our control and those that are not. In presentations, Boyd referred to three key principles to support his ideas: Gdel’s theorems, Heisenberg’s Uncertainty Principle, and the Second Law of Thermodynamics. Of course, we’re using these principles in a different way from their initial purpose and in a simplified, non-literal form. Gdel’s theorems indicate any mental model we have of reality will omit certain information and that Bayesian updating must be used to bring it in line with reality. For fighter pilots, their understanding of what is going on during a battle will always have gaps. Identifying this fundamental uncertainty gives it less power over us. The second concept Boyd referred to is Heisenberg’s Uncertainty Principle. ",
					"content_token": 182,
					"embedding": []
				},
				{
					"article_title": "The OODA Loop: How Fighter Pilots Make Fast and Accurate Decisions",
					"article_url": "https://fs.blog/ooda-loop/",
					"content": "In its simplest form, this principle describes the limit of the precision with which pairs of physical properties can be understood. We cannot know the position and the velocity of a body at the same time. We can know either its location or its speed, but not both. Boyd moved the concept of the Uncertainty Principle from particles to planes. If a pilot focuses too hard on where an enemy plane is, they will lose track of where it is going and vice versa. Trying harder to track the two variables will actually lead to more inaccuracy! Finally, Boyd made use of the Second Law of Thermodynamics. In a closed system, entropy always increases and everything moves towards chaos. Energy spreads out and becomes disorganized. Although Boyd’s notes do not specify the exact applications, his inference appears to be that a fighter pilot must be an open system or they will fail. They must draw “energy” information from outside themselves or the situation will become chaotic. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "The OODA Loop: How Fighter Pilots Make Fast and Accurate Decisions",
					"article_url": "https://fs.blog/ooda-loop/",
					"content": "They should also aim to cut their opponent off, forcing them to become a closed system. 3: Unpredictability When you act fast enough, other people view you as unpredictable. They can’t figure out the logic behind your decisions. Boyd recommended making unpredictable changes in speed and direction, writing, “We should operate at a faster tempo than our adversaries or inside our adversaries’ time scales.Such activity will make us appear ambiguous non predictable and thereby generate confusion and disorder among our adversaries.” He even helped design planes that were better equipped to make those unpredictable changes. For the same reason that you can’t run the same play seventy times in a football game, rigid military strategies often become useless after a few uses, or even one iteration, as opponents learn to recognize and counter them. The OODA Loop can be endlessly used because it is a formless strategy, unconnected to any particular maneuvers. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "The OODA Loop: How Fighter Pilots Make Fast and Accurate Decisions",
					"article_url": "https://fs.blog/ooda-loop/",
					"content": "We know that Boyd was influenced by Sun Tzu he owned seven thoroughly annotated copies of The Art of War and drew many ideas from the ancient strategist. Sun Tzu depicts war as a game of deception where the best strategy is that which an opponent cannot preempt.  Forty Second Boyd “Let your plans be dark and impenetrable as night, and when you move, fall like a thunderbolt.” Sun Tzu Boyd was no armchair strategist. He developed his ideas through extensive experience as a fighter pilot. His nickname “Forty Second Boyd” speaks to his expertise: Boyd could win any aerial battle in less than forty seconds. In a tribute written after Boyd’s death, General C.C. Krulak described him as “a towering intellect who made unsurpassed contributions to the American art of war. ",
					"content_token": 175,
					"embedding": []
				},
				{
					"article_title": "The OODA Loop: How Fighter Pilots Make Fast and Accurate Decisions",
					"article_url": "https://fs.blog/ooda-loop/",
					"content": "Indeed, he was one of the central architects of the reform of military thought.From John Boyd we learned about competitive decision-making on the battlefieldcompressing time, using time as an ally.” Reflecting Robert Greene’s maxim that everything is material, Boyd spent his career observing people and organizations. How do they adapt to changeable environments in conflicts, business, and other situations? Over time, he deduced that these situations are characterized by uncertainty. Dogmatic, rigid theories are unsuitable for chaotic situations. Rather than trying to rise through the military ranks, Boyd focused on using his position as a colonel to compose a theory of the universal logic of war. Boyd was known to ask his mentees the poignant question, “Do you want to be someone, or do you want to do something?” In his own life, he certainly focused on the latter path and, as a result, left us ideas with tangible value. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "The OODA Loop: How Fighter Pilots Make Fast and Accurate Decisions",
					"article_url": "https://fs.blog/ooda-loop/",
					"content": "The OODA Loop is just one of many. Boyd developed the OODA Loop with fighter pilots in mind, but like all good mental models, it works in other fields beyond combat. It’s used in intelligence agencies. It’s used by lawyers, doctors, businesspeople, politicians, law enforcement, marketers, athletes, coaches, and more. If you have to work fast, you might want to learn a thing or two from fighter pilots. For them, a split-second of hesitation can cost them their lives. As anyone who has ever watched Top Gun knows, pilots have a lot of decisions and processes to juggle when they’re in dogfights close-range aerial battles. Pilots move at high speeds and need to avoid enemies while tracking them and keeping a contextual knowledge of objectives, terrains, fuel, and other key variables. And as any pilot who has been in one will tell you, dogfights are nasty. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "The OODA Loop: How Fighter Pilots Make Fast and Accurate Decisions",
					"article_url": "https://fs.blog/ooda-loop/",
					"content": "No one wants them to last longer than necessary because every second increases the risk of something going wrong. Pilots have to rely on their decision-making skillsthey can’t just follow a schedule or to-do list to know what to do.  Applying the OODA Loop “We can’t just look at our own personal experiences or use the same mental recipes over and over again; we’ve got to look at other disciplines and activities and relate or connect them to what we know from our experiences and the strategic world we live in.” John Boyd In sports, there is an adage that carries over to business quite well: “Speed kills.” If you are able to be nimble, assess the ever-changing environment, and adapt quickly, you’ll always carry the advantage over any opponents. Start applying the OODA Loop to your day-to-day decisions and watch what happens. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "The OODA Loop: How Fighter Pilots Make Fast and Accurate Decisions",
					"article_url": "https://fs.blog/ooda-loop/",
					"content": "You’ll start to notice things that you would have been oblivious to before. Before jumping to your first conclusion, you’ll pause to consider your biases, take in additional information, and be more thoughtful of consequences. As with anything you practice, if you do it right, the more you do it, the better you’ll get. You’ll start making better decisions to your full potential. You’ll see more rapid progress. And as John Boyd would prescribe, you’ll start to do something in your life, and not just be somebody.  We hope you’ve enjoyed our three week exploration of perspectives on decision making. We think there is value in juxtaposing different ideas to help us learn. Stay tuned for more topic specific series in the future.",
					"content_token": 163,
					"embedding": []
				}
			]
		},
		{
			"title": "Avoiding Bad Decisions",
			"url": "https://fs.blog/avoid-bad-decisions/",
			"content": "Sometimes success is just about avoiding failure. At FS, we help people make better decisions without needing to rely on getting lucky. One aspect of decision-making that’s rarely talked about is how to avoid making bad decisions. Here are five of the biggest reasons we make bad decisions.  1. We’re unintentionally stupid We like to think that we can rationally process information like a computer, but we can’t. Cognitive biases explain why we made a bad decision but rarely help us avoid them in the first place. It’s better to focus on these warning signs that signal something is about to go wrong. Warning signs you’re about to unintentionally do something stupid: You’re tired, emotional, in a rush, or distracted. You’re operating in a group or working with an authority figure. The rule: Never make important decisions when you’re tired, emotional, distracted, or in a rush. 2. We solve the wrong problem The first person to state the problem rarely has the best insight into the problem. Once a problem is thrown out on the table, however, our type-A problem-solving nature kicks in and forgets to first ask if we’re solving the right problem. Warning signs you’re solving the wrong problem: You let someone else define the problem for you. You’re far away from the problem. You’re thinking about the problem at only one level or through a narrow lens. The rule: Never let anyone define the problem for you. 3. We use incorrect or insufficient information We like to believe that people tell us the truth. We like to believe the people we talk to understand what they are talking about. We like to believe that we have all the information. Warning signs you have incorrect or insufficient information: You’re speaking to someone who spoke to someone who spoke to someone. Someone will get in trouble when the truth comes out. You’re reading about it in the news. The rule: Seek out information from someone as close to the source as possible, because they’ve earned their knowledge and have an understanding that you don’t. When information is filtered and it often is, first consider the incentives involved and then think of the proximity to earned knowledge. 4. We fail to learn You know the person that sits beside you at work that has twenty years of experience but keeps making the same mistakes over and over? They don’t have twenty years of experiencethey have one year of experience repeated twenty times. If you can’t learn, you can’t get better. Most of us can observe and react accordingly. But to truly learn from our experiences, we must reflect on our reactions. Reflection has to be part of your process, not something you might do if you have time. Don’t use the excuse of being too busy or get too invested in protecting your ego. In short, we can’t learn from experience without reflection. Only reflection allows us to distill experience into something we can learn from to make better decisions in the future. Warning signs you’re not learning: You’re too busy to reflect. You don’t keep track of your decisions. You can’t calibrate your own decision-making. The rule: Be less busy. Keep a learning journal. Reflect every day. 5. We focus on optics over outcomes Our evolutionary programming conditions us to do what’s easy over what’s right. After all, it’s often easier to signal being virtuous than to actually be virtuous. Warning signs you’re focused on optics: You’re thinking about how you’ll defend your decision. You’re knowingly choosing what’s defendable over what’s right. You’d make a different decision if you owned the company. You catch yourself saying this is what your boss would want. The rule: Act as you would want an employee to act if you owned the company.  Avoiding bad decisions is just as important as making good ones. Knowing the warning signs and having a set of rules for your decision-making process limits the amount of luck you need to get good outcomes.",
			"tokens": 874,
			"chunks": [
				{
					"article_title": "Avoiding Bad Decisions",
					"article_url": "https://fs.blog/avoid-bad-decisions/",
					"content": "Sometimes success is just about avoiding failure. At FS, we help people make better decisions without needing to rely on getting lucky. One aspect of decision-making that’s rarely talked about is how to avoid making bad decisions. Here are five of the biggest reasons we make bad decisions.  1. We’re unintentionally stupid We like to think that we can rationally process information like a computer, but we can’t. Cognitive biases explain why we made a bad decision but rarely help us avoid them in the first place. It’s better to focus on these warning signs that signal something is about to go wrong. Warning signs you’re about to unintentionally do something stupid: You’re tired, emotional, in a rush, or distracted. You’re operating in a group or working with an authority figure. The rule: Never make important decisions when you’re tired, emotional, distracted, or in a rush. 2. ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "Avoiding Bad Decisions",
					"article_url": "https://fs.blog/avoid-bad-decisions/",
					"content": "We solve the wrong problem The first person to state the problem rarely has the best insight into the problem. Once a problem is thrown out on the table, however, our type-A problem-solving nature kicks in and forgets to first ask if we’re solving the right problem. Warning signs you’re solving the wrong problem: You let someone else define the problem for you. You’re far away from the problem. You’re thinking about the problem at only one level or through a narrow lens. The rule: Never let anyone define the problem for you. 3. We use incorrect or insufficient information We like to believe that people tell us the truth. We like to believe the people we talk to understand what they are talking about. We like to believe that we have all the information. Warning signs you have incorrect or insufficient information: You’re speaking to someone who spoke to someone who spoke to someone. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "Avoiding Bad Decisions",
					"article_url": "https://fs.blog/avoid-bad-decisions/",
					"content": "Someone will get in trouble when the truth comes out. You’re reading about it in the news. The rule: Seek out information from someone as close to the source as possible, because they’ve earned their knowledge and have an understanding that you don’t. When information is filtered and it often is, first consider the incentives involved and then think of the proximity to earned knowledge. 4. We fail to learn You know the person that sits beside you at work that has twenty years of experience but keeps making the same mistakes over and over? They don’t have twenty years of experiencethey have one year of experience repeated twenty times. If you can’t learn, you can’t get better. Most of us can observe and react accordingly. But to truly learn from our experiences, we must reflect on our reactions. Reflection has to be part of your process, not something you might do if you have time. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "Avoiding Bad Decisions",
					"article_url": "https://fs.blog/avoid-bad-decisions/",
					"content": "Don’t use the excuse of being too busy or get too invested in protecting your ego. In short, we can’t learn from experience without reflection. Only reflection allows us to distill experience into something we can learn from to make better decisions in the future. Warning signs you’re not learning: You’re too busy to reflect. You don’t keep track of your decisions. You can’t calibrate your own decision-making. The rule: Be less busy. Keep a learning journal. Reflect every day. 5. We focus on optics over outcomes Our evolutionary programming conditions us to do what’s easy over what’s right. After all, it’s often easier to signal being virtuous than to actually be virtuous. Warning signs you’re focused on optics: You’re thinking about how you’ll defend your decision. ",
					"content_token": 186,
					"embedding": []
				},
				{
					"article_title": "Avoiding Bad Decisions",
					"article_url": "https://fs.blog/avoid-bad-decisions/",
					"content": "You’re knowingly choosing what’s defendable over what’s right. You’d make a different decision if you owned the company. You catch yourself saying this is what your boss would want. The rule: Act as you would want an employee to act if you owned the company.  Avoiding bad decisions is just as important as making good ones. Knowing the warning signs and having a set of rules for your decision-making process limits the amount of luck you need to get good outcomes.",
					"content_token": 105,
					"embedding": []
				}
			]
		},
		{
			"title": "Your Thinking Rate Is Fixed",
			"url": "https://fs.blog/thinking-rate-fixed/",
			"content": "You can’t force yourself to think faster. If you try, you’re likely to end up making much worse decisions. Here’s how to improve the actual quality of your decisions instead of chasing hacks to speed them up. If you’re a knowledge worker, as an ever-growing proportion of people are, the product of your job is decisions. Much of what you do day to day consists of trying to make the right choices among competing options, meaning you have to process large amounts of information, discern what’s likely to be most effective for moving towards your desired goal, and try to anticipate potential problems further down the line. And all the while, you’re operating in an environment of uncertainty where anything could happen tomorrow. When the product of your job is your decisions, you might find yourself wanting to be able to make more decisions more quickly so you can be more productive overall. Chasing speed is a flawed approach. Because decisionsat least good onesdon’t come out of thin air. They’re supported by a lot of thinking. While experience and education can grant you the pattern-matching abilities to make some kinds of decisions using intuition, you’re still going to run into decisions that require you to sit and consider the problem from multiple angles. You’re still going to need to schedule time to do nothing but think. Otherwise making more decisions will make you less productive overall, not more, because your decisions will suck. Here’s a secret that might sound obvious but can actually transform the way you work: you can’t force yourself to think faster. Our brains just don’t work that way. The rate at which you make mental discernments is fixed. Sure, you can develop your ability to do certain kinds of thinking faster over time. You can learn new methods for decision-making. You can develop your mental models. You can build your ability to focus. But if you’re trying to speed up your thinking so you can make an extra few decisions today, forget it.  Beyond the “hurry up” culture Management consultant Tom DeMarco writes in Slack: Getting Past Burnout, Busywork, and the Myth of Total Efficiency that many knowledge work organizations have a culture where the dominant message at all times is to hurry up. Everyone is trying to work faster at all times, and they pressure everyone around them to work faster, too. No one wants to be perceived as a slacker. The result is that managers put pressure on their subordinates through a range of methods. DeMarco lists the following examples: “Turning the screws on delivery dates aggressive scheduling Loading on extra work Encouraging overtime Getting angry when disappointed Noting one subordinate’s extraordinary effort and praising it in the presence of others Being severe about anything other than superb performance Expecting great things of all your workers Railing against any apparent waste of time Setting an example yourself with the boss laboring so mightily there is certainly no time for anyone else to goof off Creating incentives to encourage desired behavior or results.” All of these things increase pressure in the work environment and repeatedly reinforce the “hurry up!” message. They make managers feel like they’re moving things along faster. That way if work isn’t getting done, it’s not their fault. But, DeMarco writes, they don’t lead to meaningful changes in behavior that make the whole organization more productive. Speeding up often results in poor decisions that create future problems. The reason more pressure doesn’t mean better productivity is that the rate at which we think is fixed. We can’t force ourselves to start making faster decisions right now just because we’re faced with an unrealistic deadline. DeMarco writes, “Think rate is fixed. No matter what you do, no matter how hard you try, you can’t pick up the pace of thinking.” If you’re doing a form of physical labor, you can move your body faster when under pressure. Of course, if it’s too fast, you’ll get injured or won’t be able to sustain it for long. If you’re a knowledge worker, you can’t pick up the pace of mental discriminations just because you’re under pressure. Chances are good that you’re already going as fast as you can. Because guess what? You can’t voluntarily slow down your thinking, either.  The limits of pressure Faced with added stress and unable to accelerate our brains instantaneously, we can do any of three things: “Eliminate wasted time. Defer tasks that are not on the critical path. Stay late.” Even if those might seem like positive things, they’re less advantageous than they appear at first glance. Their effects are marginal at best. The smarter and more qualified the knowledge worker, the less time they’re likely to be wasting anyway. Most people don’t enjoy wasting time. What you’re more likely to end up eliminating is valuable slack time for thinking. Deferring non-critical tasks doesn’t save any time overall, it just pushes work forwardsto the point where those tasks do become critical. Then something else gets deferred. Staying late might work once in a while. Again, though, its effects are limited. If we keep doing it night after night, we run out of energy, our personal lives suffer, and we make worse decisions as a result. None of the outcomes of increasing pressure result in more or better decisions. None of them speed up the rate at which people think. Even if an occasional, tactical increase in pressure whether it comes from the outside or we choose to apply it to ourselves can be effective, ongoing pressure increases are unsustainable in the long run.  Think rate is fixed It’s incredibly important to truly understand the point DeMarco makes in this part of Slack: the rate at which we process information is fixed. When you’re under pressure, the quality of your decisions plummets. You miss possible angles, you don’t think ahead, you do what makes sense now, you panic, and so on. Often, you make a snap judgment then grasp for whatever information will support it for the people you work with. You don’t have breathing room to stress-test your decisions. The clearer you can think, the better your decisions will be. Trying to think faster can only cloud your judgment. It doesn’t matter how many decisions you make if they’re not good ones. As DeMarco reiterates throughout the book, you can be efficient without being effective. Try making a list of the worst decisions you’ve made so far in your career. There’s a good chance most of them were made under intense pressure or without taking much time over them. At Farnam Street, we write a lot about how to make better decisions, and we share a lot of tools for better thinking. We made a whole course on decision-making. But none of these resources are meant to immediately accelerate your thinking. Many of them require you to actually slow down a whole lot and spend more time on your decisions. They improve the rate at which you can do certain kinds of thinking, but it’s not going to be an overnight process.  Upgrading your brain Some people read one of our articles or books about mental models and complain that it’s not an effective approach because it didn’t lead to an immediate improvement in their thinking. That’s unsurprising; our brains don’t work like that. Integrating new, better approaches takes a ton of time and repetition, just like developing any other skill. You have to keep on reflecting and making course corrections. At the end of the day, your brain is going to go where it wants to go. You’re going to think the way you think. However much you build awareness of how the world works and learn how to reorient, you’re still, to use Jonathan Haidt’s metaphor from The Righteous Mind, a tiny rider atop a gigantic elephant. None of us can reshape how we think overnight. Making good decisions is hard work. There’s a limit to how many decisions you can make in a day before you need a break. On top of that, many knowledge workers are in fields where the most relevant information has a short half-life. Making good decisions requires constant learning and verifying what you think you know. If you want to make better decisions, you need to do everything you can to reduce the pressure you’re under. You need to let your brain take whatever time it needs to think through the problem at hand. You need to get out of a reactive mode, recognize when you need to pause, and spend more time looking at problems. A good metaphor is installing an update to the operating system on your laptop. Would you rather install an update that fixes bugs and improves existing processes, or one that just makes everything run faster? Obviously, you’d prefer the former. The latter would just lead to more crashes. The same is true for updating your mental operating system. Stop trying to think faster. Start trying to think better.",
			"tokens": 1922,
			"chunks": [
				{
					"article_title": "Your Thinking Rate Is Fixed",
					"article_url": "https://fs.blog/thinking-rate-fixed/",
					"content": "You can’t force yourself to think faster. If you try, you’re likely to end up making much worse decisions. Here’s how to improve the actual quality of your decisions instead of chasing hacks to speed them up. If you’re a knowledge worker, as an ever-growing proportion of people are, the product of your job is decisions. Much of what you do day to day consists of trying to make the right choices among competing options, meaning you have to process large amounts of information, discern what’s likely to be most effective for moving towards your desired goal, and try to anticipate potential problems further down the line. And all the while, you’re operating in an environment of uncertainty where anything could happen tomorrow. When the product of your job is your decisions, you might find yourself wanting to be able to make more decisions more quickly so you can be more productive overall. Chasing speed is a flawed approach. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "Your Thinking Rate Is Fixed",
					"article_url": "https://fs.blog/thinking-rate-fixed/",
					"content": "Because decisionsat least good onesdon’t come out of thin air. They’re supported by a lot of thinking. While experience and education can grant you the pattern-matching abilities to make some kinds of decisions using intuition, you’re still going to run into decisions that require you to sit and consider the problem from multiple angles. You’re still going to need to schedule time to do nothing but think. Otherwise making more decisions will make you less productive overall, not more, because your decisions will suck. Here’s a secret that might sound obvious but can actually transform the way you work: you can’t force yourself to think faster. Our brains just don’t work that way. The rate at which you make mental discernments is fixed. Sure, you can develop your ability to do certain kinds of thinking faster over time. You can learn new methods for decision-making. You can develop your mental models. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "Your Thinking Rate Is Fixed",
					"article_url": "https://fs.blog/thinking-rate-fixed/",
					"content": "You can build your ability to focus. But if you’re trying to speed up your thinking so you can make an extra few decisions today, forget it.  Beyond the “hurry up” culture Management consultant Tom DeMarco writes in Slack: Getting Past Burnout, Busywork, and the Myth of Total Efficiency that many knowledge work organizations have a culture where the dominant message at all times is to hurry up. Everyone is trying to work faster at all times, and they pressure everyone around them to work faster, too. No one wants to be perceived as a slacker. The result is that managers put pressure on their subordinates through a range of methods. ",
					"content_token": 138,
					"embedding": []
				},
				{
					"article_title": "Your Thinking Rate Is Fixed",
					"article_url": "https://fs.blog/thinking-rate-fixed/",
					"content": "DeMarco lists the following examples: “Turning the screws on delivery dates aggressive scheduling Loading on extra work Encouraging overtime Getting angry when disappointed Noting one subordinate’s extraordinary effort and praising it in the presence of others Being severe about anything other than superb performance Expecting great things of all your workers Railing against any apparent waste of time Setting an example yourself with the boss laboring so mightily there is certainly no time for anyone else to goof off Creating incentives to encourage desired behavior or results.” All of these things increase pressure in the work environment and repeatedly reinforce the “hurry up!” message. They make managers feel like they’re moving things along faster. That way if work isn’t getting done, it’s not their fault. But, DeMarco writes, they don’t lead to meaningful changes in behavior that make the whole organization more productive. Speeding up often results in poor decisions that create future problems. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "Your Thinking Rate Is Fixed",
					"article_url": "https://fs.blog/thinking-rate-fixed/",
					"content": "The reason more pressure doesn’t mean better productivity is that the rate at which we think is fixed. We can’t force ourselves to start making faster decisions right now just because we’re faced with an unrealistic deadline. DeMarco writes, “Think rate is fixed. No matter what you do, no matter how hard you try, you can’t pick up the pace of thinking.” If you’re doing a form of physical labor, you can move your body faster when under pressure. Of course, if it’s too fast, you’ll get injured or won’t be able to sustain it for long. If you’re a knowledge worker, you can’t pick up the pace of mental discriminations just because you’re under pressure. Chances are good that you’re already going as fast as you can. ",
					"content_token": 187,
					"embedding": []
				},
				{
					"article_title": "Your Thinking Rate Is Fixed",
					"article_url": "https://fs.blog/thinking-rate-fixed/",
					"content": "Because guess what? You can’t voluntarily slow down your thinking, either.  The limits of pressure Faced with added stress and unable to accelerate our brains instantaneously, we can do any of three things: “Eliminate wasted time. Defer tasks that are not on the critical path. Stay late.” Even if those might seem like positive things, they’re less advantageous than they appear at first glance. Their effects are marginal at best. The smarter and more qualified the knowledge worker, the less time they’re likely to be wasting anyway. Most people don’t enjoy wasting time. What you’re more likely to end up eliminating is valuable slack time for thinking. Deferring non-critical tasks doesn’t save any time overall, it just pushes work forwardsto the point where those tasks do become critical. Then something else gets deferred. Staying late might work once in a while. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "Your Thinking Rate Is Fixed",
					"article_url": "https://fs.blog/thinking-rate-fixed/",
					"content": "Again, though, its effects are limited. If we keep doing it night after night, we run out of energy, our personal lives suffer, and we make worse decisions as a result. None of the outcomes of increasing pressure result in more or better decisions. None of them speed up the rate at which people think. Even if an occasional, tactical increase in pressure whether it comes from the outside or we choose to apply it to ourselves can be effective, ongoing pressure increases are unsustainable in the long run.  Think rate is fixed It’s incredibly important to truly understand the point DeMarco makes in this part of Slack: the rate at which we process information is fixed. When you’re under pressure, the quality of your decisions plummets. You miss possible angles, you don’t think ahead, you do what makes sense now, you panic, and so on. ",
					"content_token": 181,
					"embedding": []
				},
				{
					"article_title": "Your Thinking Rate Is Fixed",
					"article_url": "https://fs.blog/thinking-rate-fixed/",
					"content": "Often, you make a snap judgment then grasp for whatever information will support it for the people you work with. You don’t have breathing room to stress-test your decisions. The clearer you can think, the better your decisions will be. Trying to think faster can only cloud your judgment. It doesn’t matter how many decisions you make if they’re not good ones. As DeMarco reiterates throughout the book, you can be efficient without being effective. Try making a list of the worst decisions you’ve made so far in your career. There’s a good chance most of them were made under intense pressure or without taking much time over them. At Farnam Street, we write a lot about how to make better decisions, and we share a lot of tools for better thinking. We made a whole course on decision-making. But none of these resources are meant to immediately accelerate your thinking. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "Your Thinking Rate Is Fixed",
					"article_url": "https://fs.blog/thinking-rate-fixed/",
					"content": "Many of them require you to actually slow down a whole lot and spend more time on your decisions. They improve the rate at which you can do certain kinds of thinking, but it’s not going to be an overnight process.  Upgrading your brain Some people read one of our articles or books about mental models and complain that it’s not an effective approach because it didn’t lead to an immediate improvement in their thinking. That’s unsurprising; our brains don’t work like that. Integrating new, better approaches takes a ton of time and repetition, just like developing any other skill. You have to keep on reflecting and making course corrections. At the end of the day, your brain is going to go where it wants to go. You’re going to think the way you think. ",
					"content_token": 171,
					"embedding": []
				},
				{
					"article_title": "Your Thinking Rate Is Fixed",
					"article_url": "https://fs.blog/thinking-rate-fixed/",
					"content": "However much you build awareness of how the world works and learn how to reorient, you’re still, to use Jonathan Haidt’s metaphor from The Righteous Mind, a tiny rider atop a gigantic elephant. None of us can reshape how we think overnight. Making good decisions is hard work. There’s a limit to how many decisions you can make in a day before you need a break. On top of that, many knowledge workers are in fields where the most relevant information has a short half-life. Making good decisions requires constant learning and verifying what you think you know. If you want to make better decisions, you need to do everything you can to reduce the pressure you’re under. You need to let your brain take whatever time it needs to think through the problem at hand. You need to get out of a reactive mode, recognize when you need to pause, and spend more time looking at problems. ",
					"content_token": 194,
					"embedding": []
				},
				{
					"article_title": "Your Thinking Rate Is Fixed",
					"article_url": "https://fs.blog/thinking-rate-fixed/",
					"content": "A good metaphor is installing an update to the operating system on your laptop. Would you rather install an update that fixes bugs and improves existing processes, or one that just makes everything run faster? Obviously, you’d prefer the former. The latter would just lead to more crashes. The same is true for updating your mental operating system. Stop trying to think faster. Start trying to think better.",
					"content_token": 80,
					"embedding": []
				}
			]
		},
		{
			"title": "Solve Problems Before They Happen by Developing an “Inner Sense of Captaincy”",
			"url": "https://fs.blog/inner-sense-of-captaincy/",
			"content": "Too often we reward people who solve problems while ignoring those who prevent them in the first place. This incentivizes creating problems. According to poet David Whyte, the key to taking initiative and being proactive is viewing yourself as the captain of your own “voyage of work.” If we want to get away from glorifying those who run around putting out fires, we need to cultivate an organizational culture that empowers everyone to act responsibly at the first sign of smoke. How do we make that shift? We can start by looking at ourselves and how we consider the voyage that is our work. When do we feel fulfillment? Is it when we swoop in to save the day and everyone congratulates us? It’s worth asking why, if we think something is worth saving, we don’t put more effort into protecting it ahead of time. In Crossing the Unknown Sea, poet David Whyte suggests that we should view our work as a lifelong journey. In particular, he frames it as a sea voyage in which the greatest rewards lie in what we learn through the process, as opposed to the destination. Like a long sea voyage, the nature of our work is always changing. There are stormy days and sunny ones. There are days involving highs of delight and lows of disaster. All of this happens against the backdrop of events in our personal lives and the wider world with varying levels of influence. On a voyage, you need to look after your boat. There isn’t always time to solve problems after they happen. You need to learn how to preempt them or risk a much rougher journeyor even the end of it. Whyte refers to the practice of taking control of your voyage as “developing an inner sense of captaincy,” offering a metaphor we can all apply to our work. Developing an inner sense of captaincy is good for both us and the organizations we work in. We end up with more agency over our own lives, and our organizations waste fewer resources. Whyte’s story of how he learned this lesson highlights why that’s the case.  A moment of reckoning “Any life, and any life’s work, is a hidden journey, a secret code, deciphered in fits and starts. The details only given truth by the whole, and the whole dependent on the detail.” Shortly after graduating, Whyte landed a dream job working as a naturalist guide on board a ship in the Galapagos Islands. One morning, he awoke and could tell at once that the vessel had drifted from its anchorage during the night. Whyte leaped up to find the captain fast asleep and the boat close to crashing into a cliff. Taking control of it just in time, he managed to steer himself and the other passengers back to safetyright as the captain awoke. Though they were safe, he was profoundly shaken both by the near miss and the realization that their leader had failed. At first, Whyte’s reaction to the episode was to feel a smug contempt for the captain who had “slept through not only the anchor dragging but our long, long, nighttime drift.” The captain had failed to predict the problem or notice when it started. If Whyte hadn’t awakened, everyone on the ship could have died. But something soon changed in his perspective. Whyte knew the captain was new and far less familiar with that particular boat than himself and the other crew member. Every boat has its quirks, and experience counts for more than seniority when it comes to knowing them. He’d also felt sure the night before that they needed to put down a second anchor and knew they “should have dropped another anchor without consultation, as crews are wont to do when they do not want to argue with their captain. We should have woken too.” He writes that “this moment of reckoning under the lava cliff speaks to the many dangerous arrivals in a life of work and to the way we must continually forge our identities through our endeavors.” Whyte’s experience contains lessons with wide applicability for those of us on dry land. The idea of having an inner sense of captaincy means understanding the overarching goals of your work and being willing to make decisions that support them, even if something isn’t strictly your job or you might not get rewarded for it, or sometimes even if you don’t have permission. When you play the long game, you’re thinking of the whole voyage, not whether you’ll get a pat on the back today.  Skin in the game It’s all too easy to buy into the view that leaders have full responsibility for everything that happens, especially disasters. Sometimes in our work, when we’re not in a leadership position, we see a potential problem or an unnoticed existing one but choose not to take action. Instead, we stick to doing whatever we’ve been told to do because that feels safer. If it’s important, surely the person in charge will deal with it. If not, that’s their problem. Anyway, there’s already more than enough to do. Leaders give us a convenient scapegoat when things go wrong. However, when we assume all responsibility lies with them, we don’t learn from our mistakes. We don’t have “our own personal compass, a direction, a willingness to meet life unmediated by any cushioning parental presence.” At some point, things do become our problem. No leader can do everything and see everything. The more you rise within an organization, the more you need to take initiative. If a leader can’t rely on their subordinates to take action when they see a potential problem, everything will collapse. When we’ve been repeatedly denied agency by poor leadership and seen our efforts fall flat, we may sense we lack control. Taking action no longer feels natural. However, if we view our work as a voyage that helps us change and grow, it’s obvious why we need to overcome learned helplessness. We can’t abdicate all responsibility and blame other people for what we chose to ignore in the first place as Whyte puts it, “The captain was there in all his inherited and burdened glory and thus convenient for the blame”. By understanding how our work helps us change and grow, we develop skin in the game. On a ship, everyone is in it together. If something goes wrong, they’re all at risk. And it may not be easy or even possible to patch up a serious problem in the middle of the sea. As a result, everyone needs to pay attention and act on anything that seems amiss. Everyone needs to take responsibility for what happens, as Whyte goes on to detail: “No matter that the inherited world of the sea told us that the captain is the be-all and end-all of all responsibility, we had all contributed to the lapse, the inexcusable lapse. The edge is no place for apportioning blame. If we had merely touched that cliff, we would have been for the briny deep, crew and passengers alike. The undertow and the huge waves lacerating against that undercut, barnacle-encrusted fortress would have killed us all.” Having an inner sense of captaincy means viewing ourselves as the ones in charge of our voyage of work. It means not acting as if there are certain areas where we are incapacitated, or ignoring potential problems, just because someone else has a particular title.  Space and support to create success Developing an inner sense of captaincy is not about compensating for an incompetent leadernor does it mean thinking we always know best. The better someone is at leading people, the more they create the conditions for their team to take initiative and be proactive about preventing problems. They show by example that they inhabit a state rather than a particular role. A stronger leader can mean a more independent team. Strong leaders instill autonomy by teaching and supervising processes with the intention of eventually not needing to oversee them. Captaincy is a way of being. It is embodied in the role of captain, but it is available to everyone. For a crew to develop it, the captain needs to step back a little and encourage them to take responsibility for outcomes. They can test themselves bit by bit, building up confidence. When people feel like it’s their responsibility to contribute to overall success, not just perform specific tasks, they can respond to the unexpected without waiting for instructions. They become ever more familiar with what their organization needs to stay healthy and use second-order thinking so potential problems are more noticeable before they happen. Whyte realized that the near-disaster had a lot to do with their previous captain, Raphael. He was too good at his job, being “preternaturally alert and omnipresent, appearing on deck at the least sign of trouble.” The crew felt comfortable, knowing they could always rely on Raphael to handle any problems. Although this worked well at the time, once he left and they were no longer in such safe hands they were unused to taking initiative. Whyte explains: “Raphael had so filled his role of captain to capacity that we ourselves had become incapacitated in one crucial area: we had given up our own inner sense of captaincy. Somewhere inside of us, we had come to the decision that ultimate responsibility lay elsewhere.” Being a good leader isn’t about making sure your team doesn’t experience failure. Rather, it’s giving everyone the space and support to create success.  The voyage of work Having an inner sense of captaincy means caring about outcomes, not credit or blame. When Whyte realized that he should have dropped a second anchor the night before the near miss, he would have been doing something that ideally no one other than the crew, or even just him, would have known about. The captain and passengers would have enjoyed an untroubled night and woken none the wiser. If we prioritize getting good outcomes, our focus shifts from solving existing problems to preventing problems from happening in the first place. We put down a second anchor so the boat doesn’t drift, rather than steering it to safety when it’s about to crash. After all, we’re on the boat too. Another good comparison is picking up litter. The less connected to and responsible for a place we feel, the less likely we might be to pick up trash lying on the ground. In our homes, we’re almost certain to pick it up. If we’re walking along our street or in our neighborhood, it’s a little less likely. In a movie theater or bar when we know it’s someone’s job to pick up trash, we’re less likely to bother. What’s the equivalent to leaving trash on the ground in your job? Most organizations don’t incentivize prevention because it’s invisible. Who knows what would have happened? How do you measure something that doesn’t exist? After all, problem preventers seem relaxed. They often go home on time. They take lots of time to think. We don’t know how well they would deal with conflict, because they never seem to experience any. The invisibility of the work they do to prevent problems in the first place makes it seem like their job isn’t challenging. When we promote problem solvers, we incentivize having problems. We fail to unite everyone towards a clear goal. Because most organizations reward problem solvers, it can seem like a better idea to let things go wrong, then fix them after. That’s how you get visibility. You run from one high-level meeting to the next, reacting to one problem after another. It’s great to have people to solve those problems but it is better not to have them in the first place. Solving problems generally requires more resources than preventing them, not to mention the toll it takes on our stress levels. As the saying goes, an ounce of prevention is worth a pound of cure. An inner sense of captaincy on our voyage of work is good for us and for our organizations. It changes how we think about preventing problems. It becomes a part of an overall voyage, an opportunity to build courage and face fears. We become more fully ourselves and more in touch with our nature. Whyte writes that “having the powerful characteristics of captaincy or leadership of any form is almost always an outward sign of a person inhabiting their physical body and the deeper elements of their own nature.”",
			"tokens": 2607,
			"chunks": [
				{
					"article_title": "Solve Problems Before They Happen by Developing an “Inner Sense of Captaincy”",
					"article_url": "https://fs.blog/inner-sense-of-captaincy/",
					"content": "Too often we reward people who solve problems while ignoring those who prevent them in the first place. This incentivizes creating problems. According to poet David Whyte, the key to taking initiative and being proactive is viewing yourself as the captain of your own “voyage of work.” If we want to get away from glorifying those who run around putting out fires, we need to cultivate an organizational culture that empowers everyone to act responsibly at the first sign of smoke. How do we make that shift? We can start by looking at ourselves and how we consider the voyage that is our work. When do we feel fulfillment? Is it when we swoop in to save the day and everyone congratulates us? It’s worth asking why, if we think something is worth saving, we don’t put more effort into protecting it ahead of time. In Crossing the Unknown Sea, poet David Whyte suggests that we should view our work as a lifelong journey. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "Solve Problems Before They Happen by Developing an “Inner Sense of Captaincy”",
					"article_url": "https://fs.blog/inner-sense-of-captaincy/",
					"content": "In particular, he frames it as a sea voyage in which the greatest rewards lie in what we learn through the process, as opposed to the destination. Like a long sea voyage, the nature of our work is always changing. There are stormy days and sunny ones. There are days involving highs of delight and lows of disaster. All of this happens against the backdrop of events in our personal lives and the wider world with varying levels of influence. On a voyage, you need to look after your boat. There isn’t always time to solve problems after they happen. You need to learn how to preempt them or risk a much rougher journeyor even the end of it. Whyte refers to the practice of taking control of your voyage as “developing an inner sense of captaincy,” offering a metaphor we can all apply to our work. Developing an inner sense of captaincy is good for both us and the organizations we work in. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "Solve Problems Before They Happen by Developing an “Inner Sense of Captaincy”",
					"article_url": "https://fs.blog/inner-sense-of-captaincy/",
					"content": "We end up with more agency over our own lives, and our organizations waste fewer resources. Whyte’s story of how he learned this lesson highlights why that’s the case.  A moment of reckoning “Any life, and any life’s work, is a hidden journey, a secret code, deciphered in fits and starts. The details only given truth by the whole, and the whole dependent on the detail.” Shortly after graduating, Whyte landed a dream job working as a naturalist guide on board a ship in the Galapagos Islands. One morning, he awoke and could tell at once that the vessel had drifted from its anchorage during the night. Whyte leaped up to find the captain fast asleep and the boat close to crashing into a cliff. Taking control of it just in time, he managed to steer himself and the other passengers back to safetyright as the captain awoke. ",
					"content_token": 192,
					"embedding": []
				},
				{
					"article_title": "Solve Problems Before They Happen by Developing an “Inner Sense of Captaincy”",
					"article_url": "https://fs.blog/inner-sense-of-captaincy/",
					"content": "Though they were safe, he was profoundly shaken both by the near miss and the realization that their leader had failed. At first, Whyte’s reaction to the episode was to feel a smug contempt for the captain who had “slept through not only the anchor dragging but our long, long, nighttime drift.” The captain had failed to predict the problem or notice when it started. If Whyte hadn’t awakened, everyone on the ship could have died. But something soon changed in his perspective. Whyte knew the captain was new and far less familiar with that particular boat than himself and the other crew member. Every boat has its quirks, and experience counts for more than seniority when it comes to knowing them. He’d also felt sure the night before that they needed to put down a second anchor and knew they “should have dropped another anchor without consultation, as crews are wont to do when they do not want to argue with their captain. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "Solve Problems Before They Happen by Developing an “Inner Sense of Captaincy”",
					"article_url": "https://fs.blog/inner-sense-of-captaincy/",
					"content": "We should have woken too.” He writes that “this moment of reckoning under the lava cliff speaks to the many dangerous arrivals in a life of work and to the way we must continually forge our identities through our endeavors.” Whyte’s experience contains lessons with wide applicability for those of us on dry land. The idea of having an inner sense of captaincy means understanding the overarching goals of your work and being willing to make decisions that support them, even if something isn’t strictly your job or you might not get rewarded for it, or sometimes even if you don’t have permission. When you play the long game, you’re thinking of the whole voyage, not whether you’ll get a pat on the back today.  Skin in the game It’s all too easy to buy into the view that leaders have full responsibility for everything that happens, especially disasters. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "Solve Problems Before They Happen by Developing an “Inner Sense of Captaincy”",
					"article_url": "https://fs.blog/inner-sense-of-captaincy/",
					"content": "Sometimes in our work, when we’re not in a leadership position, we see a potential problem or an unnoticed existing one but choose not to take action. Instead, we stick to doing whatever we’ve been told to do because that feels safer. If it’s important, surely the person in charge will deal with it. If not, that’s their problem. Anyway, there’s already more than enough to do. Leaders give us a convenient scapegoat when things go wrong. However, when we assume all responsibility lies with them, we don’t learn from our mistakes. We don’t have “our own personal compass, a direction, a willingness to meet life unmediated by any cushioning parental presence.” At some point, things do become our problem. No leader can do everything and see everything. The more you rise within an organization, the more you need to take initiative. ",
					"content_token": 194,
					"embedding": []
				},
				{
					"article_title": "Solve Problems Before They Happen by Developing an “Inner Sense of Captaincy”",
					"article_url": "https://fs.blog/inner-sense-of-captaincy/",
					"content": "If a leader can’t rely on their subordinates to take action when they see a potential problem, everything will collapse. When we’ve been repeatedly denied agency by poor leadership and seen our efforts fall flat, we may sense we lack control. Taking action no longer feels natural. However, if we view our work as a voyage that helps us change and grow, it’s obvious why we need to overcome learned helplessness. We can’t abdicate all responsibility and blame other people for what we chose to ignore in the first place as Whyte puts it, “The captain was there in all his inherited and burdened glory and thus convenient for the blame” By understanding how our work helps us change and grow, we develop skin in the game. On a ship, everyone is in it together. If something goes wrong, they’re all at risk. ",
					"content_token": 183,
					"embedding": []
				},
				{
					"article_title": "Solve Problems Before They Happen by Developing an “Inner Sense of Captaincy”",
					"article_url": "https://fs.blog/inner-sense-of-captaincy/",
					"content": "And it may not be easy or even possible to patch up a serious problem in the middle of the sea. As a result, everyone needs to pay attention and act on anything that seems amiss. Everyone needs to take responsibility for what happens, as Whyte goes on to detail: “No matter that the inherited world of the sea told us that the captain is the be-all and end-all of all responsibility, we had all contributed to the lapse, the inexcusable lapse. The edge is no place for apportioning blame. If we had merely touched that cliff, we would have been for the briny deep, crew and passengers alike. The undertow and the huge waves lacerating against that undercut, barnacle-encrusted fortress would have killed us all.” Having an inner sense of captaincy means viewing ourselves as the ones in charge of our voyage of work. ",
					"content_token": 185,
					"embedding": []
				},
				{
					"article_title": "Solve Problems Before They Happen by Developing an “Inner Sense of Captaincy”",
					"article_url": "https://fs.blog/inner-sense-of-captaincy/",
					"content": "It means not acting as if there are certain areas where we are incapacitated, or ignoring potential problems, just because someone else has a particular title.  Space and support to create success Developing an inner sense of captaincy is not about compensating for an incompetent leadernor does it mean thinking we always know best. The better someone is at leading people, the more they create the conditions for their team to take initiative and be proactive about preventing problems. They show by example that they inhabit a state rather than a particular role. A stronger leader can mean a more independent team. Strong leaders instill autonomy by teaching and supervising processes with the intention of eventually not needing to oversee them. Captaincy is a way of being. It is embodied in the role of captain, but it is available to everyone. For a crew to develop it, the captain needs to step back a little and encourage them to take responsibility for outcomes. They can test themselves bit by bit, building up confidence. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "Solve Problems Before They Happen by Developing an “Inner Sense of Captaincy”",
					"article_url": "https://fs.blog/inner-sense-of-captaincy/",
					"content": "When people feel like it’s their responsibility to contribute to overall success, not just perform specific tasks, they can respond to the unexpected without waiting for instructions. They become ever more familiar with what their organization needs to stay healthy and use second-order thinking so potential problems are more noticeable before they happen. Whyte realized that the near-disaster had a lot to do with their previous captain, Raphael. He was too good at his job, being “preternaturally alert and omnipresent, appearing on deck at the least sign of trouble.” The crew felt comfortable, knowing they could always rely on Raphael to handle any problems. Although this worked well at the time, once he left and they were no longer in such safe hands they were unused to taking initiative. Whyte explains: “Raphael had so filled his role of captain to capacity that we ourselves had become incapacitated in one crucial area: we had given up our own inner sense of captaincy. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "Solve Problems Before They Happen by Developing an “Inner Sense of Captaincy”",
					"article_url": "https://fs.blog/inner-sense-of-captaincy/",
					"content": "Somewhere inside of us, we had come to the decision that ultimate responsibility lay elsewhere.” Being a good leader isn’t about making sure your team doesn’t experience failure. Rather, it’s giving everyone the space and support to create success.  The voyage of work Having an inner sense of captaincy means caring about outcomes, not credit or blame. When Whyte realized that he should have dropped a second anchor the night before the near miss, he would have been doing something that ideally no one other than the crew, or even just him, would have known about. The captain and passengers would have enjoyed an untroubled night and woken none the wiser. If we prioritize getting good outcomes, our focus shifts from solving existing problems to preventing problems from happening in the first place. We put down a second anchor so the boat doesn’t drift, rather than steering it to safety when it’s about to crash. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "Solve Problems Before They Happen by Developing an “Inner Sense of Captaincy”",
					"article_url": "https://fs.blog/inner-sense-of-captaincy/",
					"content": "After all, we’re on the boat too. Another good comparison is picking up litter. The less connected to and responsible for a place we feel, the less likely we might be to pick up trash lying on the ground. In our homes, we’re almost certain to pick it up. If we’re walking along our street or in our neighborhood, it’s a little less likely. In a movie theater or bar when we know it’s someone’s job to pick up trash, we’re less likely to bother. What’s the equivalent to leaving trash on the ground in your job? Most organizations don’t incentivize prevention because it’s invisible. Who knows what would have happened? How do you measure something that doesn’t exist? After all, problem preventers seem relaxed. They often go home on time. They take lots of time to think. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "Solve Problems Before They Happen by Developing an “Inner Sense of Captaincy”",
					"article_url": "https://fs.blog/inner-sense-of-captaincy/",
					"content": "We don’t know how well they would deal with conflict, because they never seem to experience any. The invisibility of the work they do to prevent problems in the first place makes it seem like their job isn’t challenging. When we promote problem solvers, we incentivize having problems. We fail to unite everyone towards a clear goal. Because most organizations reward problem solvers, it can seem like a better idea to let things go wrong, then fix them after. That’s how you get visibility. You run from one high-level meeting to the next, reacting to one problem after another. It’s great to have people to solve those problems but it is better not to have them in the first place. Solving problems generally requires more resources than preventing them, not to mention the toll it takes on our stress levels. As the saying goes, an ounce of prevention is worth a pound of cure. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "Solve Problems Before They Happen by Developing an “Inner Sense of Captaincy”",
					"article_url": "https://fs.blog/inner-sense-of-captaincy/",
					"content": "An inner sense of captaincy on our voyage of work is good for us and for our organizations. It changes how we think about preventing problems. It becomes a part of an overall voyage, an opportunity to build courage and face fears. We become more fully ourselves and more in touch with our nature. Whyte writes that “having the powerful characteristics of captaincy or leadership of any form is almost always an outward sign of a person inhabiting their physical body and the deeper elements of their own nature.”",
					"content_token": 103,
					"embedding": []
				}
			]
		},
		{
			"title": "12 Life Lessons From Mathematician and Philosopher Gian-Carlo Rota",
			"url": "https://fs.blog/gian-carlo-rota/",
			"content": "The mathematician and philosopher Gian-Carlo Rota spent much of his career at MIT, where students adored him for his engaging, passionate lectures. In 1996, Rota gave a talk entitled “Ten Lessons I Wish I Had Been Taught,” which contains valuable advice for making people pay attention to your ideas. Many mathematicians regard Rota as single-handedly responsible for turning combinatorics into a significant field of study. He specialized in functional analysis, probability theory, phenomenology, and combinatorics. His 1996 talk, “Ten Lessons I Wish I Had Been Taught,” was later printed in his book, Indiscrete Thoughts. Rota began by explaining that the advice we give others is always the advice we need to follow most. Seeing as it was too late for him to follow certain lessons, he decided he would share them with the audience. Here, we summarize twelve insights from Rota’s talkwhich are fascinating and practical, even if you’re not a mathematician.  Every lecture should make only one point “Every lecture should state one main point and repeat it over and over, like a theme with variations. An audience is like a herd of cows, moving slowly in the direction they are being driven towards.” When we wish to communicate with peoplein an article, an email to a coworker, a presentation, a text to a partner, and so onit’s often best to stick to making one point at a time. This matters all the more so if we’re trying to get our ideas across to a large audience. If we make one point well enough, we can be optimistic about people understanding and remembering it. But if we try to fit too much in, “the cows will scatter all over the field. The audience will lose interest and everyone will go back to the thoughts they interrupted in order to come to our lecture.”  Never run over time “After fifty minutes one microcentury as von Neumann used to say, everybody’s attention will turn elsewhere even if we are trying to prove the Riemann hypothesis. One minute over time can destroy the best of lectures.” Rota considered running over the allotted time slot to be the worst thing a lecturer could do. Our attention spans are finite. After a certain point, we stop taking in new information. In your work, it’s important to respect the time and attention of others. Put in the extra work required for brevity and clarity. Don’t expect them to find what you have to say as interesting as you do. Condensing and compressing your ideas both ensures you truly understand them and makes them easier for others to remember.  Relate to your audience “As you enter the lecture hall, try to spot someone in the audience whose work you have some familiarity with. Quickly rearrange your presentation so as to manage to mention some of that person’s work.” Reciprocity is remarkably persuasive. Sometimes, how people respond to your work has as much to do with how you respond to theirs as it does with the work itself. If you want people to pay attention to your work, always give before you take and pay attention to theirs first. Show that you see them and appreciate them. Rota explains that “everyone in the audience has come to listen to your lecture with the secret hope of hearing their work mentioned.” The less acknowledgment someone’s work has received, the more of an impact your attention is likely to have. A small act of encouragement can be enough to deter someone from quitting. With characteristic humor, Rota recounts: “I have always felt miffed after reading a paper in which I felt I was not being given proper credit, and it is safe to conjecture that the same happens to everyone else. One day I tried an experiment. After writing a rather long paper, I began to draft a thorough bibliography. On the spur of the moment I decided to cite a few papers which had nothing whatsoever to do with the content of my paper to see what might happen. Somewhat to my surprise, I received letters from two of the authors whose papers I believed were irrelevant to my article. Both letters were written in an emotionally charged tone. Each of the authors warmly congratulated me for being the first to acknowledge their contribution to the field.”  Give people something to take home “I often meet, in airports, in the street, and occasionally in embarrassing situations, MIT alumni who have taken one or more courses from me. Most of the time they admit that they have forgotten the subject of the course and all the mathematics I thought I had taught them. However, they will gladly recall some joke, some anecdote, some quirk, some side remark, or some mistake I made.” When we have a conversation, read a book, or listen to a talk, the sad fact is that we are unlikely to remember much of it even a few hours later, let alone years after the event. Even if we enjoyed and valued it, only a small part will stick in our memory. So when you’re communicating with people, try to be conscious about giving them something to take home. Choose a memorable line or idea, create a visual image, or use humor in your work. For example, in The Righteous Mind, Jonathan Haidt repeats many times that the mind is like a tiny rider on a gigantic elephant. The rider represents controlled mental processes, while the elephant represents automatic ones. It’s a distinctive image, one readers are quite likely to take home with them.  Make sure the blackboard is spotless “By starting with a spotless blackboard, you will subtly convey the impression that the lecture they are about to hear is equally spotless.” Presentation matters. The way our work looks influences how people perceive it. Taking the time to clean our equivalent of a blackboard signals that we care about what we’re doing and consider it important. In “How To Spot Bad Science,” we noted that one possible sign of bad science is that the research is presented in a thoughtless, messy way. Most researchers who take their work seriously will put in the extra effort to ensure it’s well presented.  Make it easy for people to take notes “What we write on the blackboard should correspond to what we want an attentive listener to take down in his notebook. It is preferable to write slowly and in a large handwriting, with no abbreviations. Those members of the audience who are taking notes are doing us a favor, and it is up to us to help them with their copying.” If a lecturer is using slides with writing on them instead of a blackboard, Rota adds that they should give people time to take notes. This might mean repeating themselves in a few different ways so each slide takes longer to explain which ties in with the idea that every lecture should make only one point. Moving too fast with the expectation that people will look at the slides again later is “wishful thinking.” When we present our work to people, we should make it simple for them to understand our ideas on the spot. We shouldn’t expect them to revisit it later. They might forget. And even if they don’t, we won’t be there to answer questions, take feedback, and clear up any misunderstandings.  Share the same work multiple times Rota learned this lesson when he bought Collected Papers, a volume compiling the publications of mathematician Frederic Riesz. He noted that “the editors had gone out of their way to publish every little scrap Riesz had ever published.” Putting them all in one place revealed that he had published the same ideas multiple times: Riesz would publish the first rough version of an idea in some obscure Hungarian journal. A few years later, he would send a series of notes to the French Academy’s Comptes Rendus in which the same material was further elaborated. A few more years would pass, and he would publish the definitive paper, either in French or in English. Riesz would also develop his ideas while lecturing. Explaining the same subject again and again for years allowed him to keep improving it until he was ready to publish. Rota notes, “No wonder the final version was perfect.” In our work, we might feel as if we need to have fresh ideas all of the time and that anything we share with others needs to be a finished product. But sometimes we can do our best work through an iterative process. For example, a writer might start by sharing an idea as a tweet. This gets a good response, and the replies help them expand it into a blog post. From there they keep reworking the post over several years, making it longer and more definite each time. They give a talk on the topic. Eventually, it becomes a book. Award-winning comedian Chris Rock prepares for global tours by performing dozens of times in small venues for a handful of people. Each performance is an experiment to see which jokes land, which ones don’t, and which need tweaking. By the time he’s performed a routine forty or fifty times, making it better and better, he’s ready to share it with huge audiences. Another reason to share the same work multiple times is that different people will see it each time and understand it in different ways: “The mathematical community is split into small groups, each one with its own customs, notation, and terminology. It may soon be indispensable to present the same result in several versions, each one accessible to a specific group; the price one might have to pay otherwise is to have our work rediscovered by someone who uses a different language and notation, and who will rightly claim it as his own.” Sharing your work multiple times thus has two benefits. The first is that the feedback allows you to improve and refine your work. The second is that you increase the chance of your work being definitively associated with you. If the core ideas are strong enough, they’ll shine through even in the initial incomplete versions.  You are more likely to be remembered for your expository work “Allow me to digress with a personal reminiscence. I sometimes publish in a branch of philosophy called phenomenology. . . . It so happens that the fundamental treatises of phenomenology are written in thick, heavy philosophical German. Tradition demands that no examples ever be given of what one is talking about. One day I decided, not without serious misgivings, to publish a paper that was essentially an updating of some paragraphs from a book by Edmund Husserl, with a few examples added. While I was waiting for the worst at the next meeting of the Society for Phenomenology and Existential Philosophy, a prominent phenomenologist rushed towards me with a smile on his face. He was full of praise for my paper, and he strongly encouraged me to further develop the novel and original ideas presented in it.” Rota realized that many of the mathematicians he admired the most were known more for their work explaining and building upon existing knowledge, as opposed to their entirely original work. Their extensive knowledge of their domain meant they could expand a little beyond their core specialization and synthesize charted territory. For example, David Hilbert was best known for a textbook on integral equations which was “in large part expository, leaning on the work of Hellinger and several other mathematicians whose names are now forgotten.” William Feller was known for an influential treatise on probability, with few recalling his original work in convex geometry. One of our core goals at Farnam Street is to share the best of what other people have already figured out. We all want to make original and creative contributions to the world. But the best ideas that are already out there are quite often much more useful than what we can contribute from scratch. We should never be afraid to stand on the shoulders of giants.  Every mathematician has only a few tricks “. . . mathematicians, even the very best, also rely on a few tricks which they use over and over.” Upon reading the complete works of certain influential mathematicians, such as David Hilbert, Rota realized that they always used the same tricks again and again. We don’t need to be amazing at everything to do high-quality work. The smartest and most successful people are often only good at a few thingsor even one thing. Their secret is that they maximize those strengths and don’t get distracted. They define their circle of competence and don’t attempt things they’re not good at if there’s any room to double down further on what’s already going well. It might seem as if this lesson contradicts the previous one you are more likely to be remembered for your expository work, but there’s a key difference. If you’ve hit diminishing returns with improvements to what’s already inside your circle of competence, it makes sense to experiment with things you already have an aptitude for or a strong suspicion you might but you just haven’t made them your focus.  Don’t worry about small mistakes “Once more let me begin with Hilbert. When the Germans were planning to publish Hilbert’s collected papers and to present him with a set on the occasion of one of his later birthdays, they realized that they could not publish the papers in their original versions because they were full of errors, some of them quite serious. Thereupon they hired a young unemployed mathematician, Olga Taussky-Todd, to go over Hilbert’s papers and correct all mistakes. Olga labored for three years; it turned out that all mistakes could be corrected without any major changes in the statement of the theorems. . . . At last, on Hilbert’s birthday, a freshly printed set of Hilbert’s collected papers was presented to the Geheimrat. Hilbert leafed through them carefully and did not notice anything.” Rota goes on to say: “There are two kinds of mistakes. There are fatal mistakes that destroy a theory; but there are also contingent ones, which are useful in testing the stability of a theory.” Mistakes are either contingent or fatal. Contingent mistakes don’t completely ruin what you’re working on; fatal ones do. Building in a margin of safety such as having a bit more time or funding that you expect to need turns many fatal mistakes into contingent ones. Contingent mistakes can even be useful. When details change, but the underlying theory is still sound, you know which details not to sweat.  Use Feynman’s method for solving problems “Richard Feynman was fond of giving the following advice on how to be a genius. You have to keep a dozen of your favorite problems constantly present in your mind, although by and large they will lay in a dormant state. Every time you hear or read a new trick or a new result, test it against each of your twelve problems to see whether it helps. Every once in a while there will be a hit, and people will say: How did he do it? He must be a genius!’”  Write informative introductions “Nowadays, reading a mathematics paper from top to bottom is a rare event. If we wish our paper to be read, we had better provide our prospective readers with strong motivation to do so. A lengthy introduction, summarizing the history of the subject, giving everybody his due, and perhaps enticingly outlining the content of the paper in a discursive manner, will go some of the way towards getting us a couple of readers.” As with the lesson of don’t run over time, respect that people have limited time and attention. Introductions are all about explaining what a piece of work is going to be about, what its purpose is, and why someone should be interested in it. A job posting is an introduction to a company. The description on a calendar invite to a meeting is an introduction to that meeting. An about page is an introduction to an author. The subject line on a cold email is an introduction to that message. A course curriculum is an introduction to a class. Putting extra effort into our introductions will help other people make an accurate assessment of whether they want to engage with the full thing. It will prime their minds for what to expect and answer some of their questions.  If you’re interested in learning more, check out Rota’s “10 Lessons of an MIT Education.”",
			"tokens": 3438,
			"chunks": [
				{
					"article_title": "12 Life Lessons From Mathematician and Philosopher Gian-Carlo Rota",
					"article_url": "https://fs.blog/gian-carlo-rota/",
					"content": "The mathematician and philosopher Gian-Carlo Rota spent much of his career at MIT, where students adored him for his engaging, passionate lectures. In 1996, Rota gave a talk entitled “Ten Lessons I Wish I Had Been Taught,” which contains valuable advice for making people pay attention to your ideas. Many mathematicians regard Rota as single-handedly responsible for turning combinatorics into a significant field of study. He specialized in functional analysis, probability theory, phenomenology, and combinatorics. His 1996 talk, “Ten Lessons I Wish I Had Been Taught,” was later printed in his book, Indiscrete Thoughts. Rota began by explaining that the advice we give others is always the advice we need to follow most. Seeing as it was too late for him to follow certain lessons, he decided he would share them with the audience. ",
					"content_token": 181,
					"embedding": []
				},
				{
					"article_title": "12 Life Lessons From Mathematician and Philosopher Gian-Carlo Rota",
					"article_url": "https://fs.blog/gian-carlo-rota/",
					"content": "Here, we summarize twelve insights from Rota’s talkwhich are fascinating and practical, even if you’re not a mathematician.  Every lecture should make only one point “Every lecture should state one main point and repeat it over and over, like a theme with variations. An audience is like a herd of cows, moving slowly in the direction they are being driven towards.” When we wish to communicate with peoplein an article, an email to a coworker, a presentation, a text to a partner, and so onit’s often best to stick to making one point at a time. This matters all the more so if we’re trying to get our ideas across to a large audience. If we make one point well enough, we can be optimistic about people understanding and remembering it. But if we try to fit too much in, “the cows will scatter all over the field. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "12 Life Lessons From Mathematician and Philosopher Gian-Carlo Rota",
					"article_url": "https://fs.blog/gian-carlo-rota/",
					"content": "The audience will lose interest and everyone will go back to the thoughts they interrupted in order to come to our lecture.”  Never run over time “After fifty minutes one microcentury as von Neumann used to say, everybody’s attention will turn elsewhere even if we are trying to prove the Riemann hypothesis. One minute over time can destroy the best of lectures.” Rota considered running over the allotted time slot to be the worst thing a lecturer could do. Our attention spans are finite. After a certain point, we stop taking in new information. In your work, it’s important to respect the time and attention of others. Put in the extra work required for brevity and clarity. Don’t expect them to find what you have to say as interesting as you do. Condensing and compressing your ideas both ensures you truly understand them and makes them easier for others to remember. ",
					"content_token": 189,
					"embedding": []
				},
				{
					"article_title": "12 Life Lessons From Mathematician and Philosopher Gian-Carlo Rota",
					"article_url": "https://fs.blog/gian-carlo-rota/",
					"content": " Relate to your audience “As you enter the lecture hall, try to spot someone in the audience whose work you have some familiarity with. Quickly rearrange your presentation so as to manage to mention some of that person’s work.” Reciprocity is remarkably persuasive. Sometimes, how people respond to your work has as much to do with how you respond to theirs as it does with the work itself. If you want people to pay attention to your work, always give before you take and pay attention to theirs first. Show that you see them and appreciate them. Rota explains that “everyone in the audience has come to listen to your lecture with the secret hope of hearing their work mentioned.” The less acknowledgment someone’s work has received, the more of an impact your attention is likely to have. A small act of encouragement can be enough to deter someone from quitting. ",
					"content_token": 186,
					"embedding": []
				},
				{
					"article_title": "12 Life Lessons From Mathematician and Philosopher Gian-Carlo Rota",
					"article_url": "https://fs.blog/gian-carlo-rota/",
					"content": "With characteristic humor, Rota recounts: “I have always felt miffed after reading a paper in which I felt I was not being given proper credit, and it is safe to conjecture that the same happens to everyone else. One day I tried an experiment. After writing a rather long paper, I began to draft a thorough bibliography. On the spur of the moment I decided to cite a few papers which had nothing whatsoever to do with the content of my paper to see what might happen. Somewhat to my surprise, I received letters from two of the authors whose papers I believed were irrelevant to my article. Both letters were written in an emotionally charged tone. Each of the authors warmly congratulated me for being the first to acknowledge their contribution to the field.”  Give people something to take home “I often meet, in airports, in the street, and occasionally in embarrassing situations, MIT alumni who have taken one or more courses from me. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "12 Life Lessons From Mathematician and Philosopher Gian-Carlo Rota",
					"article_url": "https://fs.blog/gian-carlo-rota/",
					"content": "Most of the time they admit that they have forgotten the subject of the course and all the mathematics I thought I had taught them. However, they will gladly recall some joke, some anecdote, some quirk, some side remark, or some mistake I made.” When we have a conversation, read a book, or listen to a talk, the sad fact is that we are unlikely to remember much of it even a few hours later, let alone years after the event. Even if we enjoyed and valued it, only a small part will stick in our memory. So when you’re communicating with people, try to be conscious about giving them something to take home. Choose a memorable line or idea, create a visual image, or use humor in your work. For example, in The Righteous Mind, Jonathan Haidt repeats many times that the mind is like a tiny rider on a gigantic elephant. The rider represents controlled mental processes, while the elephant represents automatic ones. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "12 Life Lessons From Mathematician and Philosopher Gian-Carlo Rota",
					"article_url": "https://fs.blog/gian-carlo-rota/",
					"content": "It’s a distinctive image, one readers are quite likely to take home with them.  Make sure the blackboard is spotless “By starting with a spotless blackboard, you will subtly convey the impression that the lecture they are about to hear is equally spotless.” Presentation matters. The way our work looks influences how people perceive it. Taking the time to clean our equivalent of a blackboard signals that we care about what we’re doing and consider it important. In “How To Spot Bad Science,” we noted that one possible sign of bad science is that the research is presented in a thoughtless, messy way. Most researchers who take their work seriously will put in the extra effort to ensure it’s well presented.  Make it easy for people to take notes “What we write on the blackboard should correspond to what we want an attentive listener to take down in his notebook. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "12 Life Lessons From Mathematician and Philosopher Gian-Carlo Rota",
					"article_url": "https://fs.blog/gian-carlo-rota/",
					"content": "It is preferable to write slowly and in a large handwriting, with no abbreviations. Those members of the audience who are taking notes are doing us a favor, and it is up to us to help them with their copying.” If a lecturer is using slides with writing on them instead of a blackboard, Rota adds that they should give people time to take notes. This might mean repeating themselves in a few different ways so each slide takes longer to explain which ties in with the idea that every lecture should make only one point. Moving too fast with the expectation that people will look at the slides again later is “wishful thinking.” When we present our work to people, we should make it simple for them to understand our ideas on the spot. We shouldn’t expect them to revisit it later. They might forget. ",
					"content_token": 173,
					"embedding": []
				},
				{
					"article_title": "12 Life Lessons From Mathematician and Philosopher Gian-Carlo Rota",
					"article_url": "https://fs.blog/gian-carlo-rota/",
					"content": "And even if they don’t, we won’t be there to answer questions, take feedback, and clear up any misunderstandings.  Share the same work multiple times Rota learned this lesson when he bought Collected Papers, a volume compiling the publications of mathematician Frederic Riesz. He noted that “the editors had gone out of their way to publish every little scrap Riesz had ever published.” Putting them all in one place revealed that he had published the same ideas multiple times: Riesz would publish the first rough version of an idea in some obscure Hungarian journal. A few years later, he would send a series of notes to the French Academy’s Comptes Rendus in which the same material was further elaborated. A few more years would pass, and he would publish the definitive paper, either in French or in English. Riesz would also develop his ideas while lecturing. ",
					"content_token": 192,
					"embedding": []
				},
				{
					"article_title": "12 Life Lessons From Mathematician and Philosopher Gian-Carlo Rota",
					"article_url": "https://fs.blog/gian-carlo-rota/",
					"content": "Explaining the same subject again and again for years allowed him to keep improving it until he was ready to publish. Rota notes, “No wonder the final version was perfect.” In our work, we might feel as if we need to have fresh ideas all of the time and that anything we share with others needs to be a finished product. But sometimes we can do our best work through an iterative process. For example, a writer might start by sharing an idea as a tweet. This gets a good response, and the replies help them expand it into a blog post. From there they keep reworking the post over several years, making it longer and more definite each time. They give a talk on the topic. Eventually, it becomes a book. Award-winning comedian Chris Rock prepares for global tours by performing dozens of times in small venues for a handful of people. ",
					"content_token": 180,
					"embedding": []
				},
				{
					"article_title": "12 Life Lessons From Mathematician and Philosopher Gian-Carlo Rota",
					"article_url": "https://fs.blog/gian-carlo-rota/",
					"content": "Each performance is an experiment to see which jokes land, which ones don’t, and which need tweaking. By the time he’s performed a routine forty or fifty times, making it better and better, he’s ready to share it with huge audiences. Another reason to share the same work multiple times is that different people will see it each time and understand it in different ways: “The mathematical community is split into small groups, each one with its own customs, notation, and terminology. It may soon be indispensable to present the same result in several versions, each one accessible to a specific group; the price one might have to pay otherwise is to have our work rediscovered by someone who uses a different language and notation, and who will rightly claim it as his own.” Sharing your work multiple times thus has two benefits. The first is that the feedback allows you to improve and refine your work. ",
					"content_token": 189,
					"embedding": []
				},
				{
					"article_title": "12 Life Lessons From Mathematician and Philosopher Gian-Carlo Rota",
					"article_url": "https://fs.blog/gian-carlo-rota/",
					"content": "The second is that you increase the chance of your work being definitively associated with you. If the core ideas are strong enough, they’ll shine through even in the initial incomplete versions.  You are more likely to be remembered for your expository work “Allow me to digress with a personal reminiscence. I sometimes publish in a branch of philosophy called phenomenology.    It so happens that the fundamental treatises of phenomenology are written in thick, heavy philosophical German. Tradition demands that no examples ever be given of what one is talking about. One day I decided, not without serious misgivings, to publish a paper that was essentially an updating of some paragraphs from a book by Edmund Husserl, with a few examples added. While I was waiting for the worst at the next meeting of the Society for Phenomenology and Existential Philosophy, a prominent phenomenologist rushed towards me with a smile on his face. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "12 Life Lessons From Mathematician and Philosopher Gian-Carlo Rota",
					"article_url": "https://fs.blog/gian-carlo-rota/",
					"content": "He was full of praise for my paper, and he strongly encouraged me to further develop the novel and original ideas presented in it.” Rota realized that many of the mathematicians he admired the most were known more for their work explaining and building upon existing knowledge, as opposed to their entirely original work. Their extensive knowledge of their domain meant they could expand a little beyond their core specialization and synthesize charted territory. For example, David Hilbert was best known for a textbook on integral equations which was “in large part expository, leaning on the work of Hellinger and several other mathematicians whose names are now forgotten.” William Feller was known for an influential treatise on probability, with few recalling his original work in convex geometry. One of our core goals at Farnam Street is to share the best of what other people have already figured out. We all want to make original and creative contributions to the world. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "12 Life Lessons From Mathematician and Philosopher Gian-Carlo Rota",
					"article_url": "https://fs.blog/gian-carlo-rota/",
					"content": "But the best ideas that are already out there are quite often much more useful than what we can contribute from scratch. We should never be afraid to stand on the shoulders of giants.  Every mathematician has only a few tricks “   mathematicians, even the very best, also rely on a few tricks which they use over and over.” Upon reading the complete works of certain influential mathematicians, such as David Hilbert, Rota realized that they always used the same tricks again and again. We don’t need to be amazing at everything to do high-quality work. The smartest and most successful people are often only good at a few thingsor even one thing. Their secret is that they maximize those strengths and don’t get distracted. They define their circle of competence and don’t attempt things they’re not good at if there’s any room to double down further on what’s already going well. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "12 Life Lessons From Mathematician and Philosopher Gian-Carlo Rota",
					"article_url": "https://fs.blog/gian-carlo-rota/",
					"content": "It might seem as if this lesson contradicts the previous one you are more likely to be remembered for your expository work, but there’s a key difference. If you’ve hit diminishing returns with improvements to what’s already inside your circle of competence, it makes sense to experiment with things you already have an aptitude for or a strong suspicion you might but you just haven’t made them your focus.  Don’t worry about small mistakes “Once more let me begin with Hilbert. When the Germans were planning to publish Hilbert’s collected papers and to present him with a set on the occasion of one of his later birthdays, they realized that they could not publish the papers in their original versions because they were full of errors, some of them quite serious. Thereupon they hired a young unemployed mathematician, Olga Taussky-Todd, to go over Hilbert’s papers and correct all mistakes. ",
					"content_token": 194,
					"embedding": []
				},
				{
					"article_title": "12 Life Lessons From Mathematician and Philosopher Gian-Carlo Rota",
					"article_url": "https://fs.blog/gian-carlo-rota/",
					"content": "Olga labored for three years; it turned out that all mistakes could be corrected without any major changes in the statement of the theorems.    At last, on Hilbert’s birthday, a freshly printed set of Hilbert’s collected papers was presented to the Geheimrat. Hilbert leafed through them carefully and did not notice anything.” Rota goes on to say: “There are two kinds of mistakes. There are fatal mistakes that destroy a theory; but there are also contingent ones, which are useful in testing the stability of a theory.” Mistakes are either contingent or fatal. Contingent mistakes don’t completely ruin what you’re working on; fatal ones do. Building in a margin of safety such as having a bit more time or funding that you expect to need turns many fatal mistakes into contingent ones. Contingent mistakes can even be useful. ",
					"content_token": 189,
					"embedding": []
				},
				{
					"article_title": "12 Life Lessons From Mathematician and Philosopher Gian-Carlo Rota",
					"article_url": "https://fs.blog/gian-carlo-rota/",
					"content": "When details change, but the underlying theory is still sound, you know which details not to sweat.  Use Feynman’s method for solving problems “Richard Feynman was fond of giving the following advice on how to be a genius. You have to keep a dozen of your favorite problems constantly present in your mind, although by and large they will lay in a dormant state. Every time you hear or read a new trick or a new result, test it against each of your twelve problems to see whether it helps. Every once in a while there will be a hit, and people will say: How did he do it? He must be a genius!’”  Write informative introductions “Nowadays, reading a mathematics paper from top to bottom is a rare event. If we wish our paper to be read, we had better provide our prospective readers with strong motivation to do so. ",
					"content_token": 187,
					"embedding": []
				},
				{
					"article_title": "12 Life Lessons From Mathematician and Philosopher Gian-Carlo Rota",
					"article_url": "https://fs.blog/gian-carlo-rota/",
					"content": "A lengthy introduction, summarizing the history of the subject, giving everybody his due, and perhaps enticingly outlining the content of the paper in a discursive manner, will go some of the way towards getting us a couple of readers.” As with the lesson of don’t run over time, respect that people have limited time and attention. Introductions are all about explaining what a piece of work is going to be about, what its purpose is, and why someone should be interested in it. A job posting is an introduction to a company. The description on a calendar invite to a meeting is an introduction to that meeting. An about page is an introduction to an author. The subject line on a cold email is an introduction to that message. A course curriculum is an introduction to a class. Putting extra effort into our introductions will help other people make an accurate assessment of whether they want to engage with the full thing. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "12 Life Lessons From Mathematician and Philosopher Gian-Carlo Rota",
					"article_url": "https://fs.blog/gian-carlo-rota/",
					"content": "It will prime their minds for what to expect and answer some of their questions.  If you’re interested in learning more, check out Rota’s “10 Lessons of an MIT Education.”",
					"content_token": 45,
					"embedding": []
				}
			]
		},
		{
			"title": "The Best-Case Outcomes Are Statistical Outliers",
			"url": "https://fs.blog/best-case/",
			"content": "There’s nothing wrong with hoping for the best. But the best-case scenario is rarely the one that comes to pass. Being realistic about what is likely to happen positions you for a range of possible outcomes and gives you peace of mind. We dream about achieving the best-case outcomes, but they are rare. We can’t forget to acknowledge all the other possibilities of what may happen if we want to position ourselves for success. “Hoping for the best, prepared for the worst, and unsurprised by anything in between.” Maya Angelou It’s okay to hope for the bestto look at whatever situation you’re in and say, “This time I have it figured out. This time it’s going to work.” First, having some degree of optimism is necessary for trying anything new. If we weren’t overconfident, we’d never have the guts to do something as risky and unlikely to succeed as starting a business, entering a new relationship, or sending that cold email. Anticipating that a new venture will work helps you overcome obstacles and make it work. Second, sometimes we do have it figured out. Sometimes our solutions do make things better. Even when the best-case scenario comes to pass, however, it rarely unfolds exactly as planned. Some choices create unanticipated consequences that we have to deal with. We may encounter unexpected roadblocks due to a lack of information. Or the full implementation of all our ideas and aspirations might take a lot longer than we planned for. When you look back over history, we rarely find best-case outcomes. Sure, sometimes they happenmaybe more than we think, given not every moment of the past is recorded. But let’s be honest: even historical wins, like developing the polio vaccine and figuring out how to produce clean drinking water, were not all smooth sailing. There are still people who are unable or unwilling to get the polio vaccine. And there are still many people in the world, even in developed countries like Canada, who don’t have access to clean drinking water. The best-case outcomes in these situationsa world without polio and a world with globally available clean drinking waterhave not happened, despite the existence of reliable, proven technology that can make these outcomes a reality. There are a lot of reasons why, in these situations, we haven’t achieved the best-case outcomes. Furthermore, situations like these are not unusual. We rarely achieve the dream. The more complicated a situation, the more people it involves, the more variables and dependencies that exist, the more it’s unlikely that it’s all going to work out. If we narrow our scope and say, for example, the best-case scenario for this Friday night is that we don’t burn the pizza, we can all agree on a movie, and the power doesn’t go out, it’s more likely we’ll achieve it. There are fewer variables, so there’s a greater chance that this specific scenario will come to pass. The problem is that most of us plan as if we live in an easy-to-anticipate Friday night kind of world. We don’t. There are no magic bullets for the complicated challenges facing society. There is only hard work, planning for the wide spectrum of human behavior, adjusting to changing conditions, and perseverance. There are many possible outcomes for any given endeavor and only one that we consider the best case. That is why the best-case outcomes are statistical outliersthey are only one possibility in a sea of many. They might come to pass, but you’re much better off preparing for the likelihood that they won’t. Our expectations matter. Anticipating a range of outcomes can make us feel better. If we expect the best and it happens, we’re merely satisfied. If we expect less and something better happens, we’re delighted. Knowing that the future is probably not going to be all sunshine and roses allows you to prepare for a variety of more likely outcomes, including some of the bad ones. Sometimes, too, when the worst-case scenario happens, it’s actually a huge relief. We realize it’s not all bad, we didn’t die, and we can manage if it happens again. Preparation and knowing you can handle a wide spectrum of possible challenges is how you get the peace of mind to be unsurprised by anything in between the worst and the best. ",
			"tokens": 940,
			"chunks": [
				{
					"article_title": "The Best-Case Outcomes Are Statistical Outliers",
					"article_url": "https://fs.blog/best-case/",
					"content": "There’s nothing wrong with hoping for the best. But the best-case scenario is rarely the one that comes to pass. Being realistic about what is likely to happen positions you for a range of possible outcomes and gives you peace of mind. We dream about achieving the best-case outcomes, but they are rare. We can’t forget to acknowledge all the other possibilities of what may happen if we want to position ourselves for success. “Hoping for the best, prepared for the worst, and unsurprised by anything in between.” Maya Angelou It’s okay to hope for the bestto look at whatever situation you’re in and say, “This time I have it figured out. This time it’s going to work.” First, having some degree of optimism is necessary for trying anything new. ",
					"content_token": 177,
					"embedding": []
				},
				{
					"article_title": "The Best-Case Outcomes Are Statistical Outliers",
					"article_url": "https://fs.blog/best-case/",
					"content": "If we weren’t overconfident, we’d never have the guts to do something as risky and unlikely to succeed as starting a business, entering a new relationship, or sending that cold email. Anticipating that a new venture will work helps you overcome obstacles and make it work. Second, sometimes we do have it figured out. Sometimes our solutions do make things better. Even when the best-case scenario comes to pass, however, it rarely unfolds exactly as planned. Some choices create unanticipated consequences that we have to deal with. We may encounter unexpected roadblocks due to a lack of information. Or the full implementation of all our ideas and aspirations might take a lot longer than we planned for. When you look back over history, we rarely find best-case outcomes. Sure, sometimes they happenmaybe more than we think, given not every moment of the past is recorded. ",
					"content_token": 182,
					"embedding": []
				},
				{
					"article_title": "The Best-Case Outcomes Are Statistical Outliers",
					"article_url": "https://fs.blog/best-case/",
					"content": "But let’s be honest: even historical wins, like developing the polio vaccine and figuring out how to produce clean drinking water, were not all smooth sailing. There are still people who are unable or unwilling to get the polio vaccine. And there are still many people in the world, even in developed countries like Canada, who don’t have access to clean drinking water. The best-case outcomes in these situationsa world without polio and a world with globally available clean drinking waterhave not happened, despite the existence of reliable, proven technology that can make these outcomes a reality. There are a lot of reasons why, in these situations, we haven’t achieved the best-case outcomes. Furthermore, situations like these are not unusual. We rarely achieve the dream. The more complicated a situation, the more people it involves, the more variables and dependencies that exist, the more it’s unlikely that it’s all going to work out. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "The Best-Case Outcomes Are Statistical Outliers",
					"article_url": "https://fs.blog/best-case/",
					"content": "If we narrow our scope and say, for example, the best-case scenario for this Friday night is that we don’t burn the pizza, we can all agree on a movie, and the power doesn’t go out, it’s more likely we’ll achieve it. There are fewer variables, so there’s a greater chance that this specific scenario will come to pass. The problem is that most of us plan as if we live in an easy-to-anticipate Friday night kind of world. We don’t. There are no magic bullets for the complicated challenges facing society. There is only hard work, planning for the wide spectrum of human behavior, adjusting to changing conditions, and perseverance. There are many possible outcomes for any given endeavor and only one that we consider the best case. That is why the best-case outcomes are statistical outliersthey are only one possibility in a sea of many. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "The Best-Case Outcomes Are Statistical Outliers",
					"article_url": "https://fs.blog/best-case/",
					"content": "They might come to pass, but you’re much better off preparing for the likelihood that they won’t. Our expectations matter. Anticipating a range of outcomes can make us feel better. If we expect the best and it happens, we’re merely satisfied. If we expect less and something better happens, we’re delighted. Knowing that the future is probably not going to be all sunshine and roses allows you to prepare for a variety of more likely outcomes, including some of the bad ones. Sometimes, too, when the worst-case scenario happens, it’s actually a huge relief. We realize it’s not all bad, we didn’t die, and we can manage if it happens again. Preparation and knowing you can handle a wide spectrum of possible challenges is how you get the peace of mind to be unsurprised by anything in between the worst and the best.",
					"content_token": 191,
					"embedding": []
				}
			]
		},
		{
			"title": "You’re Only As Good As Your Worst Day",
			"url": "https://fs.blog/worst-day/",
			"content": "We tend to measure performance by what happens when things are going well. Yet how people, organizations, companies, leaders, and other things do on their best day isn’t all that instructive. To find the truth, we need to look at what happens on the worst day.  “Anyone can steer the ship when the sea is calm. ”Publilius Syrus We laud athletes on a winning streak, startups with a skyrocketing valuation, hedge funds seeing record-breaking returns, and so on. But it’s easy to look good when everything goes according to plan and circumstances are calm. Anyone can succeed for a while, even if it’s just out of pure luck. It’s no great feat to do well if you’re not being challenged or tested. Watching what happens during a downswing is far more instructive.  Products and services are only as good as they are when they break, not when everything is functioning fine. When a program stops working, do you face a baffling error message with no further guidance or clear instructions for how to get help? Is customer service quick and easy to access at any time or does it require you to jump through endless convoluted hoops? Even if you’ve had a positive view of a product or service for years, a problem that takes forever to fix or a hostile response when you ask for help will no doubt make you take your business elsewhere. From a customer standpoint, companies are only as good as how they behave in a public relations crisis. Do they shirk blame and try to pin it elsewhere or do they take responsibility? Do they try to cover up what happened or do they come forward with the full truth? Do they ignore any damages or do they promise to make things better for everyone affectedno matter the cost? Reputations are fragile. One incident of bad behavior will linger in the minds of customers for a long time. From a financial standpoint, companies prove their worth when they show how they cope when something fundamental changes in the market or there’s a financial crisis. Do they keep persisting with the old business model under the illusion that what worked before should work again or do they reimagine their approach? Do they fire staff to preserve CEO bonuses or do they play the long game to ensure they’ll be able to attract top talent in the future? Do they crumble when there’s a powerful new competitor or do they rise to the challenge? Like companies, investors might be able to perform well in ideal conditions due to luck. But when the market crashes and there’s blood in the streets, very few will know how to cope or be prepared. Only the smartest will know how to survive or even profit. Leaders are only as good as how they lead during times of uncertainty and fear. Do they hide away from public sight or do they serve as a reassuring, sympathetic presence that brings everyone together? Do they do what’s defensible or what’s best for everyone in the long run? Are they forced to react in the moment or were they already prepared? Ask anyone to name the finest leaders in the history of their country and they’re not likely to name those who were in power during calm, peaceful times. They’ll name those who were at the helm during wars, economic crises, pandemics, natural disasters, and so onthose who never wavered from a vision and whose consistent, empathetic appearances gave people a sense of hope.  As individuals, we tell people the most about who we are when everything goes wrong. These times are also when we stand to learn the most about ourselves. Your kids might not remember how you behaved on a relaxed, sunny Saturday when work went well all week and you had little on your mind beyond playing with them. But they’re sure to remember how you behaved on the day when you’d lost your job due to a recession, you’d just had an argument with your partner, an unexpected bill arrived in the mail that morning, and then someone spilled spaghetti sauce on the couch. That’s the day when your behavior has the most to show them about what to model in the future. Your partner might not remember how you treated them when you were lying on a beach on holiday together with all of your worries far away and a good book in hand. But they’re sure to remember how you treated them when you had your worst disagreement ever, over a problem that seemed insurmountable and involved complex emotions. That’s the moment when they might well make a decision about whether they’re in this for the long haul. Your boss might not remember the work you did on an average week when everything went to plan. But they’re sure to remember the time when you stepped up, stretched the limits of your abilities, and delivered what seemed impossible at short notice while everything around you was on fire. That’s what they’ll recall when thinking about what you’re capable of.  You’re only as good as your worst day. Not because what you do the rest of the time doesn’t matter. Not because you should be expected to be perfect under immense stress or to behave according to plan when everything goes awry. But because what you do on your worst day is impossible to fake. It’s honest signaling. There’s little time for posturing or stalling. On your worst day, you reveal whether you’ve been planning for the possibility of disaster or just coasting along enjoying the good times. Your plans and preparation or lack thereof show how much you really care about the people who depend on you. You get to build and strengthen bonds in ways that will last a lifetime, or you risk destroying relationships in moments. You get to build trust and respect or you might break what you have irreparably. Your worst day is a chance to show your best qualities, to stand out, and to learn an enormous amount about yourself. Very few people plan or prepare for what they’ll do and how they’ll act during those times. Those who do might well end up turning their worst day into their best. ",
			"tokens": 1276,
			"chunks": [
				{
					"article_title": "You’re Only As Good As Your Worst Day",
					"article_url": "https://fs.blog/worst-day/",
					"content": "We tend to measure performance by what happens when things are going well. Yet how people, organizations, companies, leaders, and other things do on their best day isn’t all that instructive. To find the truth, we need to look at what happens on the worst day.  “Anyone can steer the ship when the sea is calm. ”Publilius Syrus We laud athletes on a winning streak, startups with a skyrocketing valuation, hedge funds seeing record-breaking returns, and so on. But it’s easy to look good when everything goes according to plan and circumstances are calm. Anyone can succeed for a while, even if it’s just out of pure luck. It’s no great feat to do well if you’re not being challenged or tested. Watching what happens during a downswing is far more instructive. ",
					"content_token": 182,
					"embedding": []
				},
				{
					"article_title": "You’re Only As Good As Your Worst Day",
					"article_url": "https://fs.blog/worst-day/",
					"content": " Products and services are only as good as they are when they break, not when everything is functioning fine. When a program stops working, do you face a baffling error message with no further guidance or clear instructions for how to get help? Is customer service quick and easy to access at any time or does it require you to jump through endless convoluted hoops? Even if you’ve had a positive view of a product or service for years, a problem that takes forever to fix or a hostile response when you ask for help will no doubt make you take your business elsewhere. From a customer standpoint, companies are only as good as how they behave in a public relations crisis. Do they shirk blame and try to pin it elsewhere or do they take responsibility? Do they try to cover up what happened or do they come forward with the full truth? Do they ignore any damages or do they promise to make things better for everyone affectedno matter the cost? Reputations are fragile. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "You’re Only As Good As Your Worst Day",
					"article_url": "https://fs.blog/worst-day/",
					"content": "One incident of bad behavior will linger in the minds of customers for a long time. From a financial standpoint, companies prove their worth when they show how they cope when something fundamental changes in the market or there’s a financial crisis. Do they keep persisting with the old business model under the illusion that what worked before should work again or do they reimagine their approach? Do they fire staff to preserve CEO bonuses or do they play the long game to ensure they’ll be able to attract top talent in the future? Do they crumble when there’s a powerful new competitor or do they rise to the challenge? Like companies, investors might be able to perform well in ideal conditions due to luck. But when the market crashes and there’s blood in the streets, very few will know how to cope or be prepared. Only the smartest will know how to survive or even profit. Leaders are only as good as how they lead during times of uncertainty and fear. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "You’re Only As Good As Your Worst Day",
					"article_url": "https://fs.blog/worst-day/",
					"content": "Do they hide away from public sight or do they serve as a reassuring, sympathetic presence that brings everyone together? Do they do what’s defensible or what’s best for everyone in the long run? Are they forced to react in the moment or were they already prepared? Ask anyone to name the finest leaders in the history of their country and they’re not likely to name those who were in power during calm, peaceful times. They’ll name those who were at the helm during wars, economic crises, pandemics, natural disasters, and so onthose who never wavered from a vision and whose consistent, empathetic appearances gave people a sense of hope.  As individuals, we tell people the most about who we are when everything goes wrong. These times are also when we stand to learn the most about ourselves. ",
					"content_token": 174,
					"embedding": []
				},
				{
					"article_title": "You’re Only As Good As Your Worst Day",
					"article_url": "https://fs.blog/worst-day/",
					"content": "Your kids might not remember how you behaved on a relaxed, sunny Saturday when work went well all week and you had little on your mind beyond playing with them. But they’re sure to remember how you behaved on the day when you’d lost your job due to a recession, you’d just had an argument with your partner, an unexpected bill arrived in the mail that morning, and then someone spilled spaghetti sauce on the couch. That’s the day when your behavior has the most to show them about what to model in the future. Your partner might not remember how you treated them when you were lying on a beach on holiday together with all of your worries far away and a good book in hand. But they’re sure to remember how you treated them when you had your worst disagreement ever, over a problem that seemed insurmountable and involved complex emotions. ",
					"content_token": 181,
					"embedding": []
				},
				{
					"article_title": "You’re Only As Good As Your Worst Day",
					"article_url": "https://fs.blog/worst-day/",
					"content": "That’s the moment when they might well make a decision about whether they’re in this for the long haul. Your boss might not remember the work you did on an average week when everything went to plan. But they’re sure to remember the time when you stepped up, stretched the limits of your abilities, and delivered what seemed impossible at short notice while everything around you was on fire. That’s what they’ll recall when thinking about what you’re capable of.  You’re only as good as your worst day. Not because what you do the rest of the time doesn’t matter. Not because you should be expected to be perfect under immense stress or to behave according to plan when everything goes awry. But because what you do on your worst day is impossible to fake. It’s honest signaling. There’s little time for posturing or stalling. ",
					"content_token": 192,
					"embedding": []
				},
				{
					"article_title": "You’re Only As Good As Your Worst Day",
					"article_url": "https://fs.blog/worst-day/",
					"content": "On your worst day, you reveal whether you’ve been planning for the possibility of disaster or just coasting along enjoying the good times. Your plans and preparation or lack thereof show how much you really care about the people who depend on you. You get to build and strengthen bonds in ways that will last a lifetime, or you risk destroying relationships in moments. You get to build trust and respect or you might break what you have irreparably. Your worst day is a chance to show your best qualities, to stand out, and to learn an enormous amount about yourself. Very few people plan or prepare for what they’ll do and how they’ll act during those times. Those who do might well end up turning their worst day into their best.",
					"content_token": 155,
					"embedding": []
				}
			]
		},
		{
			"title": "Explore Or Exploit? How To Choose New Opportunities",
			"url": "https://fs.blog/explore-or-exploit-how-to-choose-new-opportunities/",
			"content": "One big challenge we all face in life is knowing when to explore new opportunities, and when to double down on existing ones. Explore vs exploit algorithms – and poetry – teach us that it’s vital to consider how much time we have, how we can best avoid regrets, and what we can learn from failures.  “Had we but world enough, and time,This coyness, Lady, were no crime.We would sit down and think which wayTo walk and pass our long love’s day . . . Let us roll all our strength and allOur sweetness up into one ball,And tear our pleasures with rough strifeThrough the iron gates of life:Thus, though we cannot make our sunStand still, yet we will make him run.”Andrew Marvell, To His Coy Mistress Of all the questions life demands we answer, “To explore or to exploit?” is one we have to confront almost every day. Do we keep trying new restaurants? Do we keep learning new ideas? Do we keep making new friends? Or do we enjoy what we’ve come to find and love? There is no doubt that humans are great at exploring, as most generalist species are. Not content to stay in that cave, hunt that animal, or keep doing it the way our grandmother taught us, humans owe at least part of our success due to our willingness to explore. But when is what you’ve already explored enough? When can you finally settle down to enjoy the fruits of your exploration? When can you be content to exploit the knowledge you already have? Turns out that there are algorithms for that. In Algorithms to Live By, authors Brian Christian and Tom Griffiths devote an entire chapter to how computer algorithms deal with the exploreexploit conundrum and how you can apply those lessons to the same tension in your life.  How much time do you have? One of the most important factors in determining whether to continue exploring or to exploit what you’ve got is time. Christian and Griffiths explain that “seizing a day and seizing a lifetime are two entirely different endeavors. . . . When balancing favorite experiences and new ones, nothing matters as much as the interval over which we plan to enjoy them.” Time intervals can be a construct of your immediate circumstances, like the boundaries provided by a two-week vacation. For a lot of us, the last night in a lovely foreign place will see us eating at the best restaurant we have found so far. Time intervals can also be considered over the arc of your life in general. Children are consummate explorers, but as we grow up, the choice to exploit becomes more of a daily decision. How would your choices today be impacted if you knew you were going to live another five years? Twenty years? Forty years? Christian and Griffiths advise, “Explore when you will have time to use the resulting knowledge, exploit when you’re ready to cash in.” “I have known days like that, of warm winds drowsing in the heatof noon and all of summer spinning slowly on its reel,days briefly lived, that leave long music in the mindmore sweet than truth: I play them and rewind.”Russell Hoban, Summer Recorded Sometimes we are too quick to stop exploring. We have these amazing days and magical experiences, and we want to keep repeating them forever. However, changes in ourselves and the world around us are inevitable, and so committing to a path of exploitation too early leaves us unable to adapt. As much as it can be hard to walk away from that perfect day, Christian and Griffiths explain that “exploration in itself has value, since trying new things increases our chances of finding the best. So taking the future into account, rather than focusing just on the present, drives us toward novelty.” “Like as the waves make towards the pebbled shore,So do our minutes hasten to their end;Each changing place with that which goes before,In sequent toil all forwards do contend.”William Shakespeare, Sonnet 60 There is no doubt that for many of us time is our most precious resource. We never seem to have enough, and we want to maximize the value we get from how we choose to use it. So when deciding between whether to enjoy what you have or search for something better, adding time to your decision-making process can help point the way.  Minimizing the pain of regret The threat of regret looms over many exploreexploit considerations. We can regret both not searching for something better and not taking the time to enjoy what we already have. The problem with regret is that we don’t have it in advance of a poor decision. Sometimes, second-order thinking can be used as a preventative tool. But often it is when you look back over a decision that regret comes out. Christian and Griffiths define regret as “the result of comparing what we actually did with what would have been best in hindsight.” “Does the road wind uphill all the way?Yes, to the very end.Will the day’s journey take the whole long day?From morn to night, my friend.Shall I find comfort, travel-sore and weak?Of labour you shall find the sum.Will there be beds for me and all who seek?Yea, beds for all who come.”Christina Rossetti, Up-Hill If we want to minimize regret, especially in exploration, we can try to learn from those who have come before. As we choose to wander forth into new territory, however, it’s natural to wonder if we’ll regret our decision to try something new. According to Christian and Griffiths, the mathematics that underlie exploreexploit algorithms show that “you should assume the best about new people and new things, in the absence of evidence to the contrary. In the long run, optimism is the best prevention for regret.” Why? Because by being optimistic about the possibilities that are out there, you’ll explore enough that the one thing you won’t regret is missed opportunity. This is similar to one of the most effective strategies in game theory: tit for tat. Start out by being nice, then reciprocate whatever behavior you receive. It often works better paired with the occasional bout of forgiveness. “Tell me, tell me, smiling child,What the past is like to thee?An Autumn evening soft and mildWith a wind that sighs mournfully.’ Tell me, what is the present hour?A green and flowery sprayWhere a young bird sits gathering its powerTo mount and fly away.’ And what is the future, happy one?A sea beneath a cloudless sun;A mighty, glorious, dazzling seaStretching into infinity.’”Emily Bronte, Past, Present, Future  The accumulation of knowledge Christian and Griffiths write that “it’s rare that we make an isolated decision, where the outcome doesn’t provide us with any information that we’ll use to make other decisions in the future.” Not all of our explorations are going to lead us to something better, but many of them are. Not all of our exploitations are going to be satisfying, but with enough exploration behind us, many of them will. Failures are, after all, just information we can use to make better explore or exploit decisions in the future. “You knowat least you ought to know,For I have often told you soThat children are never allowedTo leave their nurses in a crowd.Now this was Jim’s especial foible,He ran away when he was able,And on this inauspicious dayHe slipped his hand and ran away!He hadn’t gone a yard whenBang!With open jaws, a lion sprang,And hungrily began to eatThe boy: beginning at his feet.”Hilaire Belloc, Jim Who Ran Away from His Nurse, and Was Eaten by a Lion Most importantly, we shouldn’t let our early exploration mishaps prevent us from continuing to push our boundaries as we grow up. Exploration is necessary in order to exploit and enjoy the knowledge hard won along the way.",
			"tokens": 1710,
			"chunks": [
				{
					"article_title": "Explore Or Exploit? How To Choose New Opportunities",
					"article_url": "https://fs.blog/explore-or-exploit-how-to-choose-new-opportunities/",
					"content": "One big challenge we all face in life is knowing when to explore new opportunities, and when to double down on existing ones. Explore vs exploit algorithms – and poetry – teach us that it’s vital to consider how much time we have, how we can best avoid regrets, and what we can learn from failures.  “Had we but world enough, and time,This coyness, Lady, were no crime.We would sit down and think which wayTo walk and pass our long love’s day    Let us roll all our strength and allOur sweetness up into one ball,And tear our pleasures with rough strifeThrough the iron gates of life:Thus, though we cannot make our sunStand still, yet we will make him run.”Andrew Marvell, To His Coy Mistress Of all the questions life demands we answer, “To explore or to exploit?” is one we have to confront almost every day. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "Explore Or Exploit? How To Choose New Opportunities",
					"article_url": "https://fs.blog/explore-or-exploit-how-to-choose-new-opportunities/",
					"content": "Do we keep trying new restaurants? Do we keep learning new ideas? Do we keep making new friends? Or do we enjoy what we’ve come to find and love? There is no doubt that humans are great at exploring, as most generalist species are. Not content to stay in that cave, hunt that animal, or keep doing it the way our grandmother taught us, humans owe at least part of our success due to our willingness to explore. But when is what you’ve already explored enough? When can you finally settle down to enjoy the fruits of your exploration? When can you be content to exploit the knowledge you already have? Turns out that there are algorithms for that. In Algorithms to Live By, authors Brian Christian and Tom Griffiths devote an entire chapter to how computer algorithms deal with the exploreexploit conundrum and how you can apply those lessons to the same tension in your life. ",
					"content_token": 187,
					"embedding": []
				},
				{
					"article_title": "Explore Or Exploit? How To Choose New Opportunities",
					"article_url": "https://fs.blog/explore-or-exploit-how-to-choose-new-opportunities/",
					"content": " How much time do you have? One of the most important factors in determining whether to continue exploring or to exploit what you’ve got is time. Christian and Griffiths explain that “seizing a day and seizing a lifetime are two entirely different endeavors.    When balancing favorite experiences and new ones, nothing matters as much as the interval over which we plan to enjoy them.” Time intervals can be a construct of your immediate circumstances, like the boundaries provided by a two-week vacation. For a lot of us, the last night in a lovely foreign place will see us eating at the best restaurant we have found so far. Time intervals can also be considered over the arc of your life in general. Children are consummate explorers, but as we grow up, the choice to exploit becomes more of a daily decision. ",
					"content_token": 170,
					"embedding": []
				},
				{
					"article_title": "Explore Or Exploit? How To Choose New Opportunities",
					"article_url": "https://fs.blog/explore-or-exploit-how-to-choose-new-opportunities/",
					"content": "How would your choices today be impacted if you knew you were going to live another five years? Twenty years? Forty years? Christian and Griffiths advise, “Explore when you will have time to use the resulting knowledge, exploit when you’re ready to cash in.” “I have known days like that, of warm winds drowsing in the heatof noon and all of summer spinning slowly on its reel,days briefly lived, that leave long music in the mindmore sweet than truth: I play them and rewind.”Russell Hoban, Summer Recorded Sometimes we are too quick to stop exploring. We have these amazing days and magical experiences, and we want to keep repeating them forever. However, changes in ourselves and the world around us are inevitable, and so committing to a path of exploitation too early leaves us unable to adapt. ",
					"content_token": 176,
					"embedding": []
				},
				{
					"article_title": "Explore Or Exploit? How To Choose New Opportunities",
					"article_url": "https://fs.blog/explore-or-exploit-how-to-choose-new-opportunities/",
					"content": "As much as it can be hard to walk away from that perfect day, Christian and Griffiths explain that “exploration in itself has value, since trying new things increases our chances of finding the best. So taking the future into account, rather than focusing just on the present, drives us toward novelty.” “Like as the waves make towards the pebbled shore,So do our minutes hasten to their end;Each changing place with that which goes before,In sequent toil all forwards do contend.”William Shakespeare, Sonnet 60 There is no doubt that for many of us time is our most precious resource. We never seem to have enough, and we want to maximize the value we get from how we choose to use it. So when deciding between whether to enjoy what you have or search for something better, adding time to your decision-making process can help point the way. ",
					"content_token": 186,
					"embedding": []
				},
				{
					"article_title": "Explore Or Exploit? How To Choose New Opportunities",
					"article_url": "https://fs.blog/explore-or-exploit-how-to-choose-new-opportunities/",
					"content": " Minimizing the pain of regret The threat of regret looms over many exploreexploit considerations. We can regret both not searching for something better and not taking the time to enjoy what we already have. The problem with regret is that we don’t have it in advance of a poor decision. Sometimes, second-order thinking can be used as a preventative tool. But often it is when you look back over a decision that regret comes out. ",
					"content_token": 92,
					"embedding": []
				},
				{
					"article_title": "Explore Or Exploit? How To Choose New Opportunities",
					"article_url": "https://fs.blog/explore-or-exploit-how-to-choose-new-opportunities/",
					"content": "Christian and Griffiths define regret as “the result of comparing what we actually did with what would have been best in hindsight.” “Does the road wind uphill all the way?Yes, to the very end.Will the day’s journey take the whole long day?From morn to night, my friend.Shall I find comfort, travel-sore and weak?Of labour you shall find the sum.Will there be beds for me and all who seek?Yea, beds for all who come.”Christina Rossetti, Up-Hill If we want to minimize regret, especially in exploration, we can try to learn from those who have come before. As we choose to wander forth into new territory, however, it’s natural to wonder if we’ll regret our decision to try something new. ",
					"content_token": 175,
					"embedding": []
				},
				{
					"article_title": "Explore Or Exploit? How To Choose New Opportunities",
					"article_url": "https://fs.blog/explore-or-exploit-how-to-choose-new-opportunities/",
					"content": "According to Christian and Griffiths, the mathematics that underlie exploreexploit algorithms show that “you should assume the best about new people and new things, in the absence of evidence to the contrary. In the long run, optimism is the best prevention for regret.” Why? Because by being optimistic about the possibilities that are out there, you’ll explore enough that the one thing you won’t regret is missed opportunity. This is similar to one of the most effective strategies in game theory: tit for tat. Start out by being nice, then reciprocate whatever behavior you receive. It often works better paired with the occasional bout of forgiveness. ",
					"content_token": 136,
					"embedding": []
				},
				{
					"article_title": "Explore Or Exploit? How To Choose New Opportunities",
					"article_url": "https://fs.blog/explore-or-exploit-how-to-choose-new-opportunities/",
					"content": "“Tell me, tell me, smiling child,What the past is like to thee?An Autumn evening soft and mildWith a wind that sighs mournfully.’ Tell me, what is the present hour?A green and flowery sprayWhere a young bird sits gathering its powerTo mount and fly away.’ And what is the future, happy one?A sea beneath a cloudless sun;A mighty, glorious, dazzling seaStretching into infinity.’”Emily Bronte, Past, Present, Future  The accumulation of knowledge Christian and Griffiths write that “it’s rare that we make an isolated decision, where the outcome doesn’t provide us with any information that we’ll use to make other decisions in the future.” Not all of our explorations are going to lead us to something better, but many of them are. ",
					"content_token": 185,
					"embedding": []
				},
				{
					"article_title": "Explore Or Exploit? How To Choose New Opportunities",
					"article_url": "https://fs.blog/explore-or-exploit-how-to-choose-new-opportunities/",
					"content": "Not all of our exploitations are going to be satisfying, but with enough exploration behind us, many of them will. Failures are, after all, just information we can use to make better explore or exploit decisions in the future. “You knowat least you ought to know,For I have often told you soThat children are never allowedTo leave their nurses in a crowd.Now this was Jim’s especial foible,He ran away when he was able,And on this inauspicious dayHe slipped his hand and ran away!He hadn’t gone a yard whenBang!With open jaws, a lion sprang,And hungrily began to eatThe boy: beginning at his feet.”Hilaire Belloc, Jim Who Ran Away from His Nurse, and Was Eaten by a Lion Most importantly, we shouldn’t let our early exploration mishaps prevent us from continuing to push our boundaries as we grow up. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "Explore Or Exploit? How To Choose New Opportunities",
					"article_url": "https://fs.blog/explore-or-exploit-how-to-choose-new-opportunities/",
					"content": "Exploration is necessary in order to exploit and enjoy the knowledge hard won along the way.",
					"content_token": 18,
					"embedding": []
				}
			]
		},
		{
			"title": "Mental Models for Career Changes",
			"url": "https://fs.blog/mental-models-for-career-changes/",
			"content": "Career changes are some of the biggest moves we will ever make, but they don’t have to be daunting. Using mental models to make decisions we determine where we want to go and how to get there. The result is a change that aligns with the person we are, as well as the person we want to be. We’ve all been there: you’re at a job, and you know it’s not for you anymore. You come in drained, you’re not excited on a Monday morning, and you feel like you could be using your time so much better. It’s not the people, and it’s not the organization. It’s the work. It’s become boring, unfulfilling, or redundant, and you know you want to do something different. But what? Just deciding to change careers doesn’t get you very far because there are more areas to work in than you know about. A big change often involves some retraining. A career shift will impact your personal life. At the end of it all, you want to be happier but know there are no guarantees. How do you find a clear path forward? No matter how ready you think you are to make a move, career changes are daunting. The stress of leaving what you’re comfortable with to venture into foreign territory stops many people from taking the first step toward something new. It doesn’t have to be this way. Using mental models can help you clarify the direction you want to go and plan for how to get there. They are tools that will give you more control over your career and more confidence in your decisions. When you do the work up front by examining your situation through the lens of a few mental models, you set yourself up for fewer regrets and more satisfaction down the road.  Get in touch with yourself Before you can decide which change to make, you need to get in touch with yourself. No change will be the right one if it doesn’t align with what you want to get out of life. First, do you know where you want to go? Are you moving with direction or just moving? As a mental model, velocity reminds us there is a difference between speed and direction. It’s easy to move fast without getting anywhere. We can stay busy all day without achieving our goals. Without considering our velocity, we run a huge risk of getting sidetracked by things that make us move faster more money, a title on a business card without that movement actually leading us where we want to end up. As the old saying goes, we want to run to something, not from something. When you start articulating your desired direction, you give yourself clear purpose in your career. It will be easier to play the long game because you know that everything you are doing is leading somewhere you want to be. When it comes to changing careers, there are a lot of options. Using the mental model of velocity will help you focus on and identify the best opportunities. Once you know where you want to end up, it’s often useful to work backward to where you are now. This is known as inversion. Start at the end and carefully consider the events that get you there in reverse order. For example, it could be something as simple as waking up happy and excited to work every day. What needs to be true in order for that to be a reality? Are you working from home, having a quiet cup of coffee as you prepare to do some creative work? Are you working on projects aligned with your values? Are you contributing to making the world a better place? Are you in an intense, collaborative team environment? Doing an inversion exercise helps you identify the elements needed for you to achieve success. Once you identify your requirements, you can use that list to evaluate opportunities that come up. Inversion will help you recognize critical factors, like finances or the support of your family, that will be necessary to get to where you want to go. If your dream direction requires you to learn a new skill or work at a junior level while you ramp up on the knowledge you’ll need, you might need to live off some savings in the short term. Inversion, combined with velocity, will help you create the foundation you need now to take action when the right time comes. Finally, the last step before you start evaluating the career environment is taking stock of the skills you already have. Why do you need to do this? So you know what you can repurpose. Here, you’re using the concept of exaptation, which is part of the broader adaptation model in biology. Exaptation refers to traits that evolved for one purpose and then, through natural selection, were used for completely unrelated capabilities. For instance, feathers probably evolved for insulation. It was only much later that they turned out to be useful for flying. History is littered with examples of technologies or tools invented for one purpose that later became the foundation for something completely different. Did you know that Play-Doh was originally created to clean coal soot off walls? And bubble wrap was originally envisioned as material for shower curtains. Using this model is partly about getting out of the “functional fixedness” mindset. You want to look at your skills, talents, and knowledge and ask of each one: what else could this be used for? Too often we fail to realize just how versatile the experience we’ve built up over the years is. We’re great at using forks to eat, but they can also be used to brush hair, dig in a garden, and pin things to walls. Being great at presenting the monthly status update doesn’t mean you’re good at presenting monthly status updates. Rather, it means you can articulate yourself well, parse information for a diverse audience, and build networks to get the right information. Now, what else can those skills be used for?  Evaluate the environment Looking at different careers, we’re usually in a situation where the “map is not the territory.” It’s hard to know how great or terrible a job is until you actually do it. We often have two types of maps for the careers we wish we had: maps of the highlights, success stories, and opinions of people who love the work and maps based on how much we love the field or discipline ourselves. The territory of the day-to-day work of these careers, however, is very different from what those two maps tell us. In order to determine if a particular career will work for us, we need better maps. For example, the reality of being an actor isn’t just the movies and programs you see them in. It’s audition after audition, with more rejections than roles. It’s intense competition and job insecurity. Being a research scientist at a university isn’t just immersing yourself in a subject you love. It’s grant applications and teaching and navigating the bureaucracy of academia. In order to build a more comprehensive map of your dream job, do your research on as large a sample size as possible. Talk to people doing the job you want. Talk to people who work in the organization. Talk to the ones that enjoy it. Talk to the ones who quit. Try to get an accurate picture of what the day-to-day is like. Very few jobs are one-dimensional. They involve things like administrative tasks, networking, project management, and accountability. How much of your day will be spent doing paperwork or updating your coworkers? How much of a connection do you need to maintain with people outside the organization? How many people will you be dependent on? What are they like? And who will you be working for? It’s not a good idea to become a writer just because you want to tell stories, open a restaurant just because you like to cook, or become a landscape designer just because you enjoy being outside. Those motivations are good places to startbecause it’s equally terrible to become a lawyer just because your parents wanted you to. But you can’t stop with what you like. There isn’t a job in the world that’s pleasurable and fulfilling 100 of the time. You give yourself a much higher chance of being satisfied with your career change if you take the time to learn as much as you can about the territory beforehand.  Elements of planning You know which direction you’re heading in, and you’ve identified a great new career possibility. Now what? Planning for change is a crucial component of switching careers. Two models, global and local maxima and activation energy, can help us identify what we need to plan. Global and local maxima refers to the high values in a mathematical function. On a graph, it’s a wavy curve with peaks and valleys. The highest peak in a section is a local maximum. The highest peak across the entire graph is the global maximum. Activation energy comes from chemistry, and is the amount of energy needed to see a reaction through to its conclusion. One of the things global and local maxima teaches us is that sometimes you have to go down a hill in order to climb up a new one. To move from a local maximum to a higher peak you have to go through a local minimum, a valley. Too often we just want to go higher right away, or at the very least we want to make a lateral move. We perceive going down as taking a step backward. A common problem is when we tie our self-worth to our salary and therefore reject any opportunities that won’t pay us as much as we’re currently making. The same goes for job titles; no one wants to be a junior anything in their mid-forties. But it’s impossible to get to the next peak if we won’t walk through the valley. If you look at your career change through the lens of global and local maxima, you will see that steps down can also be steps forward. Activation energy is another great model to use in the planning phase because it requires you to think about the real effort required for sustained change. You need to plan not just for making a change but also for seeing it through until the new thing has time to take hold. Do you have enough in the bank to support yourself if you need to retrain or take a pay cut? Do you have the emotional support to help you through the challenges of taking on a brand-new career? Just like fires don’t start with one match and a giant log, you have to plan for what you need between now and your desired result. What do you need to keep that reaction going so the flame from the match leads to the log catching fire? The same kind of thinking needs to inform your planning. After you’ve taken the first step, what will you need to keep you moving in the direction you want to go?  After you’ve done all the work After getting in touch with yourself, doing all your research, identifying possible paths, and planning for what you need to do to walk them to the end, it can still be hard to make a decision. You’ve uncovered so many nuances and encountered so many ideas that you feel overwhelmed. The reality is, when it comes to career change, there often is no perfect decision. You likely have more than one option, and whatever you choose, there’s going to be a lot of work involved. One final model you can use is probabilistic thinking. In this particular situation, it can be helpful to use a Bayesian casino. A Bayesian casino is a thought experiment where you imagine walking up to a casino game, like roulette, and quantifying how much you would bet on any particular outcome. Let’s say when investigating your career change, you’ve narrowed it down to two options. Which one would you bet on for being the better choice one year later? And how much would you part with? If you’d bet ten dollars on black, then you probably need to take a fresh look at the research you’ve done. Maybe go talk to more people, or broaden your thinking. If you’re willing to put down thousands of dollars on red, that’s very likely the right decision for you. It’s important in this thought experiment to fully imagine yourself making the bet. Imagine the money in your bank account. Imagine withdrawing it and physically putting it down on the table. How much you’re willing to part with regarding a particular career choice says a lot about how good that choice is likely to be for you. Probabilistic thinking isn’t a predictor of the future. With any big career move, there are inevitably a lot of unknowns. There are no guarantees that any choice is going to be the right one. The Bayesian casino just helps you quantify your thinking based on the knowledge you have at this moment in time. As new information comes in, return to the casino and see if your bets change.  Conclusion Career changes are some of the biggest moves we will ever make, but they don’t have to be daunting. Using mental models helps us find both the direction we want to go and a path we can take to get there. The result is a change that aligns with the person we are, as well as the person we want to be.",
			"tokens": 2767,
			"chunks": [
				{
					"article_title": "Mental Models for Career Changes",
					"article_url": "https://fs.blog/mental-models-for-career-changes/",
					"content": "Career changes are some of the biggest moves we will ever make, but they don’t have to be daunting. Using mental models to make decisions we determine where we want to go and how to get there. The result is a change that aligns with the person we are, as well as the person we want to be. We’ve all been there: you’re at a job, and you know it’s not for you anymore. You come in drained, you’re not excited on a Monday morning, and you feel like you could be using your time so much better. It’s not the people, and it’s not the organization. It’s the work. It’s become boring, unfulfilling, or redundant, and you know you want to do something different. ",
					"content_token": 176,
					"embedding": []
				},
				{
					"article_title": "Mental Models for Career Changes",
					"article_url": "https://fs.blog/mental-models-for-career-changes/",
					"content": "But what? Just deciding to change careers doesn’t get you very far because there are more areas to work in than you know about. A big change often involves some retraining. A career shift will impact your personal life. At the end of it all, you want to be happier but know there are no guarantees. How do you find a clear path forward? No matter how ready you think you are to make a move, career changes are daunting. The stress of leaving what you’re comfortable with to venture into foreign territory stops many people from taking the first step toward something new. It doesn’t have to be this way. Using mental models can help you clarify the direction you want to go and plan for how to get there. They are tools that will give you more control over your career and more confidence in your decisions. ",
					"content_token": 173,
					"embedding": []
				},
				{
					"article_title": "Mental Models for Career Changes",
					"article_url": "https://fs.blog/mental-models-for-career-changes/",
					"content": "When you do the work up front by examining your situation through the lens of a few mental models, you set yourself up for fewer regrets and more satisfaction down the road.  Get in touch with yourself Before you can decide which change to make, you need to get in touch with yourself. No change will be the right one if it doesn’t align with what you want to get out of life. First, do you know where you want to go? Are you moving with direction or just moving? As a mental model, velocity reminds us there is a difference between speed and direction. It’s easy to move fast without getting anywhere. We can stay busy all day without achieving our goals. Without considering our velocity, we run a huge risk of getting sidetracked by things that make us move faster more money, a title on a business card without that movement actually leading us where we want to end up. ",
					"content_token": 187,
					"embedding": []
				},
				{
					"article_title": "Mental Models for Career Changes",
					"article_url": "https://fs.blog/mental-models-for-career-changes/",
					"content": "As the old saying goes, we want to run to something, not from something. When you start articulating your desired direction, you give yourself clear purpose in your career. It will be easier to play the long game because you know that everything you are doing is leading somewhere you want to be. When it comes to changing careers, there are a lot of options. Using the mental model of velocity will help you focus on and identify the best opportunities. Once you know where you want to end up, it’s often useful to work backward to where you are now. This is known as inversion. Start at the end and carefully consider the events that get you there in reverse order. For example, it could be something as simple as waking up happy and excited to work every day. ",
					"content_token": 161,
					"embedding": []
				},
				{
					"article_title": "Mental Models for Career Changes",
					"article_url": "https://fs.blog/mental-models-for-career-changes/",
					"content": "What needs to be true in order for that to be a reality? Are you working from home, having a quiet cup of coffee as you prepare to do some creative work? Are you working on projects aligned with your values? Are you contributing to making the world a better place? Are you in an intense, collaborative team environment? Doing an inversion exercise helps you identify the elements needed for you to achieve success. Once you identify your requirements, you can use that list to evaluate opportunities that come up. Inversion will help you recognize critical factors, like finances or the support of your family, that will be necessary to get to where you want to go. If your dream direction requires you to learn a new skill or work at a junior level while you ramp up on the knowledge you’ll need, you might need to live off some savings in the short term. Inversion, combined with velocity, will help you create the foundation you need now to take action when the right time comes. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "Mental Models for Career Changes",
					"article_url": "https://fs.blog/mental-models-for-career-changes/",
					"content": "Finally, the last step before you start evaluating the career environment is taking stock of the skills you already have. Why do you need to do this? So you know what you can repurpose. Here, you’re using the concept of exaptation, which is part of the broader adaptation model in biology. Exaptation refers to traits that evolved for one purpose and then, through natural selection, were used for completely unrelated capabilities. For instance, feathers probably evolved for insulation. It was only much later that they turned out to be useful for flying. History is littered with examples of technologies or tools invented for one purpose that later became the foundation for something completely different. Did you know that Play-Doh was originally created to clean coal soot off walls? And bubble wrap was originally envisioned as material for shower curtains. Using this model is partly about getting out of the “functional fixedness” mindset. ",
					"content_token": 188,
					"embedding": []
				},
				{
					"article_title": "Mental Models for Career Changes",
					"article_url": "https://fs.blog/mental-models-for-career-changes/",
					"content": "You want to look at your skills, talents, and knowledge and ask of each one: what else could this be used for? Too often we fail to realize just how versatile the experience we’ve built up over the years is. We’re great at using forks to eat, but they can also be used to brush hair, dig in a garden, and pin things to walls. Being great at presenting the monthly status update doesn’t mean you’re good at presenting monthly status updates. Rather, it means you can articulate yourself well, parse information for a diverse audience, and build networks to get the right information. Now, what else can those skills be used for?  Evaluate the environment Looking at different careers, we’re usually in a situation where the “map is not the territory.” It’s hard to know how great or terrible a job is until you actually do it. ",
					"content_token": 192,
					"embedding": []
				},
				{
					"article_title": "Mental Models for Career Changes",
					"article_url": "https://fs.blog/mental-models-for-career-changes/",
					"content": "We often have two types of maps for the careers we wish we had: maps of the highlights, success stories, and opinions of people who love the work and maps based on how much we love the field or discipline ourselves. The territory of the day-to-day work of these careers, however, is very different from what those two maps tell us. In order to determine if a particular career will work for us, we need better maps. For example, the reality of being an actor isn’t just the movies and programs you see them in. It’s audition after audition, with more rejections than roles. It’s intense competition and job insecurity. Being a research scientist at a university isn’t just immersing yourself in a subject you love. It’s grant applications and teaching and navigating the bureaucracy of academia. In order to build a more comprehensive map of your dream job, do your research on as large a sample size as possible. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "Mental Models for Career Changes",
					"article_url": "https://fs.blog/mental-models-for-career-changes/",
					"content": "Talk to people doing the job you want. Talk to people who work in the organization. Talk to the ones that enjoy it. Talk to the ones who quit. Try to get an accurate picture of what the day-to-day is like. Very few jobs are one-dimensional. They involve things like administrative tasks, networking, project management, and accountability. How much of your day will be spent doing paperwork or updating your coworkers? How much of a connection do you need to maintain with people outside the organization? How many people will you be dependent on? What are they like? And who will you be working for? It’s not a good idea to become a writer just because you want to tell stories, open a restaurant just because you like to cook, or become a landscape designer just because you enjoy being outside. Those motivations are good places to startbecause it’s equally terrible to become a lawyer just because your parents wanted you to. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "Mental Models for Career Changes",
					"article_url": "https://fs.blog/mental-models-for-career-changes/",
					"content": "But you can’t stop with what you like. There isn’t a job in the world that’s pleasurable and fulfilling 100 of the time. You give yourself a much higher chance of being satisfied with your career change if you take the time to learn as much as you can about the territory beforehand.  Elements of planning You know which direction you’re heading in, and you’ve identified a great new career possibility. Now what? Planning for change is a crucial component of switching careers. Two models, global and local maxima and activation energy, can help us identify what we need to plan. Global and local maxima refers to the high values in a mathematical function. On a graph, it’s a wavy curve with peaks and valleys. The highest peak in a section is a local maximum. The highest peak across the entire graph is the global maximum. ",
					"content_token": 185,
					"embedding": []
				},
				{
					"article_title": "Mental Models for Career Changes",
					"article_url": "https://fs.blog/mental-models-for-career-changes/",
					"content": "Activation energy comes from chemistry, and is the amount of energy needed to see a reaction through to its conclusion. One of the things global and local maxima teaches us is that sometimes you have to go down a hill in order to climb up a new one. To move from a local maximum to a higher peak you have to go through a local minimum, a valley. Too often we just want to go higher right away, or at the very least we want to make a lateral move. We perceive going down as taking a step backward. A common problem is when we tie our self-worth to our salary and therefore reject any opportunities that won’t pay us as much as we’re currently making. The same goes for job titles; no one wants to be a junior anything in their mid-forties. But it’s impossible to get to the next peak if we won’t walk through the valley. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "Mental Models for Career Changes",
					"article_url": "https://fs.blog/mental-models-for-career-changes/",
					"content": "If you look at your career change through the lens of global and local maxima, you will see that steps down can also be steps forward. Activation energy is another great model to use in the planning phase because it requires you to think about the real effort required for sustained change. You need to plan not just for making a change but also for seeing it through until the new thing has time to take hold. Do you have enough in the bank to support yourself if you need to retrain or take a pay cut? Do you have the emotional support to help you through the challenges of taking on a brand-new career? Just like fires don’t start with one match and a giant log, you have to plan for what you need between now and your desired result. What do you need to keep that reaction going so the flame from the match leads to the log catching fire? The same kind of thinking needs to inform your planning. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "Mental Models for Career Changes",
					"article_url": "https://fs.blog/mental-models-for-career-changes/",
					"content": "After you’ve taken the first step, what will you need to keep you moving in the direction you want to go?  After you’ve done all the work After getting in touch with yourself, doing all your research, identifying possible paths, and planning for what you need to do to walk them to the end, it can still be hard to make a decision. You’ve uncovered so many nuances and encountered so many ideas that you feel overwhelmed. The reality is, when it comes to career change, there often is no perfect decision. You likely have more than one option, and whatever you choose, there’s going to be a lot of work involved. One final model you can use is probabilistic thinking. In this particular situation, it can be helpful to use a Bayesian casino. ",
					"content_token": 168,
					"embedding": []
				},
				{
					"article_title": "Mental Models for Career Changes",
					"article_url": "https://fs.blog/mental-models-for-career-changes/",
					"content": "A Bayesian casino is a thought experiment where you imagine walking up to a casino game, like roulette, and quantifying how much you would bet on any particular outcome. Let’s say when investigating your career change, you’ve narrowed it down to two options. Which one would you bet on for being the better choice one year later? And how much would you part with? If you’d bet ten dollars on black, then you probably need to take a fresh look at the research you’ve done. Maybe go talk to more people, or broaden your thinking. If you’re willing to put down thousands of dollars on red, that’s very likely the right decision for you. It’s important in this thought experiment to fully imagine yourself making the bet. Imagine the money in your bank account. Imagine withdrawing it and physically putting it down on the table. ",
					"content_token": 186,
					"embedding": []
				},
				{
					"article_title": "Mental Models for Career Changes",
					"article_url": "https://fs.blog/mental-models-for-career-changes/",
					"content": "How much you’re willing to part with regarding a particular career choice says a lot about how good that choice is likely to be for you. Probabilistic thinking isn’t a predictor of the future. With any big career move, there are inevitably a lot of unknowns. There are no guarantees that any choice is going to be the right one. The Bayesian casino just helps you quantify your thinking based on the knowledge you have at this moment in time. As new information comes in, return to the casino and see if your bets change.  Conclusion Career changes are some of the biggest moves we will ever make, but they don’t have to be daunting. Using mental models helps us find both the direction we want to go and a path we can take to get there. The result is a change that aligns with the person we are, as well as the person we want to be.",
					"content_token": 186,
					"embedding": []
				}
			]
		},
		{
			"title": "Common Probability Errors to Avoid",
			"url": "https://fs.blog/common-probability-errors/",
			"content": "If you’re trying to gain a rapid understanding of a new area, one of the most important things you can do is to identify common mistakes people make, then avoid them. Here are some of the most predictable errors we tend to make when thinking about statistics. Amateurs tend to focus on seeking brilliance. Professionals often know that it’s far more effective to avoid stupidity. Side-stepping typical blunders is the simplest way to get ahead of the crowd. Gaining a better understanding of probability will give you a more accurate picture of the world and help you make better decisions. However, many people fall prey to the same handful of issues because aspects of probability go against what we think is intuitive. Even if you haven’t studied the topic since high-school, you likely use probability assessments every single day in your work and life. In Naked Statistics, Charles Wheelan takes the reader on a whistlestop tour of the basics of statistics. In one chapter, he offers pointers for avoiding some of the “most common probability-related errors, misunderstandings, and ethical dilemmas.” Whether you’re somewhat new to the topic or just want a refresher, here’s a summary of Wheelan’s lessons and how you can apply them.  Assuming events are independent when they are not “The probability of flipping heads with a fair coin is 12. The probability of flipping two heads in a row is 122 or 14 since the likelihood of two independent events both happening is the product of their individual probabilities.” When an event is interconnected with another event, the former happening increases or decreases the probability of the latter happening. Your car insurance gets more expensive after an accident because car accidents are not independent events. A person who gets in one is more likely to get into another in the future. Maybe they’re not such a good driver, maybe they tend to drive after a drink, or maybe their eyesight is imperfect. Whatever the explanation, insurance companies know to revise their risk assessment. Sometimes though, an event happening might lead to changes that make it less probable in the future. If you spilled coffee on your shirt this morning, you might be less likely to do the same this afternoon because you’ll exercise more caution. If an airline had a crash last year, you may well be safer flying with them because they will have made extensive improvements to their safety procedures to prevent another disaster. One place we should pay extra attention to the independence or dependence of events is when making plans. Most of our plans don’t go as we’d like. We get delayed, we have to backtrack, we have to make unexpected changes. Sometimes we think we can compensate for a delay in one part of a plan by moving faster later on. But the parts of a plan are not independent. A delay in one area makes delays elsewhere more likely as problems compound and accumulate. Any time you think about the probability of sequences of events, be sure to identify whether they’re independent or not.  Not understanding when events are independent “A different kind of mistake occurs when events that are independent are not treated as such . . . If you flip a fair coin 1,000,000 times and get 1,000,000 heads in a row, the probability of getting heads on the next flip is still 12. The very definition of statistical independence between two events is that the outcome of one has no effect on the outcome of another.” Imagine you’re grabbing a breakfast sandwich at a local cafe when someone rudely barges into line in front of you and ignores your protestations. Later that day, as you’re waiting your turn to order a latte in a different cafe, the same thing happens: a random stranger pushes in front of you. By the time you go to pick up some pastries for your kids at a different place before heading home that evening, you’re so annoyed by all the rudeness you’ve encountered that you angrily eye every person to enter the shop, on guard for any attempts to take your place. But of course, the two rude strangers were independent events. It’s unlikely they were working together to annoy you. The fact it happened twice in one day doesn’t make it happening a third time more probable. The most important thing to remember here is that the probability of conjunctive events happening is never higher than the probability of each occurring.  Clusters happen “You’ve likely read the story in the newspaper or perhaps seen the news expose: Some statistically unlikely number of people in a particular area have contracted a rare form of cancer. It must be the water, or the local power plant, or the cell phone tower. . . . But this cluster of cases may also be the product of pure chance, even when the number of cases appears highly improbable. Yes, the probability that five people in the same school or church or workplace will contract the same rare form of leukemia may be one in a million, but there are millions of schools and churches and workplaces. It’s not highly improbable that five people might get the same rare form of leukemia in one of those places.” An important lesson of probability is that while particular improbable events are, well, improbable, the chance of any improbable event happening at all is highly probable. Your chances of winning the lottery are almost zero. But someone has to win it. Your chances of getting struck by lightning are almost zero. But with so many people walking around and so many storms, it has to happen to someone sooner or later. The same is true for clusters of improbable events. The chance of any individual winning the lottery multiple times or getting struck by lightning more than once is even closer to zero than the chance of it happening once. Yet when we look at all the people in the world, it’s certain to happen to someone. We’re all pattern-matching creatures. We find randomness hard to process and look for meaning in chaotic events. So it’s no surprise that clusters often fool us. If you encounter one, it’s wise to keep in mind the possibility that it’s a product of chance, not anything more meaningful. Sure, it might be jarring to be involved in three car crashes in a year or to run into two college roommates at the same conference. Is it all that improbable that it would happen to someone, though?  The prosecutor’s fallacy “The prosecutor’s fallacy occurs when the context surrounding statistical evidence is neglected . . . the chances of finding a coincidental one in a million match are relatively high if you run the same through a database with samples from a million people.” It’s important to look at the context surrounding statistics. Let’s say you’re evaluating whether to take a medication your doctor suggests. A quick glance at the information leaflet tells you that it carries a 1 in 10,000 risk of blood clots. Should you be concerned? Well, that depends on context. The 1 in 10,000 figure takes into account the wide spectrum of people with different genes and different lifestyles who might take the medication. If you’re an overweight chain-smoker with a family history of blood clots who takes twelve-hour flights twice a month, you might want to have a more serious discussion with your doctor than an active non-smoker with no relevant family history. Statistics give us a simple snapshot, but if we want a finer-grained picture, we need to think about context.  Reversion to the mean or regression to the mean “Probability tells us that any outlieran observation that is particularly far from the mean in one direction or the otheris likely to be followed by outcomes that are most consistent with the long-term average. . . . One way to think about this mean reversion is that performanceboth mental and physicalconsists of underlying talent-related effort plus an element of luck, good or bad. Statisticians would call this random error. In any case, those individuals who perform far above the mean for some stretch are likely to have had luck on their side; those who perform far below the mean are likely to have had bad luck. . . . When a spell of very good luck or very bad luck endsas it inevitably willthe resulting performance will be closer to the mean.” Moderate events tend to follow extreme ones. One area that regression to the mean often misleads us is when considering how people perform in areas like sports or management. We may think a single extraordinary success is predictive of future successes. Yet from one result, we can’t know if it’s an outcome of talent or luckin which case the next result may be average. Failure or success is usually followed by an event closer to the mean, not the other extreme. Regression to the mean teaches us that the way to differentiate between skill and luck is to look at someone’s track record. The more information you have, the better. Even if past performance is not always predictive of future performance, a track record of consistent high performance is a far better indicator than a single highlight.  If you want an accessible tour of basic statistics, check out Naked Statistics by Charles Wheelan.",
			"tokens": 1913,
			"chunks": [
				{
					"article_title": "Common Probability Errors to Avoid",
					"article_url": "https://fs.blog/common-probability-errors/",
					"content": "If you’re trying to gain a rapid understanding of a new area, one of the most important things you can do is to identify common mistakes people make, then avoid them. Here are some of the most predictable errors we tend to make when thinking about statistics. Amateurs tend to focus on seeking brilliance. Professionals often know that it’s far more effective to avoid stupidity. Side-stepping typical blunders is the simplest way to get ahead of the crowd. Gaining a better understanding of probability will give you a more accurate picture of the world and help you make better decisions. However, many people fall prey to the same handful of issues because aspects of probability go against what we think is intuitive. Even if you haven’t studied the topic since high-school, you likely use probability assessments every single day in your work and life. In Naked Statistics, Charles Wheelan takes the reader on a whistlestop tour of the basics of statistics. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "Common Probability Errors to Avoid",
					"article_url": "https://fs.blog/common-probability-errors/",
					"content": "In one chapter, he offers pointers for avoiding some of the “most common probability-related errors, misunderstandings, and ethical dilemmas.” Whether you’re somewhat new to the topic or just want a refresher, here’s a summary of Wheelan’s lessons and how you can apply them.  Assuming events are independent when they are not “The probability of flipping heads with a fair coin is 12. The probability of flipping two heads in a row is 122 or 14 since the likelihood of two independent events both happening is the product of their individual probabilities.” When an event is interconnected with another event, the former happening increases or decreases the probability of the latter happening. Your car insurance gets more expensive after an accident because car accidents are not independent events. A person who gets in one is more likely to get into another in the future. ",
					"content_token": 181,
					"embedding": []
				},
				{
					"article_title": "Common Probability Errors to Avoid",
					"article_url": "https://fs.blog/common-probability-errors/",
					"content": "Maybe they’re not such a good driver, maybe they tend to drive after a drink, or maybe their eyesight is imperfect. Whatever the explanation, insurance companies know to revise their risk assessment. Sometimes though, an event happening might lead to changes that make it less probable in the future. If you spilled coffee on your shirt this morning, you might be less likely to do the same this afternoon because you’ll exercise more caution. If an airline had a crash last year, you may well be safer flying with them because they will have made extensive improvements to their safety procedures to prevent another disaster. One place we should pay extra attention to the independence or dependence of events is when making plans. Most of our plans don’t go as we’d like. We get delayed, we have to backtrack, we have to make unexpected changes. Sometimes we think we can compensate for a delay in one part of a plan by moving faster later on. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "Common Probability Errors to Avoid",
					"article_url": "https://fs.blog/common-probability-errors/",
					"content": "But the parts of a plan are not independent. A delay in one area makes delays elsewhere more likely as problems compound and accumulate. Any time you think about the probability of sequences of events, be sure to identify whether they’re independent or not.  Not understanding when events are independent “A different kind of mistake occurs when events that are independent are not treated as such    If you flip a fair coin 1,000,000 times and get 1,000,000 heads in a row, the probability of getting heads on the next flip is still 12. The very definition of statistical independence between two events is that the outcome of one has no effect on the outcome of another.” Imagine you’re grabbing a breakfast sandwich at a local cafe when someone rudely barges into line in front of you and ignores your protestations. ",
					"content_token": 174,
					"embedding": []
				},
				{
					"article_title": "Common Probability Errors to Avoid",
					"article_url": "https://fs.blog/common-probability-errors/",
					"content": "Later that day, as you’re waiting your turn to order a latte in a different cafe, the same thing happens: a random stranger pushes in front of you. By the time you go to pick up some pastries for your kids at a different place before heading home that evening, you’re so annoyed by all the rudeness you’ve encountered that you angrily eye every person to enter the shop, on guard for any attempts to take your place. But of course, the two rude strangers were independent events. It’s unlikely they were working together to annoy you. The fact it happened twice in one day doesn’t make it happening a third time more probable. The most important thing to remember here is that the probability of conjunctive events happening is never higher than the probability of each occurring. ",
					"content_token": 171,
					"embedding": []
				},
				{
					"article_title": "Common Probability Errors to Avoid",
					"article_url": "https://fs.blog/common-probability-errors/",
					"content": " Clusters happen “You’ve likely read the story in the newspaper or perhaps seen the news expose: Some statistically unlikely number of people in a particular area have contracted a rare form of cancer. It must be the water, or the local power plant, or the cell phone tower.    But this cluster of cases may also be the product of pure chance, even when the number of cases appears highly improbable. Yes, the probability that five people in the same school or church or workplace will contract the same rare form of leukemia may be one in a million, but there are millions of schools and churches and workplaces. It’s not highly improbable that five people might get the same rare form of leukemia in one of those places.” An important lesson of probability is that while particular improbable events are, well, improbable, the chance of any improbable event happening at all is highly probable. Your chances of winning the lottery are almost zero. But someone has to win it. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "Common Probability Errors to Avoid",
					"article_url": "https://fs.blog/common-probability-errors/",
					"content": "Your chances of getting struck by lightning are almost zero. But with so many people walking around and so many storms, it has to happen to someone sooner or later. The same is true for clusters of improbable events. The chance of any individual winning the lottery multiple times or getting struck by lightning more than once is even closer to zero than the chance of it happening once. Yet when we look at all the people in the world, it’s certain to happen to someone. We’re all pattern-matching creatures. We find randomness hard to process and look for meaning in chaotic events. So it’s no surprise that clusters often fool us. If you encounter one, it’s wise to keep in mind the possibility that it’s a product of chance, not anything more meaningful. Sure, it might be jarring to be involved in three car crashes in a year or to run into two college roommates at the same conference. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "Common Probability Errors to Avoid",
					"article_url": "https://fs.blog/common-probability-errors/",
					"content": "Is it all that improbable that it would happen to someone, though?  The prosecutor’s fallacy “The prosecutor’s fallacy occurs when the context surrounding statistical evidence is neglected    the chances of finding a coincidental one in a million match are relatively high if you run the same through a database with samples from a million people.” It’s important to look at the context surrounding statistics. Let’s say you’re evaluating whether to take a medication your doctor suggests. A quick glance at the information leaflet tells you that it carries a 1 in 10,000 risk of blood clots. Should you be concerned? Well, that depends on context. The 1 in 10,000 figure takes into account the wide spectrum of people with different genes and different lifestyles who might take the medication. ",
					"content_token": 170,
					"embedding": []
				},
				{
					"article_title": "Common Probability Errors to Avoid",
					"article_url": "https://fs.blog/common-probability-errors/",
					"content": "If you’re an overweight chain-smoker with a family history of blood clots who takes twelve-hour flights twice a month, you might want to have a more serious discussion with your doctor than an active non-smoker with no relevant family history. Statistics give us a simple snapshot, but if we want a finer-grained picture, we need to think about context.  Reversion to the mean or regression to the mean “Probability tells us that any outlieran observation that is particularly far from the mean in one direction or the otheris likely to be followed by outcomes that are most consistent with the long-term average.    One way to think about this mean reversion is that performanceboth mental and physicalconsists of underlying talent-related effort plus an element of luck, good or bad. Statisticians would call this random error. ",
					"content_token": 181,
					"embedding": []
				},
				{
					"article_title": "Common Probability Errors to Avoid",
					"article_url": "https://fs.blog/common-probability-errors/",
					"content": "In any case, those individuals who perform far above the mean for some stretch are likely to have had luck on their side; those who perform far below the mean are likely to have had bad luck.    When a spell of very good luck or very bad luck endsas it inevitably willthe resulting performance will be closer to the mean.” Moderate events tend to follow extreme ones. One area that regression to the mean often misleads us is when considering how people perform in areas like sports or management. We may think a single extraordinary success is predictive of future successes. Yet from one result, we can’t know if it’s an outcome of talent or luckin which case the next result may be average. Failure or success is usually followed by an event closer to the mean, not the other extreme. Regression to the mean teaches us that the way to differentiate between skill and luck is to look at someone’s track record. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "Common Probability Errors to Avoid",
					"article_url": "https://fs.blog/common-probability-errors/",
					"content": "The more information you have, the better. Even if past performance is not always predictive of future performance, a track record of consistent high performance is a far better indicator than a single highlight.  If you want an accessible tour of basic statistics, check out Naked Statistics by Charles Wheelan.",
					"content_token": 58,
					"embedding": []
				}
			]
		},
		{
			"title": "A Primer on Algorithms and Bias",
			"url": "https://fs.blog/algorithms-and-bias/",
			"content": "The growing influence of algorithms on our lives means we owe it to ourselves to better understand what they are and how they work. Understanding how the data we use to inform algorithms influences the results they give can help us avoid biases and make better decisions.  Algorithms are everywhere: driving our cars, designing our social media feeds, dictating which mixer we end up buying on Amazon, diagnosing diseases, and much more. Two recent books explore algorithms and the data behind them. In Hello World: Being Human in the Age of Algorithms, mathematician Hannah Fry shows us the potential and the limitations of algorithms. And Invisible Women: Data Bias in a World Designed for Men by writer, broadcaster, and feminist activist Caroline Criado Perez demonstrates how we need to be much more conscientious of the quality of the data we feed into them. Humans or algorithms? First, what is an algorithm? Explanations of algorithms can be complex. Fry explains that at their core, they are defined as step-by-step procedures for solving a problem or achieving a particular end. We tend to use the term to refer to mathematical operations that crunch data to make decisions. When it comes to decision-making, we don’t necessarily have to choose between doing it ourselves and relying wholly on algorithms. The best outcome may be a thoughtful combination of the two. We all know that in certain contexts, humans are not the best decision-makers. For example, when we are tired, or when we already have a desired outcome in mind, we may ignore relevant information. In Thinking, Fast and Slow, Daniel Kahneman gave multiple examples from his research with Amos Tversky that demonstrated we are heavily influenced by cognitive biases such as availability and anchoring when making certain types of decisions. It’s natural, then, that we would want to employ algorithms that aren’t vulnerable to the same tendencies. In fact, their main appeal for use in decision-making is that they can override our irrationalities. Algorithms, however, aren’t without their flaws. One of the obvious ones is that because algorithms are written by humans, we often code our biases right into them. Criado Perez offers many examples of algorithmic bias. For example, an online platform designed to help companies find computer programmers looks through activity such as sharing and developing code in online communities, as well as visiting Japanese manga comics sites. People visiting certain sites with frequency received higher scores, thus making them more visible to recruiters. However, Criado Perez presents the analysis of this recruiting algorithm by Cathy O’Neil, scientist and author of Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy, who points out that “women, who do 75 of the world’s unpaid care work, may not have the spare leisure time to spend hours chatting about manga online . . . and if, like most of techdom, that manga site is dominated by males and has a sexist tone, a good number of women in the industry will probably avoid it.” Criado Perez postulates that the authors of the recruiting algorithm didn’t intend to encode a bias that discriminates against women. But, she says, “if you aren’t aware of how those biases operate, if you aren’t collecting data and taking a little time to produce evidence-based processes, you will continue to blindly perpetuate old injustices.” Fry also covers algorithmic bias and asserts that “wherever you look, in whatever sphere you examine, if you delve deep enough into any system at all, you’ll find some kind of bias.” We aren’t perfectand we shouldn’t expect our algorithms to be perfect, either. In order to have a conversation about the value of an algorithm versus a human in any decision-making context, we need to understand, as Fry explains, that “algorithms require a clear, unambiguous idea of exactly what we want them to achieve and a solid understanding of the human failings they are replacing.” Garbage in, garbage out No algorithm is going to be successful if the data it uses is junk. And there’s a lot of junk data in the world. Far from being a new problem, Criado Perez argues that “most of recorded human history is one big data gap.” And that has a serious negative impact on the value we are getting from our algorithms.  Criado Perez explains the situation this way: We live in “a world that is increasingly reliant on and in thrall to data. Big data. Which in turn is panned for Big Truths by Big Algorithms, using Big Computers. But when your data is corrupted by big silences, the truths you get are half-truths, at best.” A common human bias is one regarding the universality of our own experience. We tend to assume that what is true for us is generally true across the population. We have a hard enough time considering how things may be different for our neighbors, let alone for other genders or races. It becomes a serious problem when we gather data about one subset of the population and mistakenly assume that it represents all of the population. For example, Criado Perez examines the data gap in relation to incorrect information being used to inform decisions about safety and women’s bodies. From personal protective equipment like bulletproof vests that don’t fit properly and thus increase the chances of the women wearing them getting killed to levels of exposure to toxins that are unsafe for women’s bodies, she makes the case that without representative data, we can’t get good outputs from our algorithms. She writes that “we continue to rely on data from studies done on men as if they apply to women. Specifically, Caucasian men aged twenty-five to thirty, who weigh 70 kg. This is Reference Man’ and his superpower is being able to represent humanity as whole. Of course, he does not.” Her book contains a wide variety of disciplines and situations where the gender gap in data leads to increased negative outcomes for women. The limits of what we can do Although there is a lot we can do better when it comes to designing algorithms and collecting the data sets that feed them, it’s also important to consider their limits. We need to accept that algorithms can’t solve all problems, and there are limits to their functionality. In Hello World, Fry devotes a chapter to the use of algorithms in justice. Specifically, algorithms designed to provide information to judges about the likelihood of a defendant committing further crimes. Our first impulse is to say, “Let’s not rely on bias here. Let’s not have someone’s skin color or gender be a key factor for the algorithm.” After all, we can employ that kind of bias just fine ourselves. But simply writing bias out of an algorithm is not as easy as wishing it so. Fry explains that “unless the fraction of people who commit crimes is the same in every group of defendants, it is mathematically impossible to create a test which is equally accurate at predicting across the board and makes false positive and false negative mistakes at the same rate for every group of defendants.” Fry comes back to such limits frequently throughout her book, exploring them in various disciplines. She demonstrates to the reader that “there are boundaries to the reach of algorithms. Limits to what can be quantified.” Perhaps a better understanding of those limits is needed to inform our discussions of where we want to use algorithms. There are, however, other limits that we can do something about. Both authors make the case for more education about algorithms and their input data. Lack of understanding shouldn’t hold us back. Algorithms that have a significant impact on our lives specifically need to be open to scrutiny and analysis. If an algorithm is going to put you in jail or impact your ability to get a mortgage, then you ought to be able to have access to it. Most algorithm writers and the companies they work for wave the “proprietary” flag and refuse to open themselves up to public scrutiny. Many algorithms are a black boxwe don’t actually know how they reach the conclusions they do. But Fry says that shouldn’t deter us. Pursuing laws such as the data access and protection rights being instituted in the European Union and structures such as an algorithm-evaluating body playing a role similar to the one the U.S. Food and Drug Administration plays in evaluating whether pharmaceuticals can be made available to the U.S. market will help us decide as a society what we want and need our algorithms to do. Where do we go from here? Algorithms aren’t going away, so it’s best to acquire the knowledge needed to figure out how they can help us create the world we want. Fry suggests that one way to approach algorithms is to “imagine that we designed them to support humans in their decisions, rather than instruct them.” She envisions a world where “the algorithm and the human work together in partnership, exploiting each other’s strengths and embracing each other’s flaws.” Part of getting to a world where algorithms provide great benefit is to remember how diverse our world really is and make sure we get data that reflects the realities of that diversity. We can either actively change the algorithm, or we change the data set. And if we do the latter, we need to make sure we aren’t feeding our algorithms data that, for example, excludes half the population. As Criado Perez writes, “when we exclude half of humanity from the production of knowledge, we lose out on potentially transformative insights.” Given how complex the world of algorithms is, we need all the amazing insights we can get. Algorithms themselves perhaps offer the best hope, because they have the inherent flexibility to improve as we do. Fry gives this explanation: “There’s nothing inherent in these algorithms that means they have to repeat the biases of the past. It all comes down to the data you give them. We can choose to be crass empiricists’ as Richard Berk put it  and follow the numbers that are already there, or we can decide that the status quo is unfair and tweak the numbers accordingly.” We can get excited about the possibilities that algorithms offer us and use them to create a world that is better for everyone.",
			"tokens": 2160,
			"chunks": [
				{
					"article_title": "A Primer on Algorithms and Bias",
					"article_url": "https://fs.blog/algorithms-and-bias/",
					"content": "The growing influence of algorithms on our lives means we owe it to ourselves to better understand what they are and how they work. Understanding how the data we use to inform algorithms influences the results they give can help us avoid biases and make better decisions.  Algorithms are everywhere: driving our cars, designing our social media feeds, dictating which mixer we end up buying on Amazon, diagnosing diseases, and much more. Two recent books explore algorithms and the data behind them. In Hello World: Being Human in the Age of Algorithms, mathematician Hannah Fry shows us the potential and the limitations of algorithms. And Invisible Women: Data Bias in a World Designed for Men by writer, broadcaster, and feminist activist Caroline Criado Perez demonstrates how we need to be much more conscientious of the quality of the data we feed into them. Humans or algorithms? First, what is an algorithm? Explanations of algorithms can be complex. ",
					"content_token": 189,
					"embedding": []
				},
				{
					"article_title": "A Primer on Algorithms and Bias",
					"article_url": "https://fs.blog/algorithms-and-bias/",
					"content": "Fry explains that at their core, they are defined as step-by-step procedures for solving a problem or achieving a particular end. We tend to use the term to refer to mathematical operations that crunch data to make decisions. When it comes to decision-making, we don’t necessarily have to choose between doing it ourselves and relying wholly on algorithms. The best outcome may be a thoughtful combination of the two. We all know that in certain contexts, humans are not the best decision-makers. For example, when we are tired, or when we already have a desired outcome in mind, we may ignore relevant information. In Thinking, Fast and Slow, Daniel Kahneman gave multiple examples from his research with Amos Tversky that demonstrated we are heavily influenced by cognitive biases such as availability and anchoring when making certain types of decisions. It’s natural, then, that we would want to employ algorithms that aren’t vulnerable to the same tendencies. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "A Primer on Algorithms and Bias",
					"article_url": "https://fs.blog/algorithms-and-bias/",
					"content": "In fact, their main appeal for use in decision-making is that they can override our irrationalities. Algorithms, however, aren’t without their flaws. One of the obvious ones is that because algorithms are written by humans, we often code our biases right into them. Criado Perez offers many examples of algorithmic bias. For example, an online platform designed to help companies find computer programmers looks through activity such as sharing and developing code in online communities, as well as visiting Japanese manga comics sites. People visiting certain sites with frequency received higher scores, thus making them more visible to recruiters. ",
					"content_token": 125,
					"embedding": []
				},
				{
					"article_title": "A Primer on Algorithms and Bias",
					"article_url": "https://fs.blog/algorithms-and-bias/",
					"content": "However, Criado Perez presents the analysis of this recruiting algorithm by Cathy O’Neil, scientist and author of Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy, who points out that “women, who do 75 of the world’s unpaid care work, may not have the spare leisure time to spend hours chatting about manga online    and if, like most of techdom, that manga site is dominated by males and has a sexist tone, a good number of women in the industry will probably avoid it.” Criado Perez postulates that the authors of the recruiting algorithm didn’t intend to encode a bias that discriminates against women. ",
					"content_token": 144,
					"embedding": []
				},
				{
					"article_title": "A Primer on Algorithms and Bias",
					"article_url": "https://fs.blog/algorithms-and-bias/",
					"content": "But, she says, “if you aren’t aware of how those biases operate, if you aren’t collecting data and taking a little time to produce evidence-based processes, you will continue to blindly perpetuate old injustices.” Fry also covers algorithmic bias and asserts that “wherever you look, in whatever sphere you examine, if you delve deep enough into any system at all, you’ll find some kind of bias.” We aren’t perfectand we shouldn’t expect our algorithms to be perfect, either. ",
					"content_token": 119,
					"embedding": []
				},
				{
					"article_title": "A Primer on Algorithms and Bias",
					"article_url": "https://fs.blog/algorithms-and-bias/",
					"content": "In order to have a conversation about the value of an algorithm versus a human in any decision-making context, we need to understand, as Fry explains, that “algorithms require a clear, unambiguous idea of exactly what we want them to achieve and a solid understanding of the human failings they are replacing.” Garbage in, garbage out No algorithm is going to be successful if the data it uses is junk. And there’s a lot of junk data in the world. Far from being a new problem, Criado Perez argues that “most of recorded human history is one big data gap.” And that has a serious negative impact on the value we are getting from our algorithms.  Criado Perez explains the situation this way: We live in “a world that is increasingly reliant on and in thrall to data. Big data. Which in turn is panned for Big Truths by Big Algorithms, using Big Computers. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "A Primer on Algorithms and Bias",
					"article_url": "https://fs.blog/algorithms-and-bias/",
					"content": "But when your data is corrupted by big silences, the truths you get are half-truths, at best.” A common human bias is one regarding the universality of our own experience. We tend to assume that what is true for us is generally true across the population. We have a hard enough time considering how things may be different for our neighbors, let alone for other genders or races. It becomes a serious problem when we gather data about one subset of the population and mistakenly assume that it represents all of the population. For example, Criado Perez examines the data gap in relation to incorrect information being used to inform decisions about safety and women’s bodies. ",
					"content_token": 139,
					"embedding": []
				},
				{
					"article_title": "A Primer on Algorithms and Bias",
					"article_url": "https://fs.blog/algorithms-and-bias/",
					"content": "From personal protective equipment like bulletproof vests that don’t fit properly and thus increase the chances of the women wearing them getting killed to levels of exposure to toxins that are unsafe for women’s bodies, she makes the case that without representative data, we can’t get good outputs from our algorithms. She writes that “we continue to rely on data from studies done on men as if they apply to women. Specifically, Caucasian men aged twenty-five to thirty, who weigh 70 kg. This is Reference Man’ and his superpower is being able to represent humanity as whole. Of course, he does not.” Her book contains a wide variety of disciplines and situations where the gender gap in data leads to increased negative outcomes for women. The limits of what we can do Although there is a lot we can do better when it comes to designing algorithms and collecting the data sets that feed them, it’s also important to consider their limits. ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "A Primer on Algorithms and Bias",
					"article_url": "https://fs.blog/algorithms-and-bias/",
					"content": "We need to accept that algorithms can’t solve all problems, and there are limits to their functionality. In Hello World, Fry devotes a chapter to the use of algorithms in justice. Specifically, algorithms designed to provide information to judges about the likelihood of a defendant committing further crimes. Our first impulse is to say, “Let’s not rely on bias here. Let’s not have someone’s skin color or gender be a key factor for the algorithm.” After all, we can employ that kind of bias just fine ourselves. But simply writing bias out of an algorithm is not as easy as wishing it so. ",
					"content_token": 133,
					"embedding": []
				},
				{
					"article_title": "A Primer on Algorithms and Bias",
					"article_url": "https://fs.blog/algorithms-and-bias/",
					"content": "Fry explains that “unless the fraction of people who commit crimes is the same in every group of defendants, it is mathematically impossible to create a test which is equally accurate at predicting across the board and makes false positive and false negative mistakes at the same rate for every group of defendants.” Fry comes back to such limits frequently throughout her book, exploring them in various disciplines. She demonstrates to the reader that “there are boundaries to the reach of algorithms. Limits to what can be quantified.” Perhaps a better understanding of those limits is needed to inform our discussions of where we want to use algorithms. There are, however, other limits that we can do something about. Both authors make the case for more education about algorithms and their input data. Lack of understanding shouldn’t hold us back. Algorithms that have a significant impact on our lives specifically need to be open to scrutiny and analysis. ",
					"content_token": 188,
					"embedding": []
				},
				{
					"article_title": "A Primer on Algorithms and Bias",
					"article_url": "https://fs.blog/algorithms-and-bias/",
					"content": "If an algorithm is going to put you in jail or impact your ability to get a mortgage, then you ought to be able to have access to it. Most algorithm writers and the companies they work for wave the “proprietary” flag and refuse to open themselves up to public scrutiny. Many algorithms are a black boxwe don’t actually know how they reach the conclusions they do. But Fry says that shouldn’t deter us. Pursuing laws such as the data access and protection rights being instituted in the European Union and structures such as an algorithm-evaluating body playing a role similar to the one the U.S. Food and Drug Administration plays in evaluating whether pharmaceuticals can be made available to the U.S. market will help us decide as a society what we want and need our algorithms to do. ",
					"content_token": 170,
					"embedding": []
				},
				{
					"article_title": "A Primer on Algorithms and Bias",
					"article_url": "https://fs.blog/algorithms-and-bias/",
					"content": "Where do we go from here? Algorithms aren’t going away, so it’s best to acquire the knowledge needed to figure out how they can help us create the world we want. Fry suggests that one way to approach algorithms is to “imagine that we designed them to support humans in their decisions, rather than instruct them.” She envisions a world where “the algorithm and the human work together in partnership, exploiting each other’s strengths and embracing each other’s flaws.” Part of getting to a world where algorithms provide great benefit is to remember how diverse our world really is and make sure we get data that reflects the realities of that diversity. We can either actively change the algorithm, or we change the data set. And if we do the latter, we need to make sure we aren’t feeding our algorithms data that, for example, excludes half the population. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "A Primer on Algorithms and Bias",
					"article_url": "https://fs.blog/algorithms-and-bias/",
					"content": "As Criado Perez writes, “when we exclude half of humanity from the production of knowledge, we lose out on potentially transformative insights.” Given how complex the world of algorithms is, we need all the amazing insights we can get. Algorithms themselves perhaps offer the best hope, because they have the inherent flexibility to improve as we do. Fry gives this explanation: “There’s nothing inherent in these algorithms that means they have to repeat the biases of the past. It all comes down to the data you give them. We can choose to be crass empiricists’ as Richard Berk put it  and follow the numbers that are already there, or we can decide that the status quo is unfair and tweak the numbers accordingly.” We can get excited about the possibilities that algorithms offer us and use them to create a world that is better for everyone.",
					"content_token": 180,
					"embedding": []
				}
			]
		},
		{
			"title": "Why We Focus on Trivial Things: The Bikeshed Effect",
			"url": "https://fs.blog/bikeshed-effect/",
			"content": "Bikeshedding is a metaphor to illustrate the strange tendency we have to spend excessive time on trivial matters, often glossing over important ones. Here’s why we do it, and how to stop.   How can we stop wasting time on unimportant details? From meetings at work that drag on forever without achieving anything to weeks-long email chains that don’t solve the problem at hand, we seem to spend an inordinate amount of time on the inconsequential. Then, when an important decision needs to be made, we hardly have any time to devote to it. To answer this question, we first have to recognize why we get bogged down in the trivial. Then we must look at strategies for changing our dynamics towards generating both useful input and time to consider it. The Law of Triviality You’ve likely heard of Parkinson’s Law, which states that tasks expand to fill the amount of time allocated to them. But you might not have heard of the lesser-known Parkinson’s Law of Triviality, also coined by British naval historian and author Cyril Northcote Parkinson in the 1950s. The Law of Triviality states that the amount of time spent discussing an issue in an organization is inversely correlated to its actual importance in the scheme of things. Major, complex issues get the least discussion while simple, minor ones get the most discussion. Parkinson’s Law of Triviality is also known as “bike-shedding,” after the story Parkinson uses to illustrate it. He asks readers to imagine a financial committee meeting to discuss a three-point agenda. The points are as follows: A proposal for a 10 million nuclear power plant A proposal for a 350 bike shed A proposal for a 21 annual coffee budget What happens? The committee ends up running through the nuclear power plant proposal in little time. It’s too advanced for anyone to really dig into the details, and most of the members don’t know much about the topic in the first place. One member who does is unsure how to explain it to the others. Another member proposes a redesigned proposal, but it seems like such a huge task that the rest of the committee decline to consider it. The discussion soon moves to the bike shed. Here, the committee members feel much more comfortable voicing their opinions. They all know what a bike shed is and what it looks like. Several members begin an animated debate over the best possible material for the roof, weighing out options that might enable modest savings. They discuss the bike shed for far longer than the power plant. At last, the committee moves onto item three: the coffee budget. Suddenly, everyone’s an expert. They all know about coffee and have a strong sense of its cost and value. Before anyone realizes what is happening, they spend longer discussing the 21 coffee budget than the power plant and the bike shed combined! In the end, the committee runs out of time and decides to meet again to complete their analysis. Everyone walks away feeling satisfied, having contributed to the conversation. Why this happens Bike-shedding happens because the simpler a topic is, the more people will have an opinion on it and thus more to say about it. When something is outside of our circle of competence, like a nuclear power plant, we don’t even try to articulate an opinion. But when something is just about comprehensible to us, even if we don’t have anything of genuine value to add, we feel compelled to say something, lest we look stupid. What idiot doesn’t have anything to say about a bike shed? Everyone wants to show that they know about the topic at hand and have something to contribute. With any issue, we shouldn’t be according equal importance to every opinion anyone adds. We should emphasize the inputs from those who have done the work to have an opinion. And when we decide to contribute, we should be putting our energy into the areas where we have something valuable to add that will improve the outcome of the decision. Strategies for avoiding bike-shedding The main thing you can do to avoid bike-shedding is for your meeting to have a clear purpose. In The Art of Gathering: How We Meet and Why It Matters, Priya Parker, who has decades of experience designing high-stakes gatherings, says that any successful gathering including a business meeting needs to have a focused and particular purpose. “Specificity,” she says, “is a crucial ingredient.” Why is having a clear purpose so critical? Because you use it as the lens to filter all other decisions about your meeting, including who to have in the room. With that in mind, we can see that it’s probably not a great idea to discuss building a nuclear power plant and a bike shed in the same meeting. There’s not enough specificity there. The key is to recognize that the available input on an issue doesn’t all need considering. The most informed opinions are most relevant. This is one reason why big meetings with lots of people present, most of whom don’t need to be there, are such a waste of time in organizations. Everyone wants to participate, but not everyone has anything meaningful to contribute. When it comes to choosing your list of invitees, Parker writes, “if the purpose of your meeting is to make a decision, you may want to consider having fewer cooks in the kitchen.” If you don’t want bike-shedding to occur, avoid inviting contributions from those who are unlikely to have relevant knowledge and experience. Getting the result you wanta thoughtful, educated discussion about that power plantdepends on having the right people in the room. It also helps to have a designated individual in charge of making the final judgment. When we make decisions by committee with no one in charge, reaching a consensus can be almost impossible. The discussion drags on and on. The individual can decide in advance how much importance to accord to the issue for instance, by estimating how much its success or failure could help or harm the company’s bottom line. They can set a time limit for the discussion to create urgency. And they can end the meeting by verifying that it has indeed achieved its purpose. Any issue that invites a lot of discussions from different people might not be the most important one at hand. Avoid descending into unproductive triviality by having clear goals for your meeting and getting the best people to the table to have a productive, constructive discussion.",
			"tokens": 1333,
			"chunks": [
				{
					"article_title": "Why We Focus on Trivial Things: The Bikeshed Effect",
					"article_url": "https://fs.blog/bikeshed-effect/",
					"content": "Bikeshedding is a metaphor to illustrate the strange tendency we have to spend excessive time on trivial matters, often glossing over important ones. Here’s why we do it, and how to stop.   How can we stop wasting time on unimportant details? From meetings at work that drag on forever without achieving anything to weeks-long email chains that don’t solve the problem at hand, we seem to spend an inordinate amount of time on the inconsequential. Then, when an important decision needs to be made, we hardly have any time to devote to it. To answer this question, we first have to recognize why we get bogged down in the trivial. Then we must look at strategies for changing our dynamics towards generating both useful input and time to consider it. The Law of Triviality You’ve likely heard of Parkinson’s Law, which states that tasks expand to fill the amount of time allocated to them. ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "Why We Focus on Trivial Things: The Bikeshed Effect",
					"article_url": "https://fs.blog/bikeshed-effect/",
					"content": "But you might not have heard of the lesser-known Parkinson’s Law of Triviality, also coined by British naval historian and author Cyril Northcote Parkinson in the 1950s. The Law of Triviality states that the amount of time spent discussing an issue in an organization is inversely correlated to its actual importance in the scheme of things. Major, complex issues get the least discussion while simple, minor ones get the most discussion. Parkinson’s Law of Triviality is also known as “bike-shedding,” after the story Parkinson uses to illustrate it. He asks readers to imagine a financial committee meeting to discuss a three-point agenda. The points are as follows: A proposal for a 10 million nuclear power plant A proposal for a 350 bike shed A proposal for a 21 annual coffee budget What happens? The committee ends up running through the nuclear power plant proposal in little time. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "Why We Focus on Trivial Things: The Bikeshed Effect",
					"article_url": "https://fs.blog/bikeshed-effect/",
					"content": "It’s too advanced for anyone to really dig into the details, and most of the members don’t know much about the topic in the first place. One member who does is unsure how to explain it to the others. Another member proposes a redesigned proposal, but it seems like such a huge task that the rest of the committee decline to consider it. The discussion soon moves to the bike shed. Here, the committee members feel much more comfortable voicing their opinions. They all know what a bike shed is and what it looks like. Several members begin an animated debate over the best possible material for the roof, weighing out options that might enable modest savings. They discuss the bike shed for far longer than the power plant. At last, the committee moves onto item three: the coffee budget. Suddenly, everyone’s an expert. They all know about coffee and have a strong sense of its cost and value. ",
					"content_token": 187,
					"embedding": []
				},
				{
					"article_title": "Why We Focus on Trivial Things: The Bikeshed Effect",
					"article_url": "https://fs.blog/bikeshed-effect/",
					"content": "Before anyone realizes what is happening, they spend longer discussing the 21 coffee budget than the power plant and the bike shed combined! In the end, the committee runs out of time and decides to meet again to complete their analysis. Everyone walks away feeling satisfied, having contributed to the conversation. Why this happens Bike-shedding happens because the simpler a topic is, the more people will have an opinion on it and thus more to say about it. When something is outside of our circle of competence, like a nuclear power plant, we don’t even try to articulate an opinion. But when something is just about comprehensible to us, even if we don’t have anything of genuine value to add, we feel compelled to say something, lest we look stupid. What idiot doesn’t have anything to say about a bike shed? Everyone wants to show that they know about the topic at hand and have something to contribute. ",
					"content_token": 189,
					"embedding": []
				},
				{
					"article_title": "Why We Focus on Trivial Things: The Bikeshed Effect",
					"article_url": "https://fs.blog/bikeshed-effect/",
					"content": "With any issue, we shouldn’t be according equal importance to every opinion anyone adds. We should emphasize the inputs from those who have done the work to have an opinion. And when we decide to contribute, we should be putting our energy into the areas where we have something valuable to add that will improve the outcome of the decision. Strategies for avoiding bike-shedding The main thing you can do to avoid bike-shedding is for your meeting to have a clear purpose. In The Art of Gathering: How We Meet and Why It Matters, Priya Parker, who has decades of experience designing high-stakes gatherings, says that any successful gathering including a business meeting needs to have a focused and particular purpose. “Specificity,” she says, “is a crucial ingredient.” Why is having a clear purpose so critical? Because you use it as the lens to filter all other decisions about your meeting, including who to have in the room. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "Why We Focus on Trivial Things: The Bikeshed Effect",
					"article_url": "https://fs.blog/bikeshed-effect/",
					"content": "With that in mind, we can see that it’s probably not a great idea to discuss building a nuclear power plant and a bike shed in the same meeting. There’s not enough specificity there. The key is to recognize that the available input on an issue doesn’t all need considering. The most informed opinions are most relevant. This is one reason why big meetings with lots of people present, most of whom don’t need to be there, are such a waste of time in organizations. Everyone wants to participate, but not everyone has anything meaningful to contribute. When it comes to choosing your list of invitees, Parker writes, “if the purpose of your meeting is to make a decision, you may want to consider having fewer cooks in the kitchen.” If you don’t want bike-shedding to occur, avoid inviting contributions from those who are unlikely to have relevant knowledge and experience. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "Why We Focus on Trivial Things: The Bikeshed Effect",
					"article_url": "https://fs.blog/bikeshed-effect/",
					"content": "Getting the result you wanta thoughtful, educated discussion about that power plantdepends on having the right people in the room. It also helps to have a designated individual in charge of making the final judgment. When we make decisions by committee with no one in charge, reaching a consensus can be almost impossible. The discussion drags on and on. The individual can decide in advance how much importance to accord to the issue for instance, by estimating how much its success or failure could help or harm the company’s bottom line. They can set a time limit for the discussion to create urgency. And they can end the meeting by verifying that it has indeed achieved its purpose. Any issue that invites a lot of discussions from different people might not be the most important one at hand. Avoid descending into unproductive triviality by having clear goals for your meeting and getting the best people to the table to have a productive, constructive discussion.",
					"content_token": 186,
					"embedding": []
				}
			]
		},
		{
			"title": "Preserving Optionality: Preparing for the Unknown",
			"url": "https://fs.blog/preserving-optionality/",
			"content": "We’re often advised to excel at one thing. But as the future gets harder to predict, preserving optionality allows us to pivot when the road ahead crumbles.  How do we prepare for a world that often changes drastically and rapidly? We can preserve our optionality. We don’t often get the advice to keep our options open. Instead, we’re told to specialize by investing huge hours in our passion so we can be successful in a niche. The problem is, it’s bad advice. We live in a world that’s constantly changing, and if we can’t respond effectively to those changes, we become redundant, frustrated, and useless. Instead of focusing on becoming great at one thing, there is another, counterintuitive strategy that will get us further: preserving optionality. The more options we have, the better suited we are to deal with unpredictability and uncertainty. We can stay calm when others panic because we have choices. Optionality refers to the act of keeping as many options open as possible. Preserving optionality means avoiding limiting choices or dependencies. It means staying open to opportunities and always having a backup plan. An option is usually defined as something we have the freedom to choose. That’s a fairly broad definition. In the context of a strategy, it must also have a limited downside and an open-ended upside. Betting in a casino is not an option, for examplethe upside is known. Losses and gains are both constrained. What about betting on a new tech startup? That’s an optionthe upside is theoretically unlimited; the losses are limited to the amount you invest. Options present themselves all the time, but life-altering ones often come up during times of great change. These options are the ones we have the hardest time capitalizing on. If we’ve specialized too much, change is a threat, not an opportunity. Thus, if we aren’t certain where the opportunities are going to be and we never are, then we need to make choices to keep our options open. Baron Rothschild is often quoted as having said that “the time to buy is when there’s blood in the streets.” That’s a misquote, however. What he actually said was “buy when there’s blood in the streets, even if the blood is your own.” Rothschild recognized that those are the times when new options emerge. That’s when many investors make their fortunes and when entrepreneurs innovate. Rothschild saw opportunity in chaos. He made a fortune buying during the panic after the Battle of Waterloo. When we occupy a small niche, we sacrifice optionality. That means less freedom and greater dependency. No one can predict the futurenot even expertsso isn’t it a good idea to have as many avenues open as possible? The coach’s dilemma: strength vs. optionality In Simple Rules: How to Thrive in a Complex World, Kathleen Eisenhardt and Donald Sull describe the experience of strength coach Shannon Turley. For the uninitiated, the role of a strength coach is to help athletes stay healthy and perform better, rather than teach specific skills. Turley began his career working at Virginia Polytechnic Institute and State University. When he started, the football players there followed a strength program based on weightlifting alone. Athletes wore t-shirts listing their personal records and competed to outdo each other. The mantra was: get stronger by lifting more weight. But Turley soon realized that this program was not effective because it left the athletes with limited optionality. Turley found no correlation between weightlifting prowess and competitive performance. Being able to bench press a lot of weight didn’t serve them well on the football field. As he put it, “In football if you’re on your back, you’ve already lost.” Keeping a record of what he saw, he began looking for different options for the athletes. After gaining experience coaching in several sports, Turley realized that strength was not the most important factor for athletic success. What mattered for any type of athlete was staying free of injuries and good nutrition. Why? Because that gave athletes greater optionality. An uninjured, healthy player could stay in each game for longer and miss fewer training sessions. It also meant less chance of requiring surgery, which many of his students faced, or of being forced to retire from competitive sports at a young age. Turley began coaching football players at Stanford University. He implemented a program focusing on proper nutrition and flexibility exercises such as yoganot weightlifting. He also focused on healing existing injuries that restricted athletes’ performance. One football player he worked with had ongoing back problems, so Turley designed a regime to improve that issue. It worked: the athlete never missed a game and went on to play in the NFL. Turley’s approach served to preserve optionality for his players. Even the best athlete will lose many competitions. So the more an athlete is healthy enough to participate in games, the greater the chances of those crucial successes. Turley’s experience illustrates the trade-offs between particular physical abilities and optionality. Over-specializing in one area is highly limiting, especially if it requires extensive upkeep. Like a football player, we can retain optionality by avoiding overtly damaging risks and ensuring we stay in the game for as long as possiblewhatever that game is. That might mean lifting less metaphorical weight at any one time, while also working to keep ourselves flexible. The tyranny of small decisions Few people would deliberately lock themselves into an undesirable situation. Yet we often make small, rational decisions that end up removing options over time. This is the tyranny of small decisions. Economist Alfred Kahn identified the concept in 1966. Kahn begins the article with a provocative thought experiment: Suppose, 75 years ago, some being from outer space had made us this proposition: “I know how to make a vehicle that could in effect put 200 horses at the disposal of each of you. It would permit you to travel about, alone or in small groups, at 60 to 80 miles an hour. But the costs of this gadget are 40,000 lives per year, global warming, the decay of the inner city, endless commuting, and suburban sprawl.” What would we have chosen collectively? Put that way, the answer, of course, is nowe wouldn’t choose the advancement of transportation technology if we could immediately see the grievous cost. But we have said yes to that exact offer over time through a million small decisions, and now it is difficult to back out. Most of the modern world is built to accommodate cars. Driving is now the “rational” choice, no matter the destructive effect. Sometimes it feels as though we have no other option. Kahn’s point is that small decisions can lead to bad outcomes. At some point, alternatives disappear. We lose our optionality. It is easy to see the downsides of big decisions. The costs of smaller ones can be more elusive. In a market economy, Kahn explains, change is the result of tiny steps. Combined, they have a tremendous cumulative effect on our collective freedom. Day to day, it is hard to see the path that is forming. At some point, we may look up and not like where we are going. By then it is too late. Kahn writes: Only if consumers are given the full range of economically feasible and socially desirable alternatives in a big discrete bundle will misallocation of resources due to the tyranny of small market-determined decisions be broken. The tragedy of the commons is another such instance of the power of small decisions. Garett Hardin’s parable illustrates why common resources are used more than is desirable from the standpoint of society as a whole. No one person makes a single decision to deplete the resources. Instead, each person makes a series of small choices that ultimately cause environmental ruin. In the original example where villagers are freely able to graze their animals on common land, having access to it gives everyone a lot of options for raising animals or farming. Once the pasture is exhausted from everyone putting too many animals out to graze, however, everyone loses their optionality. Optionality can be a matter of perspective As Seneca put it, “In one and the same meadow, the cow looks for grass, the dog for a hare, and the stork for a lizard.” Where some people only see blood in the streets, other people see a chance to succeed. Preserving optionality can be as much about changing our attitudes as our circumstances. It can be about learning to spot opportunitiesand to make them. Optionality is not a new concept. A portion of the Old Testament dating back to between 450 and 180 BCE declares: Invest in seven ventures, yes, in eight; you do not know what disaster may come upon the land. If clouds are full of water, they pour rain on the earth. Whether a tree falls to the south or to the north, in the place where it falls, there it will lie. Whoever watches the wind will not plant; whoever looks at the clouds will not reap . . . Sow your seed in the morning, and at evening let your hands not be idle, for you do not know which will succeed, whether this or that, or whether both will do equally well. In today’s world, optionality can be integrated into a number of different areas of our lives by looking for ways to prepare for a variety of possible events, instead of optimizing for the recent past. Keeping our options open means developing generalist skills like creativity, rather than specializing in one area, like a particular technology. The more diverse the knowledge and skills you can draw on, the better positioned you are to take advantage of new opportunities. It means not relying on a single distributor for your company’s product or having the supply chain for an entire industry dependent on one country. You can’t make your decisions solely on how the world was yesterday. Preserving optionality means you may take a short-term hit in sales by funding diversity, but the result is you will be much better positioned in the future to keep your business going when circumstances change. It means not relying on a single energy source to power the vehicles that move us and the goods we need around. Building our society around oila finite resourceis limiting. Developing multiple forms of sustainable energy creates new options for when that finite resource is depleted. Or consider the lean startup methodology. Building a minimum viable product means having the flexibility to pivot or change plans. No demand? No problem! Just try something else. Lean startups iterate until they find productmarket fit. Many founders keep their teams as small as possible. They avoid fixed costs and commitments. They keep their options open. The lean startup methodology recognizes that a new company cannot make a grand plan; it needs to adapt and evolve. As Steve Jobs understood, most customers don’t know they will want something until they have tried it. It’s hard to prepare for changing customer desires without optionality. If a company is flexible, they can adapt to the information they receive once a product hits the market. “Wealth is not about having a lot of money; it’s about having a lot of options.”   Chris Rock Ultimately, preserving optionality means paying attention and looking at life from multiple perspectives. It means building a versatile base of foundational knowledge and allowing for serendipity and unexpected connections. We must seek to expand our comfort zone and circle of competence, and we should take minor risks that have potentially large upsides and limited downsides. Paradoxically, preserving optionality can mean saying no to a lot of opportunities and avoiding anything that will prove to be restrictive. We need to look at choices through the lens of the optionality they will give us in the future and only say yes to those that create more options. Preserving your optionality is important because it gives you the flexibility to capitalize on inevitable change. In order to keep your options open, you need diversity. Diversity of perspective, thought, knowledge, and skills. You don’t want to find yourself in a position of only being able to sell something that no one wants. Rapid, extraordinary change is the norm. In order to adapt in a way that is useful, keep your options open.",
			"tokens": 2543,
			"chunks": [
				{
					"article_title": "Preserving Optionality: Preparing for the Unknown",
					"article_url": "https://fs.blog/preserving-optionality/",
					"content": "We’re often advised to excel at one thing. But as the future gets harder to predict, preserving optionality allows us to pivot when the road ahead crumbles.  How do we prepare for a world that often changes drastically and rapidly? We can preserve our optionality. We don’t often get the advice to keep our options open. Instead, we’re told to specialize by investing huge hours in our passion so we can be successful in a niche. The problem is, it’s bad advice. We live in a world that’s constantly changing, and if we can’t respond effectively to those changes, we become redundant, frustrated, and useless. Instead of focusing on becoming great at one thing, there is another, counterintuitive strategy that will get us further: preserving optionality. The more options we have, the better suited we are to deal with unpredictability and uncertainty. We can stay calm when others panic because we have choices. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "Preserving Optionality: Preparing for the Unknown",
					"article_url": "https://fs.blog/preserving-optionality/",
					"content": "Optionality refers to the act of keeping as many options open as possible. Preserving optionality means avoiding limiting choices or dependencies. It means staying open to opportunities and always having a backup plan. An option is usually defined as something we have the freedom to choose. That’s a fairly broad definition. In the context of a strategy, it must also have a limited downside and an open-ended upside. Betting in a casino is not an option, for examplethe upside is known. Losses and gains are both constrained. What about betting on a new tech startup? That’s an optionthe upside is theoretically unlimited; the losses are limited to the amount you invest. Options present themselves all the time, but life-altering ones often come up during times of great change. These options are the ones we have the hardest time capitalizing on. If we’ve specialized too much, change is a threat, not an opportunity. ",
					"content_token": 194,
					"embedding": []
				},
				{
					"article_title": "Preserving Optionality: Preparing for the Unknown",
					"article_url": "https://fs.blog/preserving-optionality/",
					"content": "Thus, if we aren’t certain where the opportunities are going to be and we never are, then we need to make choices to keep our options open. Baron Rothschild is often quoted as having said that “the time to buy is when there’s blood in the streets.” That’s a misquote, however. What he actually said was “buy when there’s blood in the streets, even if the blood is your own.” Rothschild recognized that those are the times when new options emerge. That’s when many investors make their fortunes and when entrepreneurs innovate. Rothschild saw opportunity in chaos. He made a fortune buying during the panic after the Battle of Waterloo. When we occupy a small niche, we sacrifice optionality. That means less freedom and greater dependency. ",
					"content_token": 167,
					"embedding": []
				},
				{
					"article_title": "Preserving Optionality: Preparing for the Unknown",
					"article_url": "https://fs.blog/preserving-optionality/",
					"content": "No one can predict the futurenot even expertsso isn’t it a good idea to have as many avenues open as possible? The coach’s dilemma: strength vs. optionality In Simple Rules: How to Thrive in a Complex World, Kathleen Eisenhardt and Donald Sull describe the experience of strength coach Shannon Turley. For the uninitiated, the role of a strength coach is to help athletes stay healthy and perform better, rather than teach specific skills. Turley began his career working at Virginia Polytechnic Institute and State University. When he started, the football players there followed a strength program based on weightlifting alone. Athletes wore t-shirts listing their personal records and competed to outdo each other. The mantra was: get stronger by lifting more weight. But Turley soon realized that this program was not effective because it left the athletes with limited optionality. Turley found no correlation between weightlifting prowess and competitive performance. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "Preserving Optionality: Preparing for the Unknown",
					"article_url": "https://fs.blog/preserving-optionality/",
					"content": "Being able to bench press a lot of weight didn’t serve them well on the football field. As he put it, “In football if you’re on your back, you’ve already lost.” Keeping a record of what he saw, he began looking for different options for the athletes. After gaining experience coaching in several sports, Turley realized that strength was not the most important factor for athletic success. What mattered for any type of athlete was staying free of injuries and good nutrition. Why? Because that gave athletes greater optionality. An uninjured, healthy player could stay in each game for longer and miss fewer training sessions. It also meant less chance of requiring surgery, which many of his students faced, or of being forced to retire from competitive sports at a young age. Turley began coaching football players at Stanford University. He implemented a program focusing on proper nutrition and flexibility exercises such as yoganot weightlifting. ",
					"content_token": 194,
					"embedding": []
				},
				{
					"article_title": "Preserving Optionality: Preparing for the Unknown",
					"article_url": "https://fs.blog/preserving-optionality/",
					"content": "He also focused on healing existing injuries that restricted athletes’ performance. One football player he worked with had ongoing back problems, so Turley designed a regime to improve that issue. It worked: the athlete never missed a game and went on to play in the NFL. Turley’s approach served to preserve optionality for his players. Even the best athlete will lose many competitions. So the more an athlete is healthy enough to participate in games, the greater the chances of those crucial successes. Turley’s experience illustrates the trade-offs between particular physical abilities and optionality. Over-specializing in one area is highly limiting, especially if it requires extensive upkeep. Like a football player, we can retain optionality by avoiding overtly damaging risks and ensuring we stay in the game for as long as possiblewhatever that game is. That might mean lifting less metaphorical weight at any one time, while also working to keep ourselves flexible. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "Preserving Optionality: Preparing for the Unknown",
					"article_url": "https://fs.blog/preserving-optionality/",
					"content": "The tyranny of small decisions Few people would deliberately lock themselves into an undesirable situation. Yet we often make small, rational decisions that end up removing options over time. This is the tyranny of small decisions. Economist Alfred Kahn identified the concept in 1966. Kahn begins the article with a provocative thought experiment: Suppose, 75 years ago, some being from outer space had made us this proposition: “I know how to make a vehicle that could in effect put 200 horses at the disposal of each of you. It would permit you to travel about, alone or in small groups, at 60 to 80 miles an hour. But the costs of this gadget are 40,000 lives per year, global warming, the decay of the inner city, endless commuting, and suburban sprawl.” What would we have chosen collectively? Put that way, the answer, of course, is nowe wouldn’t choose the advancement of transportation technology if we could immediately see the grievous cost. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "Preserving Optionality: Preparing for the Unknown",
					"article_url": "https://fs.blog/preserving-optionality/",
					"content": "But we have said yes to that exact offer over time through a million small decisions, and now it is difficult to back out. Most of the modern world is built to accommodate cars. Driving is now the “rational” choice, no matter the destructive effect. Sometimes it feels as though we have no other option. Kahn’s point is that small decisions can lead to bad outcomes. At some point, alternatives disappear. We lose our optionality. It is easy to see the downsides of big decisions. The costs of smaller ones can be more elusive. In a market economy, Kahn explains, change is the result of tiny steps. Combined, they have a tremendous cumulative effect on our collective freedom. Day to day, it is hard to see the path that is forming. At some point, we may look up and not like where we are going. By then it is too late. ",
					"content_token": 183,
					"embedding": []
				},
				{
					"article_title": "Preserving Optionality: Preparing for the Unknown",
					"article_url": "https://fs.blog/preserving-optionality/",
					"content": "Kahn writes: Only if consumers are given the full range of economically feasible and socially desirable alternatives in a big discrete bundle will misallocation of resources due to the tyranny of small market-determined decisions be broken. The tragedy of the commons is another such instance of the power of small decisions. Garett Hardin’s parable illustrates why common resources are used more than is desirable from the standpoint of society as a whole. No one person makes a single decision to deplete the resources. Instead, each person makes a series of small choices that ultimately cause environmental ruin. In the original example where villagers are freely able to graze their animals on common land, having access to it gives everyone a lot of options for raising animals or farming. Once the pasture is exhausted from everyone putting too many animals out to graze, however, everyone loses their optionality. ",
					"content_token": 177,
					"embedding": []
				},
				{
					"article_title": "Preserving Optionality: Preparing for the Unknown",
					"article_url": "https://fs.blog/preserving-optionality/",
					"content": "Optionality can be a matter of perspective As Seneca put it, “In one and the same meadow, the cow looks for grass, the dog for a hare, and the stork for a lizard.” Where some people only see blood in the streets, other people see a chance to succeed. Preserving optionality can be as much about changing our attitudes as our circumstances. It can be about learning to spot opportunitiesand to make them. Optionality is not a new concept. A portion of the Old Testament dating back to between 450 and 180 BCE declares: Invest in seven ventures, yes, in eight; you do not know what disaster may come upon the land. If clouds are full of water, they pour rain on the earth. Whether a tree falls to the south or to the north, in the place where it falls, there it will lie. Whoever watches the wind will not plant; whoever looks at the clouds will not reap    ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "Preserving Optionality: Preparing for the Unknown",
					"article_url": "https://fs.blog/preserving-optionality/",
					"content": "Sow your seed in the morning, and at evening let your hands not be idle, for you do not know which will succeed, whether this or that, or whether both will do equally well. In today’s world, optionality can be integrated into a number of different areas of our lives by looking for ways to prepare for a variety of possible events, instead of optimizing for the recent past. Keeping our options open means developing generalist skills like creativity, rather than specializing in one area, like a particular technology. The more diverse the knowledge and skills you can draw on, the better positioned you are to take advantage of new opportunities. It means not relying on a single distributor for your company’s product or having the supply chain for an entire industry dependent on one country. You can’t make your decisions solely on how the world was yesterday. ",
					"content_token": 176,
					"embedding": []
				},
				{
					"article_title": "Preserving Optionality: Preparing for the Unknown",
					"article_url": "https://fs.blog/preserving-optionality/",
					"content": "Preserving optionality means you may take a short-term hit in sales by funding diversity, but the result is you will be much better positioned in the future to keep your business going when circumstances change. It means not relying on a single energy source to power the vehicles that move us and the goods we need around. Building our society around oila finite resourceis limiting. Developing multiple forms of sustainable energy creates new options for when that finite resource is depleted. Or consider the lean startup methodology. Building a minimum viable product means having the flexibility to pivot or change plans. No demand? No problem! Just try something else. Lean startups iterate until they find productmarket fit. Many founders keep their teams as small as possible. They avoid fixed costs and commitments. They keep their options open. The lean startup methodology recognizes that a new company cannot make a grand plan; it needs to adapt and evolve. ",
					"content_token": 183,
					"embedding": []
				},
				{
					"article_title": "Preserving Optionality: Preparing for the Unknown",
					"article_url": "https://fs.blog/preserving-optionality/",
					"content": "As Steve Jobs understood, most customers don’t know they will want something until they have tried it. It’s hard to prepare for changing customer desires without optionality. If a company is flexible, they can adapt to the information they receive once a product hits the market. “Wealth is not about having a lot of money; it’s about having a lot of options.”   Chris Rock Ultimately, preserving optionality means paying attention and looking at life from multiple perspectives. It means building a versatile base of foundational knowledge and allowing for serendipity and unexpected connections. We must seek to expand our comfort zone and circle of competence, and we should take minor risks that have potentially large upsides and limited downsides. Paradoxically, preserving optionality can mean saying no to a lot of opportunities and avoiding anything that will prove to be restrictive. ",
					"content_token": 180,
					"embedding": []
				},
				{
					"article_title": "Preserving Optionality: Preparing for the Unknown",
					"article_url": "https://fs.blog/preserving-optionality/",
					"content": "We need to look at choices through the lens of the optionality they will give us in the future and only say yes to those that create more options. Preserving your optionality is important because it gives you the flexibility to capitalize on inevitable change. In order to keep your options open, you need diversity. Diversity of perspective, thought, knowledge, and skills. You don’t want to find yourself in a position of only being able to sell something that no one wants. Rapid, extraordinary change is the norm. In order to adapt in a way that is useful, keep your options open.",
					"content_token": 121,
					"embedding": []
				}
			]
		},
		{
			"title": "Externalities: Why We Can Never Do “One Thing”",
			"url": "https://fs.blog/externalities-why-we-can-never-do-one-thing/",
			"content": "No action exists in a vacuum. There are ripples that have consequences that we can and can’t see. Here are the three types of externalities that can help us guide our actions so they don’t come back to bite us.  An externality affects someone without them agreeing to it. As with unintended consequences, externalities can be positive or negative. Understanding the types of externalities and the impact they have in our lives can help us improve our decision making, and how we interact with the world. Externalities provide useful mental models for understanding complex systems. They show us that systems don’t exist in isolation from other systems. Externalities may affect uninvolved third parties which make them a form of market failure an inefficient allocation of resources. We both create and are subject to externalities. Most are very minor but compound over time. They can inflict numerous second-order effects. Someone reclines their seat on an airplane. They get the benefit of comfort. The person behind bears the cost of discomfort by having less space. One family member leaves their dirty dishes in the sink. They get the benefit of using the plate. Someone else bears the cost of washing it later. We can’t expect to interact with any system without repercussions. Over time, even minor externalities can cause significant strain in our lives and relationships. The First Law of Ecology To understand externalities it is first useful to consider second-order consequences. In Filters Against Folly, Garrett Hardin describes what he considers to be the First Law of Ecology: We can never do one thing. Whenever we interact with a system, we need to ask, “And then what? What will the wider repercussions of our actions be?” There is bound to be at least one externality. Hardin gives the example of the Prohibition Amendment in the U.S. In 1920, lawmakers banned the production and sale of alcoholic beverages throughout the entire country. This was in response to an extended campaign by those who believed alcohol was evil. It wasn’t enough to restrict its consumptionit needed to go. The addition of 61 words to the American Constitution changed the social and legal landscape for over a decade. Policymakers presumably thought they could make the change and people would stop drinking. But Prohibition led to numerous externalities. Alcohol is an important part of many people’s lives. Few were willing to suddenly give it up without a fight. The demand was more than strong enough to ensure a black-market supply re-emerged. Wealthy people stockpiled alcohol in their homes before the ban went into effect. Thousands of speakeasies and gin joints flourished. Walgreens grew from 20 stores to 500, in large part due to its sales of medicinal’ whiskey. Former alcohol producers simply sold the ingredients for people to make their own. Gangsters like Al Capone made their fortune smuggling, and murdered his rivals in the process. Crime gangs undermined official institutions. Tax revenues plummeted. People lost their jobs. Prisons became overcrowded and bribery commonplace. Thousands died from crime and drinking unsafe homemade alcohol. Policymakers did not fully ask, “And then what?” before legislating. Drinking did decrease during this time, on average by about half.  But this was far from the hope of a total ban. The second-order consequences outweighed any benefits. As economist Gregory Mankiw explains in Principles of Microeconomics, In the presence of externalities, society’s interest in a market outcome extends beyond the well-being of buyers and sellers who participate in the market; it also includes the well-being of bystanders who are affected indirectly. The market equilibrium is not efficient when there are externalities. That is, the equilibrium fails to maximize the total benefit to society as a whole. Negative Externalities Negative externalities can occur during the production or consumption of a service or good. Pollution is a useful example. If a factory pollutes nearby water supplies, it causes harm without incurring costs. The costs to society are high and are not reflected in the price of whatever the factory makes. Economists often view environmental damage as another factor in a production process. But even if pollution is taxed, the harmful effects don’t go away. Transport and manufacturing release toxins into the environment, harming our health and altering our climate. The reality though, is these externalities are hard to see, and it is often difficult to trace them back to their root causes. There’s also the question of whether we are responsible for externalities or not. Imagine you’re driving down the road. As you go by an apartment, the noise disturbs someone who didn’t agree to it. Your car emits air pollution, which affects everyone living nearby. Each of these small externalities will affect people you don’t see and who didn’t choose them. They won’t receive any compensation from you. Are you really responsible for the externalities you cause? If you’re not being outright careless or malicious, isn’t it just part of life? How much responsibility do we have as individuals, anyway? Calling something a negative externality can be a convenient way of abdicating responsibility. Positive Externalities A positive externality imposes an unexpected benefit on a third party. The producer doesn’t agree to this, nor do they receive compensation for it. Scientific research often leads to positive externalities. Research findings can have applications beyond their initial scope. The resulting information becomes part of our collective knowledge base. However, the researcher who makes a discovery cannot receive the full benefits. Nor do they necessarily feel entitled to them. Blaise Pascal and Pierre de Fermat developed probability theory to solve a gambling dispute. Their work went on to inform numerous disciplines like the field of calculus and transform our understanding of the world. Probabilities are now a core part of how we think. Pascal and Fermat created a positive externality. Someone who comes up with an equation cannot expect compensation each time it gets used. As a result, the incentives to invest the time and effort to discover new equations are reduced. Algorithms, patents, and copyright laws change this by allowing creators to protect and profit from their ideas for years before other people can freely use them. We all benefit, and researchers have an incentive to continue their work. Network effects are an example of a positive externality. Silicon Valley understands this well. Each person who joins a network, like a marketplace app, increases the value to all other users. Those who own the network have an incentive improve it to encourage new users. Everyone benefits from being able to communicate with more people. While we might not join a new network intending to improve it for other people, that is what normally happens. On the flipside, network effects can also produce negative externalities, as too many members can decrease the value of a network. Positive externalities often lead to the “free rider” problem. When we enjoy something that we aren’t paying for, we tend not to value it. Not paying can remove the incentive to look after a resource and leads to a Tragedy of the Commons situation. As Aristotle put it, “For that which is common to the greatest number has the least care bestowed upon it.” A good portion of online content succumbs to the free rider problem. We enjoy it and yet we don’t pay for it. We expect it to be free and yet, if users weren’t willing to support sites like Farnam Street, they would likely fold, start publishing lower quality articles, or sell readers to advertisers who collect their data. The end result, as we see too frequently, is low-quality content funded by page-view advertising. This is why we have a membership program. Members create a positive externality for non-members by helping support the free content. Positional Externalities Positional externalities are a form of second-order effects. They occur when our decisions alter the context of future perception or value. For example, consider what happens when a person decides to start staying at the office an hour late. Perhaps they want a promotion and think it will endear them to managers. Parkinson’s Law states that tasks expand to fit the time allocated to them. What this person would otherwise get done by 5pm, now takes until 6pm. Staying late becomes their norm. Their co-workers notice and start to also stay late. Before long, staying at the office until 6pm becomes the standard for everyone. Anyone who leaves at 5pm is perceived as lazy. Now that 6pm is the norm, everyone suffers. They are forced to work more without deriving any real benefits. It’s a lose-lose situation for everyone. Someone we know once made an investment with a nearly unlimited return by gaming the system. He worked for an investment firm that valued employees according to a perception of how hard they worked and not necessarily by their results. Each Monday he brought in a series of sport coats and left them in the office. He paid the cleaning staff 20 a week to change the coat hanging on his chair and to turn on his computer. No matter what happened, it appeared he was always the first one into the office even though he often didn’t show up from a “client meeting” until 10. When it came to bonus time, he’d get an enormous return on that 20 investment. Purchasing luxury goods can create positional externalities. Veblen goods are items we value because of their scarcity and high cost. Diamonds, Lamborghinis, tailor-made suits  owning them is a status symbol, and they lose their value if they become cheaper or if too many people have them. As Luca Lambertini puts it in The Economics of Vertically Differentiated Markets,  The utility derived from consumption is a function of the quantity purchased relative to the average of the society or the reference group to whom the consumer compares.” In other words, a shiny new car seems more valuable if all your friends are driving battered old wrecks. If they have equally or more fancy cars, the value of yours drops. At some point, it seems worthless and it’s time to find a new one. In this way, the purchase of a Veblen good confers a positional externality on other people who own it too. That utility can also be a matter of comparison. A person earning 40,000 a year while their friends earn 30,000 will be happier than one earning 60,000 when their friends earn 70,000. When someone’s salary increases, it raises the bar, giving others a new point of reference. We can confer positional externalities on ourselves by changing our attitudes. Let’s say someone enjoys wine but is not a connoisseur. A 10 bottle and a 100 bottle make them equally happy. When they decide to go on a course and learn the subtleties and technicalities of fine wines, they develop an appreciation for the 100 wine and a distaste for the 10. They may no longer be able to enjoy a cheap drink because they raised their standards. Conclusion Externalities are everywhere. It’s easy to ignore the impact of our decisionsto recline an airplane seat, to stay late at the office, or drop litter. Eventually though, someone always ends up paying. Like the villagers in Hardin’s Tragedy of the Commons, who end up with no grass for their animals, we run the risk of ruining a good thing if we don’t take care of it. Keeping the three types of externalities in mind is a useful way to make decisions that won’t come back to bite you. Whenever we interact with a system, we should remember to ask Hardin’s question: and then what?",
			"tokens": 2436,
			"chunks": [
				{
					"article_title": "Externalities: Why We Can Never Do “One Thing”",
					"article_url": "https://fs.blog/externalities-why-we-can-never-do-one-thing/",
					"content": "No action exists in a vacuum. There are ripples that have consequences that we can and can’t see. Here are the three types of externalities that can help us guide our actions so they don’t come back to bite us.  An externality affects someone without them agreeing to it. As with unintended consequences, externalities can be positive or negative. Understanding the types of externalities and the impact they have in our lives can help us improve our decision making, and how we interact with the world. Externalities provide useful mental models for understanding complex systems. They show us that systems don’t exist in isolation from other systems. Externalities may affect uninvolved third parties which make them a form of market failure an inefficient allocation of resources. We both create and are subject to externalities. Most are very minor but compound over time. They can inflict numerous second-order effects. Someone reclines their seat on an airplane. They get the benefit of comfort. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "Externalities: Why We Can Never Do “One Thing”",
					"article_url": "https://fs.blog/externalities-why-we-can-never-do-one-thing/",
					"content": "The person behind bears the cost of discomfort by having less space. One family member leaves their dirty dishes in the sink. They get the benefit of using the plate. Someone else bears the cost of washing it later. We can’t expect to interact with any system without repercussions. Over time, even minor externalities can cause significant strain in our lives and relationships. The First Law of Ecology To understand externalities it is first useful to consider second-order consequences. In Filters Against Folly, Garrett Hardin describes what he considers to be the First Law of Ecology: We can never do one thing. Whenever we interact with a system, we need to ask, “And then what? What will the wider repercussions of our actions be?” There is bound to be at least one externality. Hardin gives the example of the Prohibition Amendment in the U.S. In 1920, lawmakers banned the production and sale of alcoholic beverages throughout the entire country. ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "Externalities: Why We Can Never Do “One Thing”",
					"article_url": "https://fs.blog/externalities-why-we-can-never-do-one-thing/",
					"content": "This was in response to an extended campaign by those who believed alcohol was evil. It wasn’t enough to restrict its consumptionit needed to go. The addition of 61 words to the American Constitution changed the social and legal landscape for over a decade. Policymakers presumably thought they could make the change and people would stop drinking. But Prohibition led to numerous externalities. Alcohol is an important part of many people’s lives. Few were willing to suddenly give it up without a fight. The demand was more than strong enough to ensure a black-market supply re-emerged. Wealthy people stockpiled alcohol in their homes before the ban went into effect. Thousands of speakeasies and gin joints flourished. Walgreens grew from 20 stores to 500, in large part due to its sales of medicinal’ whiskey. Former alcohol producers simply sold the ingredients for people to make their own. ",
					"content_token": 183,
					"embedding": []
				},
				{
					"article_title": "Externalities: Why We Can Never Do “One Thing”",
					"article_url": "https://fs.blog/externalities-why-we-can-never-do-one-thing/",
					"content": "Gangsters like Al Capone made their fortune smuggling, and murdered his rivals in the process. Crime gangs undermined official institutions. Tax revenues plummeted. People lost their jobs. Prisons became overcrowded and bribery commonplace. Thousands died from crime and drinking unsafe homemade alcohol. Policymakers did not fully ask, “And then what?” before legislating. Drinking did decrease during this time, on average by about half.  But this was far from the hope of a total ban. The second-order consequences outweighed any benefits. As economist Gregory Mankiw explains in Principles of Microeconomics, In the presence of externalities, society’s interest in a market outcome extends beyond the well-being of buyers and sellers who participate in the market; it also includes the well-being of bystanders who are affected indirectly. The market equilibrium is not efficient when there are externalities. That is, the equilibrium fails to maximize the total benefit to society as a whole. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "Externalities: Why We Can Never Do “One Thing”",
					"article_url": "https://fs.blog/externalities-why-we-can-never-do-one-thing/",
					"content": "Negative Externalities Negative externalities can occur during the production or consumption of a service or good. Pollution is a useful example. If a factory pollutes nearby water supplies, it causes harm without incurring costs. The costs to society are high and are not reflected in the price of whatever the factory makes. Economists often view environmental damage as another factor in a production process. But even if pollution is taxed, the harmful effects don’t go away. Transport and manufacturing release toxins into the environment, harming our health and altering our climate. The reality though, is these externalities are hard to see, and it is often difficult to trace them back to their root causes. There’s also the question of whether we are responsible for externalities or not. Imagine you’re driving down the road. As you go by an apartment, the noise disturbs someone who didn’t agree to it. Your car emits air pollution, which affects everyone living nearby. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "Externalities: Why We Can Never Do “One Thing”",
					"article_url": "https://fs.blog/externalities-why-we-can-never-do-one-thing/",
					"content": "Each of these small externalities will affect people you don’t see and who didn’t choose them. They won’t receive any compensation from you. Are you really responsible for the externalities you cause? If you’re not being outright careless or malicious, isn’t it just part of life? How much responsibility do we have as individuals, anyway? Calling something a negative externality can be a convenient way of abdicating responsibility. Positive Externalities A positive externality imposes an unexpected benefit on a third party. The producer doesn’t agree to this, nor do they receive compensation for it. Scientific research often leads to positive externalities. Research findings can have applications beyond their initial scope. The resulting information becomes part of our collective knowledge base. However, the researcher who makes a discovery cannot receive the full benefits. Nor do they necessarily feel entitled to them. ",
					"content_token": 186,
					"embedding": []
				},
				{
					"article_title": "Externalities: Why We Can Never Do “One Thing”",
					"article_url": "https://fs.blog/externalities-why-we-can-never-do-one-thing/",
					"content": "Blaise Pascal and Pierre de Fermat developed probability theory to solve a gambling dispute. Their work went on to inform numerous disciplines like the field of calculus and transform our understanding of the world. Probabilities are now a core part of how we think. Pascal and Fermat created a positive externality. Someone who comes up with an equation cannot expect compensation each time it gets used. As a result, the incentives to invest the time and effort to discover new equations are reduced. Algorithms, patents, and copyright laws change this by allowing creators to protect and profit from their ideas for years before other people can freely use them. We all benefit, and researchers have an incentive to continue their work. Network effects are an example of a positive externality. Silicon Valley understands this well. Each person who joins a network, like a marketplace app, increases the value to all other users. Those who own the network have an incentive improve it to encourage new users. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "Externalities: Why We Can Never Do “One Thing”",
					"article_url": "https://fs.blog/externalities-why-we-can-never-do-one-thing/",
					"content": "Everyone benefits from being able to communicate with more people. While we might not join a new network intending to improve it for other people, that is what normally happens. On the flipside, network effects can also produce negative externalities, as too many members can decrease the value of a network. Positive externalities often lead to the “free rider” problem. When we enjoy something that we aren’t paying for, we tend not to value it. Not paying can remove the incentive to look after a resource and leads to a Tragedy of the Commons situation. As Aristotle put it, “For that which is common to the greatest number has the least care bestowed upon it.” A good portion of online content succumbs to the free rider problem. We enjoy it and yet we don’t pay for it. ",
					"content_token": 172,
					"embedding": []
				},
				{
					"article_title": "Externalities: Why We Can Never Do “One Thing”",
					"article_url": "https://fs.blog/externalities-why-we-can-never-do-one-thing/",
					"content": "We expect it to be free and yet, if users weren’t willing to support sites like Farnam Street, they would likely fold, start publishing lower quality articles, or sell readers to advertisers who collect their data. The end result, as we see too frequently, is low-quality content funded by page-view advertising. This is why we have a membership program. Members create a positive externality for non-members by helping support the free content. Positional Externalities Positional externalities are a form of second-order effects. They occur when our decisions alter the context of future perception or value. For example, consider what happens when a person decides to start staying at the office an hour late. Perhaps they want a promotion and think it will endear them to managers. Parkinson’s Law states that tasks expand to fit the time allocated to them. What this person would otherwise get done by 5pm, now takes until 6pm. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "Externalities: Why We Can Never Do “One Thing”",
					"article_url": "https://fs.blog/externalities-why-we-can-never-do-one-thing/",
					"content": "Staying late becomes their norm. Their co-workers notice and start to also stay late. Before long, staying at the office until 6pm becomes the standard for everyone. Anyone who leaves at 5pm is perceived as lazy. Now that 6pm is the norm, everyone suffers. They are forced to work more without deriving any real benefits. It’s a lose-lose situation for everyone. Someone we know once made an investment with a nearly unlimited return by gaming the system. He worked for an investment firm that valued employees according to a perception of how hard they worked and not necessarily by their results. Each Monday he brought in a series of sport coats and left them in the office. He paid the cleaning staff 20 a week to change the coat hanging on his chair and to turn on his computer. ",
					"content_token": 166,
					"embedding": []
				},
				{
					"article_title": "Externalities: Why We Can Never Do “One Thing”",
					"article_url": "https://fs.blog/externalities-why-we-can-never-do-one-thing/",
					"content": "No matter what happened, it appeared he was always the first one into the office even though he often didn’t show up from a “client meeting” until 10. When it came to bonus time, he’d get an enormous return on that 20 investment. Purchasing luxury goods can create positional externalities. Veblen goods are items we value because of their scarcity and high cost. Diamonds, Lamborghinis, tailor-made suits  owning them is a status symbol, and they lose their value if they become cheaper or if too many people have them. As Luca Lambertini puts it in The Economics of Vertically Differentiated Markets,  The utility derived from consumption is a function of the quantity purchased relative to the average of the society or the reference group to whom the consumer compares.” In other words, a shiny new car seems more valuable if all your friends are driving battered old wrecks. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "Externalities: Why We Can Never Do “One Thing”",
					"article_url": "https://fs.blog/externalities-why-we-can-never-do-one-thing/",
					"content": "If they have equally or more fancy cars, the value of yours drops. At some point, it seems worthless and it’s time to find a new one. In this way, the purchase of a Veblen good confers a positional externality on other people who own it too. That utility can also be a matter of comparison. A person earning 40,000 a year while their friends earn 30,000 will be happier than one earning 60,000 when their friends earn 70,000. When someone’s salary increases, it raises the bar, giving others a new point of reference. We can confer positional externalities on ourselves by changing our attitudes. Let’s say someone enjoys wine but is not a connoisseur. A 10 bottle and a 100 bottle make them equally happy. ",
					"content_token": 167,
					"embedding": []
				},
				{
					"article_title": "Externalities: Why We Can Never Do “One Thing”",
					"article_url": "https://fs.blog/externalities-why-we-can-never-do-one-thing/",
					"content": "When they decide to go on a course and learn the subtleties and technicalities of fine wines, they develop an appreciation for the 100 wine and a distaste for the 10. They may no longer be able to enjoy a cheap drink because they raised their standards. Conclusion Externalities are everywhere. It’s easy to ignore the impact of our decisionsto recline an airplane seat, to stay late at the office, or drop litter. Eventually though, someone always ends up paying. Like the villagers in Hardin’s Tragedy of the Commons, who end up with no grass for their animals, we run the risk of ruining a good thing if we don’t take care of it. Keeping the three types of externalities in mind is a useful way to make decisions that won’t come back to bite you. Whenever we interact with a system, we should remember to ask Hardin’s question: and then what?",
					"content_token": 196,
					"embedding": []
				}
			]
		},
		{
			"title": "The Anatomy of a Great Decision",
			"url": "https://fs.blog/decision-anatomy/",
			"content": "Making better decisions is one of the best skills we can develop. Good decisions save time, money, and stress. Here, we break down what makes a good decision and what we can do to improve our decision-making processes.  Improving our decision-making abilities is a central goal at Farnam Street. Better decisions save time, money, and stress. While it’s an investment now, in the long run, learning principles and developing a multidisciplinary lens that we can apply throughout life is a worthy investment. As we have said before, a decision should not be judged solely on its outcome. Sometimes good decisions produce bad results. A recruiting process that has resulted in mostly excellent candidates will still occasionally fail to weed out a bad fit. It is impossible to have perfect and complete information for all the variables involved. So we do the best with what we have. Using a decision journal can move us to that place where we are consistently making better decisions. At its core, the technique of identifying and reflecting on process from beginning to end helps us achieve the two main qualities in better decisions: Using principles, not tactics Looking at a situation through a multidisciplinary lens These qualities are what we need to improve over time. And in the same way compounding interest increases our bank balance, better decisions produce exponentially better results the more of them we make. Hard decisions today, made well, prepare us to make decisions more easily in the future. When we look around, however, to see what we can learn from others who made great decisions, we often judge based solely on the outcomes. Whether a decision by a family member to buy Coca-Cola stock in the ’80s, or Caesar to cross the Rubicon, we evaluate a decision as good based on how things turned out. Evaluating decisions on outcomes prevents us from learning. We need to dive into a decision, cut it open and examine its parts. Regardless of what happened, learning how a decision was made is the place to find knowledge. So what does the anatomy of a great decision look like?  The Marshall Plan After WWII, Europe was in ruins. Much of the infrastructure had been destroyed. Many people were starving, and had lost everything they possessed. Those systems we take for granted, but on which we rely dailytransportation, manufacturing, agriculturehad been devastated. The economies were essentially broken, and the countries that saw a lot of fighting had much to rebuild. But with what money? Many countries were in serious debt. Continued, widespread economic hardships were on the horizon. In 1947, Secretary of State General George Marshall put forward a plan that has since carried his name, a plan to give a massive amount of money to several European nations. Those countries accepted, the continent was rebuilt, and Marshall is credited with one of the most positive defining acts of economics, politics, and ethics in the last century. But when you look at the thinking that went into the Marshall Plan, the reasoning behind the details, you see that it would have been a great decision regardless of the outcome. Asking the Right Questions At the beginning, participants asked questions. What do we want to achieve? What problems are we addressing? What does a successful outcome look like? From there came the principles, things like: strong economies minimize social unrest; countries that work toward mutual goals are less likely to fight each other; let’s not have another war in Europe anytime soon. Starting from these principles, decision makers evaluated the situation through a multidisciplinary lens. Economics, politics, humanitarian responsibilities, historical and psychological factorsthe plan sought to address issues on many fronts and took a wide perspective into account. The plan was developed in the State Department of the United States. It was not the work of a single individual, and contributions from many people made it into the final version that Marshall fought for in Congress. In the end, there were three key decisions made in terms of the structure of the plan: To give, versus lend, the majority of the aid To require the nations receiving the aid to work out how to allocate it To invite Russia to partake Using Multiple Lenses The decision to give rather than lend the majority of the aid was the result of looking at the situation through economic, political, and humanitarian lenses. It was also a win-win. Immediately following the war, the European nations had put significant effort into restarting their economies. But they were doing it with borrowed dollars, needing to import far more than they were capable of exporting. Many economies needed modernization, which was impossible to fund while paying for imports at the same time. Without full economic recovery in Europe, there was great danger of a recession, or even a second depression. Basically, Europe needed money. But economies are also about people. It is people who produce and consume and develop the economy. So it wasn’t just the countries that needed financial assistance, but the people in them. The designers of the plan knew that hungry, desperate people would only create more social unrest. They saw that if they didn’t give the money to Europe they might very well have to spend it on national security as Europe fell apart. And we can’t discount the impact of the physical reality of the aftermath of the war that the liberating forces confrontedstarving people, towns reduced to rubble. The case for humanitarian assistance was strong. Letting the World Do the Work For You The decision to have the participating nations allocate the aid among themselves was the answer to what the historical, political and psychological lenses revealed. Many people felt that the approach to reparations after WWI was a significant impetus for WWII. The First World War had a similar effect on the economies and infrastructures of the nations involved. In 1918, angry at Germany, France and Britain had demanded huge sums of money. The problem was, it essentially crippled Germany economically, and caused a social and political situation that created enmity among the European nations. Many argue that it was this series of events that produced a situation in which Hitler could come to power. The creators of the Marshall Plan were aware of this, and it was one of the elements that influenced the design of the terms. If Germany collapsed again, they might be fighting World War III in twenty years. By asking enemies to work together and approve each other’s share, the plan created a buy-in that defused much of the anger and animosity between the nations. Just a couple of years earlier they had been at war with each other. After sacrificing so much in both lives and money, it was natural that the various peoples were angry over both who started the war, and the many violent and destructive events that were enacted over those six years. But the US decided to not take sides and extend the alliances of the war. The plan creators realized this wouldn’t help fulfill the principles they had chosen to abide by. Europe working meant Europe working together. Outcomes Over Optics Inviting Russia to share in the aid was another important result of applying those political, historical, psychological, and humanitarian lenses. The end of WWII marked the beginning of the Cold War. More nebulous by nature, starting a couple of years after the liberation of Europe and the dropping of the atomic bomb, this political climate would shape international relations for the next 40 years. The Marshall Plan took into account how best to navigate this complicated territory. Russia had been a valuable ally during the war, holding the eastern front and inflicting considerable damage on Hitler’s efforts. But immediately post-war their actions demonstrated a desire to at least influence, if not control, the political structure of the world. Their version of communism was at direct odds with US democracy, and was thus considered a legitimate threat. Even though there was very little expectation that Russia would participate, and possibly even less desire to give them money, Russia and its allied countries were invited by both the US and the European nations to participate in the talks involving the implementation of the plan. They chose not to, and followed up with accusing the plan of being a front to American imperialist goals. This was important because it forced Russia’s hand. They could not later claim that the Iron Curtain was something that was thrust on them. It was, instead, something they deliberately chose to build. The Marshall Plan is remembered as a great decision, not strictly because of its outcomesthough it did contribute to the debatably successful reconstruction of Europe, it did not succeed in preventing the deterioration of relations with Russiabut because it was firmly grounded in principles that were identified and executed through a multidisciplinary lens.",
			"tokens": 1742,
			"chunks": [
				{
					"article_title": "The Anatomy of a Great Decision",
					"article_url": "https://fs.blog/decision-anatomy/",
					"content": "Making better decisions is one of the best skills we can develop. Good decisions save time, money, and stress. Here, we break down what makes a good decision and what we can do to improve our decision-making processes.  Improving our decision-making abilities is a central goal at Farnam Street. Better decisions save time, money, and stress. While it’s an investment now, in the long run, learning principles and developing a multidisciplinary lens that we can apply throughout life is a worthy investment. As we have said before, a decision should not be judged solely on its outcome. Sometimes good decisions produce bad results. A recruiting process that has resulted in mostly excellent candidates will still occasionally fail to weed out a bad fit. It is impossible to have perfect and complete information for all the variables involved. So we do the best with what we have. Using a decision journal can move us to that place where we are consistently making better decisions. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "The Anatomy of a Great Decision",
					"article_url": "https://fs.blog/decision-anatomy/",
					"content": "At its core, the technique of identifying and reflecting on process from beginning to end helps us achieve the two main qualities in better decisions: Using principles, not tactics Looking at a situation through a multidisciplinary lens These qualities are what we need to improve over time. And in the same way compounding interest increases our bank balance, better decisions produce exponentially better results the more of them we make. Hard decisions today, made well, prepare us to make decisions more easily in the future. When we look around, however, to see what we can learn from others who made great decisions, we often judge based solely on the outcomes. Whether a decision by a family member to buy Coca-Cola stock in the ’80s, or Caesar to cross the Rubicon, we evaluate a decision as good based on how things turned out. Evaluating decisions on outcomes prevents us from learning. We need to dive into a decision, cut it open and examine its parts. ",
					"content_token": 194,
					"embedding": []
				},
				{
					"article_title": "The Anatomy of a Great Decision",
					"article_url": "https://fs.blog/decision-anatomy/",
					"content": "Regardless of what happened, learning how a decision was made is the place to find knowledge. So what does the anatomy of a great decision look like?  The Marshall Plan After WWII, Europe was in ruins. Much of the infrastructure had been destroyed. Many people were starving, and had lost everything they possessed. Those systems we take for granted, but on which we rely dailytransportation, manufacturing, agriculturehad been devastated. The economies were essentially broken, and the countries that saw a lot of fighting had much to rebuild. But with what money? Many countries were in serious debt. Continued, widespread economic hardships were on the horizon. In 1947, Secretary of State General George Marshall put forward a plan that has since carried his name, a plan to give a massive amount of money to several European nations. Those countries accepted, the continent was rebuilt, and Marshall is credited with one of the most positive defining acts of economics, politics, and ethics in the last century. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "The Anatomy of a Great Decision",
					"article_url": "https://fs.blog/decision-anatomy/",
					"content": "But when you look at the thinking that went into the Marshall Plan, the reasoning behind the details, you see that it would have been a great decision regardless of the outcome. Asking the Right Questions At the beginning, participants asked questions. What do we want to achieve? What problems are we addressing? What does a successful outcome look like? From there came the principles, things like: strong economies minimize social unrest; countries that work toward mutual goals are less likely to fight each other; let’s not have another war in Europe anytime soon. Starting from these principles, decision makers evaluated the situation through a multidisciplinary lens. Economics, politics, humanitarian responsibilities, historical and psychological factorsthe plan sought to address issues on many fronts and took a wide perspective into account. The plan was developed in the State Department of the United States. It was not the work of a single individual, and contributions from many people made it into the final version that Marshall fought for in Congress. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "The Anatomy of a Great Decision",
					"article_url": "https://fs.blog/decision-anatomy/",
					"content": "In the end, there were three key decisions made in terms of the structure of the plan: To give, versus lend, the majority of the aid To require the nations receiving the aid to work out how to allocate it To invite Russia to partake Using Multiple Lenses The decision to give rather than lend the majority of the aid was the result of looking at the situation through economic, political, and humanitarian lenses. It was also a win-win. Immediately following the war, the European nations had put significant effort into restarting their economies. But they were doing it with borrowed dollars, needing to import far more than they were capable of exporting. Many economies needed modernization, which was impossible to fund while paying for imports at the same time. Without full economic recovery in Europe, there was great danger of a recession, or even a second depression. Basically, Europe needed money. But economies are also about people. It is people who produce and consume and develop the economy. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "The Anatomy of a Great Decision",
					"article_url": "https://fs.blog/decision-anatomy/",
					"content": "So it wasn’t just the countries that needed financial assistance, but the people in them. The designers of the plan knew that hungry, desperate people would only create more social unrest. They saw that if they didn’t give the money to Europe they might very well have to spend it on national security as Europe fell apart. And we can’t discount the impact of the physical reality of the aftermath of the war that the liberating forces confrontedstarving people, towns reduced to rubble. The case for humanitarian assistance was strong. Letting the World Do the Work For You The decision to have the participating nations allocate the aid among themselves was the answer to what the historical, political and psychological lenses revealed. Many people felt that the approach to reparations after WWI was a significant impetus for WWII. The First World War had a similar effect on the economies and infrastructures of the nations involved. ",
					"content_token": 185,
					"embedding": []
				},
				{
					"article_title": "The Anatomy of a Great Decision",
					"article_url": "https://fs.blog/decision-anatomy/",
					"content": "In 1918, angry at Germany, France and Britain had demanded huge sums of money. The problem was, it essentially crippled Germany economically, and caused a social and political situation that created enmity among the European nations. Many argue that it was this series of events that produced a situation in which Hitler could come to power. The creators of the Marshall Plan were aware of this, and it was one of the elements that influenced the design of the terms. If Germany collapsed again, they might be fighting World War III in twenty years. By asking enemies to work together and approve each other’s share, the plan created a buy-in that defused much of the anger and animosity between the nations. Just a couple of years earlier they had been at war with each other. After sacrificing so much in both lives and money, it was natural that the various peoples were angry over both who started the war, and the many violent and destructive events that were enacted over those six years. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "The Anatomy of a Great Decision",
					"article_url": "https://fs.blog/decision-anatomy/",
					"content": "But the US decided to not take sides and extend the alliances of the war. The plan creators realized this wouldn’t help fulfill the principles they had chosen to abide by. Europe working meant Europe working together. Outcomes Over Optics Inviting Russia to share in the aid was another important result of applying those political, historical, psychological, and humanitarian lenses. The end of WWII marked the beginning of the Cold War. More nebulous by nature, starting a couple of years after the liberation of Europe and the dropping of the atomic bomb, this political climate would shape international relations for the next 40 years. The Marshall Plan took into account how best to navigate this complicated territory. Russia had been a valuable ally during the war, holding the eastern front and inflicting considerable damage on Hitler’s efforts. But immediately post-war their actions demonstrated a desire to at least influence, if not control, the political structure of the world. ",
					"content_token": 188,
					"embedding": []
				},
				{
					"article_title": "The Anatomy of a Great Decision",
					"article_url": "https://fs.blog/decision-anatomy/",
					"content": "Their version of communism was at direct odds with US democracy, and was thus considered a legitimate threat. Even though there was very little expectation that Russia would participate, and possibly even less desire to give them money, Russia and its allied countries were invited by both the US and the European nations to participate in the talks involving the implementation of the plan. They chose not to, and followed up with accusing the plan of being a front to American imperialist goals. This was important because it forced Russia’s hand. They could not later claim that the Iron Curtain was something that was thrust on them. It was, instead, something they deliberately chose to build. The Marshall Plan is remembered as a great decision, not strictly because of its outcomesthough it did contribute to the debatably successful reconstruction of Europe, it did not succeed in preventing the deterioration of relations with Russiabut because it was firmly grounded in principles that were identified and executed through a multidisciplinary lens.",
					"content_token": 199,
					"embedding": []
				}
			]
		},
		{
			"title": "How Not to Be Stupid",
			"url": "https://fs.blog/how-not-to-be-stupid/",
			"content": "After a four-hour conversation on The Knowledge Project Part 1, Part 2, Adam Robinson IAmAdamRobinson and I shared another 10-minutes that shouldn’t be missed on how not to be stupid. Shane Parrish: Adam, you did a presentation once on how not to be stupid. Can you tell me about that? What is stupidity? Adam Robinson: Right. It’s so funny you should ask that, because people think stupidity is the opposite of intelligence. In fact, stupidity is the cost of intelligence operating in a complex environment. It’s almost inevitable. And so I was asked by an organizer of an investment conference in the Bahamas of some elite global investors to do a talk on anything I wanted to do, except not about investing. It’s just, pick an interesting topic. So I thought for a second and I blurt out, “Okay. How about how not to be stupid?” He laughed and he said, “Okay. Great.” It took me a month of hard thinking, mind you, just to define stupidity. By the way, if you’re in any field and you want to find ways to innovate, focus on words that are commonly used and try to define them simply. It took me about a month, and I defined stupidity as overlooking or dismissing conspicuously crucial information. Right? It’s crucial information, like you better pay attention to it. It’s conspicuous, like it’s right in front of your nose and yet you either overlook it or you dismiss it. How not to be stupid, what are the causes of human errorand it took me a couple of months of research just to come up with data points, because most stupidity is ignored or swept under the rug. I studied instances of scientific stupidity and literary stupidity and military stupidity and every other kind of stupidity, as well as two domains that engineer stupidity. One is benign: magic. The magician misdirects your attention. The whole goal of the magician is to make you stupid, to not notice something you should have. The other is frauds and cons and hoaxes. That’s alsobut that’s a malicious, malevolent kind of engineering of stupidity. The magician does so with our full consent, for entertainment purposes. The conman engineers stupidity for their own gain. I do historical research, everything, and I identify seven factors that lead to stupidity. These seven factors are fascinating. In no particular order: one, being outside your normal environment or changing your routines. Two, being in the presence of a group. Three, being in the presence of an expert or if you, yourself, are an expert. Four, doing any task that requires intense focus. Five, information overload. Six, physical or emotional stress, fatigue. SevenI’ll come back to seven. I forget it right now. It’s a few years. It’ll come back to me in a second. All seven factors are present in U.S. hospitals. All seven factors. This will astonish you. This was recently written about, but I don’t think it’s really dawned on people. In the United States every year, there are roughly 30,000 fatalities from automobile accidents. That is a benchmark. How many deaths accidentally occur, accidentally, in hospitals every year? In other words, you go in with a broken arm and you don’t come out. Not, you died as a result of what you went in for. You died because of error, human error. I would tell you the current best estimatethis is deaths, mind you, not injuriesis 210 to 440 thousand people die every year in the United States from hospital error. quoteStupidity is overlooking or dismissing conspicuously crucial informationquote Editors note, that was not part of the conversation but will add context: When it comes to overloading our cognitive brains, the seven factors are: being outside of your circle of competence, stress, rushing or urgency, fixation on an outcome, information overload, being in a group where social cohesion comes into play, and being in the presence of an “authority.” Acting alone any of these are powerful enough, but together they dramatically increase the odds you are unaware that you’ve been cognitively compromised. We know what to do, we just don’t do it correctly. Atul Gawande and I talk about this in our interview.  It’s the third leading cause of death in the United States, right behind cancer and heart disease. If those seven factorsby the way, you don’t need all seven factors to be present. They’re additive. Oh, I remember what the final one was, and it’s so funny I should forget it because it’s the one that usually triggers stupidity. Rushing or a sense of urgency. So funny I would forget that one. It’s usually the first one I say. By the way, if you’re outside your normal environment and you are rushing, you are in big trouble, which is why often people are rushing on the way to the airport and they forget their passport or they do something. It has to do with information overload. All seven factors were present at the U.S. Challenger disaster. Remember back in 1986? Didn’t have to happen. All seven factors were present. There was the musician Yo-Yo Ma, in 1998 I believe, was rushing to an appointment in New York City. He lives in Boston. He was outside his normal environment, rushing, and he was preoccupied because he was late for an appointment. Three of the seven factors. You don’t need all seven to create stupidity. In the back of the cab in which he’s being driven is his million-dollar cello in a big blue Plexiglas thing. It’s in the trunk. He gets out of the cab, he leaves it in the back of the trunk. All of a sudden, because Yo-Yo Ma is such a celebrity, the mayor is called, the police chief and all cars bulletin goes out, find this cello. Cello? They do. In the press conference, get this, he says, “I just did something stupid.” I’m using air quotes. That’s an exact phrase. “I just did something stupid. I was in a rush.” Sure enough, in my research, I found three other situations where world class musicians were in a different city, rushing, and they left their instruments. Each one of them. One a 3 million violin. He was on a national tour, left a 3 million violin in an Amtrak train. Imagine 3 million violin in the luggage compartment of an Amtrak train. Fortunately, they called ahead and they found it at the next station. He was lucky. Each of the musicians, in exactly the same Circumstance. circumstances led to stupidity. Now, Atul Gawande wrote a book called The Checklist Manifesto. Atul Gawande is brilliant. Brilliant, brilliant, brilliant. However, the problem with checklists is that the stupidity factors override them. The worst aviation disaster in history, Shane, occurred in 1977. Nearly 600 lives were lost when two planes collided during the day on the ground. Imagine, two planes collided in an airport on the ground. Six hundred lives were lost. You might say, how does that even happen? All seven factors were present. Something else. Do you know what the pilot that caused the crash was doing right before he took off and slammed into the plane? He was racing through a checklist. Checklists don’t help you if you’re stupid about the checklist. You’re just not going to use it. A really important takeaway from that, and I’m so glad we got that final question in, is beware of rushingand if these factors are present, don’t make any important decisions. It doesn’t take much. By the way, I mentioned fatigue and illness. If you’re tired or emotionally overwrought, if you have pulled an all-nighter, you have the motor control and the reflex speed of someone who is legally drunk. An all-nighter you think, I mean we’ve all pulled all-nighters, right? We all sometimes pull multiple all-nighters. You gotta be aware. You may think that cognitively you’re okay, but your motor control skills and your reflexes are those of someone who’s legally drunk. You’ve really got to be careful. By the way, multitasking is information overload. That comes under the information overload thing, and if you’re talking on Bluetooth while you’re driving a car, you have exponentially increased the odds that you’re going to get into an accident. This is why when you’re lost, the first thing you do is turn down the radio. Oh, fascinating. You’re right. When you’re in a car, when you get lost, you alwaysone of the first things you do is eliminate an input, which is the radio. That’s so funny. You’re right. Or if you’re talking with somebody you say, “Hold on a second,” because you intuitively know that that’s justsubconsciously, you know that’s distracting you. By the way, that’s so funny you should mention that, because that’s why when I tell people that statistic abouttalking on Bluetooth on the phone when you’re driving is incredibly dangerous. People say, “Yeah, but what about if someone’s in the front of the seat talking to you?” That in fact doubles your odds. If someone’s in the front seat with you, talking while you’re driving, you’ve doubled the chances of your getting into an accident. Just doubled. Just that, but the difference is that that person, when you are dealing with unusual traffic conditions, he or she will shut up. Right, they can see it. They can see it. The person on the phone who’s talking on Bluetooth doesn’t shut up. You’re still getting the input. That’s why it’s so dangerous. That’s really interesting. I never thought of that. Yeah. Well, I didn’t think about it until I researched it. Still curious? Check out our full conversation on The Knowledge Project Part 1, Part 2 and Hemingway, a Lost Suitcase, and the Recipe for Stupidity. ",
			"tokens": 2231,
			"chunks": [
				{
					"article_title": "How Not to Be Stupid",
					"article_url": "https://fs.blog/how-not-to-be-stupid/",
					"content": "After a four-hour conversation on The Knowledge Project Part 1, Part 2, Adam Robinson IAmAdamRobinson and I shared another 10-minutes that shouldn’t be missed on how not to be stupid. Shane Parrish: Adam, you did a presentation once on how not to be stupid. Can you tell me about that? What is stupidity? Adam Robinson: Right. It’s so funny you should ask that, because people think stupidity is the opposite of intelligence. In fact, stupidity is the cost of intelligence operating in a complex environment. It’s almost inevitable. And so I was asked by an organizer of an investment conference in the Bahamas of some elite global investors to do a talk on anything I wanted to do, except not about investing. It’s just, pick an interesting topic. So I thought for a second and I blurt out, “Okay. ",
					"content_token": 187,
					"embedding": []
				},
				{
					"article_title": "How Not to Be Stupid",
					"article_url": "https://fs.blog/how-not-to-be-stupid/",
					"content": "How about how not to be stupid?” He laughed and he said, “Okay. Great.” It took me a month of hard thinking, mind you, just to define stupidity. By the way, if you’re in any field and you want to find ways to innovate, focus on words that are commonly used and try to define them simply. It took me about a month, and I defined stupidity as overlooking or dismissing conspicuously crucial information. Right? It’s crucial information, like you better pay attention to it. It’s conspicuous, like it’s right in front of your nose and yet you either overlook it or you dismiss it. How not to be stupid, what are the causes of human errorand it took me a couple of months of research just to come up with data points, because most stupidity is ignored or swept under the rug. ",
					"content_token": 184,
					"embedding": []
				},
				{
					"article_title": "How Not to Be Stupid",
					"article_url": "https://fs.blog/how-not-to-be-stupid/",
					"content": "I studied instances of scientific stupidity and literary stupidity and military stupidity and every other kind of stupidity, as well as two domains that engineer stupidity. One is benign: magic. The magician misdirects your attention. The whole goal of the magician is to make you stupid, to not notice something you should have. The other is frauds and cons and hoaxes. That’s alsobut that’s a malicious, malevolent kind of engineering of stupidity. The magician does so with our full consent, for entertainment purposes. The conman engineers stupidity for their own gain. I do historical research, everything, and I identify seven factors that lead to stupidity. These seven factors are fascinating. In no particular order: one, being outside your normal environment or changing your routines. Two, being in the presence of a group. Three, being in the presence of an expert or if you, yourself, are an expert. Four, doing any task that requires intense focus. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "How Not to Be Stupid",
					"article_url": "https://fs.blog/how-not-to-be-stupid/",
					"content": "Five, information overload. Six, physical or emotional stress, fatigue. SevenI’ll come back to seven. I forget it right now. It’s a few years. It’ll come back to me in a second. All seven factors are present in U.S. hospitals. All seven factors. This will astonish you. This was recently written about, but I don’t think it’s really dawned on people. In the United States every year, there are roughly 30,000 fatalities from automobile accidents. That is a benchmark. How many deaths accidentally occur, accidentally, in hospitals every year? In other words, you go in with a broken arm and you don’t come out. Not, you died as a result of what you went in for. You died because of error, human error. ",
					"content_token": 175,
					"embedding": []
				},
				{
					"article_title": "How Not to Be Stupid",
					"article_url": "https://fs.blog/how-not-to-be-stupid/",
					"content": "I would tell you the current best estimatethis is deaths, mind you, not injuriesis 210 to 440 thousand people die every year in the United States from hospital error. quoteStupidity is overlooking or dismissing conspicuously crucial informationquote Editors note, that was not part of the conversation but will add context: When it comes to overloading our cognitive brains, the seven factors are: being outside of your circle of competence, stress, rushing or urgency, fixation on an outcome, information overload, being in a group where social cohesion comes into play, and being in the presence of an “authority.” Acting alone any of these are powerful enough, but together they dramatically increase the odds you are unaware that you’ve been cognitively compromised. We know what to do, we just don’t do it correctly. ",
					"content_token": 174,
					"embedding": []
				},
				{
					"article_title": "How Not to Be Stupid",
					"article_url": "https://fs.blog/how-not-to-be-stupid/",
					"content": "Atul Gawande and I talk about this in our interview.  It’s the third leading cause of death in the United States, right behind cancer and heart disease. If those seven factorsby the way, you don’t need all seven factors to be present. They’re additive. Oh, I remember what the final one was, and it’s so funny I should forget it because it’s the one that usually triggers stupidity. Rushing or a sense of urgency. So funny I would forget that one. It’s usually the first one I say. By the way, if you’re outside your normal environment and you are rushing, you are in big trouble, which is why often people are rushing on the way to the airport and they forget their passport or they do something. It has to do with information overload. All seven factors were present at the U.S. Challenger disaster. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "How Not to Be Stupid",
					"article_url": "https://fs.blog/how-not-to-be-stupid/",
					"content": "Remember back in 1986? Didn’t have to happen. All seven factors were present. There was the musician Yo-Yo Ma, in 1998 I believe, was rushing to an appointment in New York City. He lives in Boston. He was outside his normal environment, rushing, and he was preoccupied because he was late for an appointment. Three of the seven factors. You don’t need all seven to create stupidity. In the back of the cab in which he’s being driven is his million-dollar cello in a big blue Plexiglas thing. It’s in the trunk. He gets out of the cab, he leaves it in the back of the trunk. All of a sudden, because Yo-Yo Ma is such a celebrity, the mayor is called, the police chief and all cars bulletin goes out, find this cello. Cello? They do. ",
					"content_token": 185,
					"embedding": []
				},
				{
					"article_title": "How Not to Be Stupid",
					"article_url": "https://fs.blog/how-not-to-be-stupid/",
					"content": "In the press conference, get this, he says, “I just did something stupid.” I’m using air quotes. That’s an exact phrase. “I just did something stupid. I was in a rush.” Sure enough, in my research, I found three other situations where world class musicians were in a different city, rushing, and they left their instruments. Each one of them. One a 3 million violin. He was on a national tour, left a 3 million violin in an Amtrak train. Imagine 3 million violin in the luggage compartment of an Amtrak train. Fortunately, they called ahead and they found it at the next station. He was lucky. Each of the musicians, in exactly the same Circumstance. circumstances led to stupidity. Now, Atul Gawande wrote a book called The Checklist Manifesto. Atul Gawande is brilliant. Brilliant, brilliant, brilliant. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "How Not to Be Stupid",
					"article_url": "https://fs.blog/how-not-to-be-stupid/",
					"content": "However, the problem with checklists is that the stupidity factors override them. The worst aviation disaster in history, Shane, occurred in 1977. Nearly 600 lives were lost when two planes collided during the day on the ground. Imagine, two planes collided in an airport on the ground. Six hundred lives were lost. You might say, how does that even happen? All seven factors were present. Something else. Do you know what the pilot that caused the crash was doing right before he took off and slammed into the plane? He was racing through a checklist. Checklists don’t help you if you’re stupid about the checklist. You’re just not going to use it. A really important takeaway from that, and I’m so glad we got that final question in, is beware of rushingand if these factors are present, don’t make any important decisions. It doesn’t take much. By the way, I mentioned fatigue and illness. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "How Not to Be Stupid",
					"article_url": "https://fs.blog/how-not-to-be-stupid/",
					"content": "If you’re tired or emotionally overwrought, if you have pulled an all-nighter, you have the motor control and the reflex speed of someone who is legally drunk. An all-nighter you think, I mean we’ve all pulled all-nighters, right? We all sometimes pull multiple all-nighters. You gotta be aware. You may think that cognitively you’re okay, but your motor control skills and your reflexes are those of someone who’s legally drunk. You’ve really got to be careful. By the way, multitasking is information overload. That comes under the information overload thing, and if you’re talking on Bluetooth while you’re driving a car, you have exponentially increased the odds that you’re going to get into an accident. This is why when you’re lost, the first thing you do is turn down the radio. Oh, fascinating. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "How Not to Be Stupid",
					"article_url": "https://fs.blog/how-not-to-be-stupid/",
					"content": "You’re right. When you’re in a car, when you get lost, you alwaysone of the first things you do is eliminate an input, which is the radio. That’s so funny. You’re right. Or if you’re talking with somebody you say, “Hold on a second,” because you intuitively know that that’s justsubconsciously, you know that’s distracting you. By the way, that’s so funny you should mention that, because that’s why when I tell people that statistic abouttalking on Bluetooth on the phone when you’re driving is incredibly dangerous. People say, “Yeah, but what about if someone’s in the front of the seat talking to you?” That in fact doubles your odds. ",
					"content_token": 176,
					"embedding": []
				},
				{
					"article_title": "How Not to Be Stupid",
					"article_url": "https://fs.blog/how-not-to-be-stupid/",
					"content": "If someone’s in the front seat with you, talking while you’re driving, you’ve doubled the chances of your getting into an accident. Just doubled. Just that, but the difference is that that person, when you are dealing with unusual traffic conditions, he or she will shut up. Right, they can see it. They can see it. The person on the phone who’s talking on Bluetooth doesn’t shut up. You’re still getting the input. That’s why it’s so dangerous. That’s really interesting. I never thought of that. Yeah. Well, I didn’t think about it until I researched it. Still curious? Check out our full conversation on The Knowledge Project Part 1, Part 2 and Hemingway, a Lost Suitcase, and the Recipe for Stupidity.",
					"content_token": 182,
					"embedding": []
				}
			]
		},
		{
			"title": "Defensive Decision Making: What IS Best vs. What LOOKS Best",
			"url": "https://fs.blog/defensive-decision-making/",
			"content": "“It wasn’t the best decision we could make,” said one of my old bosses, “but it was the most defensible.” What she meant was that she wanted to choose option A but ended up choosing option B because it was the defensible default. She realized that if she chose option A and something went wrong, it would be hard to explain because it was outside of normal. On the other hand, if she chose option A and everything went right, she’d get virtually no upside. A good outcome was merely expected, but a bad outcome would have significant consequences for her. The decision she landed on wasn’t the one she would have made if she owned the entire company. Since she didn’t, she wanted to protect her downside. In asymmetrical organizations, defensive decisions like this one protect the person making the decision. My friend and advertising legend Rory Sutherland calls defensive decisions the Heathrow Option. Americans might think of it as the IBM Option. There’s a story behind this: A while ago, British Airways noticed a reluctance for personal assistants to book their bosses on flights from London City Airport to JFK. They almost always picked Heathrow, which was further away, and harder to get to. Rory believed this was because “flying from London City might be better on average,” but “because it was a non-standard option, if anything were to go wrong, you were much more likely to get it in the neck.” Of course, if you book your boss to fly out of Heathrowthe defaultand the flight is delayed, they’ll blame the airline and not you. But if you opted for the London City airport, they’d blame you. At first glance, it might seem like defensive decision making is irrational. It’s actually perfectly rational when you consider the asymmetry involved. This asymmetry also offers insight into why cultures rarely change. Some decisions place the decisionmakers in situations where outcomes offer little upside and massive downside. In these cases, it can seem like great outcomes carry a 1 upside, good outcomes are neutral, and poor outcomes carry at least 20 downsideif they don’t get you fired. It’s easy to see why people opt for the default choice in these cases. If you do something that’s differentand thus hard to defendand it works out, you’ve risked a lot for very little gain. If you do something that’s different and it doesn’t work out, and you might find yourself unemployed. This asymmetry explains why your boss, who has nice rhetoric about challenging norms and thinking outside the box, is likely to continue with the status quo rather than change things. After all, why would they risk looking like a fool by doing something different? It’s much easier to protect themselves. Defaults give people a possible out, a way to avoid being held accountable for their decisions if things go wrong. You can distance yourself from your decision and perhaps be safe from the consequences of a poor outcome. Doing the safe thing is not the same as doing the right thing. Often, the problem with the safe thing is that there is no growth, no innovation. It’s churning out more of the same. So in the short term, while you may think that the default is a better choice for your job security, in the long game there’s a negative. When you are unwilling to take risks, you stop recognizing opportunities. If you aren’t willing to put yourself out there for 1 gain, how do you grow? After all, the 1 upsides are more common than the 50 upsides. But in either case, if you become afraid of downside, then what level of risk would be acceptable? It’s not that choosing the default makes you a bad person. But a lifetime of opting for the default limits your opportunities and your potential. And for anyone who owns a company, a staff full of default decision makers is a death knell. You get amazing results when people have the space to take risks and not be penalized for every downside. ",
			"tokens": 853,
			"chunks": [
				{
					"article_title": "Defensive Decision Making: What IS Best vs. What LOOKS Best",
					"article_url": "https://fs.blog/defensive-decision-making/",
					"content": "“It wasn’t the best decision we could make,” said one of my old bosses, “but it was the most defensible.” What she meant was that she wanted to choose option A but ended up choosing option B because it was the defensible default. She realized that if she chose option A and something went wrong, it would be hard to explain because it was outside of normal. On the other hand, if she chose option A and everything went right, she’d get virtually no upside. A good outcome was merely expected, but a bad outcome would have significant consequences for her. The decision she landed on wasn’t the one she would have made if she owned the entire company. Since she didn’t, she wanted to protect her downside. In asymmetrical organizations, defensive decisions like this one protect the person making the decision. My friend and advertising legend Rory Sutherland calls defensive decisions the Heathrow Option. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "Defensive Decision Making: What IS Best vs. What LOOKS Best",
					"article_url": "https://fs.blog/defensive-decision-making/",
					"content": "Americans might think of it as the IBM Option. There’s a story behind this: A while ago, British Airways noticed a reluctance for personal assistants to book their bosses on flights from London City Airport to JFK. They almost always picked Heathrow, which was further away, and harder to get to. Rory believed this was because “flying from London City might be better on average,” but “because it was a non-standard option, if anything were to go wrong, you were much more likely to get it in the neck.” Of course, if you book your boss to fly out of Heathrowthe defaultand the flight is delayed, they’ll blame the airline and not you. But if you opted for the London City airport, they’d blame you. At first glance, it might seem like defensive decision making is irrational. It’s actually perfectly rational when you consider the asymmetry involved. ",
					"content_token": 194,
					"embedding": []
				},
				{
					"article_title": "Defensive Decision Making: What IS Best vs. What LOOKS Best",
					"article_url": "https://fs.blog/defensive-decision-making/",
					"content": "This asymmetry also offers insight into why cultures rarely change. Some decisions place the decisionmakers in situations where outcomes offer little upside and massive downside. In these cases, it can seem like great outcomes carry a 1 upside, good outcomes are neutral, and poor outcomes carry at least 20 downsideif they don’t get you fired. It’s easy to see why people opt for the default choice in these cases. If you do something that’s differentand thus hard to defendand it works out, you’ve risked a lot for very little gain. If you do something that’s different and it doesn’t work out, and you might find yourself unemployed. This asymmetry explains why your boss, who has nice rhetoric about challenging norms and thinking outside the box, is likely to continue with the status quo rather than change things. ",
					"content_token": 176,
					"embedding": []
				},
				{
					"article_title": "Defensive Decision Making: What IS Best vs. What LOOKS Best",
					"article_url": "https://fs.blog/defensive-decision-making/",
					"content": "After all, why would they risk looking like a fool by doing something different? It’s much easier to protect themselves. Defaults give people a possible out, a way to avoid being held accountable for their decisions if things go wrong. You can distance yourself from your decision and perhaps be safe from the consequences of a poor outcome. Doing the safe thing is not the same as doing the right thing. Often, the problem with the safe thing is that there is no growth, no innovation. It’s churning out more of the same. So in the short term, while you may think that the default is a better choice for your job security, in the long game there’s a negative. When you are unwilling to take risks, you stop recognizing opportunities. If you aren’t willing to put yourself out there for 1 gain, how do you grow? After all, the 1 upsides are more common than the 50 upsides. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "Defensive Decision Making: What IS Best vs. What LOOKS Best",
					"article_url": "https://fs.blog/defensive-decision-making/",
					"content": "But in either case, if you become afraid of downside, then what level of risk would be acceptable? It’s not that choosing the default makes you a bad person. But a lifetime of opting for the default limits your opportunities and your potential. And for anyone who owns a company, a staff full of default decision makers is a death knell. You get amazing results when people have the space to take risks and not be penalized for every downside.",
					"content_token": 93,
					"embedding": []
				}
			]
		},
		{
			"title": "Hemingway, a Lost Suitcase, and the Recipe for Stupidity",
			"url": "https://fs.blog/hemingway-suitcase/",
			"content": "The best intentions are no match for the havoc caused by stress, tiredness, and unusual circumstances. Even though we know these things can negatively impact our decision-making abilities, we override the caution needed to combat them with faith in our rationality. This failure to recognize our natural vulnerabilities affects everyone. In December 1922, it resulted in a lost suitcase that changed Ernest Hemingway’s life. Hemingway, then 23, wrote fiction at night while covering the Lausanne peace conference on assignment for the Toronto Daily Star. Married the year before, Hemingway missed his wife, Elizabeth Hadley Richardson, back in Paris. He asked her to join him in Lausanne. This invite resulted in all of Hemingway’s work ending up in a suitcase. “I have long held that stupidity is very largely the result of fear leading to mental inhibitions.”  Bertie Russell It’s unclear whether Hemingway asked Hadley to bring his work so he could show it to an editor who had taken an interest in him, or she brought it for another reason. Perhaps she thought he’d want to work on something over the Christmas break and wanted to give him all the options. Whatever the reason, the intentions were good. Hadley believed in Hemingway’s talent as a writer, and she was financially supporting them so he could pursue his artistic goals. Sick at the time, Hadley managed to pack everything she could find, including the originals, the carbon copies, and all handwritten notes for a novel in progress, into a single suitcase. When she arrived at Paris’s Gare de Lyon, a porter offered to take her bags to her compartment. Right before the train was to depart, Hadley realized the journey would be long and rushed off the train to purchase a bottle of Evian, leaving the bags momentarily unattended. The suitcase was gone when she came back. Devastated, she cried for the entire eight-hour train ride. Unaware of the loss, Hemingway waited for his wife at Lausanne station. When she arrived in tears, he said nothing warranted such sadness. Whatever was bothering her could be worked out together, he assured her. Hadley finally told him what had happened. Laughing, Hemingway told her not to worry because he had carbon copies of all of his writings. Hadley could barely bring herself to tell him that those too were lost. In disbelief, he rushed back to Paris. In his memoir of those years, A Moveable Feast, he recounted: “It was true alright and I remember what I did in the night after I let myself into the flat and found it was true.” All his work was lost. At this point, Hemingway wasn’t the Hemingway we know today. None of his fiction had been published. Only two very short stories remained in Paris, “Up in Michigan”which Gertrude Stein had called unpublishableand “My Old Man,” which was out with an editor at the time. In a way that would make Marcus Aurelius proud, rather than give up, Hemingway found an interesting way to adapt to the reality of the situation. With the pressure of time, Hemingway shifted his writing style to shorter sentences, cleaner paragraphs and more readable prose. He could write faster this way. Four years later, The Sun Also Rises would be published and become a bestseller. The lessons we can draw from Hemingway are obvious. It’s a classic story of a struggling artist who has a setback but overcomes it to achieve huge success. Disney created a multibillion-dollar company on the back of stories like this one. But almost everyone misses the lessonshiding in plain sightoffered by Hadley. And when it comes to avoiding catastrophic errors, we should pay close attention. Most of us are not chronically stupid. We make many good decisions and accomplish some amazing things. But we commit acts of stupidity once in a while, usually when we fail to recognize how certain variables are making us vulnerable. Stupidity is not the opposite of intelligence. My friend Adam Robinson has perhaps the best definition of stupidity I’ve come across, defining it as the overlooking or dismissing of conspicuously crucial information. quoteStupidity is overlooking or dismissing crucial information.quote There are some things you should know about stupidity. Stupidity is easier to see in others than ourselves. Stupidity is easier to recognize the farther we are from the act. And stupidity is stubbornly difficult to see in the moment, often only becoming apparent when the outcome is known. This is why it is so important to recognize what the variables are that increase the chances of us doing something stupid. Stress, being tired, being in an unusual situation, these are all things that make us vulnerable to stupidity. Back to our story: Hemingway shares some blame here, for not separating his originals and carbons. But more interesting are the details that affected Hadley’s decisionmaking at the train station. She was outside of her normal environment. She was rushing. She was ill. Each of these things on their own can increase the odds of committing an act of stupidity. Combined, they meant she was significantly vulnerable to errors in judgment. Although Hemingway recovered, and arguably became a better writer because of it, the loss of his work was devastating to both him and his wife at the time. Only the benefit of hindsight gives this episode a decent ending, something that is no guarantee for most stupid decisions. If you’re not a Farnam Street member, you can sign up today and see what you’re missing.  Sources:  https:lostmanuscripts.com20100731hemingways-lost-suitcase A Moveable Feast Adam Robinson Conversation, Presentation, Draft Manuscript  ",
			"tokens": 1213,
			"chunks": [
				{
					"article_title": "Hemingway, a Lost Suitcase, and the Recipe for Stupidity",
					"article_url": "https://fs.blog/hemingway-suitcase/",
					"content": "The best intentions are no match for the havoc caused by stress, tiredness, and unusual circumstances. Even though we know these things can negatively impact our decision-making abilities, we override the caution needed to combat them with faith in our rationality. This failure to recognize our natural vulnerabilities affects everyone. In December 1922, it resulted in a lost suitcase that changed Ernest Hemingway’s life. Hemingway, then 23, wrote fiction at night while covering the Lausanne peace conference on assignment for the Toronto Daily Star. Married the year before, Hemingway missed his wife, Elizabeth Hadley Richardson, back in Paris. He asked her to join him in Lausanne. This invite resulted in all of Hemingway’s work ending up in a suitcase. ",
					"content_token": 159,
					"embedding": []
				},
				{
					"article_title": "Hemingway, a Lost Suitcase, and the Recipe for Stupidity",
					"article_url": "https://fs.blog/hemingway-suitcase/",
					"content": "“I have long held that stupidity is very largely the result of fear leading to mental inhibitions.”  Bertie Russell It’s unclear whether Hemingway asked Hadley to bring his work so he could show it to an editor who had taken an interest in him, or she brought it for another reason. Perhaps she thought he’d want to work on something over the Christmas break and wanted to give him all the options. Whatever the reason, the intentions were good. Hadley believed in Hemingway’s talent as a writer, and she was financially supporting them so he could pursue his artistic goals. Sick at the time, Hadley managed to pack everything she could find, including the originals, the carbon copies, and all handwritten notes for a novel in progress, into a single suitcase. When she arrived at Paris’s Gare de Lyon, a porter offered to take her bags to her compartment. ",
					"content_token": 194,
					"embedding": []
				},
				{
					"article_title": "Hemingway, a Lost Suitcase, and the Recipe for Stupidity",
					"article_url": "https://fs.blog/hemingway-suitcase/",
					"content": "Right before the train was to depart, Hadley realized the journey would be long and rushed off the train to purchase a bottle of Evian, leaving the bags momentarily unattended. The suitcase was gone when she came back. Devastated, she cried for the entire eight-hour train ride. Unaware of the loss, Hemingway waited for his wife at Lausanne station. When she arrived in tears, he said nothing warranted such sadness. Whatever was bothering her could be worked out together, he assured her. Hadley finally told him what had happened. Laughing, Hemingway told her not to worry because he had carbon copies of all of his writings. Hadley could barely bring herself to tell him that those too were lost. In disbelief, he rushed back to Paris. ",
					"content_token": 162,
					"embedding": []
				},
				{
					"article_title": "Hemingway, a Lost Suitcase, and the Recipe for Stupidity",
					"article_url": "https://fs.blog/hemingway-suitcase/",
					"content": "In his memoir of those years, A Moveable Feast, he recounted: “It was true alright and I remember what I did in the night after I let myself into the flat and found it was true.” All his work was lost. At this point, Hemingway wasn’t the Hemingway we know today. None of his fiction had been published. Only two very short stories remained in Paris, “Up in Michigan”which Gertrude Stein had called unpublishableand “My Old Man,” which was out with an editor at the time. In a way that would make Marcus Aurelius proud, rather than give up, Hemingway found an interesting way to adapt to the reality of the situation. With the pressure of time, Hemingway shifted his writing style to shorter sentences, cleaner paragraphs and more readable prose. He could write faster this way. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "Hemingway, a Lost Suitcase, and the Recipe for Stupidity",
					"article_url": "https://fs.blog/hemingway-suitcase/",
					"content": "Four years later, The Sun Also Rises would be published and become a bestseller. The lessons we can draw from Hemingway are obvious. It’s a classic story of a struggling artist who has a setback but overcomes it to achieve huge success. Disney created a multibillion-dollar company on the back of stories like this one. But almost everyone misses the lessonshiding in plain sightoffered by Hadley. And when it comes to avoiding catastrophic errors, we should pay close attention. Most of us are not chronically stupid. We make many good decisions and accomplish some amazing things. But we commit acts of stupidity once in a while, usually when we fail to recognize how certain variables are making us vulnerable. Stupidity is not the opposite of intelligence. My friend Adam Robinson has perhaps the best definition of stupidity I’ve come across, defining it as the overlooking or dismissing of conspicuously crucial information. ",
					"content_token": 189,
					"embedding": []
				},
				{
					"article_title": "Hemingway, a Lost Suitcase, and the Recipe for Stupidity",
					"article_url": "https://fs.blog/hemingway-suitcase/",
					"content": "quoteStupidity is overlooking or dismissing crucial information.quote There are some things you should know about stupidity. Stupidity is easier to see in others than ourselves. Stupidity is easier to recognize the farther we are from the act. And stupidity is stubbornly difficult to see in the moment, often only becoming apparent when the outcome is known. This is why it is so important to recognize what the variables are that increase the chances of us doing something stupid. Stress, being tired, being in an unusual situation, these are all things that make us vulnerable to stupidity. Back to our story: Hemingway shares some blame here, for not separating his originals and carbons. But more interesting are the details that affected Hadley’s decisionmaking at the train station. She was outside of her normal environment. She was rushing. She was ill. Each of these things on their own can increase the odds of committing an act of stupidity. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "Hemingway, a Lost Suitcase, and the Recipe for Stupidity",
					"article_url": "https://fs.blog/hemingway-suitcase/",
					"content": "Combined, they meant she was significantly vulnerable to errors in judgment. Although Hemingway recovered, and arguably became a better writer because of it, the loss of his work was devastating to both him and his wife at the time. Only the benefit of hindsight gives this episode a decent ending, something that is no guarantee for most stupid decisions. If you’re not a Farnam Street member, you can sign up today and see what you’re missing.  Sources:  https:lostmanuscripts.com20100731hemingways-lost-suitcase A Moveable Feast Adam Robinson Conversation, Presentation, Draft Manuscript",
					"content_token": 133,
					"embedding": []
				}
			]
		},
		{
			"title": "The Decision Matrix: How to Prioritize What Matters",
			"url": "https://fs.blog/decision-matrix/",
			"content": "The decisions we spend the most time on are rarely the most important ones. Not all decisions need the same process. Sometimes, trying to impose the same process on all decisions leads to difficulty identifying which ones are most important, bogging us down and stressing us out. I remember once struggling at the intelligence agency shortly after I received a promotion. I was being asked to make too many decisions. I had no way to sort through them to figure out which ones mattered, and which ones were inconsequential. The situation built slowly over a period of weeks. My employees were scared to make decisions because their previous boss had hung them out to dry when things went wrong. My boss, a political high flyer, also liked to delegate down the riskiest decisions. As a result, I had more decisions to make than capacity to make them. I was working longer and longer to keep up with the volume of decisions. Worse, I followed the same process for all of them. I was focusing on the most urgent decisions as the cost of the most important decisions. It was clear to me that I wasn’t the right person to make all of the decisions. I needed a quick and flexible framework to categorize decisions into the ones I should be making and the ones I should be delegating. I figured most of the urgent decisions could be made by the team because they were easily reversible and not very consequential. In fact, they were only becoming urgent because the team wasn’t making the decisions in the first place. And because I was rushing through these decisions in an effort to put more time into the important decisions, I was making worse choices than the team would have. As I was walking home one night, I came up with an idea that I used from the next day on, with pretty good success. I call it the Decision Matrix. It’s a decision making version of the Eisenhower Matrix, which helps you distinguish between what’s important and what’s urgent. It’s so simple you can draw it on a napkin, and once you get it, you get it. While it won’t make the decisions for you, it will help you quickly identify which decisions you should focus on. The Decision Matrix My strategy for triaging was simple. I separated decisions into four possibilities based on the type of decision I was making.  Irreversible and inconsequential Irreversible and consequential Reversible and inconsequential Reversible and consequential  The great thing about the matrix is that it can help you quickly delegate decisions. You do have to do a bit of mental work before you start, such as defining and communicating consequentiality and reversibility, as well as where the blurring lines are.  The Decision Matrix in Practice This matrix became a powerful ally to help me manage time and make sure I wasn’t bogged down in decisions where I wasn’t the best person to decide. I delegated both types of inconsequential decisions. Inconsequential decisions are the perfect training ground to develop judgment. This saved me a ton of time. Before this people would come to me with decisions that were relatively easy to make, with fairly predictable results. The problem wasn’t making the decisionthat took seconds in most cases. The problem was the 30 minutes the person spent presenting the decision to me. I saved at least 5–7 hours a week by implementing this one change. I invested some of that time meeting with the people making these decisions once a week. I wanted to know what types of decisions they made, how they thought about them, and how the results were going. We tracked old decisions as well, so they could see their judgment improving or not. Consequential decisions are a different beast. Reversible and consequential decisions are my favorite. These decisions trick you into thinking they are one big important decision. In reality, reversible and consequential decisions are the perfect decisions to run experiments and gather information. The team or individual would decide experiments we were going to run, the results that would indicate we were on the right path, and who would be responsible for execution. They’d present these findings. Consequential and irreversible decisions are the ones that you really need to focus on. All of the time I saved from using this matrix didn’t allow me to sip drinks on the beach. Rather, I invested it in the most important decisions, the ones I couldn’t justify delegating. I also had another rule that proved helpful: unless the decision needed to be made on the spot, as some operational decisions do, I would take a 30-minute walk first. The key to successfully employing this in practice was to make sure everyone was on same page with the terms of consequential and reversible. At first, people checked with me but later, as the terms became clear, they just started deciding. While the total volume of decisions we made as a team didn’t change, how they were allocated within the team changed. I estimate that I was personally making 75 fewer decisions. But the real kicker was that the quality of all the decisions we made improved dramatically. People started feeling connected to their work again, productivity improved, and sick days a proxy for how engaged people were dropped. Give the Decision Matrix a tryespecially if you’re bogged down and fighting to manage your time, it may change your working life. Still Curious? Read The Eisenhower Matrix: Master Productivity and Eliminate Noise next.  ",
			"tokens": 1113,
			"chunks": [
				{
					"article_title": "The Decision Matrix: How to Prioritize What Matters",
					"article_url": "https://fs.blog/decision-matrix/",
					"content": "The decisions we spend the most time on are rarely the most important ones. Not all decisions need the same process. Sometimes, trying to impose the same process on all decisions leads to difficulty identifying which ones are most important, bogging us down and stressing us out. I remember once struggling at the intelligence agency shortly after I received a promotion. I was being asked to make too many decisions. I had no way to sort through them to figure out which ones mattered, and which ones were inconsequential. The situation built slowly over a period of weeks. My employees were scared to make decisions because their previous boss had hung them out to dry when things went wrong. My boss, a political high flyer, also liked to delegate down the riskiest decisions. As a result, I had more decisions to make than capacity to make them. I was working longer and longer to keep up with the volume of decisions. Worse, I followed the same process for all of them. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "The Decision Matrix: How to Prioritize What Matters",
					"article_url": "https://fs.blog/decision-matrix/",
					"content": "I was focusing on the most urgent decisions as the cost of the most important decisions. It was clear to me that I wasn’t the right person to make all of the decisions. I needed a quick and flexible framework to categorize decisions into the ones I should be making and the ones I should be delegating. I figured most of the urgent decisions could be made by the team because they were easily reversible and not very consequential. In fact, they were only becoming urgent because the team wasn’t making the decisions in the first place. And because I was rushing through these decisions in an effort to put more time into the important decisions, I was making worse choices than the team would have. As I was walking home one night, I came up with an idea that I used from the next day on, with pretty good success. I call it the Decision Matrix. ",
					"content_token": 178,
					"embedding": []
				},
				{
					"article_title": "The Decision Matrix: How to Prioritize What Matters",
					"article_url": "https://fs.blog/decision-matrix/",
					"content": "It’s a decision making version of the Eisenhower Matrix, which helps you distinguish between what’s important and what’s urgent. It’s so simple you can draw it on a napkin, and once you get it, you get it. While it won’t make the decisions for you, it will help you quickly identify which decisions you should focus on. The Decision Matrix My strategy for triaging was simple. I separated decisions into four possibilities based on the type of decision I was making.  Irreversible and inconsequential Irreversible and consequential Reversible and inconsequential Reversible and consequential  The great thing about the matrix is that it can help you quickly delegate decisions. You do have to do a bit of mental work before you start, such as defining and communicating consequentiality and reversibility, as well as where the blurring lines are. ",
					"content_token": 183,
					"embedding": []
				},
				{
					"article_title": "The Decision Matrix: How to Prioritize What Matters",
					"article_url": "https://fs.blog/decision-matrix/",
					"content": " The Decision Matrix in Practice This matrix became a powerful ally to help me manage time and make sure I wasn’t bogged down in decisions where I wasn’t the best person to decide. I delegated both types of inconsequential decisions. Inconsequential decisions are the perfect training ground to develop judgment. This saved me a ton of time. Before this people would come to me with decisions that were relatively easy to make, with fairly predictable results. The problem wasn’t making the decisionthat took seconds in most cases. The problem was the 30 minutes the person spent presenting the decision to me. I saved at least 5–7 hours a week by implementing this one change. I invested some of that time meeting with the people making these decisions once a week. I wanted to know what types of decisions they made, how they thought about them, and how the results were going. We tracked old decisions as well, so they could see their judgment improving or not. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "The Decision Matrix: How to Prioritize What Matters",
					"article_url": "https://fs.blog/decision-matrix/",
					"content": "Consequential decisions are a different beast. Reversible and consequential decisions are my favorite. These decisions trick you into thinking they are one big important decision. In reality, reversible and consequential decisions are the perfect decisions to run experiments and gather information. The team or individual would decide experiments we were going to run, the results that would indicate we were on the right path, and who would be responsible for execution. They’d present these findings. Consequential and irreversible decisions are the ones that you really need to focus on. All of the time I saved from using this matrix didn’t allow me to sip drinks on the beach. Rather, I invested it in the most important decisions, the ones I couldn’t justify delegating. I also had another rule that proved helpful: unless the decision needed to be made on the spot, as some operational decisions do, I would take a 30-minute walk first. ",
					"content_token": 189,
					"embedding": []
				},
				{
					"article_title": "The Decision Matrix: How to Prioritize What Matters",
					"article_url": "https://fs.blog/decision-matrix/",
					"content": "The key to successfully employing this in practice was to make sure everyone was on same page with the terms of consequential and reversible. At first, people checked with me but later, as the terms became clear, they just started deciding. While the total volume of decisions we made as a team didn’t change, how they were allocated within the team changed. I estimate that I was personally making 75 fewer decisions. But the real kicker was that the quality of all the decisions we made improved dramatically. People started feeling connected to their work again, productivity improved, and sick days a proxy for how engaged people were dropped. Give the Decision Matrix a tryespecially if you’re bogged down and fighting to manage your time, it may change your working life. Still Curious? Read The Eisenhower Matrix: Master Productivity and Eliminate Noise next.",
					"content_token": 170,
					"embedding": []
				}
			]
		},
		{
			"title": "Strategy vs. Tactics: Why the Difference Matters",
			"url": "https://fs.blog/strategy-vs-tactics/",
			"content": "In order to do anything meaningful, you have to know where you are going. Strategy and tactics are two terms that get thrown around a lot, and are often used interchangeably in numerous contexts. But what exactly do they mean, what is the difference, and why is it important? In this article, we will look at the contrast between strategy and tactics, and the most effective ways to use each. While strategy and tactics originated as military terminology, their use has spread to planning in many areas of life. Strategy is overarching plan or set of goals. Changing strategies is like trying to turn around an aircraft carrierit can be done but not quickly. Tactics are the specific actions or steps you undertake to accomplish your strategy. For example, in a war, a nation’s strategy might be to win the hearts and minds of the opponent’s civilian population. To achieve this they could use tactics such as radio broadcasts or building hospitals.  A personal strategy might be to get into a particular career, whereas your tactics might include choosing your educational path, seeking out a helpful mentor, or distinguishing yourself from the competition. We might have strategies for anything from gaining political power or getting promoted, to building relationships and growing the audience of a blog. Whatever we are trying to do, we would do well to understand how strategy and tactics work, the distinction, and how we can fit the two together. Without a strategy we run the risk of ambling through life, uncertain and confused about if we are making progress towards what we want. Without tactics, we are destined for a lifetime of wishful thinking or chronic dissatisfaction. As Lawrence Freedman writes in Strategy: A History, “Without a strategy, facing up to any problem or striving for any objective would be considered negligent. Certainly, no military campaign, company investment, or government initiative is likely to receive backing unless there is a strategy to evaluate. There is a call for strategy every time the path to a given destination is not straightforward.” And without tactics you become dependent on pure luck to implement your strategy. To achieve anything we need a view of both the micro and the macro, the forest and the treesand how both perspectives slot together. Strategy and tactics are complementary. Neither works well without the other. Sun Tzu recognized this two and a half millennia ago when he stated, “Strategy without tactics is the slowest route to victory. Tactics without strategy are the noise before defeat.” We need to take a long-term view and think ahead, while choosing short-term steps to take now for the sake of what we want later. The Relationship Between Strategy and Tactics Any time we decide on a goal and invest resources in achieving it, we are strategizing. Freedman writes: One common contemporary definition describes it as being about maintaining a balance between ends, ways, and means; about identifying objectives; and about the resources and methods available for meeting such objectives. This balance requires not only finding out how to achieve desired ends but also adjusting ends so that realistic ways can be found to meet them by available means. In The Grand Strategy of the Roman Empire, Edward N. Luttwak writes that strategy “is not about moving armies over geography, as in board games. It encompasses the entire struggle of adversarial forces, which need not have a spatial dimension at all.” When you think about winning a war, what does it mean to actually win? History is full of examples of wars that were “won” on paper, only to be restarted as soon as the adversary had time to regroup. So being precise in your goal, to encompass the entirety of what you want to achieve, is necessary to articulate a good strategy. It’s not about success in the moment, but success in the long term. It’s the difference between the end of WWI and WWII. World War I was about winning that war. World War II was about never fighting a war like that again. The strategies articulated and pursued by the Treaty of Versailles and the Marshall Plan were full of markedly different tactics. In Good Strategy, Bad Strategy, Richard Rumelt writes: “The most basic idea of strategy is the application of strength against weakness. Or if you prefer, strength applied to the most promising opportunityA good strategy doesn’t just draw on existing strength; it creates strength.” Rumelt’s definition of strategy as creating strength is particularly important. You don’t deplete yourself as you execute your strategy. You choose tactics that reinforce and build strength as they are deployed. Back to winning hearts and minds – the tactics require up-front costs. But as they proceed, and as the strategy unfolds, strength and further support are gained by having the support of the local population. A good strategy makes you stronger. “Grand strategy is the art of looking beyond the present battle and calculating ahead. Focus on your ultimate goal and plot to reach it.”  Robert Greene, The 33 Strategies of War The Components of Strategy The strategic theorist Henry Mintzberg provides a useful approach to thinking about strategy in adversarial situations. According to Mintzberg, there are five key components or types: Plan: A consciously chosen series of actions to achieve a goal, made in advance. Ploy: A deliberate attempt to confuse, mislead or distract an opponent. Pattern: A consistent, repeated series of actions that achieve the desired result. Position: A considered relationship between an entity organization, army, individual etc and its context. Perspective: A particular way of viewing the world, a mindset regarding actions that lead to a distinct way of behaving. Geoffrey P. Chamberlain offers a slightly different perspective on the components of strategy, useful when the strategy is more about a personal goal. He identifies seven parts: A strategy is used within a particular domain. A strategy has a single, well defined focus. A strategy lays out a path to be followed. A strategy is made up of parts tactics. Each of a strategy’s parts pushes towards the defined focus. A strategy recognises its sphere of influence. A strategy is either intentionally formed or emerges naturally. According to Rumelt, a strategy must include “premeditation, the anticipation of others’ behavior, and the purposeful design of coordinated actions. As a general rule, strategy is more important in situations where other parties have the potential to thwart or disrupt actions, or where our plans are at risk if we don’t take meaningful steps to achieve them. Good strategy requires us to both focus on a goal, and anticipate obstacles to reaching that goal.  When we encounter obstacles, we may need to employ what Freedman calls “deceits, ruses, feints, manoeuvres and a quicker wit”our tactics. “The skillful tactician may be likened to the Shuai-Jan. Now the Shuai-Jan is a snake that is found in the Ch’ang mountains. Strike at its head, and you will be attacked by its tail; strike at its tail, and you will be attacked by its head; strike at its middle, and you will be attacked by head and tail both.”  Sun Tzu, The Art of War A Few Words on Tactics Even the most elegant, well-planned strategy is useless if we do not take thoughtful steps to achieve it. While the overall goal remains stable, the steps we take to achieve it must be flexible enough to adjust to the short-term realities of our situation. The word “tactic” comes from the Ancient Greek “taktikos,” which loosely translates to “the art of ordering or arranging.” We now use the term to denote actions toward a goal. Tactics often center around the efficient use of available resources, whether money, people, time, ammunition, or materials. Tactics also tend to be shorter-term and more specific than strategies. Many tactics are timeless and have been used for centuries or even millennia. Military tactics such as ambushes, using prevailing weather, and divide-and-conquer have been around as long as people have fought each other. The same applies to tactics used by politicians and protesters. Successful tactics often include an implementation intention’a specific trigger that signals when they should be used. Simply deciding what to do is rarely enough. We need an “if this, then that” plan for where, when and why. The short-term nature and flexibility of tactics allow us to pivot as needed, choosing the right ones for the situation, to achieve our larger, strategic goals. If you don’t have a strategy, you are part of someone else’s strategy.”  Alvin Toffler Conclusion Although often regarded as interchangeable, strategy and tactics are somewhat different, though complementary concepts. According to the skilled strategist Sun Tzu, strategy is about winning before the battle begins, while tactics are about striking at weakness. Both are ancient concepts that have come to be an essential part of numerous disciplines and offer endless new ways of thinking.",
			"tokens": 1847,
			"chunks": [
				{
					"article_title": "Strategy vs. Tactics: Why the Difference Matters",
					"article_url": "https://fs.blog/strategy-vs-tactics/",
					"content": "In order to do anything meaningful, you have to know where you are going. Strategy and tactics are two terms that get thrown around a lot, and are often used interchangeably in numerous contexts. But what exactly do they mean, what is the difference, and why is it important? In this article, we will look at the contrast between strategy and tactics, and the most effective ways to use each. While strategy and tactics originated as military terminology, their use has spread to planning in many areas of life. Strategy is overarching plan or set of goals. Changing strategies is like trying to turn around an aircraft carrierit can be done but not quickly. Tactics are the specific actions or steps you undertake to accomplish your strategy. For example, in a war, a nation’s strategy might be to win the hearts and minds of the opponent’s civilian population. ",
					"content_token": 175,
					"embedding": []
				},
				{
					"article_title": "Strategy vs. Tactics: Why the Difference Matters",
					"article_url": "https://fs.blog/strategy-vs-tactics/",
					"content": "To achieve this they could use tactics such as radio broadcasts or building hospitals.  A personal strategy might be to get into a particular career, whereas your tactics might include choosing your educational path, seeking out a helpful mentor, or distinguishing yourself from the competition. We might have strategies for anything from gaining political power or getting promoted, to building relationships and growing the audience of a blog. Whatever we are trying to do, we would do well to understand how strategy and tactics work, the distinction, and how we can fit the two together. Without a strategy we run the risk of ambling through life, uncertain and confused about if we are making progress towards what we want. Without tactics, we are destined for a lifetime of wishful thinking or chronic dissatisfaction. As Lawrence Freedman writes in Strategy: A History, “Without a strategy, facing up to any problem or striving for any objective would be considered negligent. ",
					"content_token": 184,
					"embedding": []
				},
				{
					"article_title": "Strategy vs. Tactics: Why the Difference Matters",
					"article_url": "https://fs.blog/strategy-vs-tactics/",
					"content": "Certainly, no military campaign, company investment, or government initiative is likely to receive backing unless there is a strategy to evaluate. There is a call for strategy every time the path to a given destination is not straightforward.” And without tactics you become dependent on pure luck to implement your strategy. To achieve anything we need a view of both the micro and the macro, the forest and the treesand how both perspectives slot together. Strategy and tactics are complementary. Neither works well without the other. Sun Tzu recognized this two and a half millennia ago when he stated, “Strategy without tactics is the slowest route to victory. Tactics without strategy are the noise before defeat.” We need to take a long-term view and think ahead, while choosing short-term steps to take now for the sake of what we want later. The Relationship Between Strategy and Tactics Any time we decide on a goal and invest resources in achieving it, we are strategizing. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "Strategy vs. Tactics: Why the Difference Matters",
					"article_url": "https://fs.blog/strategy-vs-tactics/",
					"content": "Freedman writes: One common contemporary definition describes it as being about maintaining a balance between ends, ways, and means; about identifying objectives; and about the resources and methods available for meeting such objectives. This balance requires not only finding out how to achieve desired ends but also adjusting ends so that realistic ways can be found to meet them by available means. In The Grand Strategy of the Roman Empire, Edward N. Luttwak writes that strategy “is not about moving armies over geography, as in board games. It encompasses the entire struggle of adversarial forces, which need not have a spatial dimension at all.” When you think about winning a war, what does it mean to actually win? History is full of examples of wars that were “won” on paper, only to be restarted as soon as the adversary had time to regroup. ",
					"content_token": 177,
					"embedding": []
				},
				{
					"article_title": "Strategy vs. Tactics: Why the Difference Matters",
					"article_url": "https://fs.blog/strategy-vs-tactics/",
					"content": "So being precise in your goal, to encompass the entirety of what you want to achieve, is necessary to articulate a good strategy. It’s not about success in the moment, but success in the long term. It’s the difference between the end of WWI and WWII. World War I was about winning that war. World War II was about never fighting a war like that again. The strategies articulated and pursued by the Treaty of Versailles and the Marshall Plan were full of markedly different tactics. In Good Strategy, Bad Strategy, Richard Rumelt writes: “The most basic idea of strategy is the application of strength against weakness. Or if you prefer, strength applied to the most promising opportunityA good strategy doesn’t just draw on existing strength; it creates strength.” Rumelt’s definition of strategy as creating strength is particularly important. You don’t deplete yourself as you execute your strategy. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "Strategy vs. Tactics: Why the Difference Matters",
					"article_url": "https://fs.blog/strategy-vs-tactics/",
					"content": "You choose tactics that reinforce and build strength as they are deployed. Back to winning hearts and minds – the tactics require up-front costs. But as they proceed, and as the strategy unfolds, strength and further support are gained by having the support of the local population. A good strategy makes you stronger. “Grand strategy is the art of looking beyond the present battle and calculating ahead. Focus on your ultimate goal and plot to reach it.”  Robert Greene, The 33 Strategies of War The Components of Strategy The strategic theorist Henry Mintzberg provides a useful approach to thinking about strategy in adversarial situations. According to Mintzberg, there are five key components or types: Plan: A consciously chosen series of actions to achieve a goal, made in advance. Ploy: A deliberate attempt to confuse, mislead or distract an opponent. Pattern: A consistent, repeated series of actions that achieve the desired result. ",
					"content_token": 186,
					"embedding": []
				},
				{
					"article_title": "Strategy vs. Tactics: Why the Difference Matters",
					"article_url": "https://fs.blog/strategy-vs-tactics/",
					"content": "Position: A considered relationship between an entity organization, army, individual etc and its context. Perspective: A particular way of viewing the world, a mindset regarding actions that lead to a distinct way of behaving. Geoffrey P. Chamberlain offers a slightly different perspective on the components of strategy, useful when the strategy is more about a personal goal. He identifies seven parts: A strategy is used within a particular domain. A strategy has a single, well defined focus. A strategy lays out a path to be followed. A strategy is made up of parts tactics. Each of a strategy’s parts pushes towards the defined focus. A strategy recognises its sphere of influence. A strategy is either intentionally formed or emerges naturally. According to Rumelt, a strategy must include “premeditation, the anticipation of others’ behavior, and the purposeful design of coordinated actions. ",
					"content_token": 176,
					"embedding": []
				},
				{
					"article_title": "Strategy vs. Tactics: Why the Difference Matters",
					"article_url": "https://fs.blog/strategy-vs-tactics/",
					"content": "As a general rule, strategy is more important in situations where other parties have the potential to thwart or disrupt actions, or where our plans are at risk if we don’t take meaningful steps to achieve them. Good strategy requires us to both focus on a goal, and anticipate obstacles to reaching that goal.  When we encounter obstacles, we may need to employ what Freedman calls “deceits, ruses, feints, manoeuvres and a quicker wit”our tactics. “The skillful tactician may be likened to the Shuai-Jan. Now the Shuai-Jan is a snake that is found in the Ch’ang mountains. ",
					"content_token": 138,
					"embedding": []
				},
				{
					"article_title": "Strategy vs. Tactics: Why the Difference Matters",
					"article_url": "https://fs.blog/strategy-vs-tactics/",
					"content": "Strike at its head, and you will be attacked by its tail; strike at its tail, and you will be attacked by its head; strike at its middle, and you will be attacked by head and tail both.”  Sun Tzu, The Art of War A Few Words on Tactics Even the most elegant, well-planned strategy is useless if we do not take thoughtful steps to achieve it. While the overall goal remains stable, the steps we take to achieve it must be flexible enough to adjust to the short-term realities of our situation. The word “tactic” comes from the Ancient Greek “taktikos,” which loosely translates to “the art of ordering or arranging.” We now use the term to denote actions toward a goal. Tactics often center around the efficient use of available resources, whether money, people, time, ammunition, or materials. Tactics also tend to be shorter-term and more specific than strategies. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "Strategy vs. Tactics: Why the Difference Matters",
					"article_url": "https://fs.blog/strategy-vs-tactics/",
					"content": "Many tactics are timeless and have been used for centuries or even millennia. Military tactics such as ambushes, using prevailing weather, and divide-and-conquer have been around as long as people have fought each other. The same applies to tactics used by politicians and protesters. Successful tactics often include an implementation intention’a specific trigger that signals when they should be used. Simply deciding what to do is rarely enough. We need an “if this, then that” plan for where, when and why. The short-term nature and flexibility of tactics allow us to pivot as needed, choosing the right ones for the situation, to achieve our larger, strategic goals. If you don’t have a strategy, you are part of someone else’s strategy.”  Alvin Toffler Conclusion Although often regarded as interchangeable, strategy and tactics are somewhat different, though complementary concepts. ",
					"content_token": 184,
					"embedding": []
				},
				{
					"article_title": "Strategy vs. Tactics: Why the Difference Matters",
					"article_url": "https://fs.blog/strategy-vs-tactics/",
					"content": "According to the skilled strategist Sun Tzu, strategy is about winning before the battle begins, while tactics are about striking at weakness. Both are ancient concepts that have come to be an essential part of numerous disciplines and offer endless new ways of thinking.",
					"content_token": 49,
					"embedding": []
				}
			]
		},
		{
			"title": "Break the Chain: Stop Being a Slave",
			"url": "https://fs.blog/break-the-chain/",
			"content": "A vendor once tried to buy me a laptop. Not just any laptop but a very expensive laptop. The vendor claimed that there were no strings attached. And, as they pointed out, I was the only person in the meeting with them, so “no one would know” they had given it to me. It wasn’t a hard decision. I said no. It wasn’t because I didn’t need a laptop. In fact, I did need one. The laptop I was using was old and out of date. I had purchased it myself years ago in a fit of frustration at the ridiculous process the government wanted me to follow to obtain one from them. “No price is too high to pay for the privilege of owning yourself.”  Nietzsche Governments have clear conflict-of-interest rules for people in situations like this one. The rules, however, are impractical. They’re also expensive. I remember one dinner with a vendor that ended up costing me hundreds of dollars personally. I made a mistake: I went to wash my hands around the time the vendor picked out some wine. I came back to see a glass of wine poured for me. When the bill came, the vendor insisted on paying it. Damaging our relationship and embarrassing him, I refused and said, “That’s very generous of you, but the government is clear; I’ve got to pay my share.” My share? Over 200. I hadn’t picked the restaurant or the wine. When I returned to work a few days later and submitted a claim for the difference between my per diem and the meal, I was literally laughed at. But the real reason I said no to the laptop was that I don’t want to be owned by other people. Even if my freedom personally costs me money. However well-meaning the laptop offer might have been, I would have felt a debt to the vendor who’d given it to me. A debt that would need to be paid at some point. That debt would have created a bond between us that I didn’t want. We need to make our own way, and there is a slippery slope between accepting the generosity of people who help you along and getting dependent on them. The entitlement born from expecting others to help you is a recipe for misery. So is excessive dependence on others. The lesson is never to anticipate or rely on the kindness of strangers. This dependence means they own you. If you have a mortgage, you don’t own your house; the bank does. Working for the government taught me a lot about ownership  specifically, about dependence on other people. People refused to say what they really thought, subconsciously abiding by the maxim “whose bread I eat, his song I sing.” When people would approach me and tell me how miserable they were and how they hated their jobs, I would ask them why they didn’t leave. The answer was almost always the same: “I can’t.” Once we’re bought, it’s hard to get out. While we all start out wanting more independence, we increasingly live lifestyles that make us dependent. When I first started working in the government, I made just under 40k a year in salary. For me, just out of university, that was a killing. I felt like I could do whatever I wanted. After a while, I was making more money but still living off the same starting salary. The additional money went to savings and debt repayment. I said no to living above my means and watched as most of my friends couldn’t say no. A lot of them spent more than they made no matter how many promotions they received. Appetites for desires are rarely quenched. As people spent more, they got more into debt. As they got more into debt, they wanted more and more. As their wants exceeded even the debt-funded shopping sprees cars, trucks, houses, swimming pools, campers, play structures for the kids, etc., they got unhappier. They saw other people with things they wanted. Things they felt like they deserved. Their relationships suffered. They became miserable. They hated their jobs but they were stuck. The bank owned them. Work owned them. And they realized it too late. Part of the reason for the laptop offer was likely that vendor expected to have preferred access to me and to the government. Prefered access to information that could potentially benefit his company, to the tune of millions or tens of millions of dollars. Had I accepted the offer, it would have been hard to deny him. I saw the strings and didn’t want any part of them. Amelia Boone, the Michael Jordan of adventure racing, said, “I believe the key to self-sufficiency is breaking free of the mindset that someone, somewhere, owes you something and will come to your rescue.” The bank doesn’t owe you a mortgage, just as work doesn’t owe you a job. “Self-sufficiency,” wrote Epicurus, “is the greatest of all wealth.” Epictetus added that “wealth consists not in having great possessions, but in having few wants.” It can be hard to say no. It means refusing someone, and often it means denying yourself instant gratification. The rewards of doing this are uncertain and less tangible. I call decisions like this “first-order negative, second-order positive.” Most people don’t take the time to think through the second-order effects of their choices. If they did, they’d realize that freedom comes from the ability to say no. ",
			"tokens": 1180,
			"chunks": [
				{
					"article_title": "Break the Chain: Stop Being a Slave",
					"article_url": "https://fs.blog/break-the-chain/",
					"content": "A vendor once tried to buy me a laptop. Not just any laptop but a very expensive laptop. The vendor claimed that there were no strings attached. And, as they pointed out, I was the only person in the meeting with them, so “no one would know” they had given it to me. It wasn’t a hard decision. I said no. It wasn’t because I didn’t need a laptop. In fact, I did need one. The laptop I was using was old and out of date. I had purchased it myself years ago in a fit of frustration at the ridiculous process the government wanted me to follow to obtain one from them. “No price is too high to pay for the privilege of owning yourself.”  Nietzsche Governments have clear conflict-of-interest rules for people in situations like this one. The rules, however, are impractical. They’re also expensive. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "Break the Chain: Stop Being a Slave",
					"article_url": "https://fs.blog/break-the-chain/",
					"content": "I remember one dinner with a vendor that ended up costing me hundreds of dollars personally. I made a mistake: I went to wash my hands around the time the vendor picked out some wine. I came back to see a glass of wine poured for me. When the bill came, the vendor insisted on paying it. Damaging our relationship and embarrassing him, I refused and said, “That’s very generous of you, but the government is clear; I’ve got to pay my share.” My share? Over 200. I hadn’t picked the restaurant or the wine. When I returned to work a few days later and submitted a claim for the difference between my per diem and the meal, I was literally laughed at. But the real reason I said no to the laptop was that I don’t want to be owned by other people. Even if my freedom personally costs me money. ",
					"content_token": 189,
					"embedding": []
				},
				{
					"article_title": "Break the Chain: Stop Being a Slave",
					"article_url": "https://fs.blog/break-the-chain/",
					"content": "However well-meaning the laptop offer might have been, I would have felt a debt to the vendor who’d given it to me. A debt that would need to be paid at some point. That debt would have created a bond between us that I didn’t want. We need to make our own way, and there is a slippery slope between accepting the generosity of people who help you along and getting dependent on them. The entitlement born from expecting others to help you is a recipe for misery. So is excessive dependence on others. The lesson is never to anticipate or rely on the kindness of strangers. This dependence means they own you. If you have a mortgage, you don’t own your house; the bank does. Working for the government taught me a lot about ownership  specifically, about dependence on other people. ",
					"content_token": 170,
					"embedding": []
				},
				{
					"article_title": "Break the Chain: Stop Being a Slave",
					"article_url": "https://fs.blog/break-the-chain/",
					"content": "People refused to say what they really thought, subconsciously abiding by the maxim “whose bread I eat, his song I sing.” When people would approach me and tell me how miserable they were and how they hated their jobs, I would ask them why they didn’t leave. The answer was almost always the same: “I can’t.” Once we’re bought, it’s hard to get out. While we all start out wanting more independence, we increasingly live lifestyles that make us dependent. When I first started working in the government, I made just under 40k a year in salary. For me, just out of university, that was a killing. I felt like I could do whatever I wanted. After a while, I was making more money but still living off the same starting salary. The additional money went to savings and debt repayment. ",
					"content_token": 184,
					"embedding": []
				},
				{
					"article_title": "Break the Chain: Stop Being a Slave",
					"article_url": "https://fs.blog/break-the-chain/",
					"content": "I said no to living above my means and watched as most of my friends couldn’t say no. A lot of them spent more than they made no matter how many promotions they received. Appetites for desires are rarely quenched. As people spent more, they got more into debt. As they got more into debt, they wanted more and more. As their wants exceeded even the debt-funded shopping sprees cars, trucks, houses, swimming pools, campers, play structures for the kids, etc., they got unhappier. They saw other people with things they wanted. Things they felt like they deserved. Their relationships suffered. They became miserable. They hated their jobs but they were stuck. The bank owned them. Work owned them. And they realized it too late. Part of the reason for the laptop offer was likely that vendor expected to have preferred access to me and to the government. ",
					"content_token": 186,
					"embedding": []
				},
				{
					"article_title": "Break the Chain: Stop Being a Slave",
					"article_url": "https://fs.blog/break-the-chain/",
					"content": "Prefered access to information that could potentially benefit his company, to the tune of millions or tens of millions of dollars. Had I accepted the offer, it would have been hard to deny him. I saw the strings and didn’t want any part of them. Amelia Boone, the Michael Jordan of adventure racing, said, “I believe the key to self-sufficiency is breaking free of the mindset that someone, somewhere, owes you something and will come to your rescue.” The bank doesn’t owe you a mortgage, just as work doesn’t owe you a job. “Self-sufficiency,” wrote Epicurus, “is the greatest of all wealth.” Epictetus added that “wealth consists not in having great possessions, but in having few wants.” It can be hard to say no. It means refusing someone, and often it means denying yourself instant gratification. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "Break the Chain: Stop Being a Slave",
					"article_url": "https://fs.blog/break-the-chain/",
					"content": "The rewards of doing this are uncertain and less tangible. I call decisions like this “first-order negative, second-order positive.” Most people don’t take the time to think through the second-order effects of their choices. If they did, they’d realize that freedom comes from the ability to say no.",
					"content_token": 70,
					"embedding": []
				}
			]
		},
		{
			"title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
			"url": "https://fs.blog/against-empathy/",
			"content": "“The biggest deficit that we have in our society and in the world right now is an empathy deficit. We are in great need of people being able to stand in somebody else’s shoes and see the world through their eyes.”  Barack Obama You don’t have to look hard to find quotes expounding the need for more empathy in society. As with Barack Obama’s quote above, we are encouraged to actively build empathy with others  especially those who are different from us. The implicit message in these pleas is that empathy will make us treat each other with more respect and caring and will help reduce violence. But is this true? Does empathy make us appreciate others, help us behave in moral ways, or help us make better decisions? These are questions Paul Bloom tackles in his book Against Empathy: The Case for Rational Compassion. As the title suggests, Bloom’s book makes a case against empathy as an inherent force for good and takes a closer look at what empathy is and is not, how empathy works in our brains, how empathy can lead to immoral outcomes despite our best intentions, and how we can improve our ability to have a positive impact by strengthening our intelligence, compassion, self-control, and ability to reason. To explore these questions, we first need to define what we’re talking about. What Is Empathy? Empathy is an often-used word that can mean different things. Bloom quotes one team of empathy researchers who joke that “there are probably nearly as many definitions of empathy as people working on this topic.” For his part, Bloom defines empathy as “the act of coming to experience the world as you think someone else does.” This type of empathy was explored by philosophers of the Scottish Enlightenment. Bloom writes: As Adam Smith put it, we have the capacity to think about another person and “place ourselves in his situation and become in some measure the same person with him, and thence form some idea of his sensations, and even feel something which, though weaker in degree, is not altogether unlike them.” This is the definition and view of empathy that Bloom devotes most of the book to exploring. This is the “standing in another man’s shoes” type of empathy from Barack Obama’s quote above, which Bloom calls emotional empathy. quote”I feel your pain” is more than a metaphor. It’s literal.quote With emotional empathy, you actually experience a weaker degree of what somebody else feels. Researchers in recent years have been able to show that empathic responses of pain occur in the same area of the brain where real pain is experienced. So “I feel your pain” isn’t just a gooey metaphor; it can be made neurologically literal: Other people’s pain really does activate the same brain area as your own pain, and more generally, there is neural evidence for a correspondence between self and other. To make the shoe metaphor literal, imagine that you see somebody drop something heavy on their foot  you flinch because you know what this feels like and the parts of your brain that experience pain the anterior insula and the cingulate cortex react. You don’t feel the same degree of pain, of course  you didn’t drop anything on your foot after all  but it is likely that you have an involuntary physical reaction like a flinch, a facial grimace, or an audible outburst. This is an emotionally empathic response. But there is another form of empathy that Bloom wants us to be aware of and consider differently. It relates to our ability to understand what is going on in the minds of others. Bloom refers to this form as cognitive empathy:  if I understand that you are in pain without feeling it myself, this is what psychologists describe as social cognition, social intelligence, mind reading, theory of mind, or mentalizing. It’s also sometimes described as a form of empathy“cognitive empathy” as opposed to “emotional empathy.” In this sense, cognitive empathy speaks to our capacity to understand what is going on in the minds of others. In the case of pain, which is where a lot of empathy research is done, we’re not talking about feeling any degree of pain, as we might with emotional empathy, but instead, we simply understand that the other person is feeling pain without feeling it ourselves. Cognitive empathy goes beyond pain  our ability to understand what is going on in somebody else’s mind is an important part of being human and is necessary for us to relate to each other. quoteEmpathy and compassion are synonyms in many dictionaries and used interchangeably by many, but they have different characteristics.quote The brain is, of course, very complicated, so it is plausible that these two types of empathy could take place in the same part of the brain. So far, though, the research seems to indicate that they are largely separate: In a review article, Jamil Zaki and Kevin Ochsner note that hundreds of studies now support a certain perspective on the mind, which they call “a tale of two systems.” One system involves sharing the experience of others, what we’ve called empathy; the other involves inferences about the mental states of othersmentalizing or mind reading. While they can both be active at once, and often are, they occupy different parts of the brain. For instance, the medial prefrontal cortex, just behind the forehead, is involved in mentalizing, while the anterior cingulate cortex, sitting right behind that, is involved in empathy. The difference between cognitive and emotional empathy is important for understanding Bloom’s arguments. From Bloom’s perspective, cognitive empathy is “a useful and necessary tool for anyone who wishes to be a good personbut it is morally neutral.” On the other hand, Bloom believes that emotional empathy is “morally corrosive,” and the bulk of his attack is directed at highlighting the pitfalls of relying on emotional empathy while making the case for cultivating and practicing “rational compassion” instead. I believe that the capacity for emotional empathy, described as “sympathy” by philosophers such as Adam Smith and David Hume, often simply known as “empathy” and defended by so many scholars, theologians, educators, and politicians, is actually morally corrosive. If you are struggling with a moral decision and find yourself trying to feel someone else’s pain or pleasure, you should stop. This empathic engagement might give you some satisfaction, but it’s not how to improve things and can lead to bad decisions and bad outcomes. Much better to use reason and cost-benefit analysis, drawing on a more distanced compassion and kindness. Here again, the definition of the terms is important for understanding the argument. Empathy and compassion are synonyms in many dictionaries and used interchangeably by many, but they have different characteristics. Bloom outlines the difference:  compassion and concern are more diffuse than empathy. It is weird to talk about having empathy for the millions of victims of malaria, say, but perfectly normal to say that you are concerned about them or feel compassion for them. Also, compassion and concern don’t require mirroring of others’ feelings. If someone works to help the victims of torture and does so with energy and good cheer, it doesn’t seem right to say that as they do this, they are empathizing with the individuals they are helping. Better to say that they feel compassion for them. Bloom references a review paper written by Tania Singer and Olga Klimecki to help make the distinction clear. Singer and Klimecki write: In contrast to empathy, compassion does not mean sharing the suffering of the other: rather, it is characterized by feelings of warmth, concern and care for the other, as well as a strong motivation to improve the other’s well-being. Compassion is feeling for and not feeling with the other. To summarize, emotional empathy could be simply described as “feeling what others feel,” cognitive empathy as “understanding what others feel,” and compassion as “caring about how others feel.” quoteEmotional empathy could be simply described as “feeling what others feel,” cognitive empathy as “understanding what others feel,” and compassion as “caring about how others feel.”quote Empathy and Morality Many people believe that our ability to empathize is the basis for morality because it causes us to consider our actions from another’s perspective. “Treat others as you would like to be treated” is the basic morality lesson repeated thousands of times to children all over the world. In this way, empathy can lead us to rely on our self-centered nature. If this is true, Bloom suggests that the argument in its simplest form would go like this: Everyone is naturally interested in him- or herself; we care most about our own pleasure and pain. It requires nothing special to yank one’s hand away from a flame or to reach for a glass of water when thirsty. But empathy makes the experiences of others salient and importantyour pain becomes my pain, your thirst becomes my thirst, and so I rescue you from the fire or give you something to drink. Empathy guides us to treat others as we treat ourselves and hence expands our selfish concerns to encompass others. In this way, the willful exercise of empathy can motivate kindness that would never have otherwise occurred. Empathy can make us care about a slave, or a homeless person, or someone in solitary confinement. It can put us into the mind of a gay teenager bullied by his peers, or a victim of rape. We can empathize with a member of a despised minority or someone suffering from religious persecution in a faraway land. All these experiences are alien to me, but through the exercise of empathy, I can, in some limited way, experience them myself, and this makes me a better person. When we consider the plight of others by imagining ourselves in their situation, we experience an empathic response that can cause us to evaluate the morality of our actions. quoteWhen we consider the plight of others by imagining ourselves in their situation, we experience an empathic response that can cause us to evaluate the morality of our actions.quote In an interview, Steven Pinker hypothesizes that it was an increase in empathy, made possible by the technology of the printing press and the resulting increase in literacy, that led to the Humanitarian Revolution during the Enlightenment. The increase in empathy brought about by our ability to read accounts of violent punishments like disembowelment and mutilation caused us to reconsider the morality of treating other human beings in such ways. So in certain instances, empathy can play a role in motivating us to take moral action. But is an empathic response required to do so? To use a classic example from philosophyfirst thought up by the Chinese philosopher Menciusimagine that you are walking by a lake and see a young child struggling in shallow water. If you can easily wade into the water and save her, you should do it. It would be wrong to keep walking. What motivates this good act? It is possible, I suppose, that you might imagine what it feels like to be drowning, or anticipate what it would be like to be the child’s mother or father hearing that she drowned. Such empathic feelings could then motivate you to act. But that is hardly necessary. You don’t need empathy to realize that it’s wrong to let a child drown. Any normal person would just wade in and scoop up the child, without bothering with any of this empathic hoo-ha. And so there has to be more to morality than empathy. Our decisions about what’s right and what’s wrong, and our motivations to act, have many sources. One’s morality can be rooted in a religious worldview or a philosophical one. It can be motivated by a more diffuse concern for the fates of otherssomething often described as concern or compassion I hope most people reading this would agree that failing to attempt to save a drowning child or supporting or perpetrating violent punishments like disembowelment would be at the very least morally reprehensible, if not outright evil. But what motivates people to be “evil”? For researchers like Simon Baron-Cohen, evil is defined as “empathy erosion”  truly evil people lack the capacity to empathize, and it is this lack of empathy that causes them to act in evil ways. Bloom looks at the question of what causes people to be evil from a slightly different angle: Indeed, some argue that the myth of pure evil gets things backward. That is, it’s not that certain cruel actions are committed because the perpetrators are self-consciously and deliberatively evil. Rather it is because they think they are doing good. They are fueled by a strong moral sense. When the perpetrators of violence or cruelty believe that their actions are morally justified, what motivates them? Bloom suggests that it can be empathy. Empathy often causes us to choose sides, to choose whom to empathize with. We see this tendency play out in politics all the time. quoteEmpathy often causes us to choose sides, to choose whom to empathize with.quote Politicians representing one side believe they are saving the world, while representatives on the other side believe that their adversaries are out to destroy civilization as we know it. If I believe that I am protecting a person or group of people whom I choose to empathize with, then I may be motivated to act in a way I believe is morally justified, even though others may believe that I have harmed them. Steven Pinker weighed in on this issue when he wrote the following in The Better Angels of our Nature: If you added up all the homicides committed in pursuit of self-help justice, the casualties of religious and revolutionary wars, the people executed for victimless crimes and misdemeanors, and the targets of ideological genocides, they would surely outnumber the fatalities from amoral predation and conquest. Bloom quotes Pinker and goes on to write: Henry Adams put this in stronger terms, with regard to Robert E. Lee: “It’s always the good men who do the most harm in the world.” This might seem perverse. How can good lead to evil? One thing to keep in mind here is that we are interested in beliefs and motivations, not what’s good in some objective sense. So the idea isn’t that evil is good; rather, it’s that evil is done by those who think they are doing good. So from a moral perspective, empathy can lead us astray. We may believe we are doing good or that our actions are justified but this may not necessarily be true for all involved. This is especially troublesome when we consider how we are affected by a growing list of cognitive biases. Empathy and Biases While empathy may not be required to motivate us to save a drowning child, it can still help us consider the differing experiences or suffering of another person thus motivating us to consider things from their perspective or thus act to relieve their suffering: I see the bullied teenager and might be tempted initially to join in with his tormenters, out of sadism or boredom or a desire to dominate or be popular, but then I empathizeI feel his pain, I feel what it’s like to be bulliedso I don’t add to his suffering. Maybe I even rise to his defense. Empathy is like a spotlight directing attention and aid to where it’s needed. On the surface this seems like an excellent case for the positive power of empathy; it shines a “spotlight” on a person in need and motivates us to help them. But what happens when we dig a little deeper into this metaphor? Bloom writes  spotlights have a narrow focus, and this is one problem with empathy. It does poorly in a world where there are many people in need and where the effects of one’s actions are diffuse, often delayed, and difficult to compute, a world in which an act that helps one person in the here and now can lead to greater suffering in the future. He adds: Further, spotlights only illuminate what they are pointed at, so empathy reflects our biases. Although we might intellectually believe that the suffering of our neighbor is just as awful as the suffering of someone living in another country, it’s far easier to empathize with those who are close to us, those who are similar to us, and those we see as more attractive or vulnerable and less scary. Intellectually, a white American might believe that a black person matters just as much as a white person, but he or she will typically find it a lot easier to empathize with the plight of the latter than the former. In this regard, empathy distorts our moral judgments in pretty much the same way that prejudice does. We are all predisposed to care more deeply for those we are close to. From a purely biological perspective, we will care for and protect our children and families before the children or families of strangers. Our decision making often falls victim to narrow framing, and our actions are affected by biases like LikingLoving and DislikingHating and our tendency to discount the pain of people we don’t like: We are constituted to favor our friends and family over strangers, to care more about members of our own group than people from different, perhaps opposing, groups. This fact about human nature is inevitable given our evolutionary history. Any creature that didn’t have special sentiments toward those that shared its genes and helped it in the past would get its ass kicked from a Darwinian perspective; it would falter relative to competitors with more parochial natures. This bias to favor those close to us is generalit influences who we readily empathize with, but it also influences who we like, who we tend to care for, who we will affiliate with, who we will punish, and so on. There are many causes for human biases  empathy is only one  but taking a step back, we can see how the intuitive gut responses motivated by emotional empathy can negatively affect our ability to make rational decisions. Empathy’s narrow focus, specificity, and innumeracy mean that it’s always going to be influenced by what captures our attention, by racial preferences, and so on. It’s only when we escape from empathy and rely instead on the application of rules and principles or a calculation of costs and benefits that we can, to at least some extent, become fair and impartial. While many of us are motivated to be good and to make good decisions, it isn’t always cut and dry. Our preferences for whom to help or which organizations to support are affected by our biases. If we’re not careful, empathy can affect our ability to see the potential impacts of our actions. However, considering these impacts takes much more than empathy and a desire to do good; it takes awareness of our biases and mental effort to combat their effects:  doing actual good, instead of doing what feels good, requires dealing with complex issues and being mindful of exploitation from competing, sometimes malicious and greedy, interests. To do so, you need to step back and not fall into empathy traps. The conclusion is not that one shouldn’t give, but rather that one should give intelligently, with an eye toward consequences. In addition to biases like LikingLoving and DislikingHating, empathy can lead to biases related to the Representative Heuristic. Actions motivated by empathy often fail to take the broader picture into account; the spotlight doesn’t encourage us to consider base rates or sample size when we make our decisions. Instead, we are motivated by positive emotions for a specific individual or small group: Empathy is limited as well in that it focuses on specific individuals. Its spotlight nature renders it innumerate and myopic: It doesn’t resonate properly to the effects of our actions on groups of people, and it is insensitive to statistical data and estimated costs and benefits. Part of the challenge that exists with empathy is this innumeracy that Bloom describes. It is impossible for us to form genuine empathic connections with abstractions. Conversely, if we see the suffering of one, empathy can motivate us to help make it stop. As Mother Theresa said, “If I look at the mass, I will never act. If I look at the one, I will.” This is what psychologists call “the identifiable victim effect.” quoteWhile many of us are motivated to be good and to make good decisions, it isn’t always cut and dry.quote Perhaps an example will help illustrate.  On October 17, 1987, 18-month-old Jessica McClure fell 22 feet down an eight-inch-diameter well in the backyard of her home in Midland, Texas. Over the next 2  days, fire, police, and volunteer rescuers worked around the clock to save her. Media coverage of the emergency was broadcast all over the world resulting in Jessica McClure becoming internationally known as “Baby Jessica” and prompting then-President Ronald Reagan to proclaim that “everybody in America became the godmothers and godfathers of Jessica while this was going on.” The intense coverage and global awareness led to an influx of donations, resulting in an 800,000 trust being established in Jessica’s name. What prompted this massive outpouring of concern and support? There are millions of children in need every day all over the world. How many of the people who sent donations to Baby Jessica had ever tried to help these faceless children? In the case of Baby Jessica, they had an identifiable victim, and empathy motivated many of them to help Jessica and her family. They could imagine what it might feel like for those poor parents and they felt genuine concern for the child’s future; all the other needy children around the world were statistical abstractions. This ability to identify and put a face on the suffering child and their family enables us to experience an empathic response with them, but the random children and their families remain empathically out of reach. None of this is to say that rescuers should not have worked to save Jessica McClure  she was a real-world example of Mencius’s proverbial drowning child  but there are situations every day where we choose to help individuals at the cost of the continued suffering of others. Our actions often have diffuse and unknowable impacts. If our concern is driven by thoughts of the suffering of specific individuals, then it sets up a perverse situation in which the suffering of one can matter more than the suffering of a thousand. Furthermore, not only are we more likely to empathize with the identifiable victim, our empathy has its limits in scale as well. If we hear that an individual in a faraway land is suffering, we may have an empathic response, but will that response be increased proportionally if we learned that thousands or millions of people suffered? Adam Smith got to the heart of this question in The Theory of Moral Sentiments when he wrote: Let us suppose that the great empire of China, with all its myriads of inhabitants, was suddenly swallowed up by an earthquake, and let us consider how a man of humanity in Europe, who had no sort of connection with that part of the world, would be affected upon receiving intelligence of this dreadful calamity. He would, I imagine, first of all, express very strongly his sorrow for the misfortune of that unhappy people, he would make many melancholy reflections upon the precariousness of human life, and the vanity of all the labors of man, which could thus be annihilated in a moment. He would too, perhaps, if he was a man of speculation, enter into many reasonings concerning the effects which this disaster might produce upon the commerce of Europe, and the trade and business of the world in general. And when all this fine philosophy was over, when all these humane sentiments had been once fairly expressed, he would pursue his business or his pleasure, take his repose or his diversion, with the same ease and tranquility, as if no such accident had happened. Empathy can inadvertently motivate us to act to save the one at the expense of the many. While the examples provided are by no means clear-cut issues, it is worth considering how the morality or goodness of our actions to help the few may have negative consequences for the many. Charlie Munger has written and spoken about the Kantian Fairness Tendency, in which he suggests that for certain systems to be moral to the many, they must be unfair to the few. quoteFor certain systems to be moral to the many, they must be unfair to the few.quote Empathy and Reason We are emotional creatures, then, but we are also rational beings, with the capacity for rational decision-making. We can override, deflect, and overrule our passions, and we often should do so. It’s not hard to see this for feelings like anger and hateit’s clear that these can lead us astray, that we do better when they don’t rule us and when we are capable of circumventing them. While we need kindness and compassion and we should strive to be good people making good decisions, we are not necessarily well served by empathy in this regard; emotional empathy’s negatives often outweigh its positives. Instead, we should rely on our capacity to reason and control our emotions. Empathy is not something that can be removed or ignored; it is a normal function of our brains after all, but we can and do combine reason with our natural instincts and intuitions: The idea that human nature has two opposing facetsemotion versus reason, gut feelings versus careful, rational deliberationis the oldest and most resilient psychological theory of all. It was there in Plato, and it is now the core of the textbook account of cognitive processes, which assumes a dichotomy between “hot” and “cold” mental processes, between an intuitive “System 1” and a deliberative “System 2.” We know from Daniel Kahneman’s Thinking, Fast and Slow that these two systems are not inherently separate in practice. They are both functioning in our brains at the same time. Some decisions are made faster due to heuristics and intuitions from experiences or our biology, while other decisions are made in a more deliberative and slow fashion using reason. Bloom writes: We go through a mental process that is typically called “choice,” where we think about the consequences of our actions. There is nothing magical about this. The neural basis of mental life is fully compatible with the existence of conscious deliberation and rational thoughtwith neural systems that analyze different options, construct logical chains of argument, reason through examples and analogies, and respond to the anticipated consequences of actions. We have an impulsive, emotional, and intuitive decision-making system in System 1 and a deliberative, reasoning, and sometimes rational decision-making system in System 2. quoteWe will always have emotional reactions, but on average our decision making will be better served by improving our ability to reason rather than leveraging our ability to empathizequote We will always have emotional reactions, but on average our decision making will be better served by improving our ability to reason rather than by leveraging our ability to empathize. One way to increase our ability to reason is to focus on improving our self-control: Self-control can be seen as the purest embodiment of rationality in that it reflects the working of a brain system embedded in the frontal lobe, the part of the brain that lies behind the forehead that restrains our impulsive, irrational, or emotive desires. While Bloom is unabashedly against empathy as an inherent force for good in the world, he is also a firm supporter of being and doing good. He believes that the “feeling with” nature of emotional empathy leads us to make biased and bad decisions despite our best intentions and that we should instead foster and encourage the “caring for” nature of compassion while combining it with our intelligence, self-control, and ability to reason:  none of this is to deny the importance of traits such as compassion and kindness. We want to nurture these traits in our children and work to establish a culture that prizes and rewards them. But they are not enough. To make the world a better place, we would also want to bless people with more smarts and more self-control. These are central to leading a successful and happy lifeand a good and moral one.   Editor’s note: Where you see boldface in block quotes, emphasis has been added by Farnam Street.",
			"tokens": 5942,
			"chunks": [
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "“The biggest deficit that we have in our society and in the world right now is an empathy deficit. We are in great need of people being able to stand in somebody else’s shoes and see the world through their eyes.”  Barack Obama You don’t have to look hard to find quotes expounding the need for more empathy in society. As with Barack Obama’s quote above, we are encouraged to actively build empathy with others  especially those who are different from us. The implicit message in these pleas is that empathy will make us treat each other with more respect and caring and will help reduce violence. But is this true? Does empathy make us appreciate others, help us behave in moral ways, or help us make better decisions? These are questions Paul Bloom tackles in his book Against Empathy: The Case for Rational Compassion. ",
					"content_token": 177,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "As the title suggests, Bloom’s book makes a case against empathy as an inherent force for good and takes a closer look at what empathy is and is not, how empathy works in our brains, how empathy can lead to immoral outcomes despite our best intentions, and how we can improve our ability to have a positive impact by strengthening our intelligence, compassion, self-control, and ability to reason. To explore these questions, we first need to define what we’re talking about. What Is Empathy? Empathy is an often-used word that can mean different things. Bloom quotes one team of empathy researchers who joke that “there are probably nearly as many definitions of empathy as people working on this topic.” For his part, Bloom defines empathy as “the act of coming to experience the world as you think someone else does.” This type of empathy was explored by philosophers of the Scottish Enlightenment. ",
					"content_token": 189,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "Bloom writes: As Adam Smith put it, we have the capacity to think about another person and “place ourselves in his situation and become in some measure the same person with him, and thence form some idea of his sensations, and even feel something which, though weaker in degree, is not altogether unlike them.” This is the definition and view of empathy that Bloom devotes most of the book to exploring. This is the “standing in another man’s shoes” type of empathy from Barack Obama’s quote above, which Bloom calls emotional empathy. quote”I feel your pain” is more than a metaphor. It’s literal.quote With emotional empathy, you actually experience a weaker degree of what somebody else feels. Researchers in recent years have been able to show that empathic responses of pain occur in the same area of the brain where real pain is experienced. ",
					"content_token": 185,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "So “I feel your pain” isn’t just a gooey metaphor; it can be made neurologically literal: Other people’s pain really does activate the same brain area as your own pain, and more generally, there is neural evidence for a correspondence between self and other. To make the shoe metaphor literal, imagine that you see somebody drop something heavy on their foot  you flinch because you know what this feels like and the parts of your brain that experience pain the anterior insula and the cingulate cortex react. You don’t feel the same degree of pain, of course  you didn’t drop anything on your foot after all  but it is likely that you have an involuntary physical reaction like a flinch, a facial grimace, or an audible outburst. This is an emotionally empathic response. But there is another form of empathy that Bloom wants us to be aware of and consider differently. ",
					"content_token": 194,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "It relates to our ability to understand what is going on in the minds of others. Bloom refers to this form as cognitive empathy:  if I understand that you are in pain without feeling it myself, this is what psychologists describe as social cognition, social intelligence, mind reading, theory of mind, or mentalizing. It’s also sometimes described as a form of empathy“cognitive empathy” as opposed to “emotional empathy.” In this sense, cognitive empathy speaks to our capacity to understand what is going on in the minds of others. In the case of pain, which is where a lot of empathy research is done, we’re not talking about feeling any degree of pain, as we might with emotional empathy, but instead, we simply understand that the other person is feeling pain without feeling it ourselves. ",
					"content_token": 171,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "Cognitive empathy goes beyond pain  our ability to understand what is going on in somebody else’s mind is an important part of being human and is necessary for us to relate to each other. quoteEmpathy and compassion are synonyms in many dictionaries and used interchangeably by many, but they have different characteristics.quote The brain is, of course, very complicated, so it is plausible that these two types of empathy could take place in the same part of the brain. So far, though, the research seems to indicate that they are largely separate: In a review article, Jamil Zaki and Kevin Ochsner note that hundreds of studies now support a certain perspective on the mind, which they call “a tale of two systems.” One system involves sharing the experience of others, what we’ve called empathy; the other involves inferences about the mental states of othersmentalizing or mind reading. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "While they can both be active at once, and often are, they occupy different parts of the brain. For instance, the medial prefrontal cortex, just behind the forehead, is involved in mentalizing, while the anterior cingulate cortex, sitting right behind that, is involved in empathy. The difference between cognitive and emotional empathy is important for understanding Bloom’s arguments. From Bloom’s perspective, cognitive empathy is “a useful and necessary tool for anyone who wishes to be a good personbut it is morally neutral.” On the other hand, Bloom believes that emotional empathy is “morally corrosive,” and the bulk of his attack is directed at highlighting the pitfalls of relying on emotional empathy while making the case for cultivating and practicing “rational compassion” instead. ",
					"content_token": 163,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "I believe that the capacity for emotional empathy, described as “sympathy” by philosophers such as Adam Smith and David Hume, often simply known as “empathy” and defended by so many scholars, theologians, educators, and politicians, is actually morally corrosive. If you are struggling with a moral decision and find yourself trying to feel someone else’s pain or pleasure, you should stop. This empathic engagement might give you some satisfaction, but it’s not how to improve things and can lead to bad decisions and bad outcomes. Much better to use reason and cost-benefit analysis, drawing on a more distanced compassion and kindness. Here again, the definition of the terms is important for understanding the argument. Empathy and compassion are synonyms in many dictionaries and used interchangeably by many, but they have different characteristics. Bloom outlines the difference:  compassion and concern are more diffuse than empathy. ",
					"content_token": 192,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "It is weird to talk about having empathy for the millions of victims of malaria, say, but perfectly normal to say that you are concerned about them or feel compassion for them. Also, compassion and concern don’t require mirroring of others’ feelings. If someone works to help the victims of torture and does so with energy and good cheer, it doesn’t seem right to say that as they do this, they are empathizing with the individuals they are helping. Better to say that they feel compassion for them. Bloom references a review paper written by Tania Singer and Olga Klimecki to help make the distinction clear. Singer and Klimecki write: In contrast to empathy, compassion does not mean sharing the suffering of the other: rather, it is characterized by feelings of warmth, concern and care for the other, as well as a strong motivation to improve the other’s well-being. Compassion is feeling for and not feeling with the other. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "To summarize, emotional empathy could be simply described as “feeling what others feel,” cognitive empathy as “understanding what others feel,” and compassion as “caring about how others feel.” quoteEmotional empathy could be simply described as “feeling what others feel,” cognitive empathy as “understanding what others feel,” and compassion as “caring about how others feel.”quote Empathy and Morality Many people believe that our ability to empathize is the basis for morality because it causes us to consider our actions from another’s perspective. “Treat others as you would like to be treated” is the basic morality lesson repeated thousands of times to children all over the world. In this way, empathy can lead us to rely on our self-centered nature. ",
					"content_token": 176,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "If this is true, Bloom suggests that the argument in its simplest form would go like this: Everyone is naturally interested in him- or herself; we care most about our own pleasure and pain. It requires nothing special to yank one’s hand away from a flame or to reach for a glass of water when thirsty. But empathy makes the experiences of others salient and importantyour pain becomes my pain, your thirst becomes my thirst, and so I rescue you from the fire or give you something to drink. Empathy guides us to treat others as we treat ourselves and hence expands our selfish concerns to encompass others. In this way, the willful exercise of empathy can motivate kindness that would never have otherwise occurred. Empathy can make us care about a slave, or a homeless person, or someone in solitary confinement. It can put us into the mind of a gay teenager bullied by his peers, or a victim of rape. ",
					"content_token": 187,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "We can empathize with a member of a despised minority or someone suffering from religious persecution in a faraway land. All these experiences are alien to me, but through the exercise of empathy, I can, in some limited way, experience them myself, and this makes me a better person. When we consider the plight of others by imagining ourselves in their situation, we experience an empathic response that can cause us to evaluate the morality of our actions. quoteWhen we consider the plight of others by imagining ourselves in their situation, we experience an empathic response that can cause us to evaluate the morality of our actions.quote In an interview, Steven Pinker hypothesizes that it was an increase in empathy, made possible by the technology of the printing press and the resulting increase in literacy, that led to the Humanitarian Revolution during the Enlightenment. ",
					"content_token": 169,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "The increase in empathy brought about by our ability to read accounts of violent punishments like disembowelment and mutilation caused us to reconsider the morality of treating other human beings in such ways. So in certain instances, empathy can play a role in motivating us to take moral action. But is an empathic response required to do so? To use a classic example from philosophyfirst thought up by the Chinese philosopher Menciusimagine that you are walking by a lake and see a young child struggling in shallow water. If you can easily wade into the water and save her, you should do it. It would be wrong to keep walking. What motivates this good act? It is possible, I suppose, that you might imagine what it feels like to be drowning, or anticipate what it would be like to be the child’s mother or father hearing that she drowned. Such empathic feelings could then motivate you to act. But that is hardly necessary. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "You don’t need empathy to realize that it’s wrong to let a child drown. Any normal person would just wade in and scoop up the child, without bothering with any of this empathic hoo-ha. And so there has to be more to morality than empathy. Our decisions about what’s right and what’s wrong, and our motivations to act, have many sources. One’s morality can be rooted in a religious worldview or a philosophical one. It can be motivated by a more diffuse concern for the fates of otherssomething often described as concern or compassion I hope most people reading this would agree that failing to attempt to save a drowning child or supporting or perpetrating violent punishments like disembowelment would be at the very least morally reprehensible, if not outright evil. ",
					"content_token": 171,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "But what motivates people to be “evil”? For researchers like Simon Baron-Cohen, evil is defined as “empathy erosion”  truly evil people lack the capacity to empathize, and it is this lack of empathy that causes them to act in evil ways. Bloom looks at the question of what causes people to be evil from a slightly different angle: Indeed, some argue that the myth of pure evil gets things backward. That is, it’s not that certain cruel actions are committed because the perpetrators are self-consciously and deliberatively evil. Rather it is because they think they are doing good. They are fueled by a strong moral sense. When the perpetrators of violence or cruelty believe that their actions are morally justified, what motivates them? Bloom suggests that it can be empathy. Empathy often causes us to choose sides, to choose whom to empathize with. We see this tendency play out in politics all the time. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "quoteEmpathy often causes us to choose sides, to choose whom to empathize with.quote Politicians representing one side believe they are saving the world, while representatives on the other side believe that their adversaries are out to destroy civilization as we know it. If I believe that I am protecting a person or group of people whom I choose to empathize with, then I may be motivated to act in a way I believe is morally justified, even though others may believe that I have harmed them. Steven Pinker weighed in on this issue when he wrote the following in The Better Angels of our Nature: If you added up all the homicides committed in pursuit of self-help justice, the casualties of religious and revolutionary wars, the people executed for victimless crimes and misdemeanors, and the targets of ideological genocides, they would surely outnumber the fatalities from amoral predation and conquest. ",
					"content_token": 182,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "Bloom quotes Pinker and goes on to write: Henry Adams put this in stronger terms, with regard to Robert E. Lee: “It’s always the good men who do the most harm in the world.” This might seem perverse. How can good lead to evil? One thing to keep in mind here is that we are interested in beliefs and motivations, not what’s good in some objective sense. So the idea isn’t that evil is good; rather, it’s that evil is done by those who think they are doing good. So from a moral perspective, empathy can lead us astray. We may believe we are doing good or that our actions are justified but this may not necessarily be true for all involved. This is especially troublesome when we consider how we are affected by a growing list of cognitive biases. ",
					"content_token": 175,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "Empathy and Biases While empathy may not be required to motivate us to save a drowning child, it can still help us consider the differing experiences or suffering of another person thus motivating us to consider things from their perspective or thus act to relieve their suffering: I see the bullied teenager and might be tempted initially to join in with his tormenters, out of sadism or boredom or a desire to dominate or be popular, but then I empathizeI feel his pain, I feel what it’s like to be bulliedso I don’t add to his suffering. Maybe I even rise to his defense. Empathy is like a spotlight directing attention and aid to where it’s needed. On the surface this seems like an excellent case for the positive power of empathy; it shines a “spotlight” on a person in need and motivates us to help them. ",
					"content_token": 182,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "But what happens when we dig a little deeper into this metaphor? Bloom writes  spotlights have a narrow focus, and this is one problem with empathy. It does poorly in a world where there are many people in need and where the effects of one’s actions are diffuse, often delayed, and difficult to compute, a world in which an act that helps one person in the here and now can lead to greater suffering in the future. He adds: Further, spotlights only illuminate what they are pointed at, so empathy reflects our biases. Although we might intellectually believe that the suffering of our neighbor is just as awful as the suffering of someone living in another country, it’s far easier to empathize with those who are close to us, those who are similar to us, and those we see as more attractive or vulnerable and less scary. ",
					"content_token": 173,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "Intellectually, a white American might believe that a black person matters just as much as a white person, but he or she will typically find it a lot easier to empathize with the plight of the latter than the former. In this regard, empathy distorts our moral judgments in pretty much the same way that prejudice does. We are all predisposed to care more deeply for those we are close to. From a purely biological perspective, we will care for and protect our children and families before the children or families of strangers. Our decision making often falls victim to narrow framing, and our actions are affected by biases like LikingLoving and DislikingHating and our tendency to discount the pain of people we don’t like: We are constituted to favor our friends and family over strangers, to care more about members of our own group than people from different, perhaps opposing, groups. This fact about human nature is inevitable given our evolutionary history. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "Any creature that didn’t have special sentiments toward those that shared its genes and helped it in the past would get its ass kicked from a Darwinian perspective; it would falter relative to competitors with more parochial natures. This bias to favor those close to us is generalit influences who we readily empathize with, but it also influences who we like, who we tend to care for, who we will affiliate with, who we will punish, and so on. There are many causes for human biases  empathy is only one  but taking a step back, we can see how the intuitive gut responses motivated by emotional empathy can negatively affect our ability to make rational decisions. Empathy’s narrow focus, specificity, and innumeracy mean that it’s always going to be influenced by what captures our attention, by racial preferences, and so on. ",
					"content_token": 178,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "It’s only when we escape from empathy and rely instead on the application of rules and principles or a calculation of costs and benefits that we can, to at least some extent, become fair and impartial. While many of us are motivated to be good and to make good decisions, it isn’t always cut and dry. Our preferences for whom to help or which organizations to support are affected by our biases. If we’re not careful, empathy can affect our ability to see the potential impacts of our actions. However, considering these impacts takes much more than empathy and a desire to do good; it takes awareness of our biases and mental effort to combat their effects:  doing actual good, instead of doing what feels good, requires dealing with complex issues and being mindful of exploitation from competing, sometimes malicious and greedy, interests. To do so, you need to step back and not fall into empathy traps. ",
					"content_token": 186,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "The conclusion is not that one shouldn’t give, but rather that one should give intelligently, with an eye toward consequences. In addition to biases like LikingLoving and DislikingHating, empathy can lead to biases related to the Representative Heuristic. Actions motivated by empathy often fail to take the broader picture into account; the spotlight doesn’t encourage us to consider base rates or sample size when we make our decisions. Instead, we are motivated by positive emotions for a specific individual or small group: Empathy is limited as well in that it focuses on specific individuals. Its spotlight nature renders it innumerate and myopic: It doesn’t resonate properly to the effects of our actions on groups of people, and it is insensitive to statistical data and estimated costs and benefits. Part of the challenge that exists with empathy is this innumeracy that Bloom describes. It is impossible for us to form genuine empathic connections with abstractions. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "Conversely, if we see the suffering of one, empathy can motivate us to help make it stop. As Mother Theresa said, “If I look at the mass, I will never act. If I look at the one, I will.” This is what psychologists call “the identifiable victim effect.” quoteWhile many of us are motivated to be good and to make good decisions, it isn’t always cut and dry.quote Perhaps an example will help illustrate.  On October 17, 1987, 18-month-old Jessica McClure fell 22 feet down an eight-inch-diameter well in the backyard of her home in Midland, Texas. Over the next 2  days, fire, police, and volunteer rescuers worked around the clock to save her. ",
					"content_token": 163,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "Media coverage of the emergency was broadcast all over the world resulting in Jessica McClure becoming internationally known as “Baby Jessica” and prompting then-President Ronald Reagan to proclaim that “everybody in America became the godmothers and godfathers of Jessica while this was going on.” The intense coverage and global awareness led to an influx of donations, resulting in an 800,000 trust being established in Jessica’s name. What prompted this massive outpouring of concern and support? There are millions of children in need every day all over the world. How many of the people who sent donations to Baby Jessica had ever tried to help these faceless children? In the case of Baby Jessica, they had an identifiable victim, and empathy motivated many of them to help Jessica and her family. They could imagine what it might feel like for those poor parents and they felt genuine concern for the child’s future; all the other needy children around the world were statistical abstractions. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "This ability to identify and put a face on the suffering child and their family enables us to experience an empathic response with them, but the random children and their families remain empathically out of reach. None of this is to say that rescuers should not have worked to save Jessica McClure  she was a real-world example of Mencius’s proverbial drowning child  but there are situations every day where we choose to help individuals at the cost of the continued suffering of others. Our actions often have diffuse and unknowable impacts. If our concern is driven by thoughts of the suffering of specific individuals, then it sets up a perverse situation in which the suffering of one can matter more than the suffering of a thousand. Furthermore, not only are we more likely to empathize with the identifiable victim, our empathy has its limits in scale as well. ",
					"content_token": 172,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "If we hear that an individual in a faraway land is suffering, we may have an empathic response, but will that response be increased proportionally if we learned that thousands or millions of people suffered? Adam Smith got to the heart of this question in The Theory of Moral Sentiments when he wrote: Let us suppose that the great empire of China, with all its myriads of inhabitants, was suddenly swallowed up by an earthquake, and let us consider how a man of humanity in Europe, who had no sort of connection with that part of the world, would be affected upon receiving intelligence of this dreadful calamity. He would, I imagine, first of all, express very strongly his sorrow for the misfortune of that unhappy people, he would make many melancholy reflections upon the precariousness of human life, and the vanity of all the labors of man, which could thus be annihilated in a moment. ",
					"content_token": 184,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "He would too, perhaps, if he was a man of speculation, enter into many reasonings concerning the effects which this disaster might produce upon the commerce of Europe, and the trade and business of the world in general. And when all this fine philosophy was over, when all these humane sentiments had been once fairly expressed, he would pursue his business or his pleasure, take his repose or his diversion, with the same ease and tranquility, as if no such accident had happened. Empathy can inadvertently motivate us to act to save the one at the expense of the many. While the examples provided are by no means clear-cut issues, it is worth considering how the morality or goodness of our actions to help the few may have negative consequences for the many. Charlie Munger has written and spoken about the Kantian Fairness Tendency, in which he suggests that for certain systems to be moral to the many, they must be unfair to the few. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "quoteFor certain systems to be moral to the many, they must be unfair to the few.quote Empathy and Reason We are emotional creatures, then, but we are also rational beings, with the capacity for rational decision-making. We can override, deflect, and overrule our passions, and we often should do so. It’s not hard to see this for feelings like anger and hateit’s clear that these can lead us astray, that we do better when they don’t rule us and when we are capable of circumventing them. While we need kindness and compassion and we should strive to be good people making good decisions, we are not necessarily well served by empathy in this regard; emotional empathy’s negatives often outweigh its positives. Instead, we should rely on our capacity to reason and control our emotions. ",
					"content_token": 173,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "Empathy is not something that can be removed or ignored; it is a normal function of our brains after all, but we can and do combine reason with our natural instincts and intuitions: The idea that human nature has two opposing facetsemotion versus reason, gut feelings versus careful, rational deliberationis the oldest and most resilient psychological theory of all. It was there in Plato, and it is now the core of the textbook account of cognitive processes, which assumes a dichotomy between “hot” and “cold” mental processes, between an intuitive “System 1” and a deliberative “System 2.” We know from Daniel Kahneman’s Thinking, Fast and Slow that these two systems are not inherently separate in practice. They are both functioning in our brains at the same time. ",
					"content_token": 170,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "Some decisions are made faster due to heuristics and intuitions from experiences or our biology, while other decisions are made in a more deliberative and slow fashion using reason. Bloom writes: We go through a mental process that is typically called “choice,” where we think about the consequences of our actions. There is nothing magical about this. The neural basis of mental life is fully compatible with the existence of conscious deliberation and rational thoughtwith neural systems that analyze different options, construct logical chains of argument, reason through examples and analogies, and respond to the anticipated consequences of actions. We have an impulsive, emotional, and intuitive decision-making system in System 1 and a deliberative, reasoning, and sometimes rational decision-making system in System 2. ",
					"content_token": 156,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "quoteWe will always have emotional reactions, but on average our decision making will be better served by improving our ability to reason rather than leveraging our ability to empathizequote We will always have emotional reactions, but on average our decision making will be better served by improving our ability to reason rather than by leveraging our ability to empathize. One way to increase our ability to reason is to focus on improving our self-control: Self-control can be seen as the purest embodiment of rationality in that it reflects the working of a brain system embedded in the frontal lobe, the part of the brain that lies behind the forehead that restrains our impulsive, irrational, or emotive desires. While Bloom is unabashedly against empathy as an inherent force for good in the world, he is also a firm supporter of being and doing good. ",
					"content_token": 169,
					"embedding": []
				},
				{
					"article_title": "Making Compassionate Decisions: The Role of Empathy in Decision Making",
					"article_url": "https://fs.blog/against-empathy/",
					"content": "He believes that the “feeling with” nature of emotional empathy leads us to make biased and bad decisions despite our best intentions and that we should instead foster and encourage the “caring for” nature of compassion while combining it with our intelligence, self-control, and ability to reason:  none of this is to deny the importance of traits such as compassion and kindness. We want to nurture these traits in our children and work to establish a culture that prizes and rewards them. But they are not enough. To make the world a better place, we would also want to bless people with more smarts and more self-control. These are central to leading a successful and happy lifeand a good and moral one.   Editor’s note: Where you see boldface in block quotes, emphasis has been added by Farnam Street.",
					"content_token": 173,
					"embedding": []
				}
			]
		},
		{
			"title": "Do Algorithms Beat Us at Complex Decision Making?",
			"url": "https://fs.blog/algorithms-complex-decision-making/",
			"content": "Decision-making algorithms are undoubtedly controversial. If a decision is being made that will have a major influence on your life, most people would prefer a human make it. But what if algorithms really can make better decisions?  Algorithms are all the rage these days. AI researchers are taking more and more ground from humans in areas like rules-based games, visual recognition, and medical diagnosis. However, the idea that algorithms make better predictive decisions than humans in many fields is a very old one. In 1954, the psychologist Paul Meehl published a controversial book with a boring sounding name: Clinical vs. Statistical Prediction: A Theoretical Analysis and a Review of the Evidence. The controversy? After reviewing the data, Meehl claimed that mechanical, data-driven algorithms could better predict human behavior than trained clinical psychologists  and with much simpler criteria. He was right. The passing of time has not been friendly to humans in this game: Studies continue to show that the algorithms do a better job than experts in a range of fields. In Daniel Kahneman’s Thinking Fast and Slow, he details a selection of fields which have demonstrated inferior human judgment compared to algorithms: The range of predicted outcomes has expanded to cover medical variables such as the longevity of cancer patients, the length of hospital stays, the diagnosis of cardiac disease, and the susceptibility of babies to sudden infant death syndrome; economic measures such as the prospects of success for new businesses, the evaluation of credit risks by banks, and the future career satisfaction of workers; questions of interest to government agencies, including assessments of the suitability of foster parents, the odds of recidivism among juvenile offenders, and the likelihood of other forms of violent behavior; and miscellaneous outcomes such as the evaluation of scientific presentations, the winners of football games, and the future prices of Bordeaux wine. The connection between them? Says Kahneman: “Each of these domains entails a significant degree of uncertainty and unpredictability.” He called them “low-validity environments”, and in those environments, simple algorithms matched or outplayed humans and their “complex” decision making criteria, essentially every time.  A typical case is described in Michael Lewis’ book on the relationship between Daniel Kahneman and Amos Tversky, The Undoing Project. He writes of work done at the Oregon Research Institute on radiologists and their x-ray diagnoses:  The Oregon researchers began by creating, as a starting point, a very simple algorithm, in which the likelihood that an ulcer was malignant depended on the seven factors doctors had mentioned, equally weighted. The researchers then asked the doctors to judge the probability of cancer in ninety-six different individual stomach ulcers, on a seven-point scale from “definitely malignant” to “definitely benign.” Without telling the doctors what they were up to, they showed them each ulcer twice, mixing up the duplicates randomly in the pile so the doctors wouldn’t notice they were being asked to diagnose the exact same ulcer they had already diagnosed.  The researchers’ goal was to see if they could create an algorithm that would mimic the decision making of doctors. This simple first attempt, Lewis Goldberg assumed, was just a starting point. The algorithm would need to become more complex; it would require more advanced mathematics. It would need to account for the subtleties of the doctors’ thinking about the cues. For instance, if an ulcer was particularly big, it might lead them to reconsider the meaning of the other six cues. But then UCLA sent back the analyzed data, and the story became unsettling. Goldberg described the results as “generally terrifying”. In the first place, the simple model that the researchers had created as their starting point for understanding how doctors rendered their diagnoses proved to be extremely good at predicting the doctors’ diagnoses. The doctors might want to believe that their thought processes were subtle and complicated, but a simple model captured these perfectly well. That did not mean that their thinking was necessarily simple, only that it could be captured by a simple model. More surprisingly, the doctors’ diagnoses were all over the map: The experts didn’t agree with each other. Even more surprisingly, when presented with duplicates of the same ulcer, every doctor had contradicted himself and rendered more than one diagnosis: These doctors apparently could not even agree with themselves.  If you wanted to know whether you had cancer or not, you were better off using the algorithm that the researchers had created than you were asking the radiologist to study the X-ray. The simple algorithm had outperformed not merely the group of doctors; it had outperformed even the single best doctor.  The fact that doctors and psychiatrists, and wine experts, and so forth cannot even agree with themselves is a problem called decision making “noise”: Given the same set of data twice, we make two different decisions. Noise. Internal contradiction. Algorithms win, at least partly, because they don’t do this: The same inputs generate the same outputs every single time. They don’t get distracted, they don’t get bored, they don’t get mad, they don’t get annoyed. Basically, they don’t have off days. And they don’t fall prey to the litany of biases that humans do, like the representativeness heuristic. The algorithm doesn’t even have to be a complex one. As demonstrated above with radiology, simple rules work just as well as complex ones. Kahneman himself addresses this in Thinking, Fast and Slow when discussing Robyn Dawes’s research on the superiority of simple algorithms using a few equally-weighted predictive variables: The surprising success of equal-weighting schemes has an important practical implication: it is possible to develop useful algorithms without prior statistical research. Simple equally weight formulas based on existing statistics or on common sense are often very good predictors of significant outcomes. In a memorable example, Dawes showed that marital stability is well predicted by a formula: Frequency of lovemaking minus frequency of quarrels. You don’t want your result to be a negative number. The important conclusion from this research is that an algorithm that is constructed on the back of an envelope is often good enough to compete with an optimally weighted formula, and certainly good enough to outdo expert judgment. This logic can be applied in many domains, ranging from the selection of stocks by portfolio managers to the choices of medical treatments by doctors or patients. Stock selection, certainly a “low validity environment”, is an excellent example of the phenomenon. As John Bogle pointed out to the world in the 1970’s, a point which has only strengthened with time, the vast majority of human stock-pickers cannot outperform a simple SP 500 index fund, an investment fund that operates on strict algorithmic rules about which companies to buy and sell and in what quantities. The rules of the index aren’t complex, and many people have tried to improve on them with less success than might be imagined.  Another interesting area where this holds is interviewing and hiring, a notoriously difficult “low-validity” environment. Even elite firms often don’t do it that well, as has been well documented. Fortunately, if we take heed of the advice of the psychologists, operating in a low-validity environment has rules that can work very well. In Thinking Fast and Slow, Kahneman recommends fixing your hiring process by doing the following or some close variant, in order to replicate the success of the algorithms: Suppose you need to hire a sales representative for your firm. If you are serious about hiring the best possible person for the job, this is what you should do. First, select a few traits that are prerequisites for success in this position technical proficiency, engaging personality, reliability, and so on. Don’t overdo it  six dimensions is a good number. The traits you choose should be as independent as possible from each other, and you should feel that you can assess them reliably by asking a few factual questions. Next, make a list of questions for each trait and think about how you will score it, say on a 1-5 scale. You should have an idea of what you will call “very weak” or “very strong.” These preparations should take you half an hour or so, a small investment that can make a significant difference in the quality of the people you hire. To avoid halo effects, you must collect the information one at a time, scoring each before you move on to the next one. Do not skip around. To evaluate each candidate, add up the six scores.  Firmly resolve that you will hire the candidate whose final score is the highest, even if there is another one whom you like better–try to resit your wish to invent broken legs to change the ranking. A vast amount of research offers a promise: you are much more likely to find the best candidate if you use this procedure than if you do what people normally do in such situations, which is to go into the interview unprepared and to make choices by an overall intuitive judgment such as “I looked into his eyes and liked what I saw.” In the battle of man vs algorithm, unfortunately, man often loses. The promise of Artificial Intelligence is just that. So if we’re going to be smart humans, we must learn to be humble in situations where our intuitive judgment simply is not as good as a set of simple rules. ",
			"tokens": 2006,
			"chunks": [
				{
					"article_title": "Do Algorithms Beat Us at Complex Decision Making?",
					"article_url": "https://fs.blog/algorithms-complex-decision-making/",
					"content": "Decision-making algorithms are undoubtedly controversial. If a decision is being made that will have a major influence on your life, most people would prefer a human make it. But what if algorithms really can make better decisions?  Algorithms are all the rage these days. AI researchers are taking more and more ground from humans in areas like rules-based games, visual recognition, and medical diagnosis. However, the idea that algorithms make better predictive decisions than humans in many fields is a very old one. In 1954, the psychologist Paul Meehl published a controversial book with a boring sounding name: Clinical vs. Statistical Prediction: A Theoretical Analysis and a Review of the Evidence. The controversy? After reviewing the data, Meehl claimed that mechanical, data-driven algorithms could better predict human behavior than trained clinical psychologists  and with much simpler criteria. He was right. ",
					"content_token": 182,
					"embedding": []
				},
				{
					"article_title": "Do Algorithms Beat Us at Complex Decision Making?",
					"article_url": "https://fs.blog/algorithms-complex-decision-making/",
					"content": "The passing of time has not been friendly to humans in this game: Studies continue to show that the algorithms do a better job than experts in a range of fields. ",
					"content_token": 35,
					"embedding": []
				},
				{
					"article_title": "Do Algorithms Beat Us at Complex Decision Making?",
					"article_url": "https://fs.blog/algorithms-complex-decision-making/",
					"content": "In Daniel Kahneman’s Thinking Fast and Slow, he details a selection of fields which have demonstrated inferior human judgment compared to algorithms: The range of predicted outcomes has expanded to cover medical variables such as the longevity of cancer patients, the length of hospital stays, the diagnosis of cardiac disease, and the susceptibility of babies to sudden infant death syndrome; economic measures such as the prospects of success for new businesses, the evaluation of credit risks by banks, and the future career satisfaction of workers; questions of interest to government agencies, including assessments of the suitability of foster parents, the odds of recidivism among juvenile offenders, and the likelihood of other forms of violent behavior; and miscellaneous outcomes such as the evaluation of scientific presentations, the winners of football games, and the future prices of Bordeaux wine. ",
					"content_token": 168,
					"embedding": []
				},
				{
					"article_title": "Do Algorithms Beat Us at Complex Decision Making?",
					"article_url": "https://fs.blog/algorithms-complex-decision-making/",
					"content": "The connection between them? Says Kahneman: “Each of these domains entails a significant degree of uncertainty and unpredictability.” He called them “low-validity environments”, and in those environments, simple algorithms matched or outplayed humans and their “complex” decision making criteria, essentially every time.  A typical case is described in Michael Lewis’ book on the relationship between Daniel Kahneman and Amos Tversky, The Undoing Project. He writes of work done at the Oregon Research Institute on radiologists and their x-ray diagnoses:  The Oregon researchers began by creating, as a starting point, a very simple algorithm, in which the likelihood that an ulcer was malignant depended on the seven factors doctors had mentioned, equally weighted. ",
					"content_token": 165,
					"embedding": []
				},
				{
					"article_title": "Do Algorithms Beat Us at Complex Decision Making?",
					"article_url": "https://fs.blog/algorithms-complex-decision-making/",
					"content": "The researchers then asked the doctors to judge the probability of cancer in ninety-six different individual stomach ulcers, on a seven-point scale from “definitely malignant” to “definitely benign.” Without telling the doctors what they were up to, they showed them each ulcer twice, mixing up the duplicates randomly in the pile so the doctors wouldn’t notice they were being asked to diagnose the exact same ulcer they had already diagnosed.  The researchers’ goal was to see if they could create an algorithm that would mimic the decision making of doctors. This simple first attempt, Lewis Goldberg assumed, was just a starting point. The algorithm would need to become more complex; it would require more advanced mathematics. It would need to account for the subtleties of the doctors’ thinking about the cues. For instance, if an ulcer was particularly big, it might lead them to reconsider the meaning of the other six cues. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "Do Algorithms Beat Us at Complex Decision Making?",
					"article_url": "https://fs.blog/algorithms-complex-decision-making/",
					"content": "But then UCLA sent back the analyzed data, and the story became unsettling. Goldberg described the results as “generally terrifying” In the first place, the simple model that the researchers had created as their starting point for understanding how doctors rendered their diagnoses proved to be extremely good at predicting the doctors’ diagnoses. The doctors might want to believe that their thought processes were subtle and complicated, but a simple model captured these perfectly well. That did not mean that their thinking was necessarily simple, only that it could be captured by a simple model. More surprisingly, the doctors’ diagnoses were all over the map: The experts didn’t agree with each other. Even more surprisingly, when presented with duplicates of the same ulcer, every doctor had contradicted himself and rendered more than one diagnosis: These doctors apparently could not even agree with themselves. ",
					"content_token": 173,
					"embedding": []
				},
				{
					"article_title": "Do Algorithms Beat Us at Complex Decision Making?",
					"article_url": "https://fs.blog/algorithms-complex-decision-making/",
					"content": " If you wanted to know whether you had cancer or not, you were better off using the algorithm that the researchers had created than you were asking the radiologist to study the X-ray. The simple algorithm had outperformed not merely the group of doctors; it had outperformed even the single best doctor.  The fact that doctors and psychiatrists, and wine experts, and so forth cannot even agree with themselves is a problem called decision making “noise”: Given the same set of data twice, we make two different decisions. Noise. Internal contradiction. Algorithms win, at least partly, because they don’t do this: The same inputs generate the same outputs every single time. They don’t get distracted, they don’t get bored, they don’t get mad, they don’t get annoyed. Basically, they don’t have off days. ",
					"content_token": 189,
					"embedding": []
				},
				{
					"article_title": "Do Algorithms Beat Us at Complex Decision Making?",
					"article_url": "https://fs.blog/algorithms-complex-decision-making/",
					"content": "And they don’t fall prey to the litany of biases that humans do, like the representativeness heuristic. The algorithm doesn’t even have to be a complex one. As demonstrated above with radiology, simple rules work just as well as complex ones. Kahneman himself addresses this in Thinking, Fast and Slow when discussing Robyn Dawes’s research on the superiority of simple algorithms using a few equally-weighted predictive variables: The surprising success of equal-weighting schemes has an important practical implication: it is possible to develop useful algorithms without prior statistical research. Simple equally weight formulas based on existing statistics or on common sense are often very good predictors of significant outcomes. In a memorable example, Dawes showed that marital stability is well predicted by a formula: Frequency of lovemaking minus frequency of quarrels. You don’t want your result to be a negative number. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "Do Algorithms Beat Us at Complex Decision Making?",
					"article_url": "https://fs.blog/algorithms-complex-decision-making/",
					"content": "The important conclusion from this research is that an algorithm that is constructed on the back of an envelope is often good enough to compete with an optimally weighted formula, and certainly good enough to outdo expert judgment. This logic can be applied in many domains, ranging from the selection of stocks by portfolio managers to the choices of medical treatments by doctors or patients. Stock selection, certainly a “low validity environment”, is an excellent example of the phenomenon. As John Bogle pointed out to the world in the 1970’s, a point which has only strengthened with time, the vast majority of human stock-pickers cannot outperform a simple SP 500 index fund, an investment fund that operates on strict algorithmic rules about which companies to buy and sell and in what quantities. The rules of the index aren’t complex, and many people have tried to improve on them with less success than might be imagined. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "Do Algorithms Beat Us at Complex Decision Making?",
					"article_url": "https://fs.blog/algorithms-complex-decision-making/",
					"content": " Another interesting area where this holds is interviewing and hiring, a notoriously difficult “low-validity” environment. Even elite firms often don’t do it that well, as has been well documented. Fortunately, if we take heed of the advice of the psychologists, operating in a low-validity environment has rules that can work very well. In Thinking Fast and Slow, Kahneman recommends fixing your hiring process by doing the following or some close variant, in order to replicate the success of the algorithms: Suppose you need to hire a sales representative for your firm. If you are serious about hiring the best possible person for the job, this is what you should do. First, select a few traits that are prerequisites for success in this position technical proficiency, engaging personality, reliability, and so on. Don’t overdo it  six dimensions is a good number. ",
					"content_token": 185,
					"embedding": []
				},
				{
					"article_title": "Do Algorithms Beat Us at Complex Decision Making?",
					"article_url": "https://fs.blog/algorithms-complex-decision-making/",
					"content": "The traits you choose should be as independent as possible from each other, and you should feel that you can assess them reliably by asking a few factual questions. Next, make a list of questions for each trait and think about how you will score it, say on a 1-5 scale. You should have an idea of what you will call “very weak” or “very strong.” These preparations should take you half an hour or so, a small investment that can make a significant difference in the quality of the people you hire. To avoid halo effects, you must collect the information one at a time, scoring each before you move on to the next one. Do not skip around. To evaluate each candidate, add up the six scores.  Firmly resolve that you will hire the candidate whose final score is the highest, even if there is another one whom you like better–try to resit your wish to invent broken legs to change the ranking. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "Do Algorithms Beat Us at Complex Decision Making?",
					"article_url": "https://fs.blog/algorithms-complex-decision-making/",
					"content": "A vast amount of research offers a promise: you are much more likely to find the best candidate if you use this procedure than if you do what people normally do in such situations, which is to go into the interview unprepared and to make choices by an overall intuitive judgment such as “I looked into his eyes and liked what I saw.” In the battle of man vs algorithm, unfortunately, man often loses. The promise of Artificial Intelligence is just that. So if we’re going to be smart humans, we must learn to be humble in situations where our intuitive judgment simply is not as good as a set of simple rules.",
					"content_token": 130,
					"embedding": []
				}
			]
		},
		{
			"title": "Blog Posts, Book Reviews, and Abstracts: On Shallowness",
			"url": "https://fs.blog/on-shallowness/",
			"content": "We’re quite glad that you read Farnam Street, and we hope we’re always offering you a massive amount of value. If not, email us and tell us what we can do more effectively. But there’s a message all of our readers should appreciate: Blog posts are not enough to generate the deep fluency you need to truly understand or get better at something. We offer a starting point, not an end point. This goes just as well for book reviews, abstracts, cliff’s notes, and a good deal of short-form journalism. This is a hard message for some who want a shortcut. They want the “gist” and the “high level takeaways”, without doing the work or eating any of the broccoli. They think that’s all it takes: Check out a 5-minute read, and instantly their decision making and understanding of the world will improve right-quick. Most blogs, of course, encourage this kind of shallowness. Because it makes you feel that the whole thing is pretty easy. Here’s the problem: The world is more complex than that. It doesn’t actually work this way. The nuanced detail behind every “high level takeaway” gives you the context needed to use it in the real world. The exceptions, the edge cases, and the contradictions. Let me give you an example. A high-level takeaway from reading Kahneman’s Thinking Fast, and Slow would be that we are subject to something he and Amos Tversky call the Representativeness Heuristic. We create models of things in our head, and then fit our real-world experiences to the model, often over-fitting drastically. A very useful idea. However, that’s not enough. There are so many follow-up questions. Where do we make the most mistakes? Why does our mind create these models? Where is this generally useful? What are the nuanced examples of where this tendency fails us? And so on. Just knowing about the Heuristic, knowing that it exists, won’t perform any work for you. Or take the rise of human species as laid out by Yuval Harari. It’s great to post on his theory; how myths laid the foundation for our success, how “natural” is probably a useless concept the way it’s typically used, and how biology is the great enabler. But Harari’s book itself contains the relevant detail that fleshes all of this out. And further, his bibliography is full of resources that demand your attention to get even more backup. How did he develop that idea? You have to look to find out. Why do all this? Because without the massive, relevant detail, your mind is built on a house of cards. What Farnam Street and a lot of other great resources give you is something like a brief map of the territory. Welcome to Colonial Williamsburg! Check out the re-enactors, the museum, and the theatre. Over there is the Revolutionary City. Gettysburg is 4 hours north. Washington D.C. is closer to 2.5 hours. Great – now you have a lay of the land. Time to dig in and actually learn about the American Revolution. This book is awesome, if you actually want to do that. Going back to Kahneman, one of his and Tversky’s great findings was the concept of the Availability Heuristic. Basically, the mind operates on what it has close at hand. As Kahneman puts it, “An essential design feature of the associative machine is that it represents only activated ideas. Information that is not retrieved even unconsciously from memory might as well not exist. System 1 excels at constructing the best possible story that incorporates ideas currently activated, but it does not cannot allow for information it does not have.” That means that in the moment of decision making, when you’re thinking hard on some complex problem you face, it’s unlikely that your mind is working all that successfully without the details. It doesn’t have anything to draw on. It’d be like a chess player who read a book about great chess players, but who hadn’t actually studied all of their moves. Not very effective. The great difficulty, of course, is that we lack the time to dig deep into everything. Opportunity costs and trade-offs are quite real. That’s why you must develop excellent filters. What’s worth learning this deeply? We think it’s the first-principle style mental models. The great ideas from physical systems, biological systems, and human systems. The new-new thing you’re studying is probably either A. Wrong or B. Built on one of those great ideas anyways. Farnam Street, in a way, is just a giant filtering mechanism to get you started down the hill. But don’t stop there. Don’t stop at the starting line. Resolve to increase your depth and stop thinking you can have it all in 5 minutes or less. Use our stuff, and whoever else’s stuff you like, as an entre to the real thing. ",
			"tokens": 1085,
			"chunks": [
				{
					"article_title": "Blog Posts, Book Reviews, and Abstracts: On Shallowness",
					"article_url": "https://fs.blog/on-shallowness/",
					"content": "We’re quite glad that you read Farnam Street, and we hope we’re always offering you a massive amount of value. If not, email us and tell us what we can do more effectively. But there’s a message all of our readers should appreciate: Blog posts are not enough to generate the deep fluency you need to truly understand or get better at something. We offer a starting point, not an end point. This goes just as well for book reviews, abstracts, cliff’s notes, and a good deal of short-form journalism. This is a hard message for some who want a shortcut. They want the “gist” and the “high level takeaways”, without doing the work or eating any of the broccoli. They think that’s all it takes: Check out a 5-minute read, and instantly their decision making and understanding of the world will improve right-quick. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "Blog Posts, Book Reviews, and Abstracts: On Shallowness",
					"article_url": "https://fs.blog/on-shallowness/",
					"content": "Most blogs, of course, encourage this kind of shallowness. Because it makes you feel that the whole thing is pretty easy. Here’s the problem: The world is more complex than that. It doesn’t actually work this way. The nuanced detail behind every “high level takeaway” gives you the context needed to use it in the real world. The exceptions, the edge cases, and the contradictions. Let me give you an example. A high-level takeaway from reading Kahneman’s Thinking Fast, and Slow would be that we are subject to something he and Amos Tversky call the Representativeness Heuristic. We create models of things in our head, and then fit our real-world experiences to the model, often over-fitting drastically. A very useful idea. However, that’s not enough. There are so many follow-up questions. ",
					"content_token": 185,
					"embedding": []
				},
				{
					"article_title": "Blog Posts, Book Reviews, and Abstracts: On Shallowness",
					"article_url": "https://fs.blog/on-shallowness/",
					"content": "Where do we make the most mistakes? Why does our mind create these models? Where is this generally useful? What are the nuanced examples of where this tendency fails us? And so on. Just knowing about the Heuristic, knowing that it exists, won’t perform any work for you. Or take the rise of human species as laid out by Yuval Harari. It’s great to post on his theory; how myths laid the foundation for our success, how “natural” is probably a useless concept the way it’s typically used, and how biology is the great enabler. But Harari’s book itself contains the relevant detail that fleshes all of this out. And further, his bibliography is full of resources that demand your attention to get even more backup. How did he develop that idea? You have to look to find out. ",
					"content_token": 184,
					"embedding": []
				},
				{
					"article_title": "Blog Posts, Book Reviews, and Abstracts: On Shallowness",
					"article_url": "https://fs.blog/on-shallowness/",
					"content": "Why do all this? Because without the massive, relevant detail, your mind is built on a house of cards. What Farnam Street and a lot of other great resources give you is something like a brief map of the territory. Welcome to Colonial Williamsburg! Check out the re-enactors, the museum, and the theatre. Over there is the Revolutionary City. Gettysburg is 4 hours north. Washington D.C. is closer to 2.5 hours. Great – now you have a lay of the land. Time to dig in and actually learn about the American Revolution. This book is awesome, if you actually want to do that. Going back to Kahneman, one of his and Tversky’s great findings was the concept of the Availability Heuristic. Basically, the mind operates on what it has close at hand. As Kahneman puts it, “An essential design feature of the associative machine is that it represents only activated ideas. ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "Blog Posts, Book Reviews, and Abstracts: On Shallowness",
					"article_url": "https://fs.blog/on-shallowness/",
					"content": "Information that is not retrieved even unconsciously from memory might as well not exist. System 1 excels at constructing the best possible story that incorporates ideas currently activated, but it does not cannot allow for information it does not have.” That means that in the moment of decision making, when you’re thinking hard on some complex problem you face, it’s unlikely that your mind is working all that successfully without the details. It doesn’t have anything to draw on. It’d be like a chess player who read a book about great chess players, but who hadn’t actually studied all of their moves. Not very effective. The great difficulty, of course, is that we lack the time to dig deep into everything. Opportunity costs and trade-offs are quite real. That’s why you must develop excellent filters. What’s worth learning this deeply? We think it’s the first-principle style mental models. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "Blog Posts, Book Reviews, and Abstracts: On Shallowness",
					"article_url": "https://fs.blog/on-shallowness/",
					"content": "The great ideas from physical systems, biological systems, and human systems. The new-new thing you’re studying is probably either A. Wrong or B. Built on one of those great ideas anyways. Farnam Street, in a way, is just a giant filtering mechanism to get you started down the hill. But don’t stop there. Don’t stop at the starting line. Resolve to increase your depth and stop thinking you can have it all in 5 minutes or less. Use our stuff, and whoever else’s stuff you like, as an entre to the real thing.",
					"content_token": 126,
					"embedding": []
				}
			]
		},
		{
			"title": "Breaking the Rules: Moneyball Edition",
			"url": "https://fs.blog/breaking-rules-moneyball-edition/",
			"content": "Most of the book Simple Rules by Donald Sull and Kathleen Eisenhardt talks about identifying a problem area or an area ripe for “simple rules” and then walks you through creating your own set of rules. It’s a useful mental process. An ideal situation for simple rules is something repetitive, giving you constant feedback so you can course correct as you go. But what if your rules stop working and you need to start over completely? Simple Rules recounts the well-known Moneyball tale in its examination of this process: The story begins with Sandy Alderson. Alderson, a former Marine with no baseball background became the A’s general manager in 1983. Unlike baseball traditionalists, Alderson saw scoring runs as a process, not an outcome, and imagined baseball as a factory with a flow of players moving along the bases. This view led Alderson and later his protege and replacement, Billy Beane, to the insight that most teams overvalue batting average hits only and miss the relevance of on-base percentage walks plus hits to keeping the runners moving. Like many insightful rules, this boundary rule of picking players with a high on base percentage has subtle second – and third-order effects. Hitters with a high on-base percentage are highly disciplined i.e., patient, with a good eye for strikes. This means they get more walks, and their reputation for discipline encourages pitchers to throw strikes, which are easier to hit. They tire out pitchers by making them throw more pitches overall, and disciplined hitting does not erode much with age. These and other insights are at the heart of what author Michael Lewis famously described as moneyball. The Oakland A’s did everything right, they had examined the issues, they tried to figure out those areas which would most benefit from a set of simple rules and they had implemented them. The problem was, they were easy rules to copy.  They were operating in a Red Queen Effect world where everyone around them was co-evolving, where running fast was just enough to get ahead temporarily, but not permanently. The Red Sox were the first and most successful club to copy the A’s: By 2004, a free-spending team, the Boston Red Sox, co-opted the A’s principles and won the World Series for the first time since 1918. In contrast, the A’s went into decline, and by 2007 the were losing more games than they were winning Moneyball had struck out. What can we do when the rules stop working?  We must break them.  When the A’s had brought in Sandy Alderson, he was an outsider with no baseball background who could look at the problem in a different and new light. So how could that be replicated?  The team decided to bring in Farhan Zaidi as director of baseball operations in 2009. Zaidi spent most of his life with a pretty healthy obsession for baseball but he had a unique background: a PhD in behavioral economics.  He started on the job of breaking the old rules and crafting new ones. Like Andy Grove did once upon a time with Intel, Zaidi helped the team turn and face a new reality. Sull and Eisenhardt consider this as a key trait: To respond effectively to major change, it is essential to investigate the new situation actively, and create a reimagined vision that utilizes radically different rules. The right choice is often to move to the new rules as quickly as possible. Performance will typically decline in the short run, but the transition to the new reality will be faster and more complete in the long run. In contrast, changing slowly often results in an awkward combination of the past and the future with neither fitting the other or working well. Beane and Zaidi first did some house cleaning: They fired the team’s manager. Then, they began breaking the old Moneyball rules, things like avoiding drafting high-school players. They also decided to pay more attention to physical skills like speed and throwing. In the short term, the team performed quite poorly as fan attendance showed a steady decline. Yet, once again, against all odds, the A’s finished first in their division in 2012. Their change worked.  With a new set of Simple Rules, they became a dominant force in their division once again.  Reflecting their formidable analytic skills, the A’s brass had a new mindset that portrayed baseball as a financial market rife with arbitrage possibilities and simple rules to match.  One was a how-to rule that dictated exploiting players with splits. Simply put, players with splits have substantially different performances in two seemingly similar situations. A common split is when a player hits very well against right-handed pitchers and poorly against left-handed pitchers, or vice versa. Players with spits are mediocre when they play every game, and are low paid. In contrast, most superstars play well regardless of the situation, and are paid handsomely for their versatility. The A’s insight was that when a team has a player who can perform one side of the split well and a different player who excels at the opposite split, the two positives can create a cheap composite player. So the A’s started using a boundary rule to pick players with splits and how-to rule to exploit those splits with platooning – putting different players at the same position to take advantage of their splits against right – or left-handed pitching. If you’re reading this as a baseball fan, you’re probably thinking that exploiting splits isn’t anything new. So why did it have such an effect on their season? Well, no one had pushed it this hard before, which had some nuanced effects that might not have been immediately apparent.  For example, exploiting these splits keeps players healthier during the long 162-game season because they don’t play every day. The rule keeps everyone motivated because everyone has a role and plays often. It provides versatility when players are injured since players can fill in for each other. They didn’t stop there. Zaidi and Beane looked at the data and kept rolling out new simple rules that broke with their highly successful Moneyball past. In 2013 they added a new boundary rule to the player-selection activity: pick fly-ball hitters, meaning hitters who tend to hit the ball in the air and out of the infield in contrast with ground-ball hitters. Sixty percent of the A’s at-bat were by fly-ball hitters in 2013, the highest percentage in major-league baseball in almost a decade, and the A’s had the highest ratio of fly ball to ground balls, by far. Why fly-ball hitters?  Since one of ten fly balls is a home run, fly-ball hitters hit more home runs: an important factor in winning games. Fly-ball hitters also avoid ground-ball double plays, a rally killer if ever there as one. They are particularly effective against ground-ball pitches because they tend to swing underneath the ball, taking way the advantage of those pitchers. In fact, the A’s fly-ball hitters batted an all-star caliber .302 against ground-ball pitchers in 2013 on their way to their second consecutive division title despite having the fourth-lowest payroll in major-league baseball. Unfortunately, the new rules had a short-lived effectiveness: In 2014 the A’s fell to 2nd place and have been struggling the last two seasons. Two Cinderella stories is a great achievement, but it’s hard to maintain that edge.  This wonderful demonstration of the Red Queen Effect in sports can be described as an “arms race.’” As everyone tries to get ahead, a strange equilibrium is created by the simultaneous continual improvement, and those with more limited resources must work even harder as the pack moves ahead one at a time.  Even though they have adapted and created some wonderful “Simple Rules” in the past, the A’s and all of their competitors must stay in the race in order to return to the top: No “rule” will allow them to rest on their laurels. Second-Order Thinking and a little real-world experience show this to be true: Those that prosper consistently will think deeply, reevaluate, adapt, and continually evolve. That is the nature of a competitive world.   ",
			"tokens": 1757,
			"chunks": [
				{
					"article_title": "Breaking the Rules: Moneyball Edition",
					"article_url": "https://fs.blog/breaking-rules-moneyball-edition/",
					"content": "Most of the book Simple Rules by Donald Sull and Kathleen Eisenhardt talks about identifying a problem area or an area ripe for “simple rules” and then walks you through creating your own set of rules. It’s a useful mental process. An ideal situation for simple rules is something repetitive, giving you constant feedback so you can course correct as you go. But what if your rules stop working and you need to start over completely? Simple Rules recounts the well-known Moneyball tale in its examination of this process: The story begins with Sandy Alderson. Alderson, a former Marine with no baseball background became the A’s general manager in 1983. Unlike baseball traditionalists, Alderson saw scoring runs as a process, not an outcome, and imagined baseball as a factory with a flow of players moving along the bases. ",
					"content_token": 179,
					"embedding": []
				},
				{
					"article_title": "Breaking the Rules: Moneyball Edition",
					"article_url": "https://fs.blog/breaking-rules-moneyball-edition/",
					"content": "This view led Alderson and later his protege and replacement, Billy Beane, to the insight that most teams overvalue batting average hits only and miss the relevance of on-base percentage walks plus hits to keeping the runners moving. Like many insightful rules, this boundary rule of picking players with a high on base percentage has subtle second – and third-order effects. Hitters with a high on-base percentage are highly disciplined i.e., patient, with a good eye for strikes. This means they get more walks, and their reputation for discipline encourages pitchers to throw strikes, which are easier to hit. They tire out pitchers by making them throw more pitches overall, and disciplined hitting does not erode much with age. These and other insights are at the heart of what author Michael Lewis famously described as moneyball. ",
					"content_token": 166,
					"embedding": []
				},
				{
					"article_title": "Breaking the Rules: Moneyball Edition",
					"article_url": "https://fs.blog/breaking-rules-moneyball-edition/",
					"content": "The Oakland A’s did everything right, they had examined the issues, they tried to figure out those areas which would most benefit from a set of simple rules and they had implemented them. The problem was, they were easy rules to copy.  They were operating in a Red Queen Effect world where everyone around them was co-evolving, where running fast was just enough to get ahead temporarily, but not permanently. The Red Sox were the first and most successful club to copy the A’s: By 2004, a free-spending team, the Boston Red Sox, co-opted the A’s principles and won the World Series for the first time since 1918. In contrast, the A’s went into decline, and by 2007 the were losing more games than they were winning Moneyball had struck out. What can we do when the rules stop working?  We must break them. ",
					"content_token": 188,
					"embedding": []
				},
				{
					"article_title": "Breaking the Rules: Moneyball Edition",
					"article_url": "https://fs.blog/breaking-rules-moneyball-edition/",
					"content": " When the A’s had brought in Sandy Alderson, he was an outsider with no baseball background who could look at the problem in a different and new light. So how could that be replicated?  The team decided to bring in Farhan Zaidi as director of baseball operations in 2009. Zaidi spent most of his life with a pretty healthy obsession for baseball but he had a unique background: a PhD in behavioral economics.  He started on the job of breaking the old rules and crafting new ones. Like Andy Grove did once upon a time with Intel, Zaidi helped the team turn and face a new reality. Sull and Eisenhardt consider this as a key trait: To respond effectively to major change, it is essential to investigate the new situation actively, and create a reimagined vision that utilizes radically different rules. The right choice is often to move to the new rules as quickly as possible. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "Breaking the Rules: Moneyball Edition",
					"article_url": "https://fs.blog/breaking-rules-moneyball-edition/",
					"content": "Performance will typically decline in the short run, but the transition to the new reality will be faster and more complete in the long run. In contrast, changing slowly often results in an awkward combination of the past and the future with neither fitting the other or working well. Beane and Zaidi first did some house cleaning: They fired the team’s manager. Then, they began breaking the old Moneyball rules, things like avoiding drafting high-school players. They also decided to pay more attention to physical skills like speed and throwing. In the short term, the team performed quite poorly as fan attendance showed a steady decline. Yet, once again, against all odds, the A’s finished first in their division in 2012. ",
					"content_token": 154,
					"embedding": []
				},
				{
					"article_title": "Breaking the Rules: Moneyball Edition",
					"article_url": "https://fs.blog/breaking-rules-moneyball-edition/",
					"content": "Their change worked.  With a new set of Simple Rules, they became a dominant force in their division once again.  Reflecting their formidable analytic skills, the A’s brass had a new mindset that portrayed baseball as a financial market rife with arbitrage possibilities and simple rules to match.  One was a how-to rule that dictated exploiting players with splits. Simply put, players with splits have substantially different performances in two seemingly similar situations. A common split is when a player hits very well against right-handed pitchers and poorly against left-handed pitchers, or vice versa. Players with spits are mediocre when they play every game, and are low paid. In contrast, most superstars play well regardless of the situation, and are paid handsomely for their versatility. ",
					"content_token": 158,
					"embedding": []
				},
				{
					"article_title": "Breaking the Rules: Moneyball Edition",
					"article_url": "https://fs.blog/breaking-rules-moneyball-edition/",
					"content": "The A’s insight was that when a team has a player who can perform one side of the split well and a different player who excels at the opposite split, the two positives can create a cheap composite player. So the A’s started using a boundary rule to pick players with splits and how-to rule to exploit those splits with platooning – putting different players at the same position to take advantage of their splits against right – or left-handed pitching. If you’re reading this as a baseball fan, you’re probably thinking that exploiting splits isn’t anything new. So why did it have such an effect on their season? Well, no one had pushed it this hard before, which had some nuanced effects that might not have been immediately apparent.  For example, exploiting these splits keeps players healthier during the long 162-game season because they don’t play every day. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "Breaking the Rules: Moneyball Edition",
					"article_url": "https://fs.blog/breaking-rules-moneyball-edition/",
					"content": "The rule keeps everyone motivated because everyone has a role and plays often. It provides versatility when players are injured since players can fill in for each other. They didn’t stop there. Zaidi and Beane looked at the data and kept rolling out new simple rules that broke with their highly successful Moneyball past. In 2013 they added a new boundary rule to the player-selection activity: pick fly-ball hitters, meaning hitters who tend to hit the ball in the air and out of the infield in contrast with ground-ball hitters. Sixty percent of the A’s at-bat were by fly-ball hitters in 2013, the highest percentage in major-league baseball in almost a decade, and the A’s had the highest ratio of fly ball to ground balls, by far. Why fly-ball hitters?  Since one of ten fly balls is a home run, fly-ball hitters hit more home runs: an important factor in winning games. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "Breaking the Rules: Moneyball Edition",
					"article_url": "https://fs.blog/breaking-rules-moneyball-edition/",
					"content": "Fly-ball hitters also avoid ground-ball double plays, a rally killer if ever there as one. They are particularly effective against ground-ball pitches because they tend to swing underneath the ball, taking way the advantage of those pitchers. In fact, the A’s fly-ball hitters batted an all-star caliber .302 against ground-ball pitchers in 2013 on their way to their second consecutive division title despite having the fourth-lowest payroll in major-league baseball. Unfortunately, the new rules had a short-lived effectiveness: In 2014 the A’s fell to 2nd place and have been struggling the last two seasons. ",
					"content_token": 133,
					"embedding": []
				},
				{
					"article_title": "Breaking the Rules: Moneyball Edition",
					"article_url": "https://fs.blog/breaking-rules-moneyball-edition/",
					"content": "Two Cinderella stories is a great achievement, but it’s hard to maintain that edge.  This wonderful demonstration of the Red Queen Effect in sports can be described as an “arms race.’” As everyone tries to get ahead, a strange equilibrium is created by the simultaneous continual improvement, and those with more limited resources must work even harder as the pack moves ahead one at a time.  Even though they have adapted and created some wonderful “Simple Rules” in the past, the A’s and all of their competitors must stay in the race in order to return to the top: No “rule” will allow them to rest on their laurels. Second-Order Thinking and a little real-world experience show this to be true: Those that prosper consistently will think deeply, reevaluate, adapt, and continually evolve. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "Breaking the Rules: Moneyball Edition",
					"article_url": "https://fs.blog/breaking-rules-moneyball-edition/",
					"content": "That is the nature of a competitive world.",
					"content_token": 9,
					"embedding": []
				}
			]
		},
		{
			"title": "Simple Rules for Business Strategy",
			"url": "https://fs.blog/simple-rules-business-strategy/",
			"content": "The book Simple Rules by Donald Sull and Kathleen Eisenhardt has a very interesting chapter on strategy, which tries to answer the following question: How do you translate your broad objectives into a strategy that can provide guidelines for your employees from day to day?  It’s the last bit there which is particularly important  getting everyone on the same page.  Companies don’t seem to have a problem creating broad objectives which isn’t really a strategy. Your company might not call them that, they might call them “mission statements” or simply “corporate goals.”  They sound all well and good, but very little thought is given to how we will actually implement these lofty goals.  As Sull and Eisenhardt put it:  Developing a strategy and implementing it are often viewed as two distinct activities  first you come up with the perfect plan and then you worry about how to make it happen. This approach, common through it is, creates a disconnect between what a company is trying to accomplish and what employees do on a day-to-day basis. The authors argue that companies can bridge this gap between strategic intent and actual implementation by following three steps:  Figure out what will move the needles. Choose a bottleneck. Craft the rules.  1. Moving the Needles The authors use a dual needle metaphor to visualize corporate profits. They see it as two parallel needles: an upper needle which represents revenues and a lower needle which represents costs. The first critical step is to identify which actions will drive a wedge between the needles causing an increase in profits, a decrease in costs, and sustain this over time. In other words, as simple as it sounds, we need an actual set of steps to get from figure a. to figure b.  What action will become the wedge that will move the needles?  The authors believe the best way to answer this is to sit down with your management team and ask them to work as a group to answer the following three questions:  Who will we target as customers? What product or service will we offer? How will we provide this product at a profit?  When you are trying to massage out these answers remember to use inversion as well.  Equally important are the choices on who not to serve and what not to offer. Steve Jobs once pointed out that Apple was defined as much by what it didn’t do as by what it did. 2. Bottlenecks Speaking of inversion, in order to complete our goal we must also figure out what’s holding us back from moving the needles  the bottlenecks standing in our way. When it comes to implementing a strategy of simple rules, pinpointing the precise decision or activity where rules will have the most impact is half the battle. We use the term bottleneck to describe a specific activity or decision that hinders a company from moving the needles. You may be surprised at the amount of bottlenecks you come across, so you’ll have to practice some “triage” of your issues, sorting what’s important from what’s really important. The authors believe that the best bottlenecks to focus your attention on share three characteristics:  They have a direct and significant impact on value creation. They should represent recurrent decisions as opposed to one off’ choices. They should be obstacles that arise when opportunities exceed available resources.  Once we’ve established what the bottlenecks are, it’s time to craft the rules which will provide you a framework in which to remove them. 3. Craft the Rules Developing rules from the top down is a big mistake. When leaders rely on their gut instincts, they overemphasize recent events, build in their personal biases, and ignore data that doesn’t fit with their preconceived notions. It is much better to involve a team, typically ranging in size from four to eight members, and use a structured process to harness members’ diverse insights and points of view. When drafting the dream team to develop simple rules, it is critical to include some of the people who will be using them on a day-to-day basis. This probably seems like common sense but we’re guessing you have worked at least one place where all information and new initiatives came from above, and much of it seemingly came out of nowhere because you weren’t likely involved.  In these situations it’s very hard to get buy-in from the employees  yet they are the ones doing the work, implementing the rules. So we need to think about their involvement from the beginning. Having users make the rules confers several advantages. First, they are closest to the facts on the ground and best positioned to codify experience into usable rules. Because they will make decisions based on the rules, they can strike the right balance between guidance and discretion, avoiding rules that are overly vague or restrictive. User can also phrase the rules in language that resonates for them, rather than relying on business jargon. By actively participating in the process, users are more likely to buy into the final rules and therefore apply them in practice. Firsthand knowledge also makes it easier to explain the rules, and their underlying rationale, to colleagues who did not participate in the process. It’s important to note here that this is a process, a process in which you are never done – there is no real finish line. You must always plan to learn and to iterate as you learn  keep changing the plan as new information comes in. Rigidity to a plan is not a virtue; learning and adapting are virtues.   There’s nothing wrong with strategy. In fact, without a strategy, it’s hard to figure out what to do; some strategy or another must guide your actions as an organization. But it’s simply not enough: Detailed execution, at the employee level, is what gets things done. That’s what the Simple Rules are all about. Strategy, in our view, lives in the simple rules that guide an organization’s most important activities. They allow employees to make on-the-spot decisions and seize unexpected opportunities without losing sight of the big picture. The process you use to develop simple rules matters as much as the rules themselves. Involving a broad cross-section of employees, for example, injects more points of view into the discussion, produces a shared understanding of what matters for value creation, and increases buy-in to the simple rules. Investing the time up front to clarify what will move the needles dramatically increases the odds that simple rules will be applied where they can have the greatest impact.  Still Interested? Read the book, or check out our other post where we cover the details of creating your simple rules. ",
			"tokens": 1418,
			"chunks": [
				{
					"article_title": "Simple Rules for Business Strategy",
					"article_url": "https://fs.blog/simple-rules-business-strategy/",
					"content": "The book Simple Rules by Donald Sull and Kathleen Eisenhardt has a very interesting chapter on strategy, which tries to answer the following question: How do you translate your broad objectives into a strategy that can provide guidelines for your employees from day to day?  It’s the last bit there which is particularly important  getting everyone on the same page.  Companies don’t seem to have a problem creating broad objectives which isn’t really a strategy. Your company might not call them that, they might call them “mission statements” or simply “corporate goals.”  They sound all well and good, but very little thought is given to how we will actually implement these lofty goals.  As Sull and Eisenhardt put it:  Developing a strategy and implementing it are often viewed as two distinct activities  first you come up with the perfect plan and then you worry about how to make it happen. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "Simple Rules for Business Strategy",
					"article_url": "https://fs.blog/simple-rules-business-strategy/",
					"content": "This approach, common through it is, creates a disconnect between what a company is trying to accomplish and what employees do on a day-to-day basis. The authors argue that companies can bridge this gap between strategic intent and actual implementation by following three steps:  Figure out what will move the needles. Choose a bottleneck. Craft the rules.  1. Moving the Needles The authors use a dual needle metaphor to visualize corporate profits. They see it as two parallel needles: an upper needle which represents revenues and a lower needle which represents costs. The first critical step is to identify which actions will drive a wedge between the needles causing an increase in profits, a decrease in costs, and sustain this over time. In other words, as simple as it sounds, we need an actual set of steps to get from figure a. to figure b. ",
					"content_token": 176,
					"embedding": []
				},
				{
					"article_title": "Simple Rules for Business Strategy",
					"article_url": "https://fs.blog/simple-rules-business-strategy/",
					"content": " What action will become the wedge that will move the needles?  The authors believe the best way to answer this is to sit down with your management team and ask them to work as a group to answer the following three questions:  Who will we target as customers? What product or service will we offer? How will we provide this product at a profit?  When you are trying to massage out these answers remember to use inversion as well.  Equally important are the choices on who not to serve and what not to offer. Steve Jobs once pointed out that Apple was defined as much by what it didn’t do as by what it did. 2. Bottlenecks Speaking of inversion, in order to complete our goal we must also figure out what’s holding us back from moving the needles  the bottlenecks standing in our way. ",
					"content_token": 180,
					"embedding": []
				},
				{
					"article_title": "Simple Rules for Business Strategy",
					"article_url": "https://fs.blog/simple-rules-business-strategy/",
					"content": "When it comes to implementing a strategy of simple rules, pinpointing the precise decision or activity where rules will have the most impact is half the battle. We use the term bottleneck to describe a specific activity or decision that hinders a company from moving the needles. You may be surprised at the amount of bottlenecks you come across, so you’ll have to practice some “triage” of your issues, sorting what’s important from what’s really important. The authors believe that the best bottlenecks to focus your attention on share three characteristics:  They have a direct and significant impact on value creation. They should represent recurrent decisions as opposed to one off’ choices. They should be obstacles that arise when opportunities exceed available resources.  Once we’ve established what the bottlenecks are, it’s time to craft the rules which will provide you a framework in which to remove them. 3. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "Simple Rules for Business Strategy",
					"article_url": "https://fs.blog/simple-rules-business-strategy/",
					"content": "Craft the Rules Developing rules from the top down is a big mistake. When leaders rely on their gut instincts, they overemphasize recent events, build in their personal biases, and ignore data that doesn’t fit with their preconceived notions. It is much better to involve a team, typically ranging in size from four to eight members, and use a structured process to harness members’ diverse insights and points of view. When drafting the dream team to develop simple rules, it is critical to include some of the people who will be using them on a day-to-day basis. This probably seems like common sense but we’re guessing you have worked at least one place where all information and new initiatives came from above, and much of it seemingly came out of nowhere because you weren’t likely involved.  In these situations it’s very hard to get buy-in from the employees  yet they are the ones doing the work, implementing the rules. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "Simple Rules for Business Strategy",
					"article_url": "https://fs.blog/simple-rules-business-strategy/",
					"content": "So we need to think about their involvement from the beginning. Having users make the rules confers several advantages. First, they are closest to the facts on the ground and best positioned to codify experience into usable rules. Because they will make decisions based on the rules, they can strike the right balance between guidance and discretion, avoiding rules that are overly vague or restrictive. User can also phrase the rules in language that resonates for them, rather than relying on business jargon. By actively participating in the process, users are more likely to buy into the final rules and therefore apply them in practice. Firsthand knowledge also makes it easier to explain the rules, and their underlying rationale, to colleagues who did not participate in the process. ",
					"content_token": 148,
					"embedding": []
				},
				{
					"article_title": "Simple Rules for Business Strategy",
					"article_url": "https://fs.blog/simple-rules-business-strategy/",
					"content": "It’s important to note here that this is a process, a process in which you are never done – there is no real finish line. You must always plan to learn and to iterate as you learn  keep changing the plan as new information comes in. Rigidity to a plan is not a virtue; learning and adapting are virtues.   There’s nothing wrong with strategy. In fact, without a strategy, it’s hard to figure out what to do; some strategy or another must guide your actions as an organization. But it’s simply not enough: Detailed execution, at the employee level, is what gets things done. That’s what the Simple Rules are all about. Strategy, in our view, lives in the simple rules that guide an organization’s most important activities. They allow employees to make on-the-spot decisions and seize unexpected opportunities without losing sight of the big picture. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "Simple Rules for Business Strategy",
					"article_url": "https://fs.blog/simple-rules-business-strategy/",
					"content": "The process you use to develop simple rules matters as much as the rules themselves. Involving a broad cross-section of employees, for example, injects more points of view into the discussion, produces a shared understanding of what matters for value creation, and increases buy-in to the simple rules. Investing the time up front to clarify what will move the needles dramatically increases the odds that simple rules will be applied where they can have the greatest impact.  Still Interested? Read the book, or check out our other post where we cover the details of creating your simple rules.",
					"content_token": 118,
					"embedding": []
				}
			]
		},
		{
			"title": "Choosing your Choice Architect(ure)",
			"url": "https://fs.blog/choosing-choice-architecture/",
			"content": "“Nothing will ever be attempted if all possible objections must first be overcome.”  Samuel Johnson  In the book Nudge by Richard Thaler and Cass Sunstein they coin the terms Choice Architecture’ and Choice Architect’. For them, if you have an ability to influence the choices other people make, you are a choice architect. Considering the number of interactions we have everyday, it would be quite easy to argue that we are all Choice Architects at some point. But this also makes the inverse true; we are also wandering around someone else’s Choice Architecture.  Let’s take a look at a few of the principles of good choice architecture, so we can get a better idea of when someone is trying to nudge us.  This information can then be usedweighed when making decisions.   Defaults Thaler and Sunstein start with a discussion on “defaults” that are commonly offered to us: For reasons we have discussed, many people will take whatever option requires the least effort, or the path of least resistance. Recall the discussion of inertia, status quo bias, and the yeah, whatever’ heuristic. All these forces imply that if, for a given choice, there is a default option  an option that will obtain if the chooser does nothing  then we can expect a large number of people to end up with that option, whether or not it is good for them. And as we have also stressed, these behavioral tendencies toward doing nothing will be reinforced if the default option comes with some implicit or explicit suggestion that it represents the normal or even the recommended course of action. When making decisions people will often take the option that requires the least effort or the path of least resistance. This makes sense: It’s not just a matter of laziness, we also only have so many hours in a day. Unless you feel particularly strongly about it, if putting little to no effort towards something leads you forward or at least doesn’t noticeably kick you backwards this is what you are likely to do. Loss aversion plays a role as well. If we feel like the consequences of making a poor choice are high, we will simply decide to do nothing.  Inertia is another reason: If the ship is currently sailing forward, it can often take a lot of time and effort just to slightly change course.  You have likely seen many examples of inertia at play in your work environment and this isn’t necessarily a bad thing. Sometimes we need that ship to just steadily move forward. The important bit is to realize when this is factoring into your decisions, or more specifically, when this knowledge is being used to nudge you into making specific choices. Let’s think about some of your monthly recurring bills. While you might not be reading that magazine or going to the gym, you’re still paying for the ability to use that good or service. If you weren’t being auto-renewed monthly, what is the chance that you would put the effort into renewing that subscription or membership? Much lower, right? Publishers and gym owners know this, and they know you don’t want to go through the hassle of cancelling either, so they make that difficult, too. They understand well our tendency to want to travel the path of least resistance and avoid conflict.  This is also where they will imply that the default option is the recommended course of action. It sounds like this: “We’re sorry to hear you no longer want the magazine Mr. Smith. You know, more than half of the fortune 500 companies have a monthly subscription to magazine X, but we understand if it’s not something you’d like to do at the moment.”  or  “Mr. Smith we are sorry to hear that you want to cancel your membership at GymX. We understand if you can’t make your health a priority at this point but we’d love to see you back sometime soon. We see this all the time, these days everyone is so busy. But I’m happy to say we are noticing a shift where people are starting to make time for themselves, especially in your demographic” Just cancel them. You’ll feel better. We promise. The Structure of Complex Choices We live in a world of reviews. Product reviews, corporate reviews, movie reviews When was the last time you bought a phone or a car before checking the reviews? When was the last time that you hired an employee without checking out their references?  Thaler and Sunstein call this Collaborative Filtering and explain it as follows: You use the judgements of other people who share your tastes to filter through the vast number of books or movies available in order to increase the likelihood of picking one you like. Collaborative filtering is an effort to solve a problem of choice architecture. If you know what people like you tend to like, you might well be comfortable in selecting products you don’t know, because people like you tend to like them. For many of us, collaborative filtering is making difficult choices easier. While collaborative filtering does a great job of making difficult choices easier we have to remember that companies also know that you will use this tool and will try to manipulate it. We just have to look at the information critically, compare multiple sources and take some time to review the reviewers.  These techniques can be useful for decisions of a certain scale and complexity: when the alternatives are understood and in small enough numbers. However, once we reach a certain size we require additional tools to make the right decision.  One strategy to use is what Amos Tversky 1972 called elimination by aspects.’ Someone using this strategy first decides what aspect is most important say, commuting distance, establishes a cutoff level say, no more than a thirty-minute commute, then eliminates all the alternatives that do not come up to this standard. The process is repeated, attribute by attribute no more than 1,500 per month; at least two bedrooms; dogs permitted, until either a choice is made or the set is narrowed down enough to switch over to a compensatory evaluation of the finalists.’” This is a very useful tool if you have a good idea of which attributes are of most value to you.  When using these techniques, we have to be mindful of the fact that the companies trying to sell us goods have spent a lot of time and money figuring out what attributes are important to you as well.  For example, if you were to shop for an SUV you would notice that there are a specific number of variables they all seem to have in common now engine options, towing options, seating options, storage options. They are trying to nudge you not to eliminate them from your list. This forces you to do the tertiary research or better yet, this forces you to walk into dealerships where they will try to inflate the importance of those attributes which they do best. They also try to call things new names as a means to differentiate themselves and get onto your list. What do you mean our competitors don’t have FLEXfuel? Incentives Incentives are so ubiquitous in our lives that it’s very easy to overlook them. Unfortunately, this can influence us to make poor decisions.  Thaler and Sunstein believe this is tied into how salient the incentive is. The most important modification that must be made to a standard analysis of incentives is salience. Do the choosers actually notice the incentives they face? In free markets, the answer is usually yes, but in important cases the answer is no. Consider the example of members of an urban family deciding whether to buy a car. Suppose their choices are to take taxis and public transportation or to spend ten thousand dollars to buy a used car, which they can park on the street in front of their home. The only salient costs of owning this car will be the weekly stops at the gas station, occasional repair bills, and a yearly insurance bill. The opportunity cost of the ten thousand dollars is likely to be neglected. In other words, once they purchase the car, they tend to forget about the ten thousand dollars and stop treating it as money that could have been spent on something else. In contrast, every time the family uses a taxi the cost will be in their face, with the meter clicking every few blocks. So behavioral analysis of the incentives of car ownership will predict that people will underweight the opportunity costs of car ownership, and possibly other less salient aspects such as depreciation, and may overweight the very salient costs of using a taxi. The problems here are relatable and easily solved: If the family above had written down all the numbers related to either taxi, public transportation, or car ownership, it would have been a lot more difficult for them to undervalue the salient aspects of any of their choices. At least if the highest value attribute is cost.  This isn’t an exhaustive list of all the daily nudges we face but it’s a good start and some important, translatable, themes emerge.  Realize when you are wandering around someone’s choice architecture. Do your homework  Develop strategies to help you make decisions when you are being nudged.    Still Interested? Buy, and most importantly read, the whole book. Also, check out our other post on some of the Biases and Blunders covered in Nudge. ",
			"tokens": 1947,
			"chunks": [
				{
					"article_title": "Choosing your Choice Architect(ure)",
					"article_url": "https://fs.blog/choosing-choice-architecture/",
					"content": "“Nothing will ever be attempted if all possible objections must first be overcome.”  Samuel Johnson  In the book Nudge by Richard Thaler and Cass Sunstein they coin the terms Choice Architecture’ and Choice Architect’ For them, if you have an ability to influence the choices other people make, you are a choice architect. Considering the number of interactions we have everyday, it would be quite easy to argue that we are all Choice Architects at some point. But this also makes the inverse true; we are also wandering around someone else’s Choice Architecture.  Let’s take a look at a few of the principles of good choice architecture, so we can get a better idea of when someone is trying to nudge us.  This information can then be usedweighed when making decisions. ",
					"content_token": 170,
					"embedding": []
				},
				{
					"article_title": "Choosing your Choice Architect(ure)",
					"article_url": "https://fs.blog/choosing-choice-architecture/",
					"content": "  Defaults Thaler and Sunstein start with a discussion on “defaults” that are commonly offered to us: For reasons we have discussed, many people will take whatever option requires the least effort, or the path of least resistance. Recall the discussion of inertia, status quo bias, and the yeah, whatever’ heuristic. All these forces imply that if, for a given choice, there is a default option  an option that will obtain if the chooser does nothing  then we can expect a large number of people to end up with that option, whether or not it is good for them. And as we have also stressed, these behavioral tendencies toward doing nothing will be reinforced if the default option comes with some implicit or explicit suggestion that it represents the normal or even the recommended course of action. When making decisions people will often take the option that requires the least effort or the path of least resistance. ",
					"content_token": 187,
					"embedding": []
				},
				{
					"article_title": "Choosing your Choice Architect(ure)",
					"article_url": "https://fs.blog/choosing-choice-architecture/",
					"content": "This makes sense: It’s not just a matter of laziness, we also only have so many hours in a day. Unless you feel particularly strongly about it, if putting little to no effort towards something leads you forward or at least doesn’t noticeably kick you backwards this is what you are likely to do. Loss aversion plays a role as well. If we feel like the consequences of making a poor choice are high, we will simply decide to do nothing.  Inertia is another reason: If the ship is currently sailing forward, it can often take a lot of time and effort just to slightly change course.  You have likely seen many examples of inertia at play in your work environment and this isn’t necessarily a bad thing. Sometimes we need that ship to just steadily move forward. ",
					"content_token": 168,
					"embedding": []
				},
				{
					"article_title": "Choosing your Choice Architect(ure)",
					"article_url": "https://fs.blog/choosing-choice-architecture/",
					"content": "The important bit is to realize when this is factoring into your decisions, or more specifically, when this knowledge is being used to nudge you into making specific choices. Let’s think about some of your monthly recurring bills. While you might not be reading that magazine or going to the gym, you’re still paying for the ability to use that good or service. If you weren’t being auto-renewed monthly, what is the chance that you would put the effort into renewing that subscription or membership? Much lower, right? Publishers and gym owners know this, and they know you don’t want to go through the hassle of cancelling either, so they make that difficult, too. They understand well our tendency to want to travel the path of least resistance and avoid conflict.  This is also where they will imply that the default option is the recommended course of action. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "Choosing your Choice Architect(ure)",
					"article_url": "https://fs.blog/choosing-choice-architecture/",
					"content": "It sounds like this: “We’re sorry to hear you no longer want the magazine Mr. Smith. You know, more than half of the fortune 500 companies have a monthly subscription to magazine X, but we understand if it’s not something you’d like to do at the moment.”  or  “Mr. Smith we are sorry to hear that you want to cancel your membership at GymX. We understand if you can’t make your health a priority at this point but we’d love to see you back sometime soon. We see this all the time, these days everyone is so busy. But I’m happy to say we are noticing a shift where people are starting to make time for themselves, especially in your demographic” Just cancel them. You’ll feel better. We promise. The Structure of Complex Choices We live in a world of reviews. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "Choosing your Choice Architect(ure)",
					"article_url": "https://fs.blog/choosing-choice-architecture/",
					"content": "Product reviews, corporate reviews, movie reviews When was the last time you bought a phone or a car before checking the reviews? When was the last time that you hired an employee without checking out their references?  Thaler and Sunstein call this Collaborative Filtering and explain it as follows: You use the judgements of other people who share your tastes to filter through the vast number of books or movies available in order to increase the likelihood of picking one you like. Collaborative filtering is an effort to solve a problem of choice architecture. If you know what people like you tend to like, you might well be comfortable in selecting products you don’t know, because people like you tend to like them. For many of us, collaborative filtering is making difficult choices easier. While collaborative filtering does a great job of making difficult choices easier we have to remember that companies also know that you will use this tool and will try to manipulate it. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "Choosing your Choice Architect(ure)",
					"article_url": "https://fs.blog/choosing-choice-architecture/",
					"content": "We just have to look at the information critically, compare multiple sources and take some time to review the reviewers.  These techniques can be useful for decisions of a certain scale and complexity: when the alternatives are understood and in small enough numbers. However, once we reach a certain size we require additional tools to make the right decision.  One strategy to use is what Amos Tversky 1972 called elimination by aspects.’ Someone using this strategy first decides what aspect is most important say, commuting distance, establishes a cutoff level say, no more than a thirty-minute commute, then eliminates all the alternatives that do not come up to this standard. ",
					"content_token": 131,
					"embedding": []
				},
				{
					"article_title": "Choosing your Choice Architect(ure)",
					"article_url": "https://fs.blog/choosing-choice-architecture/",
					"content": "The process is repeated, attribute by attribute no more than 1,500 per month; at least two bedrooms; dogs permitted, until either a choice is made or the set is narrowed down enough to switch over to a compensatory evaluation of the finalists.’” This is a very useful tool if you have a good idea of which attributes are of most value to you.  When using these techniques, we have to be mindful of the fact that the companies trying to sell us goods have spent a lot of time and money figuring out what attributes are important to you as well.  For example, if you were to shop for an SUV you would notice that there are a specific number of variables they all seem to have in common now engine options, towing options, seating options, storage options. They are trying to nudge you not to eliminate them from your list. ",
					"content_token": 177,
					"embedding": []
				},
				{
					"article_title": "Choosing your Choice Architect(ure)",
					"article_url": "https://fs.blog/choosing-choice-architecture/",
					"content": "This forces you to do the tertiary research or better yet, this forces you to walk into dealerships where they will try to inflate the importance of those attributes which they do best. They also try to call things new names as a means to differentiate themselves and get onto your list. What do you mean our competitors don’t have FLEXfuel? Incentives Incentives are so ubiquitous in our lives that it’s very easy to overlook them. Unfortunately, this can influence us to make poor decisions.  Thaler and Sunstein believe this is tied into how salient the incentive is. The most important modification that must be made to a standard analysis of incentives is salience. Do the choosers actually notice the incentives they face? In free markets, the answer is usually yes, but in important cases the answer is no. Consider the example of members of an urban family deciding whether to buy a car. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "Choosing your Choice Architect(ure)",
					"article_url": "https://fs.blog/choosing-choice-architecture/",
					"content": "Suppose their choices are to take taxis and public transportation or to spend ten thousand dollars to buy a used car, which they can park on the street in front of their home. The only salient costs of owning this car will be the weekly stops at the gas station, occasional repair bills, and a yearly insurance bill. The opportunity cost of the ten thousand dollars is likely to be neglected. In other words, once they purchase the car, they tend to forget about the ten thousand dollars and stop treating it as money that could have been spent on something else. In contrast, every time the family uses a taxi the cost will be in their face, with the meter clicking every few blocks. So behavioral analysis of the incentives of car ownership will predict that people will underweight the opportunity costs of car ownership, and possibly other less salient aspects such as depreciation, and may overweight the very salient costs of using a taxi. ",
					"content_token": 184,
					"embedding": []
				},
				{
					"article_title": "Choosing your Choice Architect(ure)",
					"article_url": "https://fs.blog/choosing-choice-architecture/",
					"content": "The problems here are relatable and easily solved: If the family above had written down all the numbers related to either taxi, public transportation, or car ownership, it would have been a lot more difficult for them to undervalue the salient aspects of any of their choices. At least if the highest value attribute is cost.  This isn’t an exhaustive list of all the daily nudges we face but it’s a good start and some important, translatable, themes emerge.  Realize when you are wandering around someone’s choice architecture. Do your homework  Develop strategies to help you make decisions when you are being nudged.    Still Interested? Buy, and most importantly read, the whole book. Also, check out our other post on some of the Biases and Blunders covered in Nudge.",
					"content_token": 174,
					"embedding": []
				}
			]
		},
		{
			"title": "Luck Meets Perseverance: The Creation of IBM’s Competitive Advantage",
			"url": "https://fs.blog/ibm-competitive-advantage/",
			"content": "On Monday October 28, 1929, the stock market took one of the worst single-day tumbles anyone alive might have seen, with the Dow Jones averages falling about 13. The next day, October 29th, the market dropped yet again, a decline of 12. By the end of the year, the Dow Jones average was down more than 45 from its high of 381. Market historians are familiar with the rest of the story: The sickening slide would not stop at 45, but continue until 1932 to reach a low of 41 on the Dow, a decline of about 90 from peak to trough. American business was in a major Depression. But at least one businessman would decide that, like General Erwin Rommel would say years later, the path was not out, but through.  International Business Machines, better known as IBM, was created from the ashes of the Computing-Tabulating-Recording Company C-T-R in 1917 by Thomas J. Watson, who’d learned his business skills at the National Cash Register Company NCR. Before Watson’s reorganization of C-T-R, the company was basically in three businesses: computing scales to weigh and compute the cost of a product being weighed, time clocks to calculate and record wages, and tabulating machines which used punch cards to add up figures and sort them. Watson’s first act of genius was to recognize that the future of IBM was not going to be time cards or scales, but in helping businesses do their work more effectively and with a lot less labor. He set out to do just that with his tabulating machines. The problem was, IBM’s products weren’t yet all that different from its competitors’, and the company was small. IBM’s main tabulating product was the Hollerith machine, created by Herman Hollerith in Washington D.C. in 1890 to improve the Census tabulating process, of all things. It sounds mundane, but he saved the government 5 million and did the work in about 18th of the time. By the late 1910s, the Hollerith machine had a major competitor in the Powers Accounting Company, which had a similar product that was easier to use and more advanced than the Hollerith. Hollerith Punch Card   Hollerith Machine    Watson knew he had to push the research and development of his best product, and he did, hiring bright engineers like Fred Carroll from NCR, who would go on to be known for his Carroll Press, which allowed IBM to mass-produce the punch cards which did the “tabulating” in the pre-electronic days. By the mid-1920s, IBM had the lead. The plan was set in late 1927. Watson then pointed to where he wanted IBM to go. ”There isn’t any limit for the tabulating business for many years to come,” he said. “We have just scratched the surface in this division. I expect the bulk of increased business to come from the tabulating end, because the potentialities are greater, and we have done so little in the way of developing our machines in this field.” Underneath that statement lay a number of reasonsother than the thrill of new technologywhy Watson zeroed in on the punch card business. When seen together, the reasons clicked like a formula for total domination. IBM would never be able to make sure it was the world leader in scales or time clocks, but it could be certain that it was the absolute lord of data processing.  Watson had no epiphanies. No voice spoke to him about the future of data processing. He didn’t have a grand vision for turning IBM into a punch card company. He got there little by little, one observation after another, over a period of 10 to 12 years. Source: The Maverick and his Machine Watson’s logical, one-foot-at-a-time approach was reminiscent of Sir William Osler’s dictum: Our main business is not to see what lies dimly at a distance, but to do what lies clearly at hand. And with a strategy of patenting its proprietary punch-cards, making them exclusively usable with IBM tabulators and sorters, IBM was one of the market darlings in the lead-up to 1929. Between 1927 and 1929 alone, IBM rose about four-fold on the back of 20-30 annual growth in its profits. But it was still a small company with a lot of competition, and the punch card system was notoriously unreliable at times. He had a great system to hook in his customers, but the data processing market was still young  many businesses wouldn’t adopt it. And then came the fall.  As the stock market dropped by the day and the Depression got on, the economy itself began to shrink in 1930. GDP went down 8 that year, and then another 7 the following year. Thousands of banks failed and unemployment would eventually test 30, a figure that itself was misleading; the modern concept of “underemployment” hadn’t been codified, but if it had, it probably would have dwarfed 30. An architect working as a lowly draftsman had a job, but he’d still fallen on hard times. Everyone had. Tom Watson’s people wondered what was to become of IBM. If businesses didn’t have money, how could they purchase tabulators and punch cards? Even if it would save them money in the long run, too many businesses had cut their capital spending to the bone. The market for office spending was down 50 in 1930. Watson’s response was to push. Hard. So hard that he’d take IBM right up to the brink. IBM could beat the Depression, Watson believed. He reasoned that only 5 percent of business accounting functions were mechanized, leaving a huge market untapped. Surely there was room to keep selling machines, even in difficult times. Watson also reasoned that the need for IBM machines was so great, if businesses put off buying them now, certainly they’d buy them later, when the economy picked up. His logic told him that the pent-up demand would explode when companies decided to buy again. He wanted IBM to be ready to take advantage of that demand. He’d keep the factories building machines and parts, stockpiling the products in warehouses. In fact, between 1929 and 1932, he increased IBM’s production capacity by one-third. Watson’s greatest risk was running out of time. If IBM’s revenue dropped off or flattened because of the Depression, the company would still have enough money to keep operating for two years, maybe three. If IBM’s revenue continued to falter past 1933, the burden of running the factories and inventory would threaten IBM’s financial stability.  Watson’s logic led him to make what looked to outsiders like another insane wager. On January 12, 1932, Watson announced that IBM would spend 1 millionnearly 6 percent of its total annual revenue to build one of the first corporate research labs. The colonial-style brick structure in Endicott would house all of IBM’s inventors and engineers. Watson played up the symbolism for all it was worth. He would create instead of destroy, despite the economic plague. Source: The Maverick and his Machine Most companies pulled back, and for good reason. Demand was rapidly shrinking, and IBM’s decision to spend money expanding productive capacity, research, and employment would be suicide if demand didn’t return soon. All of that unused capacity was costly and would go to waste. Watson took an enormous risk, but he also had faith that the American economy would recover its dynamism. If it did, IBM would come out on the other side untouchable. Somehow, Watson had to stimulate demand. He had to come up with products that companies couldn’t resist, whatever the economic conditions. Again, thanks to Charles Kettering’s influence, Watson believed that RD would drive sales. ed: Kettering was chief engineer at General Motors. So Watson decided to build a lab, pull engineers together, and get them charged up to push the technology forward. Throughout the 1930s, IBM cranked out new products and innovation, finally getting its technology ahead of Remington Rand or any other potential competitors.  Within a few years, Watson’s gamble of manufacturing looked disastrous. As IBM pumped increasing amounts of money into operations and growth, revenue from 1929 to 1934 stalled, wavering between 17 million and 19 million a year. IBM edged toward insolvency. In 1932, IBM’s stock price fell to 1921 levels and stayed there11 years of gains wiped out. Source: The Maverick and his Machine By 1935, IBM was still stagnating. Watson made the smart move to get out of the money-losing scale business and use the money to keep the remaining businesses afloat, but he was drowning in excess capacity, inventions be damned. Then IBM got a stroke of luck that it would ride for almost 50 years. After all of his pushing and all of his investment, after the impossible decision to push IBM to the brink, Tom Watson was rewarded with The Social Security Act of 1935, part of FDR’s New Deal. It was perfect. No single flourish of a pen had ever created such a gigantic information processing problem. The act established Social Security in Americaa national insurance system that required workers to pay into a fund while employed so they could draw payments out of it once they retired, or if a wage-earning spouse died. To make the system work, every business had to track every employee’s hours, wages, and the amount that must be paid to Social Security. The business then had to put those figures in a form that could be reported to the federal government. Then the government had to process all those millions of reports, track the money, and send checks to those who should get them. Overnight, demand for accounting machines soared. Every business that had them needed them more. An officer for the store chain Woolworth told IBM that keeping records for Social Security was going to cost the company 250,000 a year. Businesses that didn’t have the machines wanted them. The government needed them by the boatload. Only one company could meet the demand: IBM. It had warehouses full of machines and parts and accessories, and it could immediately make more because its factories were running, finely tuned, and fully staffed. Moreover, IBM had been funding research and introducing new products, so it had better, faster, more reliable machines than Remington Rand or any other company. IBM won the contract to do all of the New Deal’s accountingthe biggest project to date to automate the government This period of time became IBM’s slingshot. Revenue jumped from 19 million in 1934 to 21 million in 1935. From there it kept going up: 25 million in 1936, 31 million in 1937. It would climb unabated for the next 45 years. From that moment until the 1980s, IBM would utterly dominate the data processing industrya record of leadership that was unmatched by any industrial company in history. Source: The Maverick and his Machine By combining aggressive opportunism and a great deal of luck, IBM was forged in the depths of the Great Depression. Like John D. Rockefeller before him, who bought up refineries during periods of depression in the oil industry, and Warren Buffett after him, who scooped up loads of cheap stocks when the stock market was crumbling in the 1970s, Watson decided that pushing ahead was the only way out. History certainly didn’t have to go his way  FDR might not have been elected or might not have been able to enact Social Security. Even if he’d done it two years later, IBM still might never have made it. But Watson’s courage and leadership did open the possibility of serendipitous fortune for IBM if the world didn’t end. Like oxygen combining with fuel to create internal combustion, those elements forged a monstrous competitive advantage when the match was finally lit. Still Interested? Check out the excellent The Maverick and his Machine by Kevin Maney, where the excerpts above come from. ",
			"tokens": 2546,
			"chunks": [
				{
					"article_title": "Luck Meets Perseverance: The Creation of IBM’s Competitive Advantage",
					"article_url": "https://fs.blog/ibm-competitive-advantage/",
					"content": "On Monday October 28, 1929, the stock market took one of the worst single-day tumbles anyone alive might have seen, with the Dow Jones averages falling about 13. The next day, October 29th, the market dropped yet again, a decline of 12. By the end of the year, the Dow Jones average was down more than 45 from its high of 381. Market historians are familiar with the rest of the story: The sickening slide would not stop at 45, but continue until 1932 to reach a low of 41 on the Dow, a decline of about 90 from peak to trough. American business was in a major Depression. But at least one businessman would decide that, like General Erwin Rommel would say years later, the path was not out, but through.  International Business Machines, better known as IBM, was created from the ashes of the Computing-Tabulating-Recording Company C-T-R in 1917 by Thomas J. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "Luck Meets Perseverance: The Creation of IBM’s Competitive Advantage",
					"article_url": "https://fs.blog/ibm-competitive-advantage/",
					"content": "Watson, who’d learned his business skills at the National Cash Register Company NCR. Before Watson’s reorganization of C-T-R, the company was basically in three businesses: computing scales to weigh and compute the cost of a product being weighed, time clocks to calculate and record wages, and tabulating machines which used punch cards to add up figures and sort them. Watson’s first act of genius was to recognize that the future of IBM was not going to be time cards or scales, but in helping businesses do their work more effectively and with a lot less labor. He set out to do just that with his tabulating machines. The problem was, IBM’s products weren’t yet all that different from its competitors’, and the company was small. IBM’s main tabulating product was the Hollerith machine, created by Herman Hollerith in Washington D.C. ",
					"content_token": 192,
					"embedding": []
				},
				{
					"article_title": "Luck Meets Perseverance: The Creation of IBM’s Competitive Advantage",
					"article_url": "https://fs.blog/ibm-competitive-advantage/",
					"content": "in 1890 to improve the Census tabulating process, of all things. It sounds mundane, but he saved the government 5 million and did the work in about 18th of the time. By the late 1910s, the Hollerith machine had a major competitor in the Powers Accounting Company, which had a similar product that was easier to use and more advanced than the Hollerith. Hollerith Punch Card   Hollerith Machine    Watson knew he had to push the research and development of his best product, and he did, hiring bright engineers like Fred Carroll from NCR, who would go on to be known for his Carroll Press, which allowed IBM to mass-produce the punch cards which did the “tabulating” in the pre-electronic days. By the mid-1920s, IBM had the lead. The plan was set in late 1927. Watson then pointed to where he wanted IBM to go. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "Luck Meets Perseverance: The Creation of IBM’s Competitive Advantage",
					"article_url": "https://fs.blog/ibm-competitive-advantage/",
					"content": "”There isn’t any limit for the tabulating business for many years to come,” he said. “We have just scratched the surface in this division. I expect the bulk of increased business to come from the tabulating end, because the potentialities are greater, and we have done so little in the way of developing our machines in this field.” Underneath that statement lay a number of reasonsother than the thrill of new technologywhy Watson zeroed in on the punch card business. When seen together, the reasons clicked like a formula for total domination. IBM would never be able to make sure it was the world leader in scales or time clocks, but it could be certain that it was the absolute lord of data processing.  Watson had no epiphanies. No voice spoke to him about the future of data processing. He didn’t have a grand vision for turning IBM into a punch card company. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "Luck Meets Perseverance: The Creation of IBM’s Competitive Advantage",
					"article_url": "https://fs.blog/ibm-competitive-advantage/",
					"content": "He got there little by little, one observation after another, over a period of 10 to 12 years. Source: The Maverick and his Machine Watson’s logical, one-foot-at-a-time approach was reminiscent of Sir William Osler’s dictum: Our main business is not to see what lies dimly at a distance, but to do what lies clearly at hand. And with a strategy of patenting its proprietary punch-cards, making them exclusively usable with IBM tabulators and sorters, IBM was one of the market darlings in the lead-up to 1929. Between 1927 and 1929 alone, IBM rose about four-fold on the back of 20-30 annual growth in its profits. But it was still a small company with a lot of competition, and the punch card system was notoriously unreliable at times. ",
					"content_token": 182,
					"embedding": []
				},
				{
					"article_title": "Luck Meets Perseverance: The Creation of IBM’s Competitive Advantage",
					"article_url": "https://fs.blog/ibm-competitive-advantage/",
					"content": "He had a great system to hook in his customers, but the data processing market was still young  many businesses wouldn’t adopt it. And then came the fall.  As the stock market dropped by the day and the Depression got on, the economy itself began to shrink in 1930. GDP went down 8 that year, and then another 7 the following year. Thousands of banks failed and unemployment would eventually test 30, a figure that itself was misleading; the modern concept of “underemployment” hadn’t been codified, but if it had, it probably would have dwarfed 30. An architect working as a lowly draftsman had a job, but he’d still fallen on hard times. Everyone had. Tom Watson’s people wondered what was to become of IBM. ",
					"content_token": 167,
					"embedding": []
				},
				{
					"article_title": "Luck Meets Perseverance: The Creation of IBM’s Competitive Advantage",
					"article_url": "https://fs.blog/ibm-competitive-advantage/",
					"content": "If businesses didn’t have money, how could they purchase tabulators and punch cards? Even if it would save them money in the long run, too many businesses had cut their capital spending to the bone. The market for office spending was down 50 in 1930. Watson’s response was to push. Hard. So hard that he’d take IBM right up to the brink. IBM could beat the Depression, Watson believed. He reasoned that only 5 percent of business accounting functions were mechanized, leaving a huge market untapped. Surely there was room to keep selling machines, even in difficult times. Watson also reasoned that the need for IBM machines was so great, if businesses put off buying them now, certainly they’d buy them later, when the economy picked up. His logic told him that the pent-up demand would explode when companies decided to buy again. He wanted IBM to be ready to take advantage of that demand. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "Luck Meets Perseverance: The Creation of IBM’s Competitive Advantage",
					"article_url": "https://fs.blog/ibm-competitive-advantage/",
					"content": "He’d keep the factories building machines and parts, stockpiling the products in warehouses. In fact, between 1929 and 1932, he increased IBM’s production capacity by one-third. Watson’s greatest risk was running out of time. If IBM’s revenue dropped off or flattened because of the Depression, the company would still have enough money to keep operating for two years, maybe three. If IBM’s revenue continued to falter past 1933, the burden of running the factories and inventory would threaten IBM’s financial stability.  Watson’s logic led him to make what looked to outsiders like another insane wager. On January 12, 1932, Watson announced that IBM would spend 1 millionnearly 6 percent of its total annual revenue to build one of the first corporate research labs. The colonial-style brick structure in Endicott would house all of IBM’s inventors and engineers. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "Luck Meets Perseverance: The Creation of IBM’s Competitive Advantage",
					"article_url": "https://fs.blog/ibm-competitive-advantage/",
					"content": "Watson played up the symbolism for all it was worth. He would create instead of destroy, despite the economic plague. Source: The Maverick and his Machine Most companies pulled back, and for good reason. Demand was rapidly shrinking, and IBM’s decision to spend money expanding productive capacity, research, and employment would be suicide if demand didn’t return soon. All of that unused capacity was costly and would go to waste. Watson took an enormous risk, but he also had faith that the American economy would recover its dynamism. If it did, IBM would come out on the other side untouchable. Somehow, Watson had to stimulate demand. He had to come up with products that companies couldn’t resist, whatever the economic conditions. Again, thanks to Charles Kettering’s influence, Watson believed that RD would drive sales. ed: Kettering was chief engineer at General Motors. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "Luck Meets Perseverance: The Creation of IBM’s Competitive Advantage",
					"article_url": "https://fs.blog/ibm-competitive-advantage/",
					"content": "So Watson decided to build a lab, pull engineers together, and get them charged up to push the technology forward. Throughout the 1930s, IBM cranked out new products and innovation, finally getting its technology ahead of Remington Rand or any other potential competitors.  Within a few years, Watson’s gamble of manufacturing looked disastrous. As IBM pumped increasing amounts of money into operations and growth, revenue from 1929 to 1934 stalled, wavering between 17 million and 19 million a year. IBM edged toward insolvency. In 1932, IBM’s stock price fell to 1921 levels and stayed there11 years of gains wiped out. Source: The Maverick and his Machine By 1935, IBM was still stagnating. Watson made the smart move to get out of the money-losing scale business and use the money to keep the remaining businesses afloat, but he was drowning in excess capacity, inventions be damned. ",
					"content_token": 187,
					"embedding": []
				},
				{
					"article_title": "Luck Meets Perseverance: The Creation of IBM’s Competitive Advantage",
					"article_url": "https://fs.blog/ibm-competitive-advantage/",
					"content": "Then IBM got a stroke of luck that it would ride for almost 50 years. After all of his pushing and all of his investment, after the impossible decision to push IBM to the brink, Tom Watson was rewarded with The Social Security Act of 1935, part of FDR’s New Deal. It was perfect. No single flourish of a pen had ever created such a gigantic information processing problem. The act established Social Security in Americaa national insurance system that required workers to pay into a fund while employed so they could draw payments out of it once they retired, or if a wage-earning spouse died. To make the system work, every business had to track every employee’s hours, wages, and the amount that must be paid to Social Security. The business then had to put those figures in a form that could be reported to the federal government. ",
					"content_token": 181,
					"embedding": []
				},
				{
					"article_title": "Luck Meets Perseverance: The Creation of IBM’s Competitive Advantage",
					"article_url": "https://fs.blog/ibm-competitive-advantage/",
					"content": "Then the government had to process all those millions of reports, track the money, and send checks to those who should get them. Overnight, demand for accounting machines soared. Every business that had them needed them more. An officer for the store chain Woolworth told IBM that keeping records for Social Security was going to cost the company 250,000 a year. Businesses that didn’t have the machines wanted them. The government needed them by the boatload. Only one company could meet the demand: IBM. It had warehouses full of machines and parts and accessories, and it could immediately make more because its factories were running, finely tuned, and fully staffed. Moreover, IBM had been funding research and introducing new products, so it had better, faster, more reliable machines than Remington Rand or any other company. ",
					"content_token": 166,
					"embedding": []
				},
				{
					"article_title": "Luck Meets Perseverance: The Creation of IBM’s Competitive Advantage",
					"article_url": "https://fs.blog/ibm-competitive-advantage/",
					"content": "IBM won the contract to do all of the New Deal’s accountingthe biggest project to date to automate the government This period of time became IBM’s slingshot. Revenue jumped from 19 million in 1934 to 21 million in 1935. From there it kept going up: 25 million in 1936, 31 million in 1937. It would climb unabated for the next 45 years. From that moment until the 1980s, IBM would utterly dominate the data processing industrya record of leadership that was unmatched by any industrial company in history. Source: The Maverick and his Machine By combining aggressive opportunism and a great deal of luck, IBM was forged in the depths of the Great Depression. Like John D. ",
					"content_token": 147,
					"embedding": []
				},
				{
					"article_title": "Luck Meets Perseverance: The Creation of IBM’s Competitive Advantage",
					"article_url": "https://fs.blog/ibm-competitive-advantage/",
					"content": "Rockefeller before him, who bought up refineries during periods of depression in the oil industry, and Warren Buffett after him, who scooped up loads of cheap stocks when the stock market was crumbling in the 1970s, Watson decided that pushing ahead was the only way out. History certainly didn’t have to go his way  FDR might not have been elected or might not have been able to enact Social Security. Even if he’d done it two years later, IBM still might never have made it. But Watson’s courage and leadership did open the possibility of serendipitous fortune for IBM if the world didn’t end. Like oxygen combining with fuel to create internal combustion, those elements forged a monstrous competitive advantage when the match was finally lit. Still Interested? Check out the excellent The Maverick and his Machine by Kevin Maney, where the excerpts above come from.",
					"content_token": 187,
					"embedding": []
				}
			]
		},
		{
			"title": "Roger Fisher on a Better Way to Negotiate, Part 2",
			"url": "https://fs.blog/roger-fisher-negotiation-part-2/",
			"content": "In Part 1 of our series on the best-selling negotiation book Getting to Yes, we covered Roger Fisher’s four-part framework on Principled Negotiation  his “way out” of highly contentious negotiation. To review, the four parts were as follows:  Separate the People from the Problem Focus on Interests, Not Positions Invent Options for Mutual Gain Insist on Objective Criteria  Habitual use of these four criteria is a way to build, or at least not destroy, win-win relationships in the process of negotiation. The truth is we all must negotiate from time to time. Refusing to negotiate is a strategy in and of itself  and usually a pretty bad one relative to the alternatives. Fisher’s framework brings up some obvious follow-on questions: What if the other side is more powerful? What if they refuse to play by your rules? What if they play dirty? Let’s check out a few. Don’t want to read online? Purchase a sexy PDF of the two-part series for only 3.99.  What if they are more Powerful? We’re all afraid of being taken advantage of in a negotiation. Our tendency to demand fairness is a big part of it, as is our tendency to try to minimize future regret. In a negotiation with a more “powerful” part, it would seem at times like our only play is to make a stand  demand that they meet us or we will not negotiate. That turns out to be a bad play sometimes, and completely unnecessary at other times. To combat this, Roger Fisher introduced a concept that a lot of people know the name of but not how to use: the Best Alternative to a Negotiated Agreement. He addresses the basic problem of powerlessness first: In response to power, the most any method of negotiation can do is to meet two objectives: first, to protect you against making an agreement you should reject and second, to help you make the most of the assets you do have so that any agreement you reach will satisfy your interest as well as possible. The common tactics are to either cave very easily, thus ending the negotiation and any possible bitterness, or to set a “bottom line” and walk away if it’s not met. They’re both weak responses: The “softie” tactic almost assures you’ll take a deal that’s not in your best interest, while the “bottom line” mentality makes you rigid, unable to learn and adapt during the negotiation process and probably too focused on one single variable at the expense of other ones. Lack of creativity. The better approach to understand your BATNA – Best Alternative to a Negotiated Agreement. It’s simple to understand in the context of a job offer negotiation: If you lose this negotiation, what alternatives do you have? If you set your “bottom line” too high and you lose, are you on the street? Or, do you have a great second or third option to go to? While the BATNA acronym is useful and explanatory, it’s really just a dressed-up version of the elementary concept we call opportunity cost, which is constantly at play in life. Realizing that opportunity cost is a “superpower” in negotiation, we can derive the following:  He with the best opportunity cost holds the power.  Let’s say you’re negotiating with a large car dealership over the price of a new sedan. Who holds the power? On the surface it might look like the dealer does, given their stature in power. But if you have three dealerships in a 30-mile radius which can sell you the same car, the power is yours, not the dealer’s. When you enter into negotiation, you can almost always afford to lose and go down the street to another dealership, find a different type of car to buy, change your mind and go used, or even keep your current car longer. That’s one reason why the car business is such a tough one. Point being, size does not  power. Opportunity cost  power. Developing alternative opportunities is the way to gain power. If you’re afraid you’re entering into a job negotiation with no power, your best bet probably isn’t to play hardball, it’s to develop other job offers, or even figure out if you can afford to start your own business. Once you can afford to walk away, the power shifts at least slightly. Raise your opportunity cost bar to shift the odds and make the negotiation a little more fair. Think about their opportunity cost as much as your own. Can they afford to lose? If not, you probably have more power than you think. If they win the opportunity cost battle, argue on merit. Roger Fisher makes this final point well: To the extent that they have muscle and you have principle, the larger a role you can establish for principle, the better off you are. If your opportunity costs are weak, you must resort to making it clear that the house is objectively worth X, that you deserve to be paid Y, or that a drawn-out fight will only ruin your relationship. This goes back to insisting on objective criteria.  What if they Won’t Play? A problem arises if you aren’t successful in shifting the negotiation to objective criteria or creating win-wins. Sometimes the other side simply takes a position and stubbornly often irrationally holds their ground. What then? There are two approaches. The first tactic Fisher argues for is Negotiation Jujitsu. In other words, using their own forcefulness against them. Not playing their game. It’s nuanced and we won’t try to cover it all here  the book does it well. But the salient point is that you can’t react emotionally to forceful negotiation. Let them criticize, let them attack if they must. But your job is to keep asking objective questions. “You say you won’t accept less than 2,000  where do you get that figure from? What makes you say that this is a fair number?” Keep things in the realm of objectivity and don’t get them further entrenched by “attacking back.” Another part of the jujitsu is to explain to them the consequences of adopting an extreme position. Ask them, hypothetically, what would happen if things went the way they preferred. Fisher gives the example of an Arab-Israeli negotiation where an American was able to get the Arab contingent to understand that if the Israelis gave in entirely, their people would castigate them back home. It was enough to end that line of negotiation. The last jujitsu tactic is to take criticism unusually well  not allowing the discussion to get personal, even if the other side wants to make it so. I understand you don’t want to be taken advantage of, neither do I  can you explain how your proposal is fair to me as well as you? Can you explain how my position could be altered to be more fair? What would you do if you were in my position? Soliciting an adversary for advice can be disarming if used wisely. All it takes is tamping down your ego. Good lines of inquiry don’t criticize, they probe and try to be helpful. And when you do so, simply pausing and letting the other side talk themselves into or out of a corner can work as well. Use silence to your advantage if you’re making sense and they’re reacting emotionally.  The second approach is to use a third-party to mediate. Have them draft up a solution as impartially as possible, with both parties giving input, and the final decision being a mere “yes” or “no” by each party. This can simplify and de-personalize the process. If you cannot change the process to one of seeking a solution on its merits, perhaps a third party can. More easily than one of those directly involved, a mediator can separate the people from the problem and direct the discussion to interests and options. Further, he or she can often suggest some impartial basis for resolving differences. A third party can also separate inventing from decision-making, reduce the number of decisions required to reach agreement, and help the sprites know what they will get when they do decide. One process designed to enable a third party to do all this is known as the one-text procedure. The essence of that procedure is to have a draft drawn up that best satisfies both sides impartially and without pre-commitment. The final decision for each party is a simple “yes” or “no” to the draft solution. You can do it yourself, asking for opinions and revisions as you go along, or have a third party take it on. In either case, you’re trying to change the game rather than fight a losing battle. What if they Play Dirty? A tricky tactic is defined as one that fails the test of reciprocity  they are designed to benefit one side only, and most often, the other side is not supposed to know they’re being used . Some of the most common dirty tactics include: Using phony facts, introducing phony authority, hiding dubious intentions, psychological manipulation, refusal to negotiate, and good-cop, bad-cop type routines. There are too many to enumerate, but the basic answer to all of them will be to refer back to the four central ideas of principle negotiation. You need to point out and negotiate the rules of the game itself when you suspect you’re becoming a victim of “tricky tactics” which you’re not supposed to know about. There are three steps in negotiating the rules of the negotiating game where the other side seems to be using a tricky tactic: recognize the tactic, raise the issue explicitly, and question the tactics’s legitimacy and desirability  negotiate over it.  You have to know what is going on to be able to do something about it. Learn to spot particular ploys that indicate deception, those designed to make you uncomfortable, and those which lock the other side into their position. Often just recognizing a tactic will neutralize it. Realizing, for example, that the other side is attacking you personally in order to impair your judgment may well frustrate the effort. The book has some great examples of dirty tactics in play, which are good to refer to. Another book to pick up some of these ploys is Cialdini’s Influence, one of the great books written to protect people against manipulation. However you learn them, it’s good to learn them well. Once you can see that it’s happening, you need to gently, non-threateningly, point out what’s going on and ask to return to principles, or to excuse yourself momentarily. These things serve to defuse an embarrassing situation. And never forget that the best defense in most cases is a worthy set of alternative opportunities, what Fisher calls the BATNA. These give you the ability to walk away if you feel yourself being manipulated with no recourse.  Negotiating is difficult. It’s a part of life that some people enjoy and some do not, leading to outcomes in the vein of the old saying Don’t ever wrestle with a pig  you’ll both get dirty but the pig will like it. Strong-willed negotiators have a natural advantage over those of us more averse to confrontation, and yet if we push back, stalemate is a usual result. Adopting the Principled Negotiation approach, rooted deeply in human nature, seems to give us the best chance of getting fair results for all involved. Still Interested? Check out Fisher’s bestselling book, read Part 1 of our two-part series, or check out our post on Fisher’s approach to giving better feedback in the workplace. ",
			"tokens": 2477,
			"chunks": [
				{
					"article_title": "Roger Fisher on a Better Way to Negotiate, Part 2",
					"article_url": "https://fs.blog/roger-fisher-negotiation-part-2/",
					"content": "In Part 1 of our series on the best-selling negotiation book Getting to Yes, we covered Roger Fisher’s four-part framework on Principled Negotiation  his “way out” of highly contentious negotiation. To review, the four parts were as follows:  Separate the People from the Problem Focus on Interests, Not Positions Invent Options for Mutual Gain Insist on Objective Criteria  Habitual use of these four criteria is a way to build, or at least not destroy, win-win relationships in the process of negotiation. The truth is we all must negotiate from time to time. Refusing to negotiate is a strategy in and of itself  and usually a pretty bad one relative to the alternatives. Fisher’s framework brings up some obvious follow-on questions: What if the other side is more powerful? What if they refuse to play by your rules? What if they play dirty? Let’s check out a few. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "Roger Fisher on a Better Way to Negotiate, Part 2",
					"article_url": "https://fs.blog/roger-fisher-negotiation-part-2/",
					"content": "Don’t want to read online? Purchase a sexy PDF of the two-part series for only 3.99.  What if they are more Powerful? We’re all afraid of being taken advantage of in a negotiation. Our tendency to demand fairness is a big part of it, as is our tendency to try to minimize future regret. In a negotiation with a more “powerful” part, it would seem at times like our only play is to make a stand  demand that they meet us or we will not negotiate. That turns out to be a bad play sometimes, and completely unnecessary at other times. To combat this, Roger Fisher introduced a concept that a lot of people know the name of but not how to use: the Best Alternative to a Negotiated Agreement. ",
					"content_token": 163,
					"embedding": []
				},
				{
					"article_title": "Roger Fisher on a Better Way to Negotiate, Part 2",
					"article_url": "https://fs.blog/roger-fisher-negotiation-part-2/",
					"content": "He addresses the basic problem of powerlessness first: In response to power, the most any method of negotiation can do is to meet two objectives: first, to protect you against making an agreement you should reject and second, to help you make the most of the assets you do have so that any agreement you reach will satisfy your interest as well as possible. The common tactics are to either cave very easily, thus ending the negotiation and any possible bitterness, or to set a “bottom line” and walk away if it’s not met. They’re both weak responses: The “softie” tactic almost assures you’ll take a deal that’s not in your best interest, while the “bottom line” mentality makes you rigid, unable to learn and adapt during the negotiation process and probably too focused on one single variable at the expense of other ones. Lack of creativity. ",
					"content_token": 188,
					"embedding": []
				},
				{
					"article_title": "Roger Fisher on a Better Way to Negotiate, Part 2",
					"article_url": "https://fs.blog/roger-fisher-negotiation-part-2/",
					"content": "The better approach to understand your BATNA – Best Alternative to a Negotiated Agreement. It’s simple to understand in the context of a job offer negotiation: If you lose this negotiation, what alternatives do you have? If you set your “bottom line” too high and you lose, are you on the street? Or, do you have a great second or third option to go to? While the BATNA acronym is useful and explanatory, it’s really just a dressed-up version of the elementary concept we call opportunity cost, which is constantly at play in life. Realizing that opportunity cost is a “superpower” in negotiation, we can derive the following:  He with the best opportunity cost holds the power.  Let’s say you’re negotiating with a large car dealership over the price of a new sedan. Who holds the power? On the surface it might look like the dealer does, given their stature in power. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "Roger Fisher on a Better Way to Negotiate, Part 2",
					"article_url": "https://fs.blog/roger-fisher-negotiation-part-2/",
					"content": "But if you have three dealerships in a 30-mile radius which can sell you the same car, the power is yours, not the dealer’s. When you enter into negotiation, you can almost always afford to lose and go down the street to another dealership, find a different type of car to buy, change your mind and go used, or even keep your current car longer. That’s one reason why the car business is such a tough one. Point being, size does not  power. Opportunity cost  power. Developing alternative opportunities is the way to gain power. If you’re afraid you’re entering into a job negotiation with no power, your best bet probably isn’t to play hardball, it’s to develop other job offers, or even figure out if you can afford to start your own business. Once you can afford to walk away, the power shifts at least slightly. ",
					"content_token": 192,
					"embedding": []
				},
				{
					"article_title": "Roger Fisher on a Better Way to Negotiate, Part 2",
					"article_url": "https://fs.blog/roger-fisher-negotiation-part-2/",
					"content": "Raise your opportunity cost bar to shift the odds and make the negotiation a little more fair. Think about their opportunity cost as much as your own. Can they afford to lose? If not, you probably have more power than you think. If they win the opportunity cost battle, argue on merit. Roger Fisher makes this final point well: To the extent that they have muscle and you have principle, the larger a role you can establish for principle, the better off you are. If your opportunity costs are weak, you must resort to making it clear that the house is objectively worth X, that you deserve to be paid Y, or that a drawn-out fight will only ruin your relationship. This goes back to insisting on objective criteria.  What if they Won’t Play? A problem arises if you aren’t successful in shifting the negotiation to objective criteria or creating win-wins. ",
					"content_token": 183,
					"embedding": []
				},
				{
					"article_title": "Roger Fisher on a Better Way to Negotiate, Part 2",
					"article_url": "https://fs.blog/roger-fisher-negotiation-part-2/",
					"content": "Sometimes the other side simply takes a position and stubbornly often irrationally holds their ground. What then? There are two approaches. The first tactic Fisher argues for is Negotiation Jujitsu. In other words, using their own forcefulness against them. Not playing their game. It’s nuanced and we won’t try to cover it all here  the book does it well. But the salient point is that you can’t react emotionally to forceful negotiation. Let them criticize, let them attack if they must. But your job is to keep asking objective questions. ",
					"content_token": 120,
					"embedding": []
				},
				{
					"article_title": "Roger Fisher on a Better Way to Negotiate, Part 2",
					"article_url": "https://fs.blog/roger-fisher-negotiation-part-2/",
					"content": "“You say you won’t accept less than 2,000  where do you get that figure from? What makes you say that this is a fair number?” Keep things in the realm of objectivity and don’t get them further entrenched by “attacking back.” Another part of the jujitsu is to explain to them the consequences of adopting an extreme position. Ask them, hypothetically, what would happen if things went the way they preferred. Fisher gives the example of an Arab-Israeli negotiation where an American was able to get the Arab contingent to understand that if the Israelis gave in entirely, their people would castigate them back home. It was enough to end that line of negotiation. The last jujitsu tactic is to take criticism unusually well  not allowing the discussion to get personal, even if the other side wants to make it so. ",
					"content_token": 182,
					"embedding": []
				},
				{
					"article_title": "Roger Fisher on a Better Way to Negotiate, Part 2",
					"article_url": "https://fs.blog/roger-fisher-negotiation-part-2/",
					"content": "I understand you don’t want to be taken advantage of, neither do I  can you explain how your proposal is fair to me as well as you? Can you explain how my position could be altered to be more fair? What would you do if you were in my position? Soliciting an adversary for advice can be disarming if used wisely. All it takes is tamping down your ego. Good lines of inquiry don’t criticize, they probe and try to be helpful. And when you do so, simply pausing and letting the other side talk themselves into or out of a corner can work as well. Use silence to your advantage if you’re making sense and they’re reacting emotionally.  The second approach is to use a third-party to mediate. ",
					"content_token": 164,
					"embedding": []
				},
				{
					"article_title": "Roger Fisher on a Better Way to Negotiate, Part 2",
					"article_url": "https://fs.blog/roger-fisher-negotiation-part-2/",
					"content": "Have them draft up a solution as impartially as possible, with both parties giving input, and the final decision being a mere “yes” or “no” by each party. This can simplify and de-personalize the process. If you cannot change the process to one of seeking a solution on its merits, perhaps a third party can. More easily than one of those directly involved, a mediator can separate the people from the problem and direct the discussion to interests and options. Further, he or she can often suggest some impartial basis for resolving differences. A third party can also separate inventing from decision-making, reduce the number of decisions required to reach agreement, and help the sprites know what they will get when they do decide. One process designed to enable a third party to do all this is known as the one-text procedure. The essence of that procedure is to have a draft drawn up that best satisfies both sides impartially and without pre-commitment. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "Roger Fisher on a Better Way to Negotiate, Part 2",
					"article_url": "https://fs.blog/roger-fisher-negotiation-part-2/",
					"content": "The final decision for each party is a simple “yes” or “no” to the draft solution. You can do it yourself, asking for opinions and revisions as you go along, or have a third party take it on. In either case, you’re trying to change the game rather than fight a losing battle. What if they Play Dirty? A tricky tactic is defined as one that fails the test of reciprocity  they are designed to benefit one side only, and most often, the other side is not supposed to know they’re being used  Some of the most common dirty tactics include: Using phony facts, introducing phony authority, hiding dubious intentions, psychological manipulation, refusal to negotiate, and good-cop, bad-cop type routines. There are too many to enumerate, but the basic answer to all of them will be to refer back to the four central ideas of principle negotiation. ",
					"content_token": 192,
					"embedding": []
				},
				{
					"article_title": "Roger Fisher on a Better Way to Negotiate, Part 2",
					"article_url": "https://fs.blog/roger-fisher-negotiation-part-2/",
					"content": "You need to point out and negotiate the rules of the game itself when you suspect you’re becoming a victim of “tricky tactics” which you’re not supposed to know about. There are three steps in negotiating the rules of the negotiating game where the other side seems to be using a tricky tactic: recognize the tactic, raise the issue explicitly, and question the tactics’s legitimacy and desirability  negotiate over it.  You have to know what is going on to be able to do something about it. Learn to spot particular ploys that indicate deception, those designed to make you uncomfortable, and those which lock the other side into their position. Often just recognizing a tactic will neutralize it. Realizing, for example, that the other side is attacking you personally in order to impair your judgment may well frustrate the effort. The book has some great examples of dirty tactics in play, which are good to refer to. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "Roger Fisher on a Better Way to Negotiate, Part 2",
					"article_url": "https://fs.blog/roger-fisher-negotiation-part-2/",
					"content": "Another book to pick up some of these ploys is Cialdini’s Influence, one of the great books written to protect people against manipulation. However you learn them, it’s good to learn them well. Once you can see that it’s happening, you need to gently, non-threateningly, point out what’s going on and ask to return to principles, or to excuse yourself momentarily. These things serve to defuse an embarrassing situation. And never forget that the best defense in most cases is a worthy set of alternative opportunities, what Fisher calls the BATNA. These give you the ability to walk away if you feel yourself being manipulated with no recourse.  Negotiating is difficult. ",
					"content_token": 152,
					"embedding": []
				},
				{
					"article_title": "Roger Fisher on a Better Way to Negotiate, Part 2",
					"article_url": "https://fs.blog/roger-fisher-negotiation-part-2/",
					"content": "It’s a part of life that some people enjoy and some do not, leading to outcomes in the vein of the old saying Don’t ever wrestle with a pig  you’ll both get dirty but the pig will like it. Strong-willed negotiators have a natural advantage over those of us more averse to confrontation, and yet if we push back, stalemate is a usual result. Adopting the Principled Negotiation approach, rooted deeply in human nature, seems to give us the best chance of getting fair results for all involved. Still Interested? Check out Fisher’s bestselling book, read Part 1 of our two-part series, or check out our post on Fisher’s approach to giving better feedback in the workplace.",
					"content_token": 158,
					"embedding": []
				}
			]
		},
		{
			"title": "Elon Musk on Regulators",
			"url": "https://fs.blog/elon-musk-regulators/",
			"content": "The Federal Aviation Administration had a meeting with Elon Musk they won’t forget. Musk met with them to discuss some approvals for the work one of his companies, SpaceX, was doing. The meeting reads like an episode of Dilbert. The FAA responded in the type of double-speak that only governments seem to master. So what did he do? He told one of the experts they were wrong. “His manager sent me this long email about how he had been in the shuttle program and in charge of 20 launches or something like that and how dare I say that the other guy was wrong,” Musk says in Ashlee Vance’s book Elon Musk: Tesla, SpaceX, and the Quest for a Fantastic Future. “Not only is he wrong,” Musk says, “let me rearticulate the reasons. We’re trying to have a really big impact in the space industry. If the rules are such that you can’t make progress, then you have to fight the rules.” And then he nails the fundamental problem with regulators. There is a fundamental problem with regulators. If a regulator agrees to change a rule and something bad happens, they can easily lose their career. Whereas if they change a rule and something good happens, they don’t even get a reward. So, it’s very asymmetric. It’s then very easy to understand why regulators resist changing the rules. It’s because there’s a big punishment on one side and no reward on the other. How would any rational person behave in such a scenario? The asymmetry he’s talking about is loss aversion. And it doesn’t stop at regulators, it extends into other areas as well. The same principle applies to most CEOs, managers and leaders. If you want to predict behavior, take a close look at the incentives. As Keynes said: “Worldly wisdom teaches that it is better for reputation to fail conventionally than to succeed unconventionally.”   ",
			"tokens": 427,
			"chunks": [
				{
					"article_title": "Elon Musk on Regulators",
					"article_url": "https://fs.blog/elon-musk-regulators/",
					"content": "The Federal Aviation Administration had a meeting with Elon Musk they won’t forget. Musk met with them to discuss some approvals for the work one of his companies, SpaceX, was doing. The meeting reads like an episode of Dilbert. The FAA responded in the type of double-speak that only governments seem to master. So what did he do? He told one of the experts they were wrong. “His manager sent me this long email about how he had been in the shuttle program and in charge of 20 launches or something like that and how dare I say that the other guy was wrong,” Musk says in Ashlee Vance’s book Elon Musk: Tesla, SpaceX, and the Quest for a Fantastic Future. “Not only is he wrong,” Musk says, “let me rearticulate the reasons. We’re trying to have a really big impact in the space industry. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "Elon Musk on Regulators",
					"article_url": "https://fs.blog/elon-musk-regulators/",
					"content": "If the rules are such that you can’t make progress, then you have to fight the rules.” And then he nails the fundamental problem with regulators. There is a fundamental problem with regulators. If a regulator agrees to change a rule and something bad happens, they can easily lose their career. Whereas if they change a rule and something good happens, they don’t even get a reward. So, it’s very asymmetric. It’s then very easy to understand why regulators resist changing the rules. It’s because there’s a big punishment on one side and no reward on the other. How would any rational person behave in such a scenario? The asymmetry he’s talking about is loss aversion. And it doesn’t stop at regulators, it extends into other areas as well. ",
					"content_token": 174,
					"embedding": []
				},
				{
					"article_title": "Elon Musk on Regulators",
					"article_url": "https://fs.blog/elon-musk-regulators/",
					"content": "The same principle applies to most CEOs, managers and leaders. If you want to predict behavior, take a close look at the incentives. As Keynes said: “Worldly wisdom teaches that it is better for reputation to fail conventionally than to succeed unconventionally.”",
					"content_token": 60,
					"embedding": []
				}
			]
		},
		{
			"title": "Three Filters Needed to Think Through Problems",
			"url": "https://fs.blog/garrett-hardin-three-filters/",
			"content": "One of the best parts of Garrett Hardins wonderful Filters Against Folly is when he explores the three filters that help us interpret reality.     No matter how much we’d like it to, the world does not only operate in our circle of competence. Thus we must learn ways to distinguish reality in areas where we lack even so much as a map.    Most geniusesespecially those who lead othersprosper not by deconstructing intricate complexities but by exploiting unrecognized simplicities.Andy BenoitMental Tools    We need not be a genius in every area but we should understand the big ideas of most disciplines and try to avoid fooling ourselves. That’s the core to the mental models approach. When you’re not an expert in a field, often the best approach is one that avoids stupidity. There are few better ways of avoiding stupidity than understanding how the world works.    We can never merely do one thing.Hardin begins by outlining his goal: to understand reality and understand human nature as it really is, removing premature judgment from the analysis.    He appropriately quotes Spinoza, who laid out his principles for political science thusly:    That I might investigate the subject matter of this science with the same freedom of spirit we generally use in mathematics, I have labored carefully not to mock, lament, or execrate human actions, but to understand them; and to this end I have looked upon passions such as love, hatred, anger, envy, ambition, pity, and other perturbations of the mind, not in the light of vices of human nature, but as properties just as pertinent to it as are heat, cold, storm, thunder, and the like to the nature of the atmosphere.    The goal of these mental filters is to understand reality by improving our ability to judge the statements of experts, promoters, and persuaders of all kinds. As the saying goes, we are all laymen in some field.    Hardin writes:    What follows is one man’s attempt to show that there is more wisdom among the laity than is generally concluded, and that there are some rather simple methods of checking on the validity of the statements of experts.        1. The Literate Filter    The first filter through which we must interpret reality, says Hardin, is the literate filter: What do the words really mean? The key to remember is that Language is action. Language is not just a way to communicate or interpret; language acts as a call to, or just as importantly, an inhibitor to action.    The first step is to try to understand what is really being said. What do the words and the labels actually mean? If a politician proposes a “Poverty Assistance Plan,” that sounds almost inarguably good, no? Many a pork-barrel program has passed based on such labels alone.    But when you examine the rhetoric, you must ask what those words are trying to do: Promote understanding, or inhibit it? If the program had a rational method of assistance to the deserving poor, the label might be appropriate. If it was simply a way to reward undeserving people in his or her district for their vote, the label might be simply a way to fool. The literate filter asks if we understand the true intent behind the words.    In a chapter called “The Sins of the Literate,” Hardin discusses the misuse of language by examining literate, but innumerate, concepts like “indefinite” or “infinite”:    He who introduces the words “infinity” or any of its derivatives “forever” or “never” for instance is also trying to escape discussion. Unfortunately he does not honestly admit the operational meaning of the high-flown language used to close off discussion. “Non-negotiable” is a dated term, no longer in common use, but “infinity” endures forever.Like old man Proteus of Greek mythology, the wish to escape debate disguises itself under a multitude of verbal forms: infinity, non-negotiable, never, forever, irresistible, immovable, indubitable, and the recent variant “not meaningfully finite.” All these words have the effect of moving discussion out of the numerate realm, where it belongs, and into a wasteland of pure literacy, where counting and measuring are repudiated.    Later, in the final chapter, Hardin repeats:    The talent for handling words is called “eloquence.” Talent is always desirable, but the talent may have an unfair, even dangerous, advantage over those with less talent. More than a century ago Ralph Waldo Emerson said, “The curse of this country is eloquent men.” The curse can be minimized by using words themselves to point out the danger of words. One of their functions is to act as inhibitors of thought. People need to be made allergic to such thought-stoppers as infinity, sacred, and absolute. The real world is a world of quantified entities: “infinity” and its like are no words for quantities but utterances used to divert attention from quantities and limits.    It is not just innumerate exaggeration we are guarding against, but the literate tendency to replace actors with abstractions, as Hardin calls it. He uses the example of donating money to a poor country Country X, which on its face sounds noble:    Country X, which is an abstraction, cannot act. Those who act in its name are rich and powerful people. Human nature being what it is, we can be sure that these people will not voluntarily do anything to diminish either their power or their richesNot uncommonly, the major part of large quantities of food sent in haste to a poor country in the tropics rot on the docks or is eaten up by rats before it can be moved to the people who need it. The wastage is seldom adequately reported back to the sending countryremember, those who gain personally from the shipping of food to poor nations gain whether fungi, rats, or people eat the food.    2. The Numerate Filter    Hardin is clear on his approach to numerical fluency: The ability to count, weigh, and compare values in a general or specific way is essential to understanding the claims of experts or assessing any problem rationally:    The numerate temperament is one that habitually looks for approximate dimensions, ratios, proportions, and rates of change in trying to grasp what is going on in the wold. Given effective education–a rare commodity, of course–a numerate orientation is probably within the reach of most people.Just as “literacy” is used here to mean more than merely reading and writing, so also will “numeracy” be used to mean more than measuring and counting. Examination of the origins of the sciences shows that many major discoveries were made with very little measuring and counting. The attitude science requires of its practitioners is respect, bordering on reverence, for ration, proportions, and rates of change.Rough and ready back-of-the-envelope calculations are often sufficient to reveal the outline of a new and important scientific discovery.In truth, the essence of many of the major insights of science can be grasped with no more than child’s ability to measure, count, and calculate.        To explain the use of the literate and numerate filters together, Hardin uses the example of the Delaney Amendment, passed in 1958 to restrict food additives. This example should be familiar to us today:    Concerned with the growing evidence that many otherwise useful substances can cause cancer, Congress degreed that henceforth, whenever a chemical at any concentration was found to cause cancer–in any fraction of any species of animal–that substance must be totally banned as an additive to human food.    From a literate standpoint, this sounds logical. The Amendment sought to eradicate harmful food additives that the free market had allowed to surface. However, says Hardin:    The Delaney Amendment is a monument to innumerate thought. “Safe” and “unsafe” are literate distinctions; nature is numerate. Everything is dangerous at some level. Even molecular oxygen, essential to human life, becomes lethal as the concentration approaches 100 percent.Sensitivity is ordinarily expressed as “1 part per X,” where X is a large number. If a substance probably increases the incidence of cancer at a concentration of 1 part per 10,000, one should probably ban it at that concentration in food, and perhaps at 1 in 100,000. But what about 1 part per million?In theory there is no final limit to sensitivity. What about 1 milligram per tank car? Or 1 milligram per terrestrial globe?    Obviously, some numerical limits must be applied. This is the usefulness of the numerate filter. As Charlie Munger says, “Quantify, always quantify.”    3. The Ecolacy Filter    Hardin introduces his final filter by requiring that we ask the question “And then what?”  There is perhaps no better question to prompt second-order thinking.    Even if we understand what is truly being said and have quantified the effects of a proposed policy or solution, it is imperative that we consider the second layer of effects or beyond. Hardin recognizes that this opens the door for potentially unlimited paralysis the poorly understood and innumerate Butterfly Effect, which he boxes in by introducing his own version of the First Law of Ecology:    We can never merely do one thing.    This is to say, all proposed solutions and interventions will have a multitude of effects, and we must try our best to consider them in their totality. Most unintended consequences are just unanticipated consequences.    In proposing this filter, Hardin is very careful to guard against the Slippery Slope argument or the idea that one step in the wrong direction will lead us directly to Hell. This, he says, is a purely literate but wholly innumerate approach to thinking.    Those who take the wedge Slippery Slope argument with the utmost seriousness act as though they think human beings are completely devoid of practical judgment. Countless examples from everyday life show the pessimists are wrongIf we took the wedge argument seriously, we would pass a law forbidding all vehicles to travel at any speed greater than zero. That would be an easy way out of the moral problem. But we pass no such law.    In reality, the ecolate filter helps us understand the layers of unintended consequences. Take inflation:    The consequences of hyperinflation beautifully illustrate the meaning of the First Law of Ecology. A government that is unwilling or unable to stop the escalation of inflation does more than merely change the price of things; it turns loose a cascade of consequences the effects of which reach far into the future.Prudent citizens who have saved their money in bank accounts and government bonds are ruined. In times of inflation people spend wildly with little care for value, because the choice and price of an object are less important than that one put his money into material things. Fatalism takes over as society sinks down into a culture of poverty.        In the end, the filters must be used wisely together. They are ways to understand reality, and cannot be divorced from one another. Hardin’s general approach to thinking sums up much like his multi-disciplinary friend Munger’s:    No single filter is sufficient for reaching a reliable decision, so invidious comparisons between the three is not called for. The well-educated person uses all of them.",
			"tokens": 2517,
			"chunks": [
				{
					"article_title": "Three Filters Needed to Think Through Problems",
					"article_url": "https://fs.blog/garrett-hardin-three-filters/",
					"content": "One of the best parts of Garrett Hardins wonderful Filters Against Folly is when he explores the three filters that help us interpret reality.     No matter how much we’d like it to, the world does not only operate in our circle of competence. Thus we must learn ways to distinguish reality in areas where we lack even so much as a map.    Most geniusesespecially those who lead othersprosper not by deconstructing intricate complexities but by exploiting unrecognized simplicities.Andy BenoitMental Tools    We need not be a genius in every area but we should understand the big ideas of most disciplines and try to avoid fooling ourselves. That’s the core to the mental models approach. When you’re not an expert in a field, often the best approach is one that avoids stupidity. There are few better ways of avoiding stupidity than understanding how the world works. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "Three Filters Needed to Think Through Problems",
					"article_url": "https://fs.blog/garrett-hardin-three-filters/",
					"content": "   We can never merely do one thing.Hardin begins by outlining his goal: to understand reality and understand human nature as it really is, removing premature judgment from the analysis.    He appropriately quotes Spinoza, who laid out his principles for political science thusly:    That I might investigate the subject matter of this science with the same freedom of spirit we generally use in mathematics, I have labored carefully not to mock, lament, or execrate human actions, but to understand them; and to this end I have looked upon passions such as love, hatred, anger, envy, ambition, pity, and other perturbations of the mind, not in the light of vices of human nature, but as properties just as pertinent to it as are heat, cold, storm, thunder, and the like to the nature of the atmosphere. ",
					"content_token": 177,
					"embedding": []
				},
				{
					"article_title": "Three Filters Needed to Think Through Problems",
					"article_url": "https://fs.blog/garrett-hardin-three-filters/",
					"content": "   The goal of these mental filters is to understand reality by improving our ability to judge the statements of experts, promoters, and persuaders of all kinds. As the saying goes, we are all laymen in some field.    Hardin writes:    What follows is one man’s attempt to show that there is more wisdom among the laity than is generally concluded, and that there are some rather simple methods of checking on the validity of the statements of experts.        1. The Literate Filter    The first filter through which we must interpret reality, says Hardin, is the literate filter: What do the words really mean? The key to remember is that Language is action. Language is not just a way to communicate or interpret; language acts as a call to, or just as importantly, an inhibitor to action. ",
					"content_token": 188,
					"embedding": []
				},
				{
					"article_title": "Three Filters Needed to Think Through Problems",
					"article_url": "https://fs.blog/garrett-hardin-three-filters/",
					"content": "   The first step is to try to understand what is really being said. What do the words and the labels actually mean? If a politician proposes a “Poverty Assistance Plan,” that sounds almost inarguably good, no? Many a pork-barrel program has passed based on such labels alone.    But when you examine the rhetoric, you must ask what those words are trying to do: Promote understanding, or inhibit it? If the program had a rational method of assistance to the deserving poor, the label might be appropriate. If it was simply a way to reward undeserving people in his or her district for their vote, the label might be simply a way to fool. The literate filter asks if we understand the true intent behind the words. ",
					"content_token": 166,
					"embedding": []
				},
				{
					"article_title": "Three Filters Needed to Think Through Problems",
					"article_url": "https://fs.blog/garrett-hardin-three-filters/",
					"content": "   In a chapter called “The Sins of the Literate,” Hardin discusses the misuse of language by examining literate, but innumerate, concepts like “indefinite” or “infinite”:    He who introduces the words “infinity” or any of its derivatives “forever” or “never” for instance is also trying to escape discussion. Unfortunately he does not honestly admit the operational meaning of the high-flown language used to close off discussion. ",
					"content_token": 114,
					"embedding": []
				},
				{
					"article_title": "Three Filters Needed to Think Through Problems",
					"article_url": "https://fs.blog/garrett-hardin-three-filters/",
					"content": "“Non-negotiable” is a dated term, no longer in common use, but “infinity” endures forever.Like old man Proteus of Greek mythology, the wish to escape debate disguises itself under a multitude of verbal forms: infinity, non-negotiable, never, forever, irresistible, immovable, indubitable, and the recent variant “not meaningfully finite.” All these words have the effect of moving discussion out of the numerate realm, where it belongs, and into a wasteland of pure literacy, where counting and measuring are repudiated.    Later, in the final chapter, Hardin repeats:    The talent for handling words is called “eloquence.” Talent is always desirable, but the talent may have an unfair, even dangerous, advantage over those with less talent. ",
					"content_token": 182,
					"embedding": []
				},
				{
					"article_title": "Three Filters Needed to Think Through Problems",
					"article_url": "https://fs.blog/garrett-hardin-three-filters/",
					"content": "More than a century ago Ralph Waldo Emerson said, “The curse of this country is eloquent men.” The curse can be minimized by using words themselves to point out the danger of words. One of their functions is to act as inhibitors of thought. People need to be made allergic to such thought-stoppers as infinity, sacred, and absolute. The real world is a world of quantified entities: “infinity” and its like are no words for quantities but utterances used to divert attention from quantities and limits.    It is not just innumerate exaggeration we are guarding against, but the literate tendency to replace actors with abstractions, as Hardin calls it. He uses the example of donating money to a poor country Country X, which on its face sounds noble:    Country X, which is an abstraction, cannot act. Those who act in its name are rich and powerful people. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "Three Filters Needed to Think Through Problems",
					"article_url": "https://fs.blog/garrett-hardin-three-filters/",
					"content": "Human nature being what it is, we can be sure that these people will not voluntarily do anything to diminish either their power or their richesNot uncommonly, the major part of large quantities of food sent in haste to a poor country in the tropics rot on the docks or is eaten up by rats before it can be moved to the people who need it. The wastage is seldom adequately reported back to the sending countryremember, those who gain personally from the shipping of food to poor nations gain whether fungi, rats, or people eat the food.    2. ",
					"content_token": 116,
					"embedding": []
				},
				{
					"article_title": "Three Filters Needed to Think Through Problems",
					"article_url": "https://fs.blog/garrett-hardin-three-filters/",
					"content": "The Numerate Filter    Hardin is clear on his approach to numerical fluency: The ability to count, weigh, and compare values in a general or specific way is essential to understanding the claims of experts or assessing any problem rationally:    The numerate temperament is one that habitually looks for approximate dimensions, ratios, proportions, and rates of change in trying to grasp what is going on in the wold. Given effective education–a rare commodity, of course–a numerate orientation is probably within the reach of most people.Just as “literacy” is used here to mean more than merely reading and writing, so also will “numeracy” be used to mean more than measuring and counting. Examination of the origins of the sciences shows that many major discoveries were made with very little measuring and counting. ",
					"content_token": 175,
					"embedding": []
				},
				{
					"article_title": "Three Filters Needed to Think Through Problems",
					"article_url": "https://fs.blog/garrett-hardin-three-filters/",
					"content": "The attitude science requires of its practitioners is respect, bordering on reverence, for ration, proportions, and rates of change.Rough and ready back-of-the-envelope calculations are often sufficient to reveal the outline of a new and important scientific discovery.In truth, the essence of many of the major insights of science can be grasped with no more than child’s ability to measure, count, and calculate.        To explain the use of the literate and numerate filters together, Hardin uses the example of the Delaney Amendment, passed in 1958 to restrict food additives. This example should be familiar to us today:    Concerned with the growing evidence that many otherwise useful substances can cause cancer, Congress degreed that henceforth, whenever a chemical at any concentration was found to cause cancer–in any fraction of any species of animal–that substance must be totally banned as an additive to human food. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "Three Filters Needed to Think Through Problems",
					"article_url": "https://fs.blog/garrett-hardin-three-filters/",
					"content": "   From a literate standpoint, this sounds logical. The Amendment sought to eradicate harmful food additives that the free market had allowed to surface. However, says Hardin:    The Delaney Amendment is a monument to innumerate thought. “Safe” and “unsafe” are literate distinctions; nature is numerate. Everything is dangerous at some level. Even molecular oxygen, essential to human life, becomes lethal as the concentration approaches 100 percent.Sensitivity is ordinarily expressed as “1 part per X,” where X is a large number. If a substance probably increases the incidence of cancer at a concentration of 1 part per 10,000, one should probably ban it at that concentration in food, and perhaps at 1 in 100,000. But what about 1 part per million?In theory there is no final limit to sensitivity. ",
					"content_token": 179,
					"embedding": []
				},
				{
					"article_title": "Three Filters Needed to Think Through Problems",
					"article_url": "https://fs.blog/garrett-hardin-three-filters/",
					"content": "What about 1 milligram per tank car? Or 1 milligram per terrestrial globe?    Obviously, some numerical limits must be applied. This is the usefulness of the numerate filter. As Charlie Munger says, “Quantify, always quantify.”    3. The Ecolacy Filter    Hardin introduces his final filter by requiring that we ask the question “And then what?”  There is perhaps no better question to prompt second-order thinking.    Even if we understand what is truly being said and have quantified the effects of a proposed policy or solution, it is imperative that we consider the second layer of effects or beyond. Hardin recognizes that this opens the door for potentially unlimited paralysis the poorly understood and innumerate Butterfly Effect, which he boxes in by introducing his own version of the First Law of Ecology:    We can never merely do one thing. ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "Three Filters Needed to Think Through Problems",
					"article_url": "https://fs.blog/garrett-hardin-three-filters/",
					"content": "   This is to say, all proposed solutions and interventions will have a multitude of effects, and we must try our best to consider them in their totality. Most unintended consequences are just unanticipated consequences.    In proposing this filter, Hardin is very careful to guard against the Slippery Slope argument or the idea that one step in the wrong direction will lead us directly to Hell. This, he says, is a purely literate but wholly innumerate approach to thinking.    Those who take the wedge Slippery Slope argument with the utmost seriousness act as though they think human beings are completely devoid of practical judgment. Countless examples from everyday life show the pessimists are wrongIf we took the wedge argument seriously, we would pass a law forbidding all vehicles to travel at any speed greater than zero. That would be an easy way out of the moral problem. But we pass no such law. ",
					"content_token": 188,
					"embedding": []
				},
				{
					"article_title": "Three Filters Needed to Think Through Problems",
					"article_url": "https://fs.blog/garrett-hardin-three-filters/",
					"content": "   In reality, the ecolate filter helps us understand the layers of unintended consequences. Take inflation:    The consequences of hyperinflation beautifully illustrate the meaning of the First Law of Ecology. A government that is unwilling or unable to stop the escalation of inflation does more than merely change the price of things; it turns loose a cascade of consequences the effects of which reach far into the future.Prudent citizens who have saved their money in bank accounts and government bonds are ruined. In times of inflation people spend wildly with little care for value, because the choice and price of an object are less important than that one put his money into material things. Fatalism takes over as society sinks down into a culture of poverty.        In the end, the filters must be used wisely together. They are ways to understand reality, and cannot be divorced from one another. ",
					"content_token": 185,
					"embedding": []
				},
				{
					"article_title": "Three Filters Needed to Think Through Problems",
					"article_url": "https://fs.blog/garrett-hardin-three-filters/",
					"content": "Hardin’s general approach to thinking sums up much like his multi-disciplinary friend Munger’s:    No single filter is sufficient for reaching a reliable decision, so invidious comparisons between the three is not called for. The well-educated person uses all of them.",
					"content_token": 60,
					"embedding": []
				}
			]
		},
		{
			"title": "Biases and Blunders",
			"url": "https://fs.blog/biases-and-blunders/",
			"content": " You would be hard pressed to come across a reading list on behavioral economics that doesn’t mention Nudge: Improving Decisions About Health, Wealth, and Happiness by Richard Thaler and Cass Sunstein. It is a fascinating look at how we can create environments or choice architecture’ to help people make better decisions. But one of the reasons it’s been so influential is because it helps us understand why people sometimes make bad decisions in the first place. If we really want to understand how we can nudge people into making better choices, it’s important to understand why they often make such poor ones. Let’s take a look at how Thaler and Sunstein explain some of our common mistakes in a chapter aptly called Biases and Blunders.’ Anchoring and Adjustment Humans have a tendency to put too much emphasis on one piece of information when making decisions. When we overweigh one piece of information and make assumptions based on it, we call that an anchor. Say I borrow a 400-page-book from a friend and I think to myself, the last book I read was about 300 pages and I read it in 5 days so I’ll let my friend know I’ll have her book back to her in 7 days. Problem is, I’ve only compared one factor related to me reading books and now I’ve made a decision without taking into account many other factors which could affect the outcome. For example, is the new book a topic I will digest at the same rate? Will I have the same time over those 7 days for reading? I have looked at number of pages but are the number of words per page similar? As Thaler and Sunstein explain: This process is called anchoring and adjustment.’ You start with some anchor, the number you know, and adjust in the direction you think is appropriate. So far, so good. The bias occurs because the adjustments are typically insufficient. Availability Heuristic This is the tendency of our mind to overweigh information that is recent and readily available. What did you think about the last time you read about a plane crash? Did you start thinking about you being in a plane crash? Imagine how much it would weigh on your mind if you were set to fly the next day. We assess the likelihood of risks by asking how readily examples come to mind. If people can easily think of relevant examples, they are far more likely to be frightened and concerned than if they cannot. Accessibility and salience are closely related to availability, and they are important as well. If you have personally experienced a serious earthquake, you’re more likely to believe that an earthquake is likely than if you read about it in a weekly magazine. Thus, vivid and easily imagined causes of death for example, tornadoes often receive inflated estimates of probability, and less-vivid causes for example, asthma attacks receive low estimates, even if they occur with a far greater frequency here, by a factor of twenty. Timing counts too: more recent events have a greater impact on our behavior, and on our fears, than earlier ones. Representativeness Heuristic Use of the representativeness heuristic can cause serious misperceptions of patterns in everyday life. When events are determined by chance, such as a sequence of coin tosses, people expect the resulting string of heads and tails to be representative of what they think of as random. Unfortunately, people do not have accurate perceptions of what random sequences look like. When they see the outcomes of random processes, they often detect patterns that they think have great meaning but in fact are just due to chance. It would seem as though we have issues with randomness. Our brains automatically want to see patterns when none may exist. Try a coin toss experiment on yourself. Simply flip a coin and keep track if it’s heads or tails. At some point you will hit a streak’ of either heads or tails and you will notice that you experience a sort of cognitive dissonance; you know that a streak’ at some point is statistically probable but you can’t help but thinking the next toss has to break the streak because for some reason in your head it’s not right. That unwillingness to accept randomness, our need for a pattern, often clouds our judgement when making decisions. Unrealistic Optimism We have touched upon optimism bias in the past. Optimism truly is a double-edged sword. On one hand it is extremely important to be able to look past a bad moment and tell yourself that it will get better. Optimism is one of the great drivers of human progress. On the other hand, if you never take those rose-coloured glasses off, you will make mistakes and take risks that could have been avoided. When assessing the possible negative outcomes associated with risky behaviour we often think it won’t happen to me.’ This is a brain trick: We are often insensitive to the base rate. Unrealistic optimism is a pervasive feature of human life; it characterizes most people in most social categories. When they overestimate their personal immunity from harm, people may fail to take sensible preventive steps. If people are running risks because of unrealistic optimism, they might be able to benefit from a nudge. Loss Aversion When they have to give something up, they are hurt more than they are pleased if they acquire the very same thing. We are familiar with loss aversion in the context described above but Thaler and Sunstein take the concept a step further and explain how it plays a role in default choices.’ Loss aversion can make us so fearful of making the wrong decision that we don’t make any decision. This explains why so many people settle for default options. The combination of loss aversion with mindless choosing implies that if an option is designated as the default,’ it will attract a large market share. Default options thus act as powerful nudges. In many contexts defaults have some extra nudging power because consumers may feel, rightly or wrongly, that default options come with an implicit endorsement from the default setter, be it the employer, government, or TV scheduler. Of course, this is not the only reason default options are so popular. “Anchoring,” which we mentioned above, plays a role here. Our mind anchors immediately to the default option, especially in unfamiliar territory for us. We also have the tendency towards inertia, given that mental effort is tantamount to physical effort – thinking hard requires physical resources. If we don’t know the difference between two 401k plans and they both seem similar, why expend the mental effort to switch away from the default investment option? You may not have that thought consciously; it often happens as a “click, whirr.” State of Arousal Our prefered definition requires recognizing that people’s state of arousal varies over time. To simplify things we will consider just the two endpoints: hot and cold. When Sally is very hungry and appetizing aromas are emanating from the kitchen, we can say she is in a hot state. When Sally is thinking abstractly on Tuesday about the right number of cashews she should consume before dinner on Saturday, she is in a cold state. We will call something tempting’ if we consume more of it when hot than when cold. None of this means that decisions made in a cold state are always better. For example, sometimes we have to be in a hot state to overcome our fears about trying new things. Sometimes dessert really is delicious, and we do best to go for it. Sometimes it is best to fall in love. But it is clear that when we are in a hot state, we can often get into a lot of trouble. For most of us, however, self-control issues arise because we underestimate the effect of arousal. This is something the behavioral economist George Loewenstein 1996 calls the hot-cold empathy gap.’ When in a cold state, we do not appreciate how much our desires and our behavior reflects a certain naivete about the effects that context can have on choice. The concept of arousal is analogous to mood. At the risk of stating the obvious, our mood can play a definitive role in our decision making. We all know it, but how many among us truly use that insight to make better decisions? This is one reason we advocate decision journals when it comes to meaningful decisions probably no need to log in your cashew calculations; a big part of tracking your decisions is your mood when you make them. A zillion contextual clues go into your state of arousal, but taking a quick pause to note which state you’re in as you make a decision can make a difference over time. Mood is also affected by chemicals. This one may be familiar to you coffee or tea addicts out there. Do you recall the last time you felt terrible or uncertain about a decision when you were tired, only to feel confident and spunky about the same topic after a cup of java? Or, how about alcohol? There’s a reason it’s called a “social lubricant” – our decision making changes when we’ve consumed enough of it. Lastly, the connection between sleep and mood goes deep. Need we say more? Peer Pressure Peer pressure is another tricky nudge that can be both positive or negative. We can be nudged to make better decisions when we think that our peer group is doing the same. If we think our neighbors conserve more energy or recycle more, we start making a better effort to reduce our consumption and recycle. If we think the people around us are eating better and exercising more we tend to do the same. Information we get from peer groups can also help us make better decisions because of collaborative filtering’; the choices of our peer groups help us filter out and narrow down our choices. If your friends who share similar views and tastes as you recommend book X, then you may like it as well. Google, Amazon and Netflix are built on this principle. However, if we are all reading the same book because we constantly see people with it, but none of us actually like it, then we all lose. We run off the mountain with the other lemmings. Social influences come in two basic categories. The first involves information. If many people do something or think something, their actions and their thoughts convey information about what might be best for you to do or think. The second involves peer pressure. If you care about what other people think about you perhaps in the mistaken belief that they are paying some attention to what you are doing, then you might go along with the crowd to avoid their wrath or curry their favor. An important problem here is pluralistic ignorance’ – that is, ignorance, on the part of all or most, about what other people think. We may follow a practice or a tradition not because we like it, or even think it defensible, but merely because we think that most other people like it. Many social practices persist for this reason, and a small shock, or nudge, can dislodge them. How do we beat social influence? It’s very difficult, and not always desirable: If you are about to enter a building a lot of people are running away from, there’s a better than good chance you should too. But this useful instinct leads us awry. A simple algorithm, when you feel yourself acting out of social proof, is to ask yourself: Would I still do this if everyone else was not?  For more, check out Nudge.",
			"tokens": 2390,
			"chunks": [
				{
					"article_title": "Biases and Blunders",
					"article_url": "https://fs.blog/biases-and-blunders/",
					"content": " You would be hard pressed to come across a reading list on behavioral economics that doesn’t mention Nudge: Improving Decisions About Health, Wealth, and Happiness by Richard Thaler and Cass Sunstein. It is a fascinating look at how we can create environments or choice architecture’ to help people make better decisions. But one of the reasons it’s been so influential is because it helps us understand why people sometimes make bad decisions in the first place. If we really want to understand how we can nudge people into making better choices, it’s important to understand why they often make such poor ones. Let’s take a look at how Thaler and Sunstein explain some of our common mistakes in a chapter aptly called Biases and Blunders.’ Anchoring and Adjustment Humans have a tendency to put too much emphasis on one piece of information when making decisions. ",
					"content_token": 186,
					"embedding": []
				},
				{
					"article_title": "Biases and Blunders",
					"article_url": "https://fs.blog/biases-and-blunders/",
					"content": "When we overweigh one piece of information and make assumptions based on it, we call that an anchor. Say I borrow a 400-page-book from a friend and I think to myself, the last book I read was about 300 pages and I read it in 5 days so I’ll let my friend know I’ll have her book back to her in 7 days. Problem is, I’ve only compared one factor related to me reading books and now I’ve made a decision without taking into account many other factors which could affect the outcome. ",
					"content_token": 118,
					"embedding": []
				},
				{
					"article_title": "Biases and Blunders",
					"article_url": "https://fs.blog/biases-and-blunders/",
					"content": "For example, is the new book a topic I will digest at the same rate? Will I have the same time over those 7 days for reading? I have looked at number of pages but are the number of words per page similar? As Thaler and Sunstein explain: This process is called anchoring and adjustment.’ You start with some anchor, the number you know, and adjust in the direction you think is appropriate. So far, so good. The bias occurs because the adjustments are typically insufficient. Availability Heuristic This is the tendency of our mind to overweigh information that is recent and readily available. What did you think about the last time you read about a plane crash? Did you start thinking about you being in a plane crash? Imagine how much it would weigh on your mind if you were set to fly the next day. We assess the likelihood of risks by asking how readily examples come to mind. ",
					"content_token": 188,
					"embedding": []
				},
				{
					"article_title": "Biases and Blunders",
					"article_url": "https://fs.blog/biases-and-blunders/",
					"content": "If people can easily think of relevant examples, they are far more likely to be frightened and concerned than if they cannot. Accessibility and salience are closely related to availability, and they are important as well. If you have personally experienced a serious earthquake, you’re more likely to believe that an earthquake is likely than if you read about it in a weekly magazine. Thus, vivid and easily imagined causes of death for example, tornadoes often receive inflated estimates of probability, and less-vivid causes for example, asthma attacks receive low estimates, even if they occur with a far greater frequency here, by a factor of twenty. Timing counts too: more recent events have a greater impact on our behavior, and on our fears, than earlier ones. Representativeness Heuristic Use of the representativeness heuristic can cause serious misperceptions of patterns in everyday life. ",
					"content_token": 182,
					"embedding": []
				},
				{
					"article_title": "Biases and Blunders",
					"article_url": "https://fs.blog/biases-and-blunders/",
					"content": "When events are determined by chance, such as a sequence of coin tosses, people expect the resulting string of heads and tails to be representative of what they think of as random. Unfortunately, people do not have accurate perceptions of what random sequences look like. When they see the outcomes of random processes, they often detect patterns that they think have great meaning but in fact are just due to chance. It would seem as though we have issues with randomness. Our brains automatically want to see patterns when none may exist. Try a coin toss experiment on yourself. Simply flip a coin and keep track if it’s heads or tails. At some point you will hit a streak’ of either heads or tails and you will notice that you experience a sort of cognitive dissonance; you know that a streak’ at some point is statistically probable but you can’t help but thinking the next toss has to break the streak because for some reason in your head it’s not right. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "Biases and Blunders",
					"article_url": "https://fs.blog/biases-and-blunders/",
					"content": "That unwillingness to accept randomness, our need for a pattern, often clouds our judgement when making decisions. Unrealistic Optimism We have touched upon optimism bias in the past. Optimism truly is a double-edged sword. On one hand it is extremely important to be able to look past a bad moment and tell yourself that it will get better. Optimism is one of the great drivers of human progress. On the other hand, if you never take those rose-coloured glasses off, you will make mistakes and take risks that could have been avoided. When assessing the possible negative outcomes associated with risky behaviour we often think it won’t happen to me.’ This is a brain trick: We are often insensitive to the base rate. Unrealistic optimism is a pervasive feature of human life; it characterizes most people in most social categories. When they overestimate their personal immunity from harm, people may fail to take sensible preventive steps. ",
					"content_token": 194,
					"embedding": []
				},
				{
					"article_title": "Biases and Blunders",
					"article_url": "https://fs.blog/biases-and-blunders/",
					"content": "If people are running risks because of unrealistic optimism, they might be able to benefit from a nudge. Loss Aversion When they have to give something up, they are hurt more than they are pleased if they acquire the very same thing. We are familiar with loss aversion in the context described above but Thaler and Sunstein take the concept a step further and explain how it plays a role in default choices.’ Loss aversion can make us so fearful of making the wrong decision that we don’t make any decision. This explains why so many people settle for default options. The combination of loss aversion with mindless choosing implies that if an option is designated as the default,’ it will attract a large market share. Default options thus act as powerful nudges. In many contexts defaults have some extra nudging power because consumers may feel, rightly or wrongly, that default options come with an implicit endorsement from the default setter, be it the employer, government, or TV scheduler. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "Biases and Blunders",
					"article_url": "https://fs.blog/biases-and-blunders/",
					"content": "Of course, this is not the only reason default options are so popular. “Anchoring,” which we mentioned above, plays a role here. Our mind anchors immediately to the default option, especially in unfamiliar territory for us. We also have the tendency towards inertia, given that mental effort is tantamount to physical effort – thinking hard requires physical resources. If we don’t know the difference between two 401k plans and they both seem similar, why expend the mental effort to switch away from the default investment option? You may not have that thought consciously; it often happens as a “click, whirr.” State of Arousal Our prefered definition requires recognizing that people’s state of arousal varies over time. To simplify things we will consider just the two endpoints: hot and cold. When Sally is very hungry and appetizing aromas are emanating from the kitchen, we can say she is in a hot state. ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "Biases and Blunders",
					"article_url": "https://fs.blog/biases-and-blunders/",
					"content": "When Sally is thinking abstractly on Tuesday about the right number of cashews she should consume before dinner on Saturday, she is in a cold state. We will call something tempting’ if we consume more of it when hot than when cold. None of this means that decisions made in a cold state are always better. For example, sometimes we have to be in a hot state to overcome our fears about trying new things. Sometimes dessert really is delicious, and we do best to go for it. Sometimes it is best to fall in love. But it is clear that when we are in a hot state, we can often get into a lot of trouble. For most of us, however, self-control issues arise because we underestimate the effect of arousal. ",
					"content_token": 153,
					"embedding": []
				},
				{
					"article_title": "Biases and Blunders",
					"article_url": "https://fs.blog/biases-and-blunders/",
					"content": "This is something the behavioral economist George Loewenstein 1996 calls the hot-cold empathy gap.’ When in a cold state, we do not appreciate how much our desires and our behavior reflects a certain naivete about the effects that context can have on choice. The concept of arousal is analogous to mood. At the risk of stating the obvious, our mood can play a definitive role in our decision making. We all know it, but how many among us truly use that insight to make better decisions? This is one reason we advocate decision journals when it comes to meaningful decisions probably no need to log in your cashew calculations; a big part of tracking your decisions is your mood when you make them. A zillion contextual clues go into your state of arousal, but taking a quick pause to note which state you’re in as you make a decision can make a difference over time. Mood is also affected by chemicals. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "Biases and Blunders",
					"article_url": "https://fs.blog/biases-and-blunders/",
					"content": "This one may be familiar to you coffee or tea addicts out there. Do you recall the last time you felt terrible or uncertain about a decision when you were tired, only to feel confident and spunky about the same topic after a cup of java? Or, how about alcohol? There’s a reason it’s called a “social lubricant” – our decision making changes when we’ve consumed enough of it. Lastly, the connection between sleep and mood goes deep. Need we say more? Peer Pressure Peer pressure is another tricky nudge that can be both positive or negative. We can be nudged to make better decisions when we think that our peer group is doing the same. If we think our neighbors conserve more energy or recycle more, we start making a better effort to reduce our consumption and recycle. If we think the people around us are eating better and exercising more we tend to do the same. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "Biases and Blunders",
					"article_url": "https://fs.blog/biases-and-blunders/",
					"content": "Information we get from peer groups can also help us make better decisions because of collaborative filtering’; the choices of our peer groups help us filter out and narrow down our choices. If your friends who share similar views and tastes as you recommend book X, then you may like it as well. Google, Amazon and Netflix are built on this principle. However, if we are all reading the same book because we constantly see people with it, but none of us actually like it, then we all lose. We run off the mountain with the other lemmings. Social influences come in two basic categories. The first involves information. If many people do something or think something, their actions and their thoughts convey information about what might be best for you to do or think. The second involves peer pressure. ",
					"content_token": 165,
					"embedding": []
				},
				{
					"article_title": "Biases and Blunders",
					"article_url": "https://fs.blog/biases-and-blunders/",
					"content": "If you care about what other people think about you perhaps in the mistaken belief that they are paying some attention to what you are doing, then you might go along with the crowd to avoid their wrath or curry their favor. An important problem here is pluralistic ignorance’ – that is, ignorance, on the part of all or most, about what other people think. We may follow a practice or a tradition not because we like it, or even think it defensible, but merely because we think that most other people like it. Many social practices persist for this reason, and a small shock, or nudge, can dislodge them. How do we beat social influence? It’s very difficult, and not always desirable: If you are about to enter a building a lot of people are running away from, there’s a better than good chance you should too. But this useful instinct leads us awry. ",
					"content_token": 189,
					"embedding": []
				},
				{
					"article_title": "Biases and Blunders",
					"article_url": "https://fs.blog/biases-and-blunders/",
					"content": "A simple algorithm, when you feel yourself acting out of social proof, is to ask yourself: Would I still do this if everyone else was not?  For more, check out Nudge.",
					"content_token": 41,
					"embedding": []
				}
			]
		},
		{
			"title": "How People Make Big Decisions",
			"url": "https://fs.blog/how-people-make-big-decision/",
			"content": "We all go through psychological steps when we make big decisions. Some people call this the “existential cycle,” which really has four stages: doing, contemplating, preparing, and experimenting.  Echoing Tolstoy on regret avoidance, Sebastian Bailey and Octavius Black write in Mind Gym: Achieve More by Thinking Differently: These four stages are much like exercises in risk management. No one wants to look back on his or her life at some point and say I wish I would have or If only I had. While there are other ways, the existential cycle helps us make life changing decisions  like who to marry, where to work, and where to live. The first stage, “doing,” is where you spend most of your life: It is your settled, equilibrium position. The doing may be all sorts of things writing emails, riding horses, reading books, washing up, going to meetings, listening to lectures, cooking, dancing, running, sharing stories with friends, telling jokes, or making love. Of course, these are not done all at the same time not unless you’re really talented. Whatever the activity may be, and however enjoyable or dull it is, you are doing it and it tends to keep you occupied. Sometimes we get to “contemplating,” where we consider whether or how things would be different. What would life be like if you move to California? Hint: It won’t make you happier. Then occasionally we move to “preparing.” You search on the web for real estate agents in San Diego or Key West, find out what property prices are, check weather patterns, possibly even visit your preferred destination on your next vacation. You have moved beyond imagining how things could be different to investigating the practical options for how to make them different. Finally you make the change. You leave your job, buy a house, and move all your possessions. This stage is called “experimenting.” After you’ve settled in and started the beachside bar you’d dreamed about, this becomes your normal way of living, and you are once again in a state of doing. The process isn’t overly complicated or hard. The challenge becomes moving through it at the right pace in a way that aligns with your principles.  The Doing Magnet As you travel around your cycle, you will have conversations with yourself that stop you from moving on to the next stage and instead take you back to doing. Sometimes these thoughts can be very sensible and prevent you from wasting time or following the wrong path. But sometimes, unfortunately, they prevent you from both spotting and taking opportunities that could dramatically improve your life. The trick lies in recognizing the internal conversations and being able to make an informed decision about whether to listen to them or to ignore them and move on. When the Doing Magnet is Weak Irrational exuberance are those people who are forever saying things like I wish I hadn’t rushed into that or If only I’d thought about it first. Rather than never crossing the Rubicon, they’re happy to head over far too easily without ever considering the size of the army on the other side. In terms of the existential cycle, their doing magnet is relatively weak the centrifugal momentum of the next new thing is stronger than the gravitational force of the status quo. If you find that you can’t hold down a job, you can’t keep a relationship, you spend money on a whim, or you haven’t gotten around to making your home into a place you like living in, and you regret it, then you may be suffering from a form of irrational exuberance. The best advice in this situation is this: spend longer at the preparing stage before wading across your Rubicon. For example, consider one of these choices:  Think through all the possible disadvantages of taking this course of action as well as the advantages really make an effort to present the case for caution on this occasion.   Contrast the allure of the new situation with how your existing life might improve even if you don’t make this big change. People who are always moving on to new jobs often fail to consider how their current jobs could get better. A new job may be attractive, but it is wrong to assume the old one will stay the same. New possibilities could open up. What happens when your boss moves on?   Contemplate the bigger and better gains and pleasures you could have if you didn’t always go for instant gratification. Could the gratification get more gratifying?   Consider any decisions you made in the past that led to situations you later regretted. What can you learn from these that will help you make a wiser decision this time.  If you Want to Improve, you have to Cross the Rubicon “Do. Or do not. There is no try.”  Yoda You have a choice in how you run your life. There is no “can’t,” only “will” and “won’t.” The trick is knowing why you are, or aren’t, moving around the existential cycle and, in particular, crossing your Rubicon. Like we’ve said, the right thing isn’t to always cross or always not cross. The right thing is to understand why you want to cross or don’t want to cross, and then make your decision. Nevertheless, none of us want to live our lives in a constant state of doing. I might not be in good enough shape today to swim 2.4 miles, but that doesn’t mean I won’t be in the future. Plus, our reasons for remaining in one state may not be strong. At some point, in certain aspects of our lives, if we want to progress, we must cross the Rubicon. A decision to not cross the Rubicon based on the wrong reasons when catastrophic fantasies rule our mind-sets is what causes people to look back on their lives and think If only.  All of us who have looked back and been proud of what we have done have crossed the Rubicon at least once and maybe many times. There’s a famous Latin maxim, carpe diem, which translated means “seize the day.” The question you have to ask yourself is, When it comes to crossing Rubicons, just how much of a Caesar am I prepared to be?",
			"tokens": 1334,
			"chunks": [
				{
					"article_title": "How People Make Big Decisions",
					"article_url": "https://fs.blog/how-people-make-big-decision/",
					"content": "We all go through psychological steps when we make big decisions. Some people call this the “existential cycle,” which really has four stages: doing, contemplating, preparing, and experimenting.  Echoing Tolstoy on regret avoidance, Sebastian Bailey and Octavius Black write in Mind Gym: Achieve More by Thinking Differently: These four stages are much like exercises in risk management. No one wants to look back on his or her life at some point and say I wish I would have or If only I had. While there are other ways, the existential cycle helps us make life changing decisions  like who to marry, where to work, and where to live. The first stage, “doing,” is where you spend most of your life: It is your settled, equilibrium position. ",
					"content_token": 165,
					"embedding": []
				},
				{
					"article_title": "How People Make Big Decisions",
					"article_url": "https://fs.blog/how-people-make-big-decision/",
					"content": "The doing may be all sorts of things writing emails, riding horses, reading books, washing up, going to meetings, listening to lectures, cooking, dancing, running, sharing stories with friends, telling jokes, or making love. Of course, these are not done all at the same time not unless you’re really talented. Whatever the activity may be, and however enjoyable or dull it is, you are doing it and it tends to keep you occupied. Sometimes we get to “contemplating,” where we consider whether or how things would be different. What would life be like if you move to California? Hint: It won’t make you happier. Then occasionally we move to “preparing.” You search on the web for real estate agents in San Diego or Key West, find out what property prices are, check weather patterns, possibly even visit your preferred destination on your next vacation. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "How People Make Big Decisions",
					"article_url": "https://fs.blog/how-people-make-big-decision/",
					"content": "You have moved beyond imagining how things could be different to investigating the practical options for how to make them different. Finally you make the change. You leave your job, buy a house, and move all your possessions. This stage is called “experimenting.” After you’ve settled in and started the beachside bar you’d dreamed about, this becomes your normal way of living, and you are once again in a state of doing. The process isn’t overly complicated or hard. The challenge becomes moving through it at the right pace in a way that aligns with your principles.  The Doing Magnet As you travel around your cycle, you will have conversations with yourself that stop you from moving on to the next stage and instead take you back to doing. Sometimes these thoughts can be very sensible and prevent you from wasting time or following the wrong path. But sometimes, unfortunately, they prevent you from both spotting and taking opportunities that could dramatically improve your life. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "How People Make Big Decisions",
					"article_url": "https://fs.blog/how-people-make-big-decision/",
					"content": "The trick lies in recognizing the internal conversations and being able to make an informed decision about whether to listen to them or to ignore them and move on. When the Doing Magnet is Weak Irrational exuberance are those people who are forever saying things like I wish I hadn’t rushed into that or If only I’d thought about it first. Rather than never crossing the Rubicon, they’re happy to head over far too easily without ever considering the size of the army on the other side. In terms of the existential cycle, their doing magnet is relatively weak the centrifugal momentum of the next new thing is stronger than the gravitational force of the status quo. ",
					"content_token": 138,
					"embedding": []
				},
				{
					"article_title": "How People Make Big Decisions",
					"article_url": "https://fs.blog/how-people-make-big-decision/",
					"content": "If you find that you can’t hold down a job, you can’t keep a relationship, you spend money on a whim, or you haven’t gotten around to making your home into a place you like living in, and you regret it, then you may be suffering from a form of irrational exuberance. The best advice in this situation is this: spend longer at the preparing stage before wading across your Rubicon. For example, consider one of these choices:  Think through all the possible disadvantages of taking this course of action as well as the advantages really make an effort to present the case for caution on this occasion.   Contrast the allure of the new situation with how your existing life might improve even if you don’t make this big change. People who are always moving on to new jobs often fail to consider how their current jobs could get better. ",
					"content_token": 184,
					"embedding": []
				},
				{
					"article_title": "How People Make Big Decisions",
					"article_url": "https://fs.blog/how-people-make-big-decision/",
					"content": "A new job may be attractive, but it is wrong to assume the old one will stay the same. New possibilities could open up. What happens when your boss moves on?   Contemplate the bigger and better gains and pleasures you could have if you didn’t always go for instant gratification. Could the gratification get more gratifying?   Consider any decisions you made in the past that led to situations you later regretted. What can you learn from these that will help you make a wiser decision this time.  If you Want to Improve, you have to Cross the Rubicon “Do. Or do not. There is no try.”  Yoda You have a choice in how you run your life. ",
					"content_token": 149,
					"embedding": []
				},
				{
					"article_title": "How People Make Big Decisions",
					"article_url": "https://fs.blog/how-people-make-big-decision/",
					"content": "There is no “can’t,” only “will” and “won’t.” The trick is knowing why you are, or aren’t, moving around the existential cycle and, in particular, crossing your Rubicon. Like we’ve said, the right thing isn’t to always cross or always not cross. The right thing is to understand why you want to cross or don’t want to cross, and then make your decision. Nevertheless, none of us want to live our lives in a constant state of doing. I might not be in good enough shape today to swim 2.4 miles, but that doesn’t mean I won’t be in the future. Plus, our reasons for remaining in one state may not be strong. At some point, in certain aspects of our lives, if we want to progress, we must cross the Rubicon. ",
					"content_token": 194,
					"embedding": []
				},
				{
					"article_title": "How People Make Big Decisions",
					"article_url": "https://fs.blog/how-people-make-big-decision/",
					"content": "A decision to not cross the Rubicon based on the wrong reasons when catastrophic fantasies rule our mind-sets is what causes people to look back on their lives and think If only.  All of us who have looked back and been proud of what we have done have crossed the Rubicon at least once and maybe many times. There’s a famous Latin maxim, carpe diem, which translated means “seize the day.” The question you have to ask yourself is, When it comes to crossing Rubicons, just how much of a Caesar am I prepared to be?",
					"content_token": 120,
					"embedding": []
				}
			]
		},
		{
			"title": "The Biological Bases of Human Resilience",
			"url": "https://fs.blog/biological-human-resilience/",
			"content": "In Stronger: Develop the Resilience You Need to Succeed there is a section on the Biological Bases of Human Resilience that is fascinating. It turns out the key to developing resilience at the biological level is to interpret experience in a way that increases performance and facilitates homeostasis. Changing attitudes and developing resilience through training is key. Optimism is your friend. In 1975, neurologist Paul MacLean coined the term triune brain to describe its three functional levels: The neocortex is the most sophisticated component of the human brain, representing its highest functioning level. Not only does the neocortex interpret sensory signals, communications, and gross proprioceptive-based control of motor musculoskeletal behaviors, but part of itthe ventromedial prefrontal cortex vmPFCpresides over imagination, logic, decision making, problem solving, planning, apprehension, and, most important, the interpretation of experience. It is the vmPFC that labels an experience real or imagined as threatening, punishing, or rewarding. It finds solutions to problems, it sees the opportunity in danger, and it sees the glass as half full rather than half empty. Based on the nature of the interpretation of experience, the vmPFC then activates the second level of the triune brain: the limbic system. The limbic system is relevant in any discussion of stress and resilience because of its role as the human brain’s emotional control center. The limbic system is believed to be just that, a system, consisting of numerous highly connected neural structures, for example, the hypothalamus, hippocampus, septum, cingulate gyrus, and the amygdala. The amygdala is the primary anatomic center for fear, anger, trauma, and aggression. It’s also the center of the fight-or-flight response, a term coined by psychologist Walter Cannon in 1915. The amygdala serves as the primary survival mechanism in the human body. Thus, it’s a key anatomic component in the biology of resilience. The brain stem and spinal cord represent the lowest level of the triune brain. The major functions of this level are the maintenance of so-called vegetative roles such as heartbeat, respiration, vasomotor activity, and the conduction of impulses to many higher levels of the brain. The spinal cord represents the central pathway for neurons as they conduct signals to and from the brain. The brain stem is the basic engine that drives the machinery of the human body. Human resilience represents a most elegant and ongoing dance between the vmPFC and the amygdala. When faced with danger, the vmPFC activates the amygdala so as to prepare you to fight, flee, or otherwise resolve the threat. Highly resilient people appear to be able to effectively regulate the amygdala so as to benefit from its activation but then allow it to quickly recover its baseline activity. This process of recovery to a steady state is what Cannon called “the reestablishment of homeostasis.” Consequently, the bodies of resilient people are supercharged with moderate increases in hormones such as adrenalin, noradrenalin, gamma-Aminobutyric acid, neuropeptide Y and Cortisol,which allow you to do “superhuman” things for short periods of time. When these hormones surge, your strength and perception increase, your memory improves, your eyesight may get better, your tolerance for pain increases, and you react to stimuli faster. In other words, you’re better prepared to meet any challenge success fully. The person who is not resilient experiences homeostatic failure, during which the vmPFC interpretations either overstimulate or understimulate the limbic system. The result of overstimulation can be anxiety, panic attacks, confusion, reduced problem-solving capacity, irritability, anger, even violence for example, road rage, airline rage, and seizures. The result of under stimulation may be hopelessness, depression, resentment, and a lack of motivation. With highly frequent or chronic overstimulation the amygdala can develop a state of chronic hypersensitivity at the cellular level. Amygdaloid nerve cells literally become highly irritable and will over-respond to experiences that would have not otherwise caused excitation. It’s like having 10 cups of coffee. ",
			"tokens": 871,
			"chunks": [
				{
					"article_title": "The Biological Bases of Human Resilience",
					"article_url": "https://fs.blog/biological-human-resilience/",
					"content": "In Stronger: Develop the Resilience You Need to Succeed there is a section on the Biological Bases of Human Resilience that is fascinating. It turns out the key to developing resilience at the biological level is to interpret experience in a way that increases performance and facilitates homeostasis. Changing attitudes and developing resilience through training is key. Optimism is your friend. In 1975, neurologist Paul MacLean coined the term triune brain to describe its three functional levels: The neocortex is the most sophisticated component of the human brain, representing its highest functioning level. Not only does the neocortex interpret sensory signals, communications, and gross proprioceptive-based control of motor musculoskeletal behaviors, but part of itthe ventromedial prefrontal cortex vmPFCpresides over imagination, logic, decision making, problem solving, planning, apprehension, and, most important, the interpretation of experience. ",
					"content_token": 187,
					"embedding": []
				},
				{
					"article_title": "The Biological Bases of Human Resilience",
					"article_url": "https://fs.blog/biological-human-resilience/",
					"content": "It is the vmPFC that labels an experience real or imagined as threatening, punishing, or rewarding. It finds solutions to problems, it sees the opportunity in danger, and it sees the glass as half full rather than half empty. Based on the nature of the interpretation of experience, the vmPFC then activates the second level of the triune brain: the limbic system. The limbic system is relevant in any discussion of stress and resilience because of its role as the human brain’s emotional control center. The limbic system is believed to be just that, a system, consisting of numerous highly connected neural structures, for example, the hypothalamus, hippocampus, septum, cingulate gyrus, and the amygdala. The amygdala is the primary anatomic center for fear, anger, trauma, and aggression. It’s also the center of the fight-or-flight response, a term coined by psychologist Walter Cannon in 1915. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "The Biological Bases of Human Resilience",
					"article_url": "https://fs.blog/biological-human-resilience/",
					"content": "The amygdala serves as the primary survival mechanism in the human body. Thus, it’s a key anatomic component in the biology of resilience. The brain stem and spinal cord represent the lowest level of the triune brain. The major functions of this level are the maintenance of so-called vegetative roles such as heartbeat, respiration, vasomotor activity, and the conduction of impulses to many higher levels of the brain. The spinal cord represents the central pathway for neurons as they conduct signals to and from the brain. The brain stem is the basic engine that drives the machinery of the human body. Human resilience represents a most elegant and ongoing dance between the vmPFC and the amygdala. When faced with danger, the vmPFC activates the amygdala so as to prepare you to fight, flee, or otherwise resolve the threat. Highly resilient people appear to be able to effectively regulate the amygdala so as to benefit from its activation but then allow it to quickly recover its baseline activity. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "The Biological Bases of Human Resilience",
					"article_url": "https://fs.blog/biological-human-resilience/",
					"content": "This process of recovery to a steady state is what Cannon called “the reestablishment of homeostasis.” Consequently, the bodies of resilient people are supercharged with moderate increases in hormones such as adrenalin, noradrenalin, gamma-Aminobutyric acid, neuropeptide Y and Cortisol,which allow you to do “superhuman” things for short periods of time. When these hormones surge, your strength and perception increase, your memory improves, your eyesight may get better, your tolerance for pain increases, and you react to stimuli faster. In other words, you’re better prepared to meet any challenge success fully. The person who is not resilient experiences homeostatic failure, during which the vmPFC interpretations either overstimulate or understimulate the limbic system. ",
					"content_token": 170,
					"embedding": []
				},
				{
					"article_title": "The Biological Bases of Human Resilience",
					"article_url": "https://fs.blog/biological-human-resilience/",
					"content": "The result of overstimulation can be anxiety, panic attacks, confusion, reduced problem-solving capacity, irritability, anger, even violence for example, road rage, airline rage, and seizures. The result of under stimulation may be hopelessness, depression, resentment, and a lack of motivation. With highly frequent or chronic overstimulation the amygdala can develop a state of chronic hypersensitivity at the cellular level. Amygdaloid nerve cells literally become highly irritable and will over-respond to experiences that would have not otherwise caused excitation. It’s like having 10 cups of coffee.",
					"content_token": 122,
					"embedding": []
				}
			]
		},
		{
			"title": "Keeping Things Simple and Tuning out Folly",
			"url": "https://fs.blog/keeping-things-simple/",
			"content": "Keeping things simple makes a huge difference and yet we are drawn to the sexiness of complexity. Einstein was a master of  sifting the essential from the non-essential. And consider this from Charlie Munger: The Complete Investor: Peter Bevelin’s book Seeking Wisdom: From Darwin to Munger has a section on the importance of simplicity. Bevelin advised: “Turn complicated problems into simple ones. Break down a problem into its components, but look at the problem holistically.” Keeping things as simple as possible, but no more so, is a constant theme in Munger’s public statements. In a joint letter to shareholders, Munger and Buffett once wrote: “Simplicity has a way of improving performance through enabling us to better understand what we are doing.”  By focusing on finding decisions and bets that are easy, avoiding what is hard, and stripping away anything that is extraneous, Munger believes that an investor can make better decisions. By “tuning out folly” and swatting away unimportant things “so your mind isn’t cluttered with them  you’re better able to pick up a few sensible things to do,” said Munger. Focus enables both simplicity and clarity of thought, which in Munger’s view leads to a more positive investing result. “If something is too hard, we move on to something else. What could be simpler than that?”  Charlie Munger There is a compelling advantage in life to be found in exploiting unrecognized simplicities, something Peter Thiel tries to tease out in interviews. Essential to recognizing simplicity is scheduling time to think. “We have three baskets: in, out, and too tough We have to have a special insight, or we’ll put it in the too tough basket.”  Charlie Munger Simplicity is Filtering William James said: “The art of being wise is the art of knowing what to overlook.” And there are no truer words that have been spoken. In Arthur Conan Doyle’s The Reigate Puzzle, Sherlock Holmes says: “It is of the highest importance in the art of detection to be able to recognize, out of a number of facts, which are incidental and which vital.” And part of filtering is understanding what you know and what you don’t know, that is, understanding your circle of competence. “We have a passion for keeping things simple.”  Charlie Munger In an interview with Jason Zweig, Munger said: Confucius said that real knowledge is knowing the extent of one’s ignorance. Aristotle and Socrates said the same thing. Is it a skill that can be taught or learned? It probably can, if you have enough of a stake riding on the outcome. Some people are extraordinarily good at knowing the limits of their knowledge, because they have to be. Think of somebody who’s been a professional tightrope walker for 20 yearsand has survived. He couldn’t survive as a tightrope walker for 20 years unless he knows exactly what he knows and what he doesn’t know. He’s worked so hard at it, because he knows if he gets it wrong he won’t survive. The survivors know. Another time he offered: Part of that having uncommon sense, I think, is being able to tune out folly, as distinguished from recognizing wisdom. You’ve got whole categories of things you just bat away so your brain isn’t cluttered with them. That way, you’re better able to pick up a few sensible things to do. Warren Buffett, the CEO of Berkshire Hathaway agrees: Yeah, we don’t consider many stupid things. I mean, we get rid of ’em fast.. Just getting rid of the nonsense  just figuring out that if people call you and say, “I’ve got this great, wonderful idea”, you don’t spend 10 minutes once you know in the first sentence that it isn’t a great, wonderful idea Don’t be polite and go through the whole process. And Peter Bevelin, writing in Seeking Wisdom, offers: Often we try to get too much information, including misinformation, or information of no use to explain or predict. We also focus on details and what’s irrelevant or unknowable and overlook the obvious truths. Dealing with what’s important forces us to prioritize. There are often just a few actions that produce most of what we are trying to achieve. There are only a few decisions of real importance. More information doesn’t equal more knowledge or better decisions. And remember that today we not only have access to more information, but also misinformation. And the harder we work at something the more confident we become. It’s worth pausing to reflect on three things at this point: 1 understanding and seeking simplicity; 2 dealing with the easy problems first; and 3 honing your skills by learning what to overlook and getting rid of bad ideas quickly how many organizations do that!? this goes hand in hand with understanding your circle of competence. ",
			"tokens": 1076,
			"chunks": [
				{
					"article_title": "Keeping Things Simple and Tuning out Folly",
					"article_url": "https://fs.blog/keeping-things-simple/",
					"content": "Keeping things simple makes a huge difference and yet we are drawn to the sexiness of complexity. Einstein was a master of  sifting the essential from the non-essential. And consider this from Charlie Munger: The Complete Investor: Peter Bevelin’s book Seeking Wisdom: From Darwin to Munger has a section on the importance of simplicity. Bevelin advised: “Turn complicated problems into simple ones. Break down a problem into its components, but look at the problem holistically.” Keeping things as simple as possible, but no more so, is a constant theme in Munger’s public statements. ",
					"content_token": 130,
					"embedding": []
				},
				{
					"article_title": "Keeping Things Simple and Tuning out Folly",
					"article_url": "https://fs.blog/keeping-things-simple/",
					"content": "In a joint letter to shareholders, Munger and Buffett once wrote: “Simplicity has a way of improving performance through enabling us to better understand what we are doing.”  By focusing on finding decisions and bets that are easy, avoiding what is hard, and stripping away anything that is extraneous, Munger believes that an investor can make better decisions. By “tuning out folly” and swatting away unimportant things “so your mind isn’t cluttered with them  you’re better able to pick up a few sensible things to do,” said Munger. Focus enables both simplicity and clarity of thought, which in Munger’s view leads to a more positive investing result. “If something is too hard, we move on to something else. ",
					"content_token": 168,
					"embedding": []
				},
				{
					"article_title": "Keeping Things Simple and Tuning out Folly",
					"article_url": "https://fs.blog/keeping-things-simple/",
					"content": "What could be simpler than that?”  Charlie Munger There is a compelling advantage in life to be found in exploiting unrecognized simplicities, something Peter Thiel tries to tease out in interviews. Essential to recognizing simplicity is scheduling time to think. “We have three baskets: in, out, and too tough We have to have a special insight, or we’ll put it in the too tough basket.”  Charlie Munger Simplicity is Filtering William James said: “The art of being wise is the art of knowing what to overlook.” And there are no truer words that have been spoken. ",
					"content_token": 132,
					"embedding": []
				},
				{
					"article_title": "Keeping Things Simple and Tuning out Folly",
					"article_url": "https://fs.blog/keeping-things-simple/",
					"content": "In Arthur Conan Doyle’s The Reigate Puzzle, Sherlock Holmes says: “It is of the highest importance in the art of detection to be able to recognize, out of a number of facts, which are incidental and which vital.” And part of filtering is understanding what you know and what you don’t know, that is, understanding your circle of competence. “We have a passion for keeping things simple.”  Charlie Munger In an interview with Jason Zweig, Munger said: Confucius said that real knowledge is knowing the extent of one’s ignorance. Aristotle and Socrates said the same thing. Is it a skill that can be taught or learned? It probably can, if you have enough of a stake riding on the outcome. Some people are extraordinarily good at knowing the limits of their knowledge, because they have to be. ",
					"content_token": 181,
					"embedding": []
				},
				{
					"article_title": "Keeping Things Simple and Tuning out Folly",
					"article_url": "https://fs.blog/keeping-things-simple/",
					"content": "Think of somebody who’s been a professional tightrope walker for 20 yearsand has survived. He couldn’t survive as a tightrope walker for 20 years unless he knows exactly what he knows and what he doesn’t know. He’s worked so hard at it, because he knows if he gets it wrong he won’t survive. The survivors know. Another time he offered: Part of that having uncommon sense, I think, is being able to tune out folly, as distinguished from recognizing wisdom. You’ve got whole categories of things you just bat away so your brain isn’t cluttered with them. That way, you’re better able to pick up a few sensible things to do. Warren Buffett, the CEO of Berkshire Hathaway agrees: Yeah, we don’t consider many stupid things. I mean, we get rid of ’em fast. ",
					"content_token": 192,
					"embedding": []
				},
				{
					"article_title": "Keeping Things Simple and Tuning out Folly",
					"article_url": "https://fs.blog/keeping-things-simple/",
					"content": "Just getting rid of the nonsense  just figuring out that if people call you and say, “I’ve got this great, wonderful idea”, you don’t spend 10 minutes once you know in the first sentence that it isn’t a great, wonderful idea Don’t be polite and go through the whole process. And Peter Bevelin, writing in Seeking Wisdom, offers: Often we try to get too much information, including misinformation, or information of no use to explain or predict. We also focus on details and what’s irrelevant or unknowable and overlook the obvious truths. Dealing with what’s important forces us to prioritize. There are often just a few actions that produce most of what we are trying to achieve. There are only a few decisions of real importance. More information doesn’t equal more knowledge or better decisions. And remember that today we not only have access to more information, but also misinformation. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "Keeping Things Simple and Tuning out Folly",
					"article_url": "https://fs.blog/keeping-things-simple/",
					"content": "And the harder we work at something the more confident we become. It’s worth pausing to reflect on three things at this point: 1 understanding and seeking simplicity; 2 dealing with the easy problems first; and 3 honing your skills by learning what to overlook and getting rid of bad ideas quickly how many organizations do that!? this goes hand in hand with understanding your circle of competence.",
					"content_token": 79,
					"embedding": []
				}
			]
		},
		{
			"title": "Focusing Illusions",
			"url": "https://fs.blog/focusing-illusions/",
			"content": " My favorite chapter in the book Rapt: Attention and the Focused Life by Winifred Gallagher is called Decisions: Focusing Illusions.’ It’s a really great summary of how focusing on the wrong things affects the weights we use to make decisions. There is a lot of great content packed into this chapter but I’ll attempt to highlight a few points.   Bounded Rationality According to the principle of bounded rationality,’ which Daniel Kahneman first applied to economic decisions and more recently to choices concerning quality of life, we are reasonable-enough beings but sometimes liable to focus on the wrong things. Our thinking gets befuddled not so much by our emotions as by our cognitive illusions,’ or mistaken intuitions, and other flawed, fragmented mental constructs.   LossRisk Aversion If you’re pondering a choice that involves risk, you might focus too much on the threat of possible loss, thereby obscuring an even likelier potential benefit. Where this common scenario is concerned, research shows that we aren’t so much risk-averse as loss-averse, in that we’re generally much more sensitive to what we might have to give up than to what we might gain.   The Focusing Illusion The key to understanding why you pay more attention to your thoughts about living than to life itself is neatly summed up by what Kahneman proudly calls his fortune cookie maxim’ a.k.a the focusing illusion: Nothing in life is as important as you think it is while you are thinking about it.’ Why? Because you’re thinking about it! In one much-cited illustration of the focusing illusion, Kahneman asked some people if they would be happier if they lived in California. Because the climate is often delightful there, most subjects thought so. For the same reason, even Californians assume they’re happier than people who live elsewhere. When Kahneman actually measured their well-being however, Michiganders and others are just as contented as Californians. The reason is that 99 percent of the stuff of life – relationships, work, home, recreation – is the same no matter where you are, and once you settle in a place, no matter how salubrious, you don’t think about it’s climate very much. If you’re prompted to evaluate it, however, the weather immediately looms large, simply because you’re paying attention to it. This illusion inclines you to accentuate the difference between Place A and Place B, making it seem to matter much more than it really does, which is marginal. To test the fortune cookie rule, you have only to ask yourself how happy you are. The question automatically summons your remembering self, which will focus on any recent change in your life – marriage or divorce, new job or home. You’ll then think about this novel event, which in turn will increase its import and influence your answer. If you’re pleased that you’ve just left the suburbs for the city, say, you’ll decide that life is pretty good. If you regret the move, you’ll be dissatisfied in general. Fifteen years on, however, the change that looms so large now will pale next to a more recent event – a career change, perhaps or becoming a grandparent – which will draw your focus and, simply because you’re thinking about it, bias your evaluation of your general well-being.   The Effects of Adaptation Like focusing too much on the opinions of your remembering self, overlooking the effects of adaptation – the process of becoming used to a situation – can obstruct wise decisions about how to live. As Kahneman says, when planning for the future, we don’t consider that we will stop paying attention to a thing.’ The tendency to stop focusing on a particular event or experience over time, no matter how wonderful or awful, helps explain why the differences in well-being between groups of people in very different circumstances tend to be surprisingly small – sometimes astoundingly so. The classic examples are paraplegics and lottery winners, who respectively aren’t nearly as miserable or happy as you’d think. That’s where attention comes in,’ says Kahneman. People think that if they win the lottery, they’ll be happy forever. Of course, they will not. For a while, they are happy because of the novelty, and because they think about winning all the time. Then they adapt and stop paying attention to it.’ Similarly, he says, Everyone is surprised by how happy paraplegics can be, but they are not paraplegic full-time. They do other things. They enjoy their meals, their friends, the newspaper. It has to do with the allocation of attention.’ Like couples who’ve just fallen in love, professionals starting a career, or children who go to camp for the first time, paraplegics and lottery winners initially pay a lot of attention to their new situation. Then, like everybody else, they get used to it and shift their focus to the next big thing. Their seemingly blase attitude surprises us, because when we imagine ourselves in their place, we focus on how we’d feel at the moment of becoming paralyzed or wildly rich, when such an event utterly monopolizes one’s focus. We forget that we, too, would get used to wealth, a wheelchair, and most other things under the sun, then turn our attention elsewhere.   Good Enough Finally, don’t worry if the choice you made wasn’t the absolute best, as long as it meets your needs. Offering the single most important lesson from his research, Schwartz says, Good enough is almost always good enough. If you have that attitude, many problems about decisions and much paralysis melt away.’ ",
			"tokens": 1217,
			"chunks": [
				{
					"article_title": "Focusing Illusions",
					"article_url": "https://fs.blog/focusing-illusions/",
					"content": " My favorite chapter in the book Rapt: Attention and the Focused Life by Winifred Gallagher is called Decisions: Focusing Illusions.’ It’s a really great summary of how focusing on the wrong things affects the weights we use to make decisions. There is a lot of great content packed into this chapter but I’ll attempt to highlight a few points.   Bounded Rationality According to the principle of bounded rationality,’ which Daniel Kahneman first applied to economic decisions and more recently to choices concerning quality of life, we are reasonable-enough beings but sometimes liable to focus on the wrong things. Our thinking gets befuddled not so much by our emotions as by our cognitive illusions,’ or mistaken intuitions, and other flawed, fragmented mental constructs. ",
					"content_token": 163,
					"embedding": []
				},
				{
					"article_title": "Focusing Illusions",
					"article_url": "https://fs.blog/focusing-illusions/",
					"content": "  LossRisk Aversion If you’re pondering a choice that involves risk, you might focus too much on the threat of possible loss, thereby obscuring an even likelier potential benefit. Where this common scenario is concerned, research shows that we aren’t so much risk-averse as loss-averse, in that we’re generally much more sensitive to what we might have to give up than to what we might gain.   The Focusing Illusion The key to understanding why you pay more attention to your thoughts about living than to life itself is neatly summed up by what Kahneman proudly calls his fortune cookie maxim’ a.k.a the focusing illusion: Nothing in life is as important as you think it is while you are thinking about it.’ Why? Because you’re thinking about it! In one much-cited illustration of the focusing illusion, Kahneman asked some people if they would be happier if they lived in California. ",
					"content_token": 202,
					"embedding": []
				},
				{
					"article_title": "Focusing Illusions",
					"article_url": "https://fs.blog/focusing-illusions/",
					"content": "Because the climate is often delightful there, most subjects thought so. For the same reason, even Californians assume they’re happier than people who live elsewhere. When Kahneman actually measured their well-being however, Michiganders and others are just as contented as Californians. The reason is that 99 percent of the stuff of life – relationships, work, home, recreation – is the same no matter where you are, and once you settle in a place, no matter how salubrious, you don’t think about it’s climate very much. If you’re prompted to evaluate it, however, the weather immediately looms large, simply because you’re paying attention to it. This illusion inclines you to accentuate the difference between Place A and Place B, making it seem to matter much more than it really does, which is marginal. To test the fortune cookie rule, you have only to ask yourself how happy you are. ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "Focusing Illusions",
					"article_url": "https://fs.blog/focusing-illusions/",
					"content": "The question automatically summons your remembering self, which will focus on any recent change in your life – marriage or divorce, new job or home. You’ll then think about this novel event, which in turn will increase its import and influence your answer. If you’re pleased that you’ve just left the suburbs for the city, say, you’ll decide that life is pretty good. If you regret the move, you’ll be dissatisfied in general. Fifteen years on, however, the change that looms so large now will pale next to a more recent event – a career change, perhaps or becoming a grandparent – which will draw your focus and, simply because you’re thinking about it, bias your evaluation of your general well-being. ",
					"content_token": 160,
					"embedding": []
				},
				{
					"article_title": "Focusing Illusions",
					"article_url": "https://fs.blog/focusing-illusions/",
					"content": "  The Effects of Adaptation Like focusing too much on the opinions of your remembering self, overlooking the effects of adaptation – the process of becoming used to a situation – can obstruct wise decisions about how to live. As Kahneman says, when planning for the future, we don’t consider that we will stop paying attention to a thing.’ The tendency to stop focusing on a particular event or experience over time, no matter how wonderful or awful, helps explain why the differences in well-being between groups of people in very different circumstances tend to be surprisingly small – sometimes astoundingly so. The classic examples are paraplegics and lottery winners, who respectively aren’t nearly as miserable or happy as you’d think. That’s where attention comes in,’ says Kahneman. People think that if they win the lottery, they’ll be happy forever. Of course, they will not. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "Focusing Illusions",
					"article_url": "https://fs.blog/focusing-illusions/",
					"content": "For a while, they are happy because of the novelty, and because they think about winning all the time. Then they adapt and stop paying attention to it.’ Similarly, he says, Everyone is surprised by how happy paraplegics can be, but they are not paraplegic full-time. They do other things. They enjoy their meals, their friends, the newspaper. It has to do with the allocation of attention.’ Like couples who’ve just fallen in love, professionals starting a career, or children who go to camp for the first time, paraplegics and lottery winners initially pay a lot of attention to their new situation. Then, like everybody else, they get used to it and shift their focus to the next big thing. ",
					"content_token": 156,
					"embedding": []
				},
				{
					"article_title": "Focusing Illusions",
					"article_url": "https://fs.blog/focusing-illusions/",
					"content": "Their seemingly blase attitude surprises us, because when we imagine ourselves in their place, we focus on how we’d feel at the moment of becoming paralyzed or wildly rich, when such an event utterly monopolizes one’s focus. We forget that we, too, would get used to wealth, a wheelchair, and most other things under the sun, then turn our attention elsewhere.   Good Enough Finally, don’t worry if the choice you made wasn’t the absolute best, as long as it meets your needs. Offering the single most important lesson from his research, Schwartz says, Good enough is almost always good enough. If you have that attitude, many problems about decisions and much paralysis melt away.’",
					"content_token": 151,
					"embedding": []
				}
			]
		},
		{
			"title": "The Pursuit of Worldly Wisdom",
			"url": "https://fs.blog/munger-worldly-wisdom/",
			"content": "Charlie Munger, the billionaire business partner of Warren Buffett and a major inspiration behind this site, is not only one of the best investors the world has witnessed, but he’s also one of the best thinkers. A quick recap is in order.    Munger has illuminated timeless wisdom in the minds’ search algorithm, Academic Economics, stretch goals, mental models, the value of thinking backward and forward, problem-solving, partnerships, and inversion among others.    What is elementary, worldly wisdom? Well, the first rule is that you can’t really know anything if you just remember isolated facts and try and bang em back. If the facts don’t hang together on a latticework of theory, you don’t have them in a usable form. Charlie MungerHe’s even offered two sets of book recommendations.    In his book, Charlie Munger: The Complete Investor, which has become my new go-to recommendation for people interested in an introduction to Munger’s thinking, Tren Griffin lays out Munger’s path to worldly wisdom.    Munger has adopted an approach to business and life that he refers to as worldly wisdom. Munger believes that by using a range of different models from many different disciplinespsychology, history, mathematics, physics, philosophy, biology, and so ona person can use the combined output of the synthesis to produce something that has more value than the sum of its parts. Robert Hagstrom wrote a wonderful book on worldly wisdom entitled Investing: The Last Liberal Art, in which he states that “each discipline entwines with, and in the process strengthens, every other. From each discipline the thoughtful person draws significant mental models, the key ideas that combine to produce a cohesive understanding. Those who cultivate this broad view are well on their way to achieving worldly wisdom.”It is clear that Munger loves to learn. He actually has fun when he is learning, and that makes the worldly wisdom investing process enjoyable for him. This is important because many people do not find investing enjoyable, especially when compared to gambling, which science has shown can generate pleasure via chemicals e.g., dopamine even though it is an activity with a negative net present value. What Munger has done is created a systemworldly wisdomthat allows him to generate the same chemical rewards in an activity that has a positive net present value. When you learn something new, your brain gives itself a chemical reward, which motivates you to do the work necessary to be a successful investor. If you do this work and adopt a worldly wisdom mindset, Munger believes you will create an investing edge over other investors.    You’ve got to have models in your head. And you’ve got to array your experienceboth vicarious and directon this latticework of models. charlie mungerMunger used a latticework of mental models in developing his approach. Herbert Simon, in his autobiography, Models of My Life, captured the idea of a mental model when he said:    A large part of the difference between the experienced decision maker and the novice in these situations is not any particular intangible like “judgment” or “intuition.” If one could open the lid, so to speak, and see what was in the head of the experienced decision maker, one would find that he had at his disposal repertoires of possible actions; that he had checklists of things to think about before he acted; and that he had mechanisms in his mind to evoke these, and bring these to his conscious attention when the situations for decisions arose.    Latticework of Mental Models    Munger carefully chose the latticework model, to convey the idea that things are interconnected. We need more than a deep understanding of one segment, we need a working knowledge of all of them and how they interact and link. This is conveyed by the Japanese proverb “The frog in a well knows nothing of the mighty ocean.”    In Charlie Munger: The Complete Investor, Griffin continues:    Understanding the worldly wisdom methodology is made easier if you see it applied in an example. To illustrate the method, Munger gave the example of a business that raises the price of its product and yet sells more of that product. This would appear to violate the rule of supply and demand as taught in economics. However, if one thinks about the discipline of psychology, one might conclude that the product is a Geffen good, which people desire more of at higher prices. Or one could conclude that low prices signal poor quality to buyers and that raising prices will result in more sales. Alternatively, you can look for bias caused by incentives and discover that what has actually happened in his example is that the seller has bribed the purchasing agents of the purchasers.    Munger described a situation in which this actually happens:    Suppose you’re the manager of a mutual fund, and you want to sell more. People commonly come to the following answer: You raise the commissions which, of course, reduces the number of units of real investments delivered to the ultimate buyer, so you’re increasing the price per unit of real investment that you’re selling the ultimate customer. And you’re using that extra commission to bribe the customer’s purchasing agent. You’re bribing the broker to betray his client and put the client’s money into the high-commission product.    While we can’t know everything, we can know the big ideas from multiple disciplines. We don’t want to be the frog. This is one way we can add value in the decision-making process and it allows for the effective use of what I call the Munger two-step.    “Simply put,” Griffin writes, “Munger believes that people who think very broadly and understand many different models from many different disciplines make better decisions.”    In a 2003 speech at UCB Business School entitled Academic Economics  Strengths and Weaknesses, after Considering Interdisciplinary Needs, Munger said:    You’ve got a complex system and it spews out a lot of wonderful numbers that enable you to measure some factors. But there are other factors that are terribly important, yet there’s no precise numbering you can put to these factors. You know they’re important, but you don’t have the numbers. Well, practically 1 everybody overweighs the stuff that can be numbered, because it yields to the statistical techniques they’re taught in academia, and 2 doesn’t mix in the hard-to-measure stuff that may be more important. That is a mistake I’ve tried all my life to avoid, and I have no regrets for having done that.    Worldly Wisdom    Griffin continues:    In Munger’s view, it is better to be worldly wise than to spend lots of time working with a single model that is precisely wrong.A multiple-model approach that is only approximately right will produce a far better outcome in anything that involves people or a social system. While making the case for a lattice of mental models approach described here shortly, Robert Hagstrom pointed out that Munger is providing support for those who advocate for a wide-ranging liberal arts education.    Munger would be what the poet Archilochus calls a fox. The ancient Greeks said “The fox knows many things; the hedgehog one great thing.”    The theory of modern education is that you need a general education before you specialize. And I think to some extent, before you’re going to be a great stock picker, you need some general education. Charlie MungerCommenting on Munger, former Microsoft CEO Bill Gates said, “he is truly the broadest thinker I have ever encountered.” Buffett added that Munger has “the best 30-second mind in the world. He goes from A to Z in one move. He sees the essence of everything before you even finish the sentence.”    How does Munger do this? That’s a question worth slowing down and thinking about.    You have to realize the truth of biologist Julian Huxley’s idea that Life is just one damn relatedness after another.’ So you must have the models, and you must see the relatedness and the effects from the relatedness. Charlie MungerWhere do we get these ideas?     We let history be our guide. If one way to ensure you make poor decisions is to use a small sample size, we can reason that we should seek out the biggest sample sizes we can.    What crosses most of history? Biology, Chemistry, Physics. And of course, throw in some Psychology so we can better understand how we are led astray.    Thinking    Griffin continues:    Munger’s breadth of knowledge is something that is naturally part of his character but also something that he intentionally cultivates. In his view, to know nothing about an important subject is to invite problems. Both Munger and Buffett set aside plenty of time each day to just think. Anyone reading the news is provided with constant reminders of the consequences of not thinking. Thinking is a surprisingly underrated activity. Researchers published a study in 2014 that revealed that approximately a quarter of women and two-thirds of men chose electric shocks over spending time alone with their own thoughts.    If you can’t be alone with your thoughts, you don’t deserve them. We try to run away from the pain of thinking. Instead, we turn to the instant gratification of Netflix.    Munger’s speeches and essays are filled with the thoughts of great people from the past and present from many different domains. Munger is also careful to set aside a lot of time in his schedule for reading. To say he loves books is an understatement. Buffett has said that Munger has read hundreds of biographies, as just one example. He is very purposeful in his approach to worldly wisdom, preferring not to fill his calendar with appointments and meetings.    When talking about how to get smarter, Buffett said: “You could hardly find a partnership in which two people settle on reading more hours of the day than in ours.” Adding, “Look, my job is essentially just corralling more and more and more facts and information, and occasionally seeing whether that leads to some action.”    This is where we go astray so easily. It’s easy to think about our own discipline, the one we live in on a daily basis. This comes naturally. However, it’s likely to lead to problems. We become the proverbial man with a hammer, “To the man with a hammer everything looks like a nail. If you only have one model you will fit whatever problem you face to the model you have.” It’s hard work to think. That’s why so few people seem to take this passage. But it should be hard, otherwise, it would be too easy.    I believe in the discipline of mastering the best that other people have ever figured out. I don’t believe in just sitting down and trying to dream it all up yourself. Nobody’s that smart. Charlie MungerA Multidisciplinary Approach    The tagline for this website: Mastering the best of what other people have already figured out, comes from the Munger quote above.    Griffin continues:    It is critical for a person who desires to be wise to think broadly and learn from others. Munger has said many times that someone who is really smart but has devoted all of their time to being an expert in a narrow area may be dangerous to themselves and others. Examples of this include macroeconomists who study the economy but are disastrous when investing their own portfolios and marketing experts who may think that most all business problems can be solved through marketing. Financiers tend to think similarly about their own profession. Too many people believe that what they do at work is hard and what others do is easy.    The best approach is the multi-disciplinary one, Munger argues:    You may say, “My God, this is already getting way too tough.” But, fortunately, it isn’t that toughbecause eighty or ninety important models will carry about 90 percent of the freight in making you a worldly wise person. And, of those, only a mere handful really carry very heavy freight.    “This reference to eighty or ninety important models” Griffin writes, “has caused people to ask Munger for a complete list of these important models.”    While Munger identified many models in the discipline of psychology in his famous The Psychology of Human Misjudgment speech and mentioned other models on an ad-hoc basis, he has never prepared a complete list covering all disciplines.Munger believes that by learning to recognize certain dysfunctional decision-making processes, an investor can learn to make fewer mistakes. He also believes that no matter how hard someone works and learns, mistakes cannot be completely eliminated. The best one can hope for is to reduce their frequency and, hopefully, their magnitude.    Munger elaborates in a 1995 speech at Harvard University:    Man’s imperfect, limited-capacity brain easily drifts into working with what’s easily available to it. And the brain can’t use what it can’t remember or when it’s blocked from recognizing because it’s heavily influenced by one or more psychological tendencies bearing strongly on it  the deep structure of the human mind requires that the way to full scope competency of virtually any kind is to learn it all to fluencylike it or not.    In a 2007 speech at USC law school, Munger says:    I constantly see people rise in life who are not the smartest, sometimes not even the most diligent, but they are learning machines. They go to bed every night a little wiser than they were when they got up, and boy, does that help, particularly when you have a long run ahead of you.  So if civilization can progress only with an advanced method of invention, you can progress only when you learn the method of learning. Nothing has served me better in my long life than continuous learning. I went through life constantly practicing because if you don’t practice it, you lose it the multidisciplinary approach and I can’t tell you what that’s done for me. It’s made life more fun, it’s made me more constructive, it’s made me more helpful to others, and it’s made me enormously rich. You name it, that attitude really helps.    Back to Griffin, writing in Charlie Munger: The Complete Investor, who says:    In looking at a decision, Munger believes that it is wise to ask questions. Have dysfunctional decision-making heuristics from psychology caused an error? Are there approaches one can use to find those mistakes? Munger likes to use a model from algebra and invert problems to find a solution. Looking for models that can reveal and explain mistakes so one can accumulate worldly wisdom is actually lots of fun. It is like a puzzle to be solved.A lattice approach is, in effect, a double-check on the investing process. But instead of just two checks, you are checking the result over and over. Munger believes that by going over your decision-making process and carefully using skills, ideas, and models from many disciplines, you can more consistently not be stupid. You will always make some bone-headed mistakes even if you’re careful, but his process is designed to decrease the probability of those mistakes.    Munger likes checklists to ensure he is taking advantage of as many models as possible. At the 2002 Berkshire Hathaway annual meeting, Munger said: “You need a different checklist and different mental models for different companies. I can never make it easy by saying, “Here are three things.” You have to derive it yourself to ingrain it in your head for the rest of your life.”    Learning From Mistakes    An aspect of Munger’s approach is learning from your mistakes. I’ve made more than my fair share of them.    I like people admitting they were complete stupid horses’ asses. I know I’ll perform better if I rub my nose in my mistakes. This is a wonderful trick to learn. Charlie MungerGriffin writes:    Munger has said repeatedly that he made more mistakes earlier in life than he is making now. One of his early mistakes was to own a company that made electrical transformers. He has also said that he has found himself in real estate ventures that would only be enjoyed by a masochist. He seems to have more tolerance for mistakes in real estate than other areas of business. The idea of building things as opposed to just trading stocks has a particular appeal to Munger.Munger believes that one great way to avoid mistakes is to own a business that is simple to understand, given your education and experience. He pointed out: “Where you have complexity, by nature you can have fraud and mistakes.” This approach echoes the view of Buffett, who likes challenges that are the business equivalent of netting fish in a barrel.Buffett has said that if you cannot explain why you failed after you have made a mistake, the business was too complex for you. In other words, Munger and Buffett like to understand why they made a mistake so they can learn from the experience. If you cannot understand the business, then you cannot determine what you did wrong. If you cannot determine what you did wrong, then you cannot learn. If you cannot learn, you will not know what you’re doing, which is the real cause of risk.    Forgetting your mistakes is a terrible error if you’re trying to improve your cognition. Reality doesn’t remind you. Why not celebrate stupidities in both categories? Charlie mungerGriffin concludes:    Munger has chosen the word wisdom purposefully because he believes that mere knowledge, especially from only one domain, is not enough. To be wise, one must also have experience, common sense, and good judgment. How one actually applies these things in life is what makes a person wise.    Charlie Munger: The Complete Investor is about more than investing, it’s about the pursuit of wisdom across boundaries.",
			"tokens": 3914,
			"chunks": [
				{
					"article_title": "The Pursuit of Worldly Wisdom",
					"article_url": "https://fs.blog/munger-worldly-wisdom/",
					"content": "Charlie Munger, the billionaire business partner of Warren Buffett and a major inspiration behind this site, is not only one of the best investors the world has witnessed, but he’s also one of the best thinkers. A quick recap is in order.    Munger has illuminated timeless wisdom in the minds’ search algorithm, Academic Economics, stretch goals, mental models, the value of thinking backward and forward, problem-solving, partnerships, and inversion among others.    What is elementary, worldly wisdom? Well, the first rule is that you can’t really know anything if you just remember isolated facts and try and bang em back. If the facts don’t hang together on a latticework of theory, you don’t have them in a usable form. Charlie MungerHe’s even offered two sets of book recommendations. ",
					"content_token": 181,
					"embedding": []
				},
				{
					"article_title": "The Pursuit of Worldly Wisdom",
					"article_url": "https://fs.blog/munger-worldly-wisdom/",
					"content": "   In his book, Charlie Munger: The Complete Investor, which has become my new go-to recommendation for people interested in an introduction to Munger’s thinking, Tren Griffin lays out Munger’s path to worldly wisdom.    Munger has adopted an approach to business and life that he refers to as worldly wisdom. Munger believes that by using a range of different models from many different disciplinespsychology, history, mathematics, physics, philosophy, biology, and so ona person can use the combined output of the synthesis to produce something that has more value than the sum of its parts. Robert Hagstrom wrote a wonderful book on worldly wisdom entitled Investing: The Last Liberal Art, in which he states that “each discipline entwines with, and in the process strengthens, every other. From each discipline the thoughtful person draws significant mental models, the key ideas that combine to produce a cohesive understanding. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "The Pursuit of Worldly Wisdom",
					"article_url": "https://fs.blog/munger-worldly-wisdom/",
					"content": "Those who cultivate this broad view are well on their way to achieving worldly wisdom.”It is clear that Munger loves to learn. He actually has fun when he is learning, and that makes the worldly wisdom investing process enjoyable for him. This is important because many people do not find investing enjoyable, especially when compared to gambling, which science has shown can generate pleasure via chemicals e.g., dopamine even though it is an activity with a negative net present value. What Munger has done is created a systemworldly wisdomthat allows him to generate the same chemical rewards in an activity that has a positive net present value. When you learn something new, your brain gives itself a chemical reward, which motivates you to do the work necessary to be a successful investor. If you do this work and adopt a worldly wisdom mindset, Munger believes you will create an investing edge over other investors.    You’ve got to have models in your head. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "The Pursuit of Worldly Wisdom",
					"article_url": "https://fs.blog/munger-worldly-wisdom/",
					"content": "And you’ve got to array your experienceboth vicarious and directon this latticework of models. charlie mungerMunger used a latticework of mental models in developing his approach. Herbert Simon, in his autobiography, Models of My Life, captured the idea of a mental model when he said:    A large part of the difference between the experienced decision maker and the novice in these situations is not any particular intangible like “judgment” or “intuition.” If one could open the lid, so to speak, and see what was in the head of the experienced decision maker, one would find that he had at his disposal repertoires of possible actions; that he had checklists of things to think about before he acted; and that he had mechanisms in his mind to evoke these, and bring these to his conscious attention when the situations for decisions arose. ",
					"content_token": 187,
					"embedding": []
				},
				{
					"article_title": "The Pursuit of Worldly Wisdom",
					"article_url": "https://fs.blog/munger-worldly-wisdom/",
					"content": "   Latticework of Mental Models    Munger carefully chose the latticework model, to convey the idea that things are interconnected. We need more than a deep understanding of one segment, we need a working knowledge of all of them and how they interact and link. This is conveyed by the Japanese proverb “The frog in a well knows nothing of the mighty ocean.”    In Charlie Munger: The Complete Investor, Griffin continues:    Understanding the worldly wisdom methodology is made easier if you see it applied in an example. To illustrate the method, Munger gave the example of a business that raises the price of its product and yet sells more of that product. This would appear to violate the rule of supply and demand as taught in economics. However, if one thinks about the discipline of psychology, one might conclude that the product is a Geffen good, which people desire more of at higher prices. ",
					"content_token": 194,
					"embedding": []
				},
				{
					"article_title": "The Pursuit of Worldly Wisdom",
					"article_url": "https://fs.blog/munger-worldly-wisdom/",
					"content": "Or one could conclude that low prices signal poor quality to buyers and that raising prices will result in more sales. Alternatively, you can look for bias caused by incentives and discover that what has actually happened in his example is that the seller has bribed the purchasing agents of the purchasers.    Munger described a situation in which this actually happens:    Suppose you’re the manager of a mutual fund, and you want to sell more. People commonly come to the following answer: You raise the commissions which, of course, reduces the number of units of real investments delivered to the ultimate buyer, so you’re increasing the price per unit of real investment that you’re selling the ultimate customer. And you’re using that extra commission to bribe the customer’s purchasing agent. You’re bribing the broker to betray his client and put the client’s money into the high-commission product. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "The Pursuit of Worldly Wisdom",
					"article_url": "https://fs.blog/munger-worldly-wisdom/",
					"content": "   While we can’t know everything, we can know the big ideas from multiple disciplines. We don’t want to be the frog. This is one way we can add value in the decision-making process and it allows for the effective use of what I call the Munger two-step.    “Simply put,” Griffin writes, “Munger believes that people who think very broadly and understand many different models from many different disciplines make better decisions.”    In a 2003 speech at UCB Business School entitled Academic Economics  Strengths and Weaknesses, after Considering Interdisciplinary Needs, Munger said:    You’ve got a complex system and it spews out a lot of wonderful numbers that enable you to measure some factors. But there are other factors that are terribly important, yet there’s no precise numbering you can put to these factors. ",
					"content_token": 192,
					"embedding": []
				},
				{
					"article_title": "The Pursuit of Worldly Wisdom",
					"article_url": "https://fs.blog/munger-worldly-wisdom/",
					"content": "You know they’re important, but you don’t have the numbers. Well, practically 1 everybody overweighs the stuff that can be numbered, because it yields to the statistical techniques they’re taught in academia, and 2 doesn’t mix in the hard-to-measure stuff that may be more important. That is a mistake I’ve tried all my life to avoid, and I have no regrets for having done that.    Worldly Wisdom    Griffin continues:    In Munger’s view, it is better to be worldly wise than to spend lots of time working with a single model that is precisely wrong.A multiple-model approach that is only approximately right will produce a far better outcome in anything that involves people or a social system. ",
					"content_token": 169,
					"embedding": []
				},
				{
					"article_title": "The Pursuit of Worldly Wisdom",
					"article_url": "https://fs.blog/munger-worldly-wisdom/",
					"content": "While making the case for a lattice of mental models approach described here shortly, Robert Hagstrom pointed out that Munger is providing support for those who advocate for a wide-ranging liberal arts education.    Munger would be what the poet Archilochus calls a fox. The ancient Greeks said “The fox knows many things; the hedgehog one great thing.”    The theory of modern education is that you need a general education before you specialize. And I think to some extent, before you’re going to be a great stock picker, you need some general education. Charlie MungerCommenting on Munger, former Microsoft CEO Bill Gates said, “he is truly the broadest thinker I have ever encountered.” Buffett added that Munger has “the best 30-second mind in the world. He goes from A to Z in one move. ",
					"content_token": 186,
					"embedding": []
				},
				{
					"article_title": "The Pursuit of Worldly Wisdom",
					"article_url": "https://fs.blog/munger-worldly-wisdom/",
					"content": "He sees the essence of everything before you even finish the sentence.”    How does Munger do this? That’s a question worth slowing down and thinking about.    You have to realize the truth of biologist Julian Huxley’s idea that Life is just one damn relatedness after another.’ So you must have the models, and you must see the relatedness and the effects from the relatedness. Charlie MungerWhere do we get these ideas?     We let history be our guide. If one way to ensure you make poor decisions is to use a small sample size, we can reason that we should seek out the biggest sample sizes we can.    What crosses most of history? Biology, Chemistry, Physics. And of course, throw in some Psychology so we can better understand how we are led astray. ",
					"content_token": 181,
					"embedding": []
				},
				{
					"article_title": "The Pursuit of Worldly Wisdom",
					"article_url": "https://fs.blog/munger-worldly-wisdom/",
					"content": "   Thinking    Griffin continues:    Munger’s breadth of knowledge is something that is naturally part of his character but also something that he intentionally cultivates. In his view, to know nothing about an important subject is to invite problems. Both Munger and Buffett set aside plenty of time each day to just think. Anyone reading the news is provided with constant reminders of the consequences of not thinking. Thinking is a surprisingly underrated activity. Researchers published a study in 2014 that revealed that approximately a quarter of women and two-thirds of men chose electric shocks over spending time alone with their own thoughts.    If you can’t be alone with your thoughts, you don’t deserve them. We try to run away from the pain of thinking. Instead, we turn to the instant gratification of Netflix.    Munger’s speeches and essays are filled with the thoughts of great people from the past and present from many different domains. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "The Pursuit of Worldly Wisdom",
					"article_url": "https://fs.blog/munger-worldly-wisdom/",
					"content": "Munger is also careful to set aside a lot of time in his schedule for reading. To say he loves books is an understatement. Buffett has said that Munger has read hundreds of biographies, as just one example. He is very purposeful in his approach to worldly wisdom, preferring not to fill his calendar with appointments and meetings.    When talking about how to get smarter, Buffett said: “You could hardly find a partnership in which two people settle on reading more hours of the day than in ours.” Adding, “Look, my job is essentially just corralling more and more and more facts and information, and occasionally seeing whether that leads to some action.”    This is where we go astray so easily. It’s easy to think about our own discipline, the one we live in on a daily basis. This comes naturally. However, it’s likely to lead to problems. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "The Pursuit of Worldly Wisdom",
					"article_url": "https://fs.blog/munger-worldly-wisdom/",
					"content": "We become the proverbial man with a hammer, “To the man with a hammer everything looks like a nail. If you only have one model you will fit whatever problem you face to the model you have.” It’s hard work to think. That’s why so few people seem to take this passage. But it should be hard, otherwise, it would be too easy.    I believe in the discipline of mastering the best that other people have ever figured out. I don’t believe in just sitting down and trying to dream it all up yourself. Nobody’s that smart. Charlie MungerA Multidisciplinary Approach    The tagline for this website: Mastering the best of what other people have already figured out, comes from the Munger quote above.    Griffin continues:    It is critical for a person who desires to be wise to think broadly and learn from others. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "The Pursuit of Worldly Wisdom",
					"article_url": "https://fs.blog/munger-worldly-wisdom/",
					"content": "Munger has said many times that someone who is really smart but has devoted all of their time to being an expert in a narrow area may be dangerous to themselves and others. Examples of this include macroeconomists who study the economy but are disastrous when investing their own portfolios and marketing experts who may think that most all business problems can be solved through marketing. Financiers tend to think similarly about their own profession. Too many people believe that what they do at work is hard and what others do is easy.    The best approach is the multi-disciplinary one, Munger argues:    You may say, “My God, this is already getting way too tough.” But, fortunately, it isn’t that toughbecause eighty or ninety important models will carry about 90 percent of the freight in making you a worldly wise person. And, of those, only a mere handful really carry very heavy freight. ",
					"content_token": 192,
					"embedding": []
				},
				{
					"article_title": "The Pursuit of Worldly Wisdom",
					"article_url": "https://fs.blog/munger-worldly-wisdom/",
					"content": "   “This reference to eighty or ninety important models” Griffin writes, “has caused people to ask Munger for a complete list of these important models.”    While Munger identified many models in the discipline of psychology in his famous The Psychology of Human Misjudgment speech and mentioned other models on an ad-hoc basis, he has never prepared a complete list covering all disciplines.Munger believes that by learning to recognize certain dysfunctional decision-making processes, an investor can learn to make fewer mistakes. He also believes that no matter how hard someone works and learns, mistakes cannot be completely eliminated. The best one can hope for is to reduce their frequency and, hopefully, their magnitude.    Munger elaborates in a 1995 speech at Harvard University:    Man’s imperfect, limited-capacity brain easily drifts into working with what’s easily available to it. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "The Pursuit of Worldly Wisdom",
					"article_url": "https://fs.blog/munger-worldly-wisdom/",
					"content": "And the brain can’t use what it can’t remember or when it’s blocked from recognizing because it’s heavily influenced by one or more psychological tendencies bearing strongly on it  the deep structure of the human mind requires that the way to full scope competency of virtually any kind is to learn it all to fluencylike it or not.    In a 2007 speech at USC law school, Munger says:    I constantly see people rise in life who are not the smartest, sometimes not even the most diligent, but they are learning machines. They go to bed every night a little wiser than they were when they got up, and boy, does that help, particularly when you have a long run ahead of you.  So if civilization can progress only with an advanced method of invention, you can progress only when you learn the method of learning. Nothing has served me better in my long life than continuous learning. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "The Pursuit of Worldly Wisdom",
					"article_url": "https://fs.blog/munger-worldly-wisdom/",
					"content": "I went through life constantly practicing because if you don’t practice it, you lose it the multidisciplinary approach and I can’t tell you what that’s done for me. It’s made life more fun, it’s made me more constructive, it’s made me more helpful to others, and it’s made me enormously rich. You name it, that attitude really helps.    Back to Griffin, writing in Charlie Munger: The Complete Investor, who says:    In looking at a decision, Munger believes that it is wise to ask questions. Have dysfunctional decision-making heuristics from psychology caused an error? Are there approaches one can use to find those mistakes? Munger likes to use a model from algebra and invert problems to find a solution. Looking for models that can reveal and explain mistakes so one can accumulate worldly wisdom is actually lots of fun. ",
					"content_token": 194,
					"embedding": []
				},
				{
					"article_title": "The Pursuit of Worldly Wisdom",
					"article_url": "https://fs.blog/munger-worldly-wisdom/",
					"content": "It is like a puzzle to be solved.A lattice approach is, in effect, a double-check on the investing process. But instead of just two checks, you are checking the result over and over. Munger believes that by going over your decision-making process and carefully using skills, ideas, and models from many disciplines, you can more consistently not be stupid. You will always make some bone-headed mistakes even if you’re careful, but his process is designed to decrease the probability of those mistakes.    Munger likes checklists to ensure he is taking advantage of as many models as possible. At the 2002 Berkshire Hathaway annual meeting, Munger said: “You need a different checklist and different mental models for different companies. ",
					"content_token": 156,
					"embedding": []
				},
				{
					"article_title": "The Pursuit of Worldly Wisdom",
					"article_url": "https://fs.blog/munger-worldly-wisdom/",
					"content": "I can never make it easy by saying, “Here are three things.” You have to derive it yourself to ingrain it in your head for the rest of your life.”    Learning From Mistakes    An aspect of Munger’s approach is learning from your mistakes. I’ve made more than my fair share of them.    I like people admitting they were complete stupid horses’ asses. I know I’ll perform better if I rub my nose in my mistakes. This is a wonderful trick to learn. Charlie MungerGriffin writes:    Munger has said repeatedly that he made more mistakes earlier in life than he is making now. One of his early mistakes was to own a company that made electrical transformers. He has also said that he has found himself in real estate ventures that would only be enjoyed by a masochist. ",
					"content_token": 189,
					"embedding": []
				},
				{
					"article_title": "The Pursuit of Worldly Wisdom",
					"article_url": "https://fs.blog/munger-worldly-wisdom/",
					"content": "He seems to have more tolerance for mistakes in real estate than other areas of business. The idea of building things as opposed to just trading stocks has a particular appeal to Munger.Munger believes that one great way to avoid mistakes is to own a business that is simple to understand, given your education and experience. He pointed out: “Where you have complexity, by nature you can have fraud and mistakes.” This approach echoes the view of Buffett, who likes challenges that are the business equivalent of netting fish in a barrel.Buffett has said that if you cannot explain why you failed after you have made a mistake, the business was too complex for you. In other words, Munger and Buffett like to understand why they made a mistake so they can learn from the experience. If you cannot understand the business, then you cannot determine what you did wrong. If you cannot determine what you did wrong, then you cannot learn. ",
					"content_token": 192,
					"embedding": []
				},
				{
					"article_title": "The Pursuit of Worldly Wisdom",
					"article_url": "https://fs.blog/munger-worldly-wisdom/",
					"content": "If you cannot learn, you will not know what you’re doing, which is the real cause of risk.    Forgetting your mistakes is a terrible error if you’re trying to improve your cognition. Reality doesn’t remind you. Why not celebrate stupidities in both categories? Charlie mungerGriffin concludes:    Munger has chosen the word wisdom purposefully because he believes that mere knowledge, especially from only one domain, is not enough. To be wise, one must also have experience, common sense, and good judgment. How one actually applies these things in life is what makes a person wise.    Charlie Munger: The Complete Investor is about more than investing, it’s about the pursuit of wisdom across boundaries.",
					"content_token": 158,
					"embedding": []
				}
			]
		},
		{
			"title": "The Two Types of Knowledge: The Max Planck/Chauffeur Test",
			"url": "https://fs.blog/two-types-of-knowledge/",
			"content": "Charlie Munger, the billionaire business partner of Warren Buffett, frequently tells the story below to illustrate how to distinguish between the two types of knowledge: real knowledge and pretend knowledge. At the 2007 Commencement to the USC Law School, Munger explained it this way: I frequently tell the apocryphal story about how Max Planck, after he won the Nobel Prize, went around Germany giving the same standard lecture on the new quantum mechanics. Over time, his chauffeur memorized the lecture and said, “Would you mind, Professor Planck, because it’s so boring to stay in our routine. What if I gave the lecture in Munich and you just sat in front wearing my chauffeur’s hat?” Planck said, “Why not?” And the chauffeur got up and gave this long lecture on quantum mechanics. After which a physics professor stood up and asked a perfectly ghastly question. The speaker said, “Well I’m surprised that in an advanced city like Munich I get such an elementary question. I’m going to ask my chauffeur to reply.” The point of the story is not the quick-wittedness of the protagonist, but rather  to echo Richard Feynman  it’s about making a distinction between knowing the name of something and knowing something. Two Types of Knowledge The first type of knowledge is real. It can’t be bought. It can’t be copied. If you want real knowledge you need to earn it. The second type of knowledge is copied. On the surface you know the answer but you lack the understanding to show your work. Munger continues: In this world we have two kinds of knowledge. One is Planck knowledge, the people who really know. They’ve paid the dues, they have the aptitude. And then we’ve got chauffeur knowledge. They’ve learned the talk. They may have a big head of hair, they may have fine temper in the voice, they’ll make a hell of an impression. But in the end, all they have is chauffeur knowledge. I think I’ve just described practically every politician in the United States. And you are going to have the problem in your life of getting the responsibility into the people with the Planck knowledge and away from the people with the chauffeur knowledge. And there are huge forces working against you. My generation has failed you a bit but you wouldn’t like it to be too easy now would you? Real knowledge comes when people do the work. On the other hand, we have the people who don’t do the work  they pretend. While they’ve learned to put on a good show, they lack understanding. They can’t answer questions that don’t rely on memorization. They can’t explain things without using jargon or vague terms. They have no idea how things interact. They can’t predict the consequences. “Any fool can know. The point is to understand.”  Albert Einstein The problem is that it’s difficult to separate the two. This is the Batesian Mimicry problem. One way to tease out the difference between Planck and chauffeur knowledge is to ask them why. In The Art of Thinking Clearly, Rolf Dobelli offers some commentary on distinguishing fake from real knowledge: With journalists, it is more difficult. Some have acquired true knowledge. Often they are veteran reporters who have specialized for years in a clearly defined area. They make a serious effort to understand the complexity of a subject and to communicate it. They tend to write long articles that highlight a variety of cases and exceptions. The majority of journalists, however, fall into the category of chauffeur. They conjure up articles off the tops of their heads or, rather, from Google searches. Their texts are one-sided, short, and often as compensation for their patchy knowledge snarky and self-satisfied in tone. The same superficiality is present in business. The larger a company, the more the CEO is expected to possess “star quality.” Dedication, solemnity, and reliability are undervalued, at least at the top. Too often shareholders and business journalists seem to believe that showmanship will deliver better results, which is obviously not the case. One way to guard against this is to understand your circle of competence. Dobelli concludes with some advice worth taking to heart. Be on the lookout for chauffeur knowledge. Do not confuse the company spokesperson, the ringmaster, the newscaster, the schmoozer, the verbiage vendor, or the clich generator with those who possess true knowledge. How do you recognize the difference? There is a clear indicator: True experts recognize the limits of what they know and what they do not know. If they find themselves outside their circle of competence, they keep quiet or simply say, “I don’t know.” This they utter unapologetically, even with a certain pride. From chauffeurs, we hear every line except this. Sorting through the people with real knowledge from those that do not is so important that Elon Musk tries to tease it out in interviews. ",
			"tokens": 1095,
			"chunks": [
				{
					"article_title": "The Two Types of Knowledge: The Max Planck/Chauffeur Test",
					"article_url": "https://fs.blog/two-types-of-knowledge/",
					"content": "Charlie Munger, the billionaire business partner of Warren Buffett, frequently tells the story below to illustrate how to distinguish between the two types of knowledge: real knowledge and pretend knowledge. At the 2007 Commencement to the USC Law School, Munger explained it this way: I frequently tell the apocryphal story about how Max Planck, after he won the Nobel Prize, went around Germany giving the same standard lecture on the new quantum mechanics. Over time, his chauffeur memorized the lecture and said, “Would you mind, Professor Planck, because it’s so boring to stay in our routine. What if I gave the lecture in Munich and you just sat in front wearing my chauffeur’s hat?” Planck said, “Why not?” And the chauffeur got up and gave this long lecture on quantum mechanics. After which a physics professor stood up and asked a perfectly ghastly question. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "The Two Types of Knowledge: The Max Planck/Chauffeur Test",
					"article_url": "https://fs.blog/two-types-of-knowledge/",
					"content": "The speaker said, “Well I’m surprised that in an advanced city like Munich I get such an elementary question. I’m going to ask my chauffeur to reply.” The point of the story is not the quick-wittedness of the protagonist, but rather  to echo Richard Feynman  it’s about making a distinction between knowing the name of something and knowing something. Two Types of Knowledge The first type of knowledge is real. It can’t be bought. It can’t be copied. If you want real knowledge you need to earn it. The second type of knowledge is copied. On the surface you know the answer but you lack the understanding to show your work. Munger continues: In this world we have two kinds of knowledge. One is Planck knowledge, the people who really know. They’ve paid the dues, they have the aptitude. ",
					"content_token": 192,
					"embedding": []
				},
				{
					"article_title": "The Two Types of Knowledge: The Max Planck/Chauffeur Test",
					"article_url": "https://fs.blog/two-types-of-knowledge/",
					"content": "And then we’ve got chauffeur knowledge. They’ve learned the talk. They may have a big head of hair, they may have fine temper in the voice, they’ll make a hell of an impression. But in the end, all they have is chauffeur knowledge. I think I’ve just described practically every politician in the United States. And you are going to have the problem in your life of getting the responsibility into the people with the Planck knowledge and away from the people with the chauffeur knowledge. And there are huge forces working against you. My generation has failed you a bit but you wouldn’t like it to be too easy now would you? Real knowledge comes when people do the work. On the other hand, we have the people who don’t do the work  they pretend. While they’ve learned to put on a good show, they lack understanding. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "The Two Types of Knowledge: The Max Planck/Chauffeur Test",
					"article_url": "https://fs.blog/two-types-of-knowledge/",
					"content": "They can’t answer questions that don’t rely on memorization. They can’t explain things without using jargon or vague terms. They have no idea how things interact. They can’t predict the consequences. “Any fool can know. The point is to understand.”  Albert Einstein The problem is that it’s difficult to separate the two. This is the Batesian Mimicry problem. One way to tease out the difference between Planck and chauffeur knowledge is to ask them why. In The Art of Thinking Clearly, Rolf Dobelli offers some commentary on distinguishing fake from real knowledge: With journalists, it is more difficult. Some have acquired true knowledge. Often they are veteran reporters who have specialized for years in a clearly defined area. They make a serious effort to understand the complexity of a subject and to communicate it. They tend to write long articles that highlight a variety of cases and exceptions. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "The Two Types of Knowledge: The Max Planck/Chauffeur Test",
					"article_url": "https://fs.blog/two-types-of-knowledge/",
					"content": "The majority of journalists, however, fall into the category of chauffeur. They conjure up articles off the tops of their heads or, rather, from Google searches. Their texts are one-sided, short, and often as compensation for their patchy knowledge snarky and self-satisfied in tone. The same superficiality is present in business. The larger a company, the more the CEO is expected to possess “star quality.” Dedication, solemnity, and reliability are undervalued, at least at the top. Too often shareholders and business journalists seem to believe that showmanship will deliver better results, which is obviously not the case. One way to guard against this is to understand your circle of competence. Dobelli concludes with some advice worth taking to heart. Be on the lookout for chauffeur knowledge. ",
					"content_token": 172,
					"embedding": []
				},
				{
					"article_title": "The Two Types of Knowledge: The Max Planck/Chauffeur Test",
					"article_url": "https://fs.blog/two-types-of-knowledge/",
					"content": "Do not confuse the company spokesperson, the ringmaster, the newscaster, the schmoozer, the verbiage vendor, or the clich generator with those who possess true knowledge. How do you recognize the difference? There is a clear indicator: True experts recognize the limits of what they know and what they do not know. If they find themselves outside their circle of competence, they keep quiet or simply say, “I don’t know.” This they utter unapologetically, even with a certain pride. From chauffeurs, we hear every line except this. Sorting through the people with real knowledge from those that do not is so important that Elon Musk tries to tease it out in interviews.",
					"content_token": 149,
					"embedding": []
				}
			]
		},
		{
			"title": "Making Decisions in a Complex Adaptive System",
			"url": "https://fs.blog/decisions-complex-adaptive-system/",
			"content": " In Think Twice: Harnessing the Power of Counterintuition, Mauboussin does a good job adding to the work we’ve already done on complex adaptive systems: You can think of a complex adaptive system in three parts see the image at the top of this post. First, there is a group of heterogeneous agents. These agents can be neurons in your brain, bees in a hive, investors in a market, or people in a city. Heterogeneity means each agent has different and evolving decision rules that both reflect the environment and attempt to anticipate change in it. Second, these agents interact with one another, and their interactions create structure scientists often call this emergence. Finally, the structure that emerges behaves like a higher-level system and has properties and characteristics that are distinct from those of the underlying agents themselves.  The whole is greater than the sum of the parts.  The inability to understand the system based on its components prompted Nobel Prize winner and physicist Philip Anderson, to draft the essay, “More Is Different.” Anderson wrote, “The behavior of large and complex aggregates of elementary particles, it turns out, is not to be understood in terms of the simple extrapolation of the properties of a few particles. Instead, at each level of complexity entirely new properties appear.” Mauboussin comments that we are fooled by randomness: The problem goes beyond the inscrutable nature of complex adaptive systems. Humans have a deep desire to understand cause and effect, as such links probably conferred humans with evolutionary advantage. In complex adaptive systems, there is no simple method for understanding the whole by studying the parts, so searching for simple agent-level causes of system-level effects is useless. Yet our minds are not beyond making up a cause to relieve the itch of an unexplained effect. When a mind seeking links between cause and effect meets a system that conceals them, accidents will happen.  Misplaced Focus on the Individual One mistake we make is extrapolating the behaviour of an individual component, say an individual, to explain the entire system. Yet when we have to solve a problem dealing with a complex system, we often address an individual component. In so doing, we ignore Garrett Hardin’s first law of Ecology, you can never do merely one thing and become a fragilista. That unintended system-level consequences arise from even the best-intentioned individual-level actions has long been recognized. But the decision-making challenge remains for a couple of reasons. First, our modern world has more interconnected systems than before. So we encounter these systems with greater frequency and, most likely, with greater consequence. Second, we still attempt to cure problems in complex systems with a nave understanding of cause and effect.  When I speak with executives from around the world going through a period of poor performance, it doesn’t take long for them to mention they want to hire a star from another company. “If only we had Kate,” they’ll say, “we could smash the competition and regain our footing.” At first, poaching stars from competitors or even teams within the same organization seems like a winning strategy. But once the star comes over the results often fail to materialize. What we fail to grasp is that their performance is part of an ecosystem and removing them from that ecosystem  that is isolating the individual performance  is incredibly hard without properly considering the entire ecosystem. Reversion to the mean also likely accounts for some of the star’s fading as well. Three Harvard professors concluded, “When a company hires a star, the star’s performance plunges, there is a sharp decline in the functioning of the group or team the person works with, and the company’s market value falls.” If it sounds like a lot of work to think this through at many levels, it should be. Why should it be easy? Another example of this at an organizational level has to do with innovation. Most people want to solve the innovation problem. Ignoring for a second that that is the improper framing, how do most organizations go about this? They copy what the most successful organizations do. I can’t count the number of times the solution to an organization’s “innovation problem” is to be more like Google. Well-intentioned executives blindly copy approaches by others such as 20 innovation time, without giving an ounce of thought to the role the ecosystem plays. Isolating and focusing on an individual part of a complex adaptive system without an appreciation and understanding of that system itself is sure to lead to disaster.  What Should We Do? So this begs the question, what should we do when we find ourselves dealing with a complex adaptive system? Mauboussin provides three pieces of advice: 1. Consider the system at the correct level. Remember the phrase “more is different.” The most prevalent trap is extrapolating the behavior of individual agents to gain a sense of system behavior. If you want to understand the stock market, study it at the market level. Consider what you see and read from individuals as entertainment, not as education. Similarly, be aware that the function of an individual agent outside the system may be very different from that function within the system. For instance, mammalian cells have the same metabolic rates in vitro, whether they are from shrews or elephants. But the metabolic rate of cells in small mammals is much higher than the rate of those in large mammals. The same structural cells work at different rates, depending on the animals they find themselves in. 2. Watch for tightly coupled systems.  A system is tightly coupled when there is no slack between items, allowing a process to go from one stage to the next without any opportunity to intervene. Aircraft, space missions, and nuclear power plants are classic examples of complex, tightly coupled systems. Engineers try to build in buffers or redundancies to avoid failure, but frequently don’t anticipate all possible contingencies. Most complex adaptive systems are loosely coupled, where removing or incapacitating one or a few agents has little impact on the system’s performance. For example, if you randomly remove some investors, the stock market will continue to function fine. But when the agents lose diversity and behave in a coordinated fashion, a complex adaptive system can behave in a tightly coupled fashion. Booms and crashes in financial markets are an illustration. 3. Use simulations to create virtual worlds. Dealing with complex systems is inherently tricky because the feedback is equivocal, information is limited, and there is no clear link between cause and effect. Simulation is a tool that can help our learning process. Simulations are low cost, provide feedback, and have proved their value in other domains like military planning and pilot training. Still Curious? Think Twice: Harnessing the Power of Counterintuition. ",
			"tokens": 1404,
			"chunks": [
				{
					"article_title": "Making Decisions in a Complex Adaptive System",
					"article_url": "https://fs.blog/decisions-complex-adaptive-system/",
					"content": " In Think Twice: Harnessing the Power of Counterintuition, Mauboussin does a good job adding to the work we’ve already done on complex adaptive systems: You can think of a complex adaptive system in three parts see the image at the top of this post. First, there is a group of heterogeneous agents. These agents can be neurons in your brain, bees in a hive, investors in a market, or people in a city. Heterogeneity means each agent has different and evolving decision rules that both reflect the environment and attempt to anticipate change in it. Second, these agents interact with one another, and their interactions create structure scientists often call this emergence. Finally, the structure that emerges behaves like a higher-level system and has properties and characteristics that are distinct from those of the underlying agents themselves.  The whole is greater than the sum of the parts. ",
					"content_token": 182,
					"embedding": []
				},
				{
					"article_title": "Making Decisions in a Complex Adaptive System",
					"article_url": "https://fs.blog/decisions-complex-adaptive-system/",
					"content": " The inability to understand the system based on its components prompted Nobel Prize winner and physicist Philip Anderson, to draft the essay, “More Is Different.” Anderson wrote, “The behavior of large and complex aggregates of elementary particles, it turns out, is not to be understood in terms of the simple extrapolation of the properties of a few particles. Instead, at each level of complexity entirely new properties appear.” Mauboussin comments that we are fooled by randomness: The problem goes beyond the inscrutable nature of complex adaptive systems. Humans have a deep desire to understand cause and effect, as such links probably conferred humans with evolutionary advantage. In complex adaptive systems, there is no simple method for understanding the whole by studying the parts, so searching for simple agent-level causes of system-level effects is useless. Yet our minds are not beyond making up a cause to relieve the itch of an unexplained effect. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "Making Decisions in a Complex Adaptive System",
					"article_url": "https://fs.blog/decisions-complex-adaptive-system/",
					"content": "When a mind seeking links between cause and effect meets a system that conceals them, accidents will happen.  Misplaced Focus on the Individual One mistake we make is extrapolating the behaviour of an individual component, say an individual, to explain the entire system. Yet when we have to solve a problem dealing with a complex system, we often address an individual component. In so doing, we ignore Garrett Hardin’s first law of Ecology, you can never do merely one thing and become a fragilista. That unintended system-level consequences arise from even the best-intentioned individual-level actions has long been recognized. But the decision-making challenge remains for a couple of reasons. First, our modern world has more interconnected systems than before. So we encounter these systems with greater frequency and, most likely, with greater consequence. Second, we still attempt to cure problems in complex systems with a nave understanding of cause and effect. ",
					"content_token": 194,
					"embedding": []
				},
				{
					"article_title": "Making Decisions in a Complex Adaptive System",
					"article_url": "https://fs.blog/decisions-complex-adaptive-system/",
					"content": " When I speak with executives from around the world going through a period of poor performance, it doesn’t take long for them to mention they want to hire a star from another company. “If only we had Kate,” they’ll say, “we could smash the competition and regain our footing.” At first, poaching stars from competitors or even teams within the same organization seems like a winning strategy. But once the star comes over the results often fail to materialize. What we fail to grasp is that their performance is part of an ecosystem and removing them from that ecosystem  that is isolating the individual performance  is incredibly hard without properly considering the entire ecosystem. Reversion to the mean also likely accounts for some of the star’s fading as well. ",
					"content_token": 162,
					"embedding": []
				},
				{
					"article_title": "Making Decisions in a Complex Adaptive System",
					"article_url": "https://fs.blog/decisions-complex-adaptive-system/",
					"content": "Three Harvard professors concluded, “When a company hires a star, the star’s performance plunges, there is a sharp decline in the functioning of the group or team the person works with, and the company’s market value falls.” If it sounds like a lot of work to think this through at many levels, it should be. Why should it be easy? Another example of this at an organizational level has to do with innovation. Most people want to solve the innovation problem. Ignoring for a second that that is the improper framing, how do most organizations go about this? They copy what the most successful organizations do. I can’t count the number of times the solution to an organization’s “innovation problem” is to be more like Google. Well-intentioned executives blindly copy approaches by others such as 20 innovation time, without giving an ounce of thought to the role the ecosystem plays. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "Making Decisions in a Complex Adaptive System",
					"article_url": "https://fs.blog/decisions-complex-adaptive-system/",
					"content": "Isolating and focusing on an individual part of a complex adaptive system without an appreciation and understanding of that system itself is sure to lead to disaster.  What Should We Do? So this begs the question, what should we do when we find ourselves dealing with a complex adaptive system? Mauboussin provides three pieces of advice: 1. Consider the system at the correct level. Remember the phrase “more is different.” The most prevalent trap is extrapolating the behavior of individual agents to gain a sense of system behavior. If you want to understand the stock market, study it at the market level. Consider what you see and read from individuals as entertainment, not as education. Similarly, be aware that the function of an individual agent outside the system may be very different from that function within the system. For instance, mammalian cells have the same metabolic rates in vitro, whether they are from shrews or elephants. ",
					"content_token": 188,
					"embedding": []
				},
				{
					"article_title": "Making Decisions in a Complex Adaptive System",
					"article_url": "https://fs.blog/decisions-complex-adaptive-system/",
					"content": "But the metabolic rate of cells in small mammals is much higher than the rate of those in large mammals. The same structural cells work at different rates, depending on the animals they find themselves in. 2. Watch for tightly coupled systems.  A system is tightly coupled when there is no slack between items, allowing a process to go from one stage to the next without any opportunity to intervene. Aircraft, space missions, and nuclear power plants are classic examples of complex, tightly coupled systems. Engineers try to build in buffers or redundancies to avoid failure, but frequently don’t anticipate all possible contingencies. Most complex adaptive systems are loosely coupled, where removing or incapacitating one or a few agents has little impact on the system’s performance. For example, if you randomly remove some investors, the stock market will continue to function fine. But when the agents lose diversity and behave in a coordinated fashion, a complex adaptive system can behave in a tightly coupled fashion. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "Making Decisions in a Complex Adaptive System",
					"article_url": "https://fs.blog/decisions-complex-adaptive-system/",
					"content": "Booms and crashes in financial markets are an illustration. 3. Use simulations to create virtual worlds. Dealing with complex systems is inherently tricky because the feedback is equivocal, information is limited, and there is no clear link between cause and effect. Simulation is a tool that can help our learning process. Simulations are low cost, provide feedback, and have proved their value in other domains like military planning and pilot training. Still Curious? Think Twice: Harnessing the Power of Counterintuition.",
					"content_token": 103,
					"embedding": []
				}
			]
		},
		{
			"title": "Billy Beane on Making Better Decisions, Challenging Entrenched Thinking, and Avoiding Biases",
			"url": "https://fs.blog/billy-beane-making-better-decisions/",
			"content": "Billy Beane was put in the spotlight when Brad Pitt played him in the movie rendition of Moneyball: The Art of Winning an Unfair Game. Sports fans, however, knew long before Moneyball that Beane was special. He’s the guy credited with taking a low budget team and turning them around by challenging the fundamental notions of a sport that had been around 150 years. In a fascinating interview given on stage at the RSA conference in April 2015, Beane offered advice on how to make good decisions by challenging organizational norms, effectively using data, and avoiding biases. When asked about pushing through entrenched thinking, Beane replied: I sort of represented that entrenched thinking in some respect, because I was the guy who came up in the business – a business that was 150 years old – as a former player. Quite frankly, I had a great mentor, a gentleman who didn’t come up in the industry, in Sandy Alderson. When I hired, I made sure I looked outside at somebody who didn’t have the experience bias with my first, and maybe even one of the best hires I ever had was Paul DePodesta, who was a Harvard Econ major, didn’t play sports, and really, was able to come in and look at things with an eye that wasn’t biased. We also took ideas from people outside the industry, guys like Bill James and Sean Cook and applied them. On how biases creep into our thought process no matter how old we are or in what industry we operate, Beane commented on taking the emotion out of the decision-making process and making it more rational. Your own experiences, particularly in sports, where that experience may also be tied to an emotion as well, you tend to say, in football or soccer, in soccer there’s a goal, and not all goals are created in terms of how you emotionally react to them. Baseball’s a little bit the same way. So you kind of have to take a blind eye and look at things from the start and not make assumptions. For us, we ultimately wanted to take all the emotion out of our decision making, and that came, many times, with your own experience. One way to do that is to let data help you make decisions. But data is everywhere and cheap. How can we leverage data analytics and extract meaningful information? On this Beane advocates an approach that makes sure you have cognitive diversity in the room – in other words, people that wouldn’t normally be there. The book was really based on public information, as I said. Bill James had been writing for years, but because they didn’t come up in the industry, it really was never applied. Again, sports is very emotional. Very much, you have to come pass the eye test. What we wanted to do was make sure our eyes weren’t fooling us. As far as today, the game and sports has changed dramatically. In fact, looking at the book now, it feels like you’re watching an episode of “The Flintstones” a little bit when you see some of this stuff. The only thing that I haven’t changed is making sure that I bring in guys that normally wouldn’t be in this room. The advantage I have is I have access to intellectual capital that normally would be in this room, but want to work for a sports team. We have access to data, everything  was being measured, thrown into this huge vat of data, and it’s up to my staff to sift through what has relevance and which doesn’t as it applies to predicting player performance. One of the keys to looking at data is to bring different lenses to it to gain insight. You also need to put processes and systems in place with respective feedback loops to make sure you’re not a suckerthat is, you can distinguish between luck and skill. You’re constantly evaluating. Sometimes, even when you have success, there’s an assumption that that success was based on your process. Actually, you’re always analyzing your process, making sure that the reason you weren’t correct wasn’t through serendipity, but the reason was because you have a good process and you’re doing things properly. It’s challenging because the business of sports has become very, very intelligent. Baseball teams, football teams, basketball teams, they’re all using this, and hiring, once again, guys that normally would probably be in this room. The world is always changing as its a dynamic system. Your processes need to be adaptive. Static processes in a dynamic world lead to extinction. There’s so many variables in sports, too. We try and quantify things that you don’t think you can quantify, things that peopleOnce again, when you talk about challenging assumptions, things that people assume can’t be quantified. You try and quantify them so, at least, you’re creating a process that, more than anything, when you are right or wrong, you can at least go back and look and see why you were right or wrong, similar to a mathematical equation. Beane found a way to challenge assumptions and in so doing gain insight that he had the courage and authority to put into practice. How did he change the way things were done? Well, sometimes you don’t. Early on in our process, we lost employees because there certainly wasn’t a belief. Now, understand, when we started out we had a great platform. We were challenged from revenue standpoint, so it was an opportunity in some sense, and we really had no other way to operate. Through the course of doing things this way, we certainly lost people, but in the same sense, another year later we would gain two more people who were interested in going down this road. For us, it was rational. It made sense, and we really had no other choice. But, as Keynes so aptly put it “Worldly wisdom teaches us that it is better for the reputation to fail conventionally than to succeed unconventionally.” And that path was not a linear story to success. There were moments when he doubted himself and operating in a cut-throat industry probably didn’t make things easier. All eyes were on him. Was there pressure to go back to the way things were always done? Unfortunately, probably for some A’s fans. They probably doubted me more than I did. I think the one thing about the process, it was like a math equation. At least we knew why we were doing something. Our other option, to us, didn’t make much sense. Certainly, you’re hoping you’re going in the right direction, and the assumption is that you are. We felt like that was the best road that we could travel. I think, if anything, we certainly didn’t fear failure, because we felt like going a traditional path was certainly the surest of failure, based on our revenues and the payroll that we were on. We had a lot of autonomy, too. Autonomy within, we were given a budget. The only limitations we had in terms of our intellectual curiosity was really making sure we stayed in the budget our ownership gave us. “Listen, hey, do what you want to do, but make sure you stay within the lines a little bit.” But again, the fearWe knew going down another subjective path, we were certain to fail. We weren’t going to consistently put something together that was on a year by year basis. The fear of going that route, there was greater fear going that route than going an objective route. As a leader, it was Beane’s job to make sure the strategy they were using to find under-rated players was embedded throughout the organization. At times it was challenging, because we hired some reallyI was a former baseball player, and a lot of guys who had come up in the business, the guys we were bringing in were guys with PhDs in behavioral economics and Harvard masters in statistics, and things like that. Bridging that gap initially was challenging because most, certainly a baseball player like myself, my default position isn’t to run a regression log. We operate in a world with tremendous amounts of data and information, but we’re not challenging the platform that we’re starting with to the extent we should be. Even with a very young and progressive group of thinkers that are around me,  with a little bit of experience, you will always start at a platform that you assume to be true based on previous success. We always have to analyze our foundation because very quickly a culture and a tradition of doing things can get ingrained in a very short period of time. If you assume from a false platform that you’re correct, you can go really awry. For us, it is constantlyAlso, not being wrapped up in your own hubris with success and understanding that even with an objective based decision making, you are not going to be right 100 percent of the time. ",
			"tokens": 1904,
			"chunks": [
				{
					"article_title": "Billy Beane on Making Better Decisions, Challenging Entrenched Thinking, and Avoiding Biases",
					"article_url": "https://fs.blog/billy-beane-making-better-decisions/",
					"content": "Billy Beane was put in the spotlight when Brad Pitt played him in the movie rendition of Moneyball: The Art of Winning an Unfair Game. Sports fans, however, knew long before Moneyball that Beane was special. He’s the guy credited with taking a low budget team and turning them around by challenging the fundamental notions of a sport that had been around 150 years. In a fascinating interview given on stage at the RSA conference in April 2015, Beane offered advice on how to make good decisions by challenging organizational norms, effectively using data, and avoiding biases. When asked about pushing through entrenched thinking, Beane replied: I sort of represented that entrenched thinking in some respect, because I was the guy who came up in the business – a business that was 150 years old – as a former player. Quite frankly, I had a great mentor, a gentleman who didn’t come up in the industry, in Sandy Alderson. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "Billy Beane on Making Better Decisions, Challenging Entrenched Thinking, and Avoiding Biases",
					"article_url": "https://fs.blog/billy-beane-making-better-decisions/",
					"content": "When I hired, I made sure I looked outside at somebody who didn’t have the experience bias with my first, and maybe even one of the best hires I ever had was Paul DePodesta, who was a Harvard Econ major, didn’t play sports, and really, was able to come in and look at things with an eye that wasn’t biased. We also took ideas from people outside the industry, guys like Bill James and Sean Cook and applied them. On how biases creep into our thought process no matter how old we are or in what industry we operate, Beane commented on taking the emotion out of the decision-making process and making it more rational. Your own experiences, particularly in sports, where that experience may also be tied to an emotion as well, you tend to say, in football or soccer, in soccer there’s a goal, and not all goals are created in terms of how you emotionally react to them. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "Billy Beane on Making Better Decisions, Challenging Entrenched Thinking, and Avoiding Biases",
					"article_url": "https://fs.blog/billy-beane-making-better-decisions/",
					"content": "Baseball’s a little bit the same way. So you kind of have to take a blind eye and look at things from the start and not make assumptions. For us, we ultimately wanted to take all the emotion out of our decision making, and that came, many times, with your own experience. One way to do that is to let data help you make decisions. But data is everywhere and cheap. How can we leverage data analytics and extract meaningful information? On this Beane advocates an approach that makes sure you have cognitive diversity in the room – in other words, people that wouldn’t normally be there. The book was really based on public information, as I said. Bill James had been writing for years, but because they didn’t come up in the industry, it really was never applied. Again, sports is very emotional. Very much, you have to come pass the eye test. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "Billy Beane on Making Better Decisions, Challenging Entrenched Thinking, and Avoiding Biases",
					"article_url": "https://fs.blog/billy-beane-making-better-decisions/",
					"content": "What we wanted to do was make sure our eyes weren’t fooling us. As far as today, the game and sports has changed dramatically. In fact, looking at the book now, it feels like you’re watching an episode of “The Flintstones” a little bit when you see some of this stuff. The only thing that I haven’t changed is making sure that I bring in guys that normally wouldn’t be in this room. The advantage I have is I have access to intellectual capital that normally would be in this room, but want to work for a sports team. We have access to data, everything  was being measured, thrown into this huge vat of data, and it’s up to my staff to sift through what has relevance and which doesn’t as it applies to predicting player performance. One of the keys to looking at data is to bring different lenses to it to gain insight. ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "Billy Beane on Making Better Decisions, Challenging Entrenched Thinking, and Avoiding Biases",
					"article_url": "https://fs.blog/billy-beane-making-better-decisions/",
					"content": "You also need to put processes and systems in place with respective feedback loops to make sure you’re not a suckerthat is, you can distinguish between luck and skill. You’re constantly evaluating. Sometimes, even when you have success, there’s an assumption that that success was based on your process. Actually, you’re always analyzing your process, making sure that the reason you weren’t correct wasn’t through serendipity, but the reason was because you have a good process and you’re doing things properly. It’s challenging because the business of sports has become very, very intelligent. Baseball teams, football teams, basketball teams, they’re all using this, and hiring, once again, guys that normally would probably be in this room. The world is always changing as its a dynamic system. Your processes need to be adaptive. Static processes in a dynamic world lead to extinction. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "Billy Beane on Making Better Decisions, Challenging Entrenched Thinking, and Avoiding Biases",
					"article_url": "https://fs.blog/billy-beane-making-better-decisions/",
					"content": "There’s so many variables in sports, too. We try and quantify things that you don’t think you can quantify, things that peopleOnce again, when you talk about challenging assumptions, things that people assume can’t be quantified. You try and quantify them so, at least, you’re creating a process that, more than anything, when you are right or wrong, you can at least go back and look and see why you were right or wrong, similar to a mathematical equation. Beane found a way to challenge assumptions and in so doing gain insight that he had the courage and authority to put into practice. How did he change the way things were done? Well, sometimes you don’t. Early on in our process, we lost employees because there certainly wasn’t a belief. Now, understand, when we started out we had a great platform. ",
					"content_token": 186,
					"embedding": []
				},
				{
					"article_title": "Billy Beane on Making Better Decisions, Challenging Entrenched Thinking, and Avoiding Biases",
					"article_url": "https://fs.blog/billy-beane-making-better-decisions/",
					"content": "We were challenged from revenue standpoint, so it was an opportunity in some sense, and we really had no other way to operate. Through the course of doing things this way, we certainly lost people, but in the same sense, another year later we would gain two more people who were interested in going down this road. For us, it was rational. It made sense, and we really had no other choice. But, as Keynes so aptly put it “Worldly wisdom teaches us that it is better for the reputation to fail conventionally than to succeed unconventionally.” And that path was not a linear story to success. There were moments when he doubted himself and operating in a cut-throat industry probably didn’t make things easier. All eyes were on him. Was there pressure to go back to the way things were always done? Unfortunately, probably for some A’s fans. They probably doubted me more than I did. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "Billy Beane on Making Better Decisions, Challenging Entrenched Thinking, and Avoiding Biases",
					"article_url": "https://fs.blog/billy-beane-making-better-decisions/",
					"content": "I think the one thing about the process, it was like a math equation. At least we knew why we were doing something. Our other option, to us, didn’t make much sense. Certainly, you’re hoping you’re going in the right direction, and the assumption is that you are. We felt like that was the best road that we could travel. I think, if anything, we certainly didn’t fear failure, because we felt like going a traditional path was certainly the surest of failure, based on our revenues and the payroll that we were on. We had a lot of autonomy, too. Autonomy within, we were given a budget. The only limitations we had in terms of our intellectual curiosity was really making sure we stayed in the budget our ownership gave us. ",
					"content_token": 168,
					"embedding": []
				},
				{
					"article_title": "Billy Beane on Making Better Decisions, Challenging Entrenched Thinking, and Avoiding Biases",
					"article_url": "https://fs.blog/billy-beane-making-better-decisions/",
					"content": "“Listen, hey, do what you want to do, but make sure you stay within the lines a little bit.” But again, the fearWe knew going down another subjective path, we were certain to fail. We weren’t going to consistently put something together that was on a year by year basis. The fear of going that route, there was greater fear going that route than going an objective route. As a leader, it was Beane’s job to make sure the strategy they were using to find under-rated players was embedded throughout the organization. At times it was challenging, because we hired some reallyI was a former baseball player, and a lot of guys who had come up in the business, the guys we were bringing in were guys with PhDs in behavioral economics and Harvard masters in statistics, and things like that. ",
					"content_token": 176,
					"embedding": []
				},
				{
					"article_title": "Billy Beane on Making Better Decisions, Challenging Entrenched Thinking, and Avoiding Biases",
					"article_url": "https://fs.blog/billy-beane-making-better-decisions/",
					"content": "Bridging that gap initially was challenging because most, certainly a baseball player like myself, my default position isn’t to run a regression log. We operate in a world with tremendous amounts of data and information, but we’re not challenging the platform that we’re starting with to the extent we should be. Even with a very young and progressive group of thinkers that are around me,  with a little bit of experience, you will always start at a platform that you assume to be true based on previous success. We always have to analyze our foundation because very quickly a culture and a tradition of doing things can get ingrained in a very short period of time. If you assume from a false platform that you’re correct, you can go really awry. ",
					"content_token": 162,
					"embedding": []
				},
				{
					"article_title": "Billy Beane on Making Better Decisions, Challenging Entrenched Thinking, and Avoiding Biases",
					"article_url": "https://fs.blog/billy-beane-making-better-decisions/",
					"content": "For us, it is constantlyAlso, not being wrapped up in your own hubris with success and understanding that even with an objective based decision making, you are not going to be right 100 percent of the time.",
					"content_token": 43,
					"embedding": []
				}
			]
		},
		{
			"title": "How Situations Influence Decisions",
			"url": "https://fs.blog/how-situations-influence-decisions/",
			"content": "Michael Mauboussin, the first guest on our podcast, The Knowledge Project, explains how our situations influence our decisions enormously in Think Twice: Harnessing the Power of Counterintuition. Mistakes born out of situations are difficult to avoid, in part because the influences on us are operating at a subconscious level. “Making good decisions in the face of subconscious pressure,” Mauboussin writes, “requires a very high degree of background knowledge and self-awareness.” How do you feel when you read the word “treasure”? Do you feel good? What images come to mind? If you are like most people, just ruminating on “treasure” gives you a little lift. Our minds naturally make connections and associate ideas. So if someone introduces a cue to you a word, a smell, a symbol your mind often starts down an associative path. And you can be sure the initial cue will color a decision that waits at the path’s end. All this happens outside of your perception. People around us also influence our decisions, often with good reason. Social influence arises for a couple of reasons. The first is asymmetric information, a fancy phrase meaning someone knows something you don’t. In those cases, imitation makes sense because the information upgrade allows you to make better decisions. Peer pressure, or the desire to be part of the in-group, is a second source of social influence. For good evolutionary reasons, humans like to be part of a group a collection of interdependent individuals and naturally spend a good deal of time assessing who is “in” and who is “out.” Experiments in social psychology have repeatedly confirmed this. We explain behavior based on an individual’s choices and disposition and not the situation. That is, we associate bad behavior with the person and not the situation. Unless, of course, we’re talking about ourselves. This is “the fundamental attribution error”, a phrase coined by Lee Ross, a social psychologist at Stanford University. There are two sides to this sword as the power of situations can work for good and evil. “Some of the greatest atrocities known to mankind,” Mauboussin writes, “resulted from putting normal people into bad situations.” We believe our choices are independent of circumstance, however, the evidence points in another direction. Some Wine With Your Music? Consider how something as simple as the music playing in a store influences what wine we purchase. Imagine strolling down the supermarket aisle and coming upon a display of French and German wines, roughly matched for price and quality. You do some quick comparisons, place a German wine in your cart, and continue shopping. After you check out, a researcher approaches and asks why you bought the German wine. You mention the price, the wine’s dryness, and how you anticipate it will go nicely with a meal you are planning. The researcher then asks whether you noticed German music playing and whether it had any bearing on your decision. Like most, you would acknowledge hearing the music and avow that it had nothing to do with your selection. But this isn’t a hypothetical, it’s an actual study and the results affirm that the environment influences our decisions. In this test, the researchers placed the French and German wines next to each other, along with small national flags. Over two weeks, the scientists alternated playing French accordion music and German Bierkeller pieces and watched the results. When French music played, French wines represented 77 percent of the sales. When German music played, consumers selected German wines 73 percent of the time. See the image below The music made a huge difference in shaping purchases. But that’s not what the shoppers thought. While the customers acknowledged that the music made them think of either France or Germany, 86 percent denied the tunes had any influence on their choice.  This is an example of priming, which psychologists formally define as “the incidental activation of knowledge structures by the current situational context.”1 and priming happens all the time. For priming to be most effective it must have a strong connection to our situation’s goals. Another example of how situations influence us is the default. In a fast moving world of non-stop bits and bytes the default is the path of least resistance  that is, it’s the system one option. To move away from the default is labor-intensive on our brains. Studies have repeatedly shown that most people go with defaults. This applies to a wide array of choices, from insignificant issues like the ringtone on a new cell phone to consequential issues like financial savings, educational choice, and medical alternatives. Richard Thaler, an economist, and Cass Sunstein, a law professor, call the relationship between choice presentation and the ultimate decision “choice architecture.” They convincingly argue that we can easily nudge people toward a particular decision based solely on how we arrange the choices for them. One context for decision making is how choices are structured. Knowing that many people opt for the default option, we can influence for better or worse large groups of people. Mauboussin relates a story about a prominent psychologist popular on the speaking circuit that “underscores how underappreciated choice architecture remains.” When companies call to invite him to speak, he offers them two choices. Either they can pay him his set fee and get a standard presentation, or they can pay him nothing in exchange for the opportunity to work with him on an experiment to improve choice architecture e.g., redesign a form or Web site. Of course, the psychologist benefits by getting more real-world results on choice architecture, but it seems like a pretty good deal for the company as well, because an improved architecture might translate into financial benefits vastly in excess of his speaking fee. He noted ruefully that so far not one company has taken him up on his experiment offer. As a brief aside, I engage in public speaking on a fairly regular basis. I’ve toyed with similar ideas. Once I even went as far as offering to speak for no pre-set fee, only “value added” as judged by the client. They opted for the fee. Another great example of how environments affect behavior is Stanley Milgram’s famous experiment on obedience to authority. “Ordinary people, simply doing their jobs, and without any particular hostility on their part, can become agents in a terrible destructive process,” wrote Stanley Milgram.  quoteSituations are generally more powerful than we thinkquote The key point is that situations are generally more powerful than we think and we can do things to resist the pull of “unwelcome social influence.” Mauboussin offers four tips: 1. Be aware of your situation. You can think of this in two parts. There is the conscious element, where you can create a positive environment for decision making in your own surroundings by focusing on process, keeping stress to an acceptable level, being a thoughtful choice architect, and making sure to diffuse the forces that encourage negative behaviors. Then there is coping with the subconscious influences. Control over these influences requires awareness of the influence, motivation to deal with it, and the willingness to devote attention to address possible poor decisions. In the real world, satisfying all three control conditions is extremely difficult, but the path starts with awareness. 2. Consider the situation first and the individual second. This concept, called attributional charity, insists that you evaluate the decisions of others by starting with the situation and then turning to the individuals, not the other way around. While easier for Easterners than Westerners, most of us consistently underestimate the role of the situation in assessing the decisions we see others make. Try not to make the fundamental attribution error. 3. Watch out for the institutional imperative. Warren Buffett, the celebrated investor and chairman of Berkshire Hathaway, coined the term institutional imperative to explain the tendency of organizations to “mindlessly” imitate what peers are doing. There are typically two underlying drivers of the imperative. First, companies want to be part of the in-group, much as individuals do. So if some companies in an industry are doing mergers, chasing growth, or expanding geographically, others will be tempted to follow. Second are incentives. Executives often reap financial rewards by following the group. When decision makers make money from being part of the crowd, the draw is nearly inescapable. One example comes from a Financial Times interview with the former chief executive officer of Citigroup Chuck Prince in 2007, before the brunt of the financial crisis. “When the music stops, things will be complicated,” offered Prince, demonstrating that he had some sense of what was to come. “But as long as the music is playing, you’ve got to get up and dance.” The institutional imperative is rarely a good dance partner. 4. Avoid inertia. Periodically revisit your processes and ask whether they are serving their purpose. Organizations sometimes adopt routines and structures that become crystallized, impeding positive change. Efforts to reform education in the United States, for example, have been met with resistance from teachers and administrators who prefer the status quo. We like to think that we’re better than the situation, that we follow the decision-making process and rationally weigh the facts, consider alternatives, and determine the best course of action. While others are easily influenced, we are not. This is how we’re wrong. Decision making is fundamentally a social exercise, something I cover in my Re:Think Decision Making workshop. 1. “Automaticity of Social Behavior: Direct Effects of Trait Construction and Stereotype Activation on Action” ",
			"tokens": 2004,
			"chunks": [
				{
					"article_title": "How Situations Influence Decisions",
					"article_url": "https://fs.blog/how-situations-influence-decisions/",
					"content": "Michael Mauboussin, the first guest on our podcast, The Knowledge Project, explains how our situations influence our decisions enormously in Think Twice: Harnessing the Power of Counterintuition. Mistakes born out of situations are difficult to avoid, in part because the influences on us are operating at a subconscious level. “Making good decisions in the face of subconscious pressure,” Mauboussin writes, “requires a very high degree of background knowledge and self-awareness.” How do you feel when you read the word “treasure”? Do you feel good? What images come to mind? If you are like most people, just ruminating on “treasure” gives you a little lift. Our minds naturally make connections and associate ideas. So if someone introduces a cue to you a word, a smell, a symbol your mind often starts down an associative path. ",
					"content_token": 188,
					"embedding": []
				},
				{
					"article_title": "How Situations Influence Decisions",
					"article_url": "https://fs.blog/how-situations-influence-decisions/",
					"content": "And you can be sure the initial cue will color a decision that waits at the path’s end. All this happens outside of your perception. People around us also influence our decisions, often with good reason. Social influence arises for a couple of reasons. The first is asymmetric information, a fancy phrase meaning someone knows something you don’t. In those cases, imitation makes sense because the information upgrade allows you to make better decisions. Peer pressure, or the desire to be part of the in-group, is a second source of social influence. For good evolutionary reasons, humans like to be part of a group a collection of interdependent individuals and naturally spend a good deal of time assessing who is “in” and who is “out.” Experiments in social psychology have repeatedly confirmed this. We explain behavior based on an individual’s choices and disposition and not the situation. That is, we associate bad behavior with the person and not the situation. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "How Situations Influence Decisions",
					"article_url": "https://fs.blog/how-situations-influence-decisions/",
					"content": "Unless, of course, we’re talking about ourselves. This is “the fundamental attribution error”, a phrase coined by Lee Ross, a social psychologist at Stanford University. There are two sides to this sword as the power of situations can work for good and evil. “Some of the greatest atrocities known to mankind,” Mauboussin writes, “resulted from putting normal people into bad situations.” We believe our choices are independent of circumstance, however, the evidence points in another direction. Some Wine With Your Music? Consider how something as simple as the music playing in a store influences what wine we purchase. Imagine strolling down the supermarket aisle and coming upon a display of French and German wines, roughly matched for price and quality. You do some quick comparisons, place a German wine in your cart, and continue shopping. After you check out, a researcher approaches and asks why you bought the German wine. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "How Situations Influence Decisions",
					"article_url": "https://fs.blog/how-situations-influence-decisions/",
					"content": "You mention the price, the wine’s dryness, and how you anticipate it will go nicely with a meal you are planning. The researcher then asks whether you noticed German music playing and whether it had any bearing on your decision. Like most, you would acknowledge hearing the music and avow that it had nothing to do with your selection. But this isn’t a hypothetical, it’s an actual study and the results affirm that the environment influences our decisions. In this test, the researchers placed the French and German wines next to each other, along with small national flags. Over two weeks, the scientists alternated playing French accordion music and German Bierkeller pieces and watched the results. When French music played, French wines represented 77 percent of the sales. When German music played, consumers selected German wines 73 percent of the time. See the image below The music made a huge difference in shaping purchases. But that’s not what the shoppers thought. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "How Situations Influence Decisions",
					"article_url": "https://fs.blog/how-situations-influence-decisions/",
					"content": "While the customers acknowledged that the music made them think of either France or Germany, 86 percent denied the tunes had any influence on their choice.  This is an example of priming, which psychologists formally define as “the incidental activation of knowledge structures by the current situational context.”1 and priming happens all the time. For priming to be most effective it must have a strong connection to our situation’s goals. Another example of how situations influence us is the default. In a fast moving world of non-stop bits and bytes the default is the path of least resistance  that is, it’s the system one option. To move away from the default is labor-intensive on our brains. Studies have repeatedly shown that most people go with defaults. This applies to a wide array of choices, from insignificant issues like the ringtone on a new cell phone to consequential issues like financial savings, educational choice, and medical alternatives. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "How Situations Influence Decisions",
					"article_url": "https://fs.blog/how-situations-influence-decisions/",
					"content": "Richard Thaler, an economist, and Cass Sunstein, a law professor, call the relationship between choice presentation and the ultimate decision “choice architecture.” They convincingly argue that we can easily nudge people toward a particular decision based solely on how we arrange the choices for them. One context for decision making is how choices are structured. Knowing that many people opt for the default option, we can influence for better or worse large groups of people. Mauboussin relates a story about a prominent psychologist popular on the speaking circuit that “underscores how underappreciated choice architecture remains.” When companies call to invite him to speak, he offers them two choices. Either they can pay him his set fee and get a standard presentation, or they can pay him nothing in exchange for the opportunity to work with him on an experiment to improve choice architecture e.g., redesign a form or Web site. ",
					"content_token": 188,
					"embedding": []
				},
				{
					"article_title": "How Situations Influence Decisions",
					"article_url": "https://fs.blog/how-situations-influence-decisions/",
					"content": "Of course, the psychologist benefits by getting more real-world results on choice architecture, but it seems like a pretty good deal for the company as well, because an improved architecture might translate into financial benefits vastly in excess of his speaking fee. He noted ruefully that so far not one company has taken him up on his experiment offer. As a brief aside, I engage in public speaking on a fairly regular basis. I’ve toyed with similar ideas. Once I even went as far as offering to speak for no pre-set fee, only “value added” as judged by the client. They opted for the fee. Another great example of how environments affect behavior is Stanley Milgram’s famous experiment on obedience to authority. “Ordinary people, simply doing their jobs, and without any particular hostility on their part, can become agents in a terrible destructive process,” wrote Stanley Milgram. ",
					"content_token": 189,
					"embedding": []
				},
				{
					"article_title": "How Situations Influence Decisions",
					"article_url": "https://fs.blog/how-situations-influence-decisions/",
					"content": " quoteSituations are generally more powerful than we thinkquote The key point is that situations are generally more powerful than we think and we can do things to resist the pull of “unwelcome social influence.” Mauboussin offers four tips: 1. Be aware of your situation. You can think of this in two parts. There is the conscious element, where you can create a positive environment for decision making in your own surroundings by focusing on process, keeping stress to an acceptable level, being a thoughtful choice architect, and making sure to diffuse the forces that encourage negative behaviors. Then there is coping with the subconscious influences. Control over these influences requires awareness of the influence, motivation to deal with it, and the willingness to devote attention to address possible poor decisions. In the real world, satisfying all three control conditions is extremely difficult, but the path starts with awareness. 2. Consider the situation first and the individual second. ",
					"content_token": 189,
					"embedding": []
				},
				{
					"article_title": "How Situations Influence Decisions",
					"article_url": "https://fs.blog/how-situations-influence-decisions/",
					"content": "This concept, called attributional charity, insists that you evaluate the decisions of others by starting with the situation and then turning to the individuals, not the other way around. While easier for Easterners than Westerners, most of us consistently underestimate the role of the situation in assessing the decisions we see others make. Try not to make the fundamental attribution error. 3. Watch out for the institutional imperative. Warren Buffett, the celebrated investor and chairman of Berkshire Hathaway, coined the term institutional imperative to explain the tendency of organizations to “mindlessly” imitate what peers are doing. There are typically two underlying drivers of the imperative. First, companies want to be part of the in-group, much as individuals do. So if some companies in an industry are doing mergers, chasing growth, or expanding geographically, others will be tempted to follow. Second are incentives. Executives often reap financial rewards by following the group. ",
					"content_token": 188,
					"embedding": []
				},
				{
					"article_title": "How Situations Influence Decisions",
					"article_url": "https://fs.blog/how-situations-influence-decisions/",
					"content": "When decision makers make money from being part of the crowd, the draw is nearly inescapable. One example comes from a Financial Times interview with the former chief executive officer of Citigroup Chuck Prince in 2007, before the brunt of the financial crisis. “When the music stops, things will be complicated,” offered Prince, demonstrating that he had some sense of what was to come. “But as long as the music is playing, you’ve got to get up and dance.” The institutional imperative is rarely a good dance partner. 4. Avoid inertia. Periodically revisit your processes and ask whether they are serving their purpose. Organizations sometimes adopt routines and structures that become crystallized, impeding positive change. Efforts to reform education in the United States, for example, have been met with resistance from teachers and administrators who prefer the status quo. ",
					"content_token": 177,
					"embedding": []
				},
				{
					"article_title": "How Situations Influence Decisions",
					"article_url": "https://fs.blog/how-situations-influence-decisions/",
					"content": "We like to think that we’re better than the situation, that we follow the decision-making process and rationally weigh the facts, consider alternatives, and determine the best course of action. While others are easily influenced, we are not. This is how we’re wrong. Decision making is fundamentally a social exercise, something I cover in my Re:Think Decision Making workshop. 1. “Automaticity of Social Behavior: Direct Effects of Trait Construction and Stereotype Activation on Action”",
					"content_token": 106,
					"embedding": []
				}
			]
		},
		{
			"title": "Simple Rules: How to Thrive in a Complex World",
			"url": "https://fs.blog/simple-rules/",
			"content": " “Simple rules are shortcut strategies that save time and effort by focusing our attention and simplifying the way we process information. The rules aren’t universal they’re tailored to the particular situation and the person using them.”  We use simple rules to guide decision making every day. In fact, without them, we’d be paralyzed by the sheer mental brainpower required to sift through the complicated messiness of our world. You can think of them as heuristics. Like heuristics, most of the time they work yet some of the time they don’t. Simple Rules: How to Thrive in a Complex World, a book by Donald Sull and Kathleen Eisenhardt, explores the understated power that comes from using simple rules. As they define them, simple rules refer to “a handful of guidelines tailored to the user and the task at hand, which balance concrete guidance with the freedom to exercise judgment.” These rules “provide a powerful weapon against the complexity that threatens to overwhelm individuals, organizations, and society as a whole. Complexity arises whenever a system technical, social, or natural has multiple interdependent parts.” They work, the authors argue, because they do three things well. First, they confer the flexibility to pursue new opportunities while maintaining some consistency. Second, they can produce better decisions. When information is limited and time is short, simple rules make it fast and easy for people, organizations, and governments to make sound choices. They can even outperform complicated decision-making approaches in some situations. Finally, simple rules allow the members of a community to synchronize their activities with one another on the fly. Effective simple rules share four common traits  First, they are limited to a handful. Capping the number of rules makes them easy to remember and maintains a focus on what matters most. Second, simple rules are tailored to the person or organization using them. College athletes and middle-aged dieters may both rely on simple rules to decide what to eat, but their rules will be very different. Third, simple rules apply to a well-defined activity or decision, such as prioritizing injured soldiers for medical care. Rules that cover multiple activities or choices end up as vague platitudes, such as “Do your best” and “Focus on customers.” Finally, simple rules provide clear guidance while conferring the latitude to exercise discretion. Simple Rules for a Complex World People often attempt to address complex problems with complex solutions. For example, governments tend to manage complexity by trying to anticipate every possible scenario that might arise, and then promulgate regulations to cover every case. Consider how central bankers responded to increased complexity in the global banking system. In 1988 bankers from around the world met in Basel, Switzerland, to agree on international banking regulations, and published a 30-page agreement known as Basel I. Sixteen years later, the Basel II accord was an order of magnitude larger, at 347 pages, and Basel III was twice as long as its predecessor. When it comes to the sheer volume of regulations generated, the U.S. Congress makes the central bankers look like amateurs. The Glass-Steagall Act, a law passed during the Great Depression, which guided U.S. banking regulation for seven decades, totaled 37 pages. Its successor, Dodd-Frank, is expected to weigh in at over 30,000 pages when all supporting legislation is complete. Meeting complexity with complexity can create more confusion than it resolves. The policies governing U.S. income taxes totaled 3.8 million words as of 2010. Imagine a book that is seven times as long as War and Peace, but without any characters, plot points, or insight into the human condition. That book is the U.S. tax code.  Applying complicated solutions to complex problems is an understandable approach, but flawed. The parts of a complex system can interact with one another in many different ways, which quickly overwhelms our ability to envision all possible outcomes.  Complicated solutions can overwhelm people, thereby increasing the odds that they will stop following the rules. A study of personal income tax compliance in forty-five countries found that the complexity of the tax code was the single best predictor of whether citizens would dodge or pay their taxes. The complexity of the regulations mattered more than the highest marginal tax rate, average levels of education or income, how fair the tax system was perceived to be, and the level of government scrutiny of tax returns. Simple Rules Focus on the Critical Variables Simple rules do not trump complicated ones all the time but they work more often than we think. Gerd Gigerenzer is a key contributor in this space. He thinks that simple rules can allow for better decision making. Why can simpler models outperform more complex ones? When underlying cause-and-effect relationships are poorly understood, decision makers often look for patterns in historical data under the assumption that past events are a good indicator of future trends. The obvious problem with this approach is that the future may be genuinely different from the past. But a second problem is subtler. Historical data includes not only useful signal, but also noise happenstance correlations between variables that do not reveal an enduring cause-and-effect relationship. Fitting a model too closely to historical data hardwires error into the model, which is known as overfitting. The result is a precise prediction of the past that may tell us little about what the future holds. Simple rules focus on the critical variables that govern a situation and help you ignore the peripheral ones. Of course, in order to identify the key variables, you need to be operating in your circle of competence. When we pay too much attention to irrelevant or otherwise unimportant information, we fail to grasp the power of the most important ones and give them the weighting they deserve. Simple rules also make it more likely people will act on them. This is something Napoleon intuitively understood. When instructing his troops, Napoleon realized that complicated instructions were difficult to understand, explain, and execute. So, rather than complicated strategies he passed along simple ones, such as: Attack. Making Better Decisions The book mentions three types of rules that “improve decision making by structuring choices and centering on what to do and what not to do: boundary, prioritizing, and stopping rules. Boundary Rules cover what to do  Boundary rules guide the choice of what to do and not do without requiring a lot of time, analysis, or information. Boundary rules work well for categorical choices, like a judge’s yes-or-no decision on a defendant’s bail, and decisions requiring many potential opportunities to be screened quickly. These rules also come in handy when time, convenience, and cost matter. Prioritizing rules rank options to help decide which of multiple paths to pursue. Prioritizing rules can help you rank a group of alternatives competing for scarce money, time, or attention.  They are especially powerful when applied to a bottleneck, an activity or decision that keeps individuals or organizations from reaching their objectives. Bottlenecks represent pinch-points in companies, where the number of opportunities swamps available resources, and prioritizing rules can ensure that these resources are deployed where they can have the greatest impact. In business settings, prioritizing rules can be used to assign engineers to new-product-development projects, focus sales representatives on the most promising customers, and allocate advertising expenditure across multiple products, to name only a few possibilities. Stopping rules help you learn when to reverse a decision. Nobel Prize-winning economist Herbert Simon argued that we lack the information, time, and mental engine to determine the single best path when faced with a slew of options. Instead, we rely on a heuristic to help us stop searching when we find something that’s good enough. Simon called this satisficing. If you think that’s hard, it’s even hard to stop doing something we’re already doing. Yet when it comes to our key investments of time, money, and energy we have to know when to pull the plug. Sometimes we pursue goals at all costs and ignore our self-imposed stopping rule. This goal induced blindness can be deadly. A cross-continental team of researchers matched 145 Chicagoans with demographically similar Parisians. Both the Chicagoans and Parisians used stopping rules to decide when to finish eating, but the rules themselves were very different. The Parisians employed rules like “Stop eating when I start feeling full,” linking their decision to internal cues about satiation. The Chicagoans, in contrast, were more likely to follow rules linked to external factors, such as “Stop eating when I run out of a beverage,” or “Stop eating when the TV show I’m watching is over.” Stopping rules that rely on internal cues like when the food stops tasting good or you feel full decrease the odds that people eat more than their body needs or even wants. Stopping rules are particularly critical in situations when people tend to double down on a losing hand. These three decision rulesboundary, prioritizing, and stoppinghelp provide guidelines on what to do”what is acceptable to do, what is more, important to do, and what to stop doing.” Doing Things Better Process rules, in contrast to boundary rules, focus on how to do things better. Process rules work because they steer a middle path between the chaos of too few rules that can result in confusion and mistakes, and the rigidity of so many rules that there is little ability to adapt to the unexpected or take advantage of new opportunities. Simply put, process rules are useful whenever flexibility trumps consistency. The most widely used process rule is the how-to rule. How-to rules guide the basics of executing tasks, from playing golf to designing new products. The other process rules, coordination and timing, are special cases of how-to rules that apply in particular situations. Coordination rules center on getting something done when multiple actors people, organizations, or nations have to work together. These rules orchestrate the behaviors of, for example, schooling fish, Zipcar members, and content contributors at Wikipedia. In contrast, timing rules center on getting things done in situations where temporal factors such as rhythms, sequences, and deadlines are relevant. These rules set the timing of, for example, when to get up every day and when dragonflies migrate. While I was skeptical, the book is well worth reading. I suggest you check it out.",
			"tokens": 2146,
			"chunks": [
				{
					"article_title": "Simple Rules: How to Thrive in a Complex World",
					"article_url": "https://fs.blog/simple-rules/",
					"content": " “Simple rules are shortcut strategies that save time and effort by focusing our attention and simplifying the way we process information. The rules aren’t universal they’re tailored to the particular situation and the person using them.”  We use simple rules to guide decision making every day. In fact, without them, we’d be paralyzed by the sheer mental brainpower required to sift through the complicated messiness of our world. You can think of them as heuristics. Like heuristics, most of the time they work yet some of the time they don’t. Simple Rules: How to Thrive in a Complex World, a book by Donald Sull and Kathleen Eisenhardt, explores the understated power that comes from using simple rules. ",
					"content_token": 160,
					"embedding": []
				},
				{
					"article_title": "Simple Rules: How to Thrive in a Complex World",
					"article_url": "https://fs.blog/simple-rules/",
					"content": "As they define them, simple rules refer to “a handful of guidelines tailored to the user and the task at hand, which balance concrete guidance with the freedom to exercise judgment.” These rules “provide a powerful weapon against the complexity that threatens to overwhelm individuals, organizations, and society as a whole. Complexity arises whenever a system technical, social, or natural has multiple interdependent parts.” They work, the authors argue, because they do three things well. First, they confer the flexibility to pursue new opportunities while maintaining some consistency. Second, they can produce better decisions. When information is limited and time is short, simple rules make it fast and easy for people, organizations, and governments to make sound choices. They can even outperform complicated decision-making approaches in some situations. Finally, simple rules allow the members of a community to synchronize their activities with one another on the fly. ",
					"content_token": 186,
					"embedding": []
				},
				{
					"article_title": "Simple Rules: How to Thrive in a Complex World",
					"article_url": "https://fs.blog/simple-rules/",
					"content": "Effective simple rules share four common traits  First, they are limited to a handful. Capping the number of rules makes them easy to remember and maintains a focus on what matters most. Second, simple rules are tailored to the person or organization using them. College athletes and middle-aged dieters may both rely on simple rules to decide what to eat, but their rules will be very different. Third, simple rules apply to a well-defined activity or decision, such as prioritizing injured soldiers for medical care. Rules that cover multiple activities or choices end up as vague platitudes, such as “Do your best” and “Focus on customers.” Finally, simple rules provide clear guidance while conferring the latitude to exercise discretion. Simple Rules for a Complex World People often attempt to address complex problems with complex solutions. For example, governments tend to manage complexity by trying to anticipate every possible scenario that might arise, and then promulgate regulations to cover every case. ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "Simple Rules: How to Thrive in a Complex World",
					"article_url": "https://fs.blog/simple-rules/",
					"content": "Consider how central bankers responded to increased complexity in the global banking system. In 1988 bankers from around the world met in Basel, Switzerland, to agree on international banking regulations, and published a 30-page agreement known as Basel I. Sixteen years later, the Basel II accord was an order of magnitude larger, at 347 pages, and Basel III was twice as long as its predecessor. When it comes to the sheer volume of regulations generated, the U.S. Congress makes the central bankers look like amateurs. The Glass-Steagall Act, a law passed during the Great Depression, which guided U.S. banking regulation for seven decades, totaled 37 pages. Its successor, Dodd-Frank, is expected to weigh in at over 30,000 pages when all supporting legislation is complete. Meeting complexity with complexity can create more confusion than it resolves. The policies governing U.S. income taxes totaled 3.8 million words as of 2010. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "Simple Rules: How to Thrive in a Complex World",
					"article_url": "https://fs.blog/simple-rules/",
					"content": "Imagine a book that is seven times as long as War and Peace, but without any characters, plot points, or insight into the human condition. That book is the U.S. tax code.  Applying complicated solutions to complex problems is an understandable approach, but flawed. The parts of a complex system can interact with one another in many different ways, which quickly overwhelms our ability to envision all possible outcomes.  Complicated solutions can overwhelm people, thereby increasing the odds that they will stop following the rules. A study of personal income tax compliance in forty-five countries found that the complexity of the tax code was the single best predictor of whether citizens would dodge or pay their taxes. The complexity of the regulations mattered more than the highest marginal tax rate, average levels of education or income, how fair the tax system was perceived to be, and the level of government scrutiny of tax returns. ",
					"content_token": 181,
					"embedding": []
				},
				{
					"article_title": "Simple Rules: How to Thrive in a Complex World",
					"article_url": "https://fs.blog/simple-rules/",
					"content": "Simple Rules Focus on the Critical Variables Simple rules do not trump complicated ones all the time but they work more often than we think. Gerd Gigerenzer is a key contributor in this space. He thinks that simple rules can allow for better decision making. Why can simpler models outperform more complex ones? When underlying cause-and-effect relationships are poorly understood, decision makers often look for patterns in historical data under the assumption that past events are a good indicator of future trends. The obvious problem with this approach is that the future may be genuinely different from the past. But a second problem is subtler. Historical data includes not only useful signal, but also noise happenstance correlations between variables that do not reveal an enduring cause-and-effect relationship. Fitting a model too closely to historical data hardwires error into the model, which is known as overfitting. The result is a precise prediction of the past that may tell us little about what the future holds. ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "Simple Rules: How to Thrive in a Complex World",
					"article_url": "https://fs.blog/simple-rules/",
					"content": "Simple rules focus on the critical variables that govern a situation and help you ignore the peripheral ones. Of course, in order to identify the key variables, you need to be operating in your circle of competence. When we pay too much attention to irrelevant or otherwise unimportant information, we fail to grasp the power of the most important ones and give them the weighting they deserve. Simple rules also make it more likely people will act on them. This is something Napoleon intuitively understood. When instructing his troops, Napoleon realized that complicated instructions were difficult to understand, explain, and execute. So, rather than complicated strategies he passed along simple ones, such as: Attack. Making Better Decisions The book mentions three types of rules that “improve decision making by structuring choices and centering on what to do and what not to do: boundary, prioritizing, and stopping rules. ",
					"content_token": 178,
					"embedding": []
				},
				{
					"article_title": "Simple Rules: How to Thrive in a Complex World",
					"article_url": "https://fs.blog/simple-rules/",
					"content": "Boundary Rules cover what to do  Boundary rules guide the choice of what to do and not do without requiring a lot of time, analysis, or information. Boundary rules work well for categorical choices, like a judge’s yes-or-no decision on a defendant’s bail, and decisions requiring many potential opportunities to be screened quickly. These rules also come in handy when time, convenience, and cost matter. Prioritizing rules rank options to help decide which of multiple paths to pursue. Prioritizing rules can help you rank a group of alternatives competing for scarce money, time, or attention.  They are especially powerful when applied to a bottleneck, an activity or decision that keeps individuals or organizations from reaching their objectives. Bottlenecks represent pinch-points in companies, where the number of opportunities swamps available resources, and prioritizing rules can ensure that these resources are deployed where they can have the greatest impact. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "Simple Rules: How to Thrive in a Complex World",
					"article_url": "https://fs.blog/simple-rules/",
					"content": "In business settings, prioritizing rules can be used to assign engineers to new-product-development projects, focus sales representatives on the most promising customers, and allocate advertising expenditure across multiple products, to name only a few possibilities. Stopping rules help you learn when to reverse a decision. Nobel Prize-winning economist Herbert Simon argued that we lack the information, time, and mental engine to determine the single best path when faced with a slew of options. Instead, we rely on a heuristic to help us stop searching when we find something that’s good enough. Simon called this satisficing. If you think that’s hard, it’s even hard to stop doing something we’re already doing. Yet when it comes to our key investments of time, money, and energy we have to know when to pull the plug. Sometimes we pursue goals at all costs and ignore our self-imposed stopping rule. This goal induced blindness can be deadly. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "Simple Rules: How to Thrive in a Complex World",
					"article_url": "https://fs.blog/simple-rules/",
					"content": "A cross-continental team of researchers matched 145 Chicagoans with demographically similar Parisians. Both the Chicagoans and Parisians used stopping rules to decide when to finish eating, but the rules themselves were very different. The Parisians employed rules like “Stop eating when I start feeling full,” linking their decision to internal cues about satiation. The Chicagoans, in contrast, were more likely to follow rules linked to external factors, such as “Stop eating when I run out of a beverage,” or “Stop eating when the TV show I’m watching is over.” Stopping rules that rely on internal cues like when the food stops tasting good or you feel full decrease the odds that people eat more than their body needs or even wants. Stopping rules are particularly critical in situations when people tend to double down on a losing hand. ",
					"content_token": 178,
					"embedding": []
				},
				{
					"article_title": "Simple Rules: How to Thrive in a Complex World",
					"article_url": "https://fs.blog/simple-rules/",
					"content": "These three decision rulesboundary, prioritizing, and stoppinghelp provide guidelines on what to do”what is acceptable to do, what is more, important to do, and what to stop doing.” Doing Things Better Process rules, in contrast to boundary rules, focus on how to do things better. Process rules work because they steer a middle path between the chaos of too few rules that can result in confusion and mistakes, and the rigidity of so many rules that there is little ability to adapt to the unexpected or take advantage of new opportunities. Simply put, process rules are useful whenever flexibility trumps consistency. The most widely used process rule is the how-to rule. How-to rules guide the basics of executing tasks, from playing golf to designing new products. The other process rules, coordination and timing, are special cases of how-to rules that apply in particular situations. ",
					"content_token": 181,
					"embedding": []
				},
				{
					"article_title": "Simple Rules: How to Thrive in a Complex World",
					"article_url": "https://fs.blog/simple-rules/",
					"content": "Coordination rules center on getting something done when multiple actors people, organizations, or nations have to work together. These rules orchestrate the behaviors of, for example, schooling fish, Zipcar members, and content contributors at Wikipedia. In contrast, timing rules center on getting things done in situations where temporal factors such as rhythms, sequences, and deadlines are relevant. These rules set the timing of, for example, when to get up every day and when dragonflies migrate. While I was skeptical, the book is well worth reading. I suggest you check it out.",
					"content_token": 114,
					"embedding": []
				}
			]
		},
		{
			"title": "The Wisdom of Crowds and The Expert Squeeze",
			"url": "https://fs.blog/the-expert-squeeze/",
			"content": "As networks harness the wisdom of crowds, the ability of experts to add value in their predictions is steadily declining. This is the expert squeeze.  In Think Twice: Harnessing the Power of Counterintuition, Michael Mauboussin, the first guest on my podcast, The Knowledge Project, explains the expert squeeze and its implications for how we make decisions. As networks harness the wisdom of crowds and computing power grows, the ability of experts to add value in their predictions is steadily declining. I call this the expert squeeze, and evidence for it is mounting. Despite this trend, we still pine for experts individuals with special skill or know-how believing that many forms of knowledge are technical and specialized. We openly defer to people in white lab coats or pinstripe suits, believing they hold the answers, and we harbor misgivings about computergenerated outcomes or the collective opinion of a bunch of tyros. The expert squeeze means that people stuck in old habits of thinking are failing to use new means to gain insight into the problems they face. Knowing when to look beyond experts requires a totally fresh point of view, and one that does not come naturally. To be sure, the future for experts is not all bleak. Experts retain an advantage in some crucial areas. The challenge is to know when and how to use them. The Value of Experts So how can we manage this in our role as the decision-maker? The first step is to classify the problem. The figure above  The Value of Experts helps to guide this process. The second column from the left covers problems that have rules-based solutions with limited possible outcomes. Here, someone can investigate the problem based on past patterns and write down rules to guide decisions. Experts do well with these tasks, but once the principles are clear and well defined, computers are cheaper and more reliable. Think of tasks such as credit scoring or simple forms of medical diagnosis. Experts agree about how to approach these problems because the solutions are transparent and for the most part tried and true.  Now let’s go to the opposite extreme, the column on the far right that deals with probabilistic fields with a wide range of outcomes. Here are no simple rules. You can only express possible outcomes in probabilities, and the range of outcomes is wide. Examples include economic and political forecasts. The evidence shows that collectives outperform experts in solving these problems.  The middle two columns are the remaining province for experts. Experts do well with rules-based problems with a wide range of outcomes because they are better than computers at eliminating bad choices and making creative connections between bits of information. Once you’ve classified the problem, you can turn to the best method for solving it.  computers and collectives remain underutilized guides for decision making across a host of realms including medicine, business, and sports. That said, experts remain vital in three capacities. First, experts must create the very systems that replace them.  Of course, the experts must stay on top of these systems, improving the market or equation as need be. Next, we need experts for strategy. I mean strategy broadly, including not only day-to-day tactics but also the ability to troubleshoot by recognizing interconnections as well as the creative process of innovation, which involves combining ideas in novel ways. Decisions about how best to challenge a competitor, which rules to enforce, or how to recombine existing building blocks to create novel products or experiences are jobs for experts. Finally, we need people to deal with people. A lot of decision making involves psychology as much as it does statistics. A leader must understand others, make good decisions, and encourage others to buy in to the decision. So what are the practical tips you can do to make the expert squeeze work for you instead of against you? Here Mauboussin offers 3 tips. 1. Match the problem you face with the most appropriate solution. What we know is that experts do a poor job in many settings, suggesting that you should try to supplement expert views with other approaches. 2. Seek diversity. Philip Tetlock’s work shows that while expert predictions are poor overall, some are better than others. What distinguishes predictive ability is not who the experts are or what they believe, but rather how they think. Borrowing from Archilochus through Isaiah Berlin Tetlock sorted experts into hedgehogs and foxes. Hedgehogs know one big thing and try to explain everything through that lens. Foxes tend to know a little about a lot of things and are not married to a single explanation for complex problems. Tetlock finds that foxes are better predictors than hedgehogs. Foxes arrive at their decisions by stitching “together diverse sources of information,” lending credence to the importance of diversity. Naturally, hedgehogs are periodically right and often spectacularly so but do not predict as well as foxes over time. For many important decisions, diversity is the key at both the individual and collective levels. 3. Use technology when possible. Leverage technology to side-step the squeeze when possible. Flooded with candidates and aware of the futility of most interviews, Google decided to create algorithms to identify attractive potential employees. First, the company asked seasoned employees to fill out a three-hundred-question survey, capturing details about their tenure, their behavior, and their personality. The company then compared the survey results to measures of employee performance, seeking connections. Among other findings, Google executives recognized that academic accomplishments did not always correlate with on-the-job performance. This novel approach enabled Google to sidestep problems with ineffective interviews and to start addressing the discrepancy. Learning the difference between when experts help or hurt can go a long way toward avoiding stupidity. This starts with identifying the type of problem you’re facing and then considering the various approaches to solve the problem with pros and cons. Still curious? Follow up by reading Generalists vs. Specialists, Think Twice: Harnessing the Power of Counterintuition, and reviewing the work of Philip Tetlock. ",
			"tokens": 1234,
			"chunks": [
				{
					"article_title": "The Wisdom of Crowds and The Expert Squeeze",
					"article_url": "https://fs.blog/the-expert-squeeze/",
					"content": "As networks harness the wisdom of crowds, the ability of experts to add value in their predictions is steadily declining. This is the expert squeeze.  In Think Twice: Harnessing the Power of Counterintuition, Michael Mauboussin, the first guest on my podcast, The Knowledge Project, explains the expert squeeze and its implications for how we make decisions. As networks harness the wisdom of crowds and computing power grows, the ability of experts to add value in their predictions is steadily declining. I call this the expert squeeze, and evidence for it is mounting. Despite this trend, we still pine for experts individuals with special skill or know-how believing that many forms of knowledge are technical and specialized. We openly defer to people in white lab coats or pinstripe suits, believing they hold the answers, and we harbor misgivings about computergenerated outcomes or the collective opinion of a bunch of tyros. ",
					"content_token": 186,
					"embedding": []
				},
				{
					"article_title": "The Wisdom of Crowds and The Expert Squeeze",
					"article_url": "https://fs.blog/the-expert-squeeze/",
					"content": "The expert squeeze means that people stuck in old habits of thinking are failing to use new means to gain insight into the problems they face. Knowing when to look beyond experts requires a totally fresh point of view, and one that does not come naturally. To be sure, the future for experts is not all bleak. Experts retain an advantage in some crucial areas. The challenge is to know when and how to use them. The Value of Experts So how can we manage this in our role as the decision-maker? The first step is to classify the problem. The figure above  The Value of Experts helps to guide this process. The second column from the left covers problems that have rules-based solutions with limited possible outcomes. Here, someone can investigate the problem based on past patterns and write down rules to guide decisions. Experts do well with these tasks, but once the principles are clear and well defined, computers are cheaper and more reliable. ",
					"content_token": 188,
					"embedding": []
				},
				{
					"article_title": "The Wisdom of Crowds and The Expert Squeeze",
					"article_url": "https://fs.blog/the-expert-squeeze/",
					"content": "Think of tasks such as credit scoring or simple forms of medical diagnosis. Experts agree about how to approach these problems because the solutions are transparent and for the most part tried and true.  Now let’s go to the opposite extreme, the column on the far right that deals with probabilistic fields with a wide range of outcomes. Here are no simple rules. You can only express possible outcomes in probabilities, and the range of outcomes is wide. Examples include economic and political forecasts. The evidence shows that collectives outperform experts in solving these problems.  The middle two columns are the remaining province for experts. Experts do well with rules-based problems with a wide range of outcomes because they are better than computers at eliminating bad choices and making creative connections between bits of information. Once you’ve classified the problem, you can turn to the best method for solving it. ",
					"content_token": 178,
					"embedding": []
				},
				{
					"article_title": "The Wisdom of Crowds and The Expert Squeeze",
					"article_url": "https://fs.blog/the-expert-squeeze/",
					"content": " computers and collectives remain underutilized guides for decision making across a host of realms including medicine, business, and sports. That said, experts remain vital in three capacities. First, experts must create the very systems that replace them.  Of course, the experts must stay on top of these systems, improving the market or equation as need be. Next, we need experts for strategy. I mean strategy broadly, including not only day-to-day tactics but also the ability to troubleshoot by recognizing interconnections as well as the creative process of innovation, which involves combining ideas in novel ways. Decisions about how best to challenge a competitor, which rules to enforce, or how to recombine existing building blocks to create novel products or experiences are jobs for experts. Finally, we need people to deal with people. A lot of decision making involves psychology as much as it does statistics. A leader must understand others, make good decisions, and encourage others to buy in to the decision. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "The Wisdom of Crowds and The Expert Squeeze",
					"article_url": "https://fs.blog/the-expert-squeeze/",
					"content": "So what are the practical tips you can do to make the expert squeeze work for you instead of against you? Here Mauboussin offers 3 tips. 1. Match the problem you face with the most appropriate solution. What we know is that experts do a poor job in many settings, suggesting that you should try to supplement expert views with other approaches. 2. Seek diversity. Philip Tetlock’s work shows that while expert predictions are poor overall, some are better than others. What distinguishes predictive ability is not who the experts are or what they believe, but rather how they think. Borrowing from Archilochus through Isaiah Berlin Tetlock sorted experts into hedgehogs and foxes. Hedgehogs know one big thing and try to explain everything through that lens. Foxes tend to know a little about a lot of things and are not married to a single explanation for complex problems. Tetlock finds that foxes are better predictors than hedgehogs. ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "The Wisdom of Crowds and The Expert Squeeze",
					"article_url": "https://fs.blog/the-expert-squeeze/",
					"content": "Foxes arrive at their decisions by stitching “together diverse sources of information,” lending credence to the importance of diversity. Naturally, hedgehogs are periodically right and often spectacularly so but do not predict as well as foxes over time. For many important decisions, diversity is the key at both the individual and collective levels. 3. Use technology when possible. Leverage technology to side-step the squeeze when possible. Flooded with candidates and aware of the futility of most interviews, Google decided to create algorithms to identify attractive potential employees. First, the company asked seasoned employees to fill out a three-hundred-question survey, capturing details about their tenure, their behavior, and their personality. The company then compared the survey results to measures of employee performance, seeking connections. Among other findings, Google executives recognized that academic accomplishments did not always correlate with on-the-job performance. ",
					"content_token": 184,
					"embedding": []
				},
				{
					"article_title": "The Wisdom of Crowds and The Expert Squeeze",
					"article_url": "https://fs.blog/the-expert-squeeze/",
					"content": "This novel approach enabled Google to sidestep problems with ineffective interviews and to start addressing the discrepancy. Learning the difference between when experts help or hurt can go a long way toward avoiding stupidity. This starts with identifying the type of problem you’re facing and then considering the various approaches to solve the problem with pros and cons. Still curious? Follow up by reading Generalists vs. Specialists, Think Twice: Harnessing the Power of Counterintuition, and reviewing the work of Philip Tetlock.",
					"content_token": 103,
					"embedding": []
				}
			]
		},
		{
			"title": "13 Practical Ideas That Have Helped Me Make Better Decisions",
			"url": "https://fs.blog/practical-ideas-better-decisions/",
			"content": " This article is a collaboration between Mark Steed and myself. He did most of the work. Mark was a participant at the last Re:Think Decision Making event as well as a member of the Good Judgment Project. I asked him to put together something on making better predictions. This is the result. We all face decisions. Sometimes we think hard about a specific decision, other times, we make decisions without thinking. If you’ve studied the genre you’ve probably read Taleb, Tversky, Kahneman, Gladwell, Ariely, Munger, Tetlock, Mauboussin andor Thaler. These pioneers write a lot about “rationality” and “biases”. Rationality dictates the selection of the best choice among however many options. Biases of a cognitive or emotional nature creep in and are capable of preventing the identification of the “rational” choice. These biases can exist in our DNA or can be formed through life experiences. The mentioned authors consider biases extensively, and, lucky for us, their writings are eye-opening and entertaining. Rather than rehash what brighter minds have discussed, I’ll focus on practical ideas that have helped me make better decisions. I think of this as a list of “lessons learned so far” from my work in asset management and as a forecaster for the Good Judgment Project. I’ve held back on submitting this given the breadth and depth of the FS readers, but, rather than expect perfection, I wanted to put something on the table because I suspect many of you have useful ideas that will help move the conversation forward. 1. This is a messy business. Studying decision science can easily motivate self-loathing. There are over one-hundred cognitive biases that might prevent us from making calculated and “rational” decisions. What, you can’t create a decision tree with 124 decision nodes, complete with assorted probabilities in split seconds? I asked around, and it turns out, not many people can. Since there is no way to eliminate all the potential cognitive biases and I don’t possess the mental faculties of Dr. Spock or C-3PO, I might as well live with the fact that some decisions will be more elegant than others. 2. We live and work in dynamic environments. Dynamic environments adapt. The opposite of dynamic environments are static environments. Financial markets, geopolitical events, team sports, etc. are examples of dynamic “environments” because relationships between agents evolve and problems are often unpredictable. Changes from one period are conditional on what happened the previous period. Casinos are more representative of static environments. Not casinos necessarily, but the games inside. If you play Roulette, your odds of winning are always the same and it doesn’t matter what happened the previous turn. 3. Good explanatory models are not necessarily good predictive models. Dynamic environments have a habit of desecrating rigid models. While blindly following an elegant model may be ill-advised, strong explanatory models are excellent guideposts when paired with sound judgment and intuition. Just as I’m not comfortable with the automatic pilot flying a plane without a human in the cockpit, I’m also not comfortable with a human flying a plane without the help of technology. It has been said before, people make models better and models make people better. 4. Instinct is not always irrational.  The rule of thumb, otherwise known as heuristics, provide better results than more complicated analytical techniques. Gerd Gigerenzer, is the thought leader and his book Risk Savvy: How to Make Good Decisions is worth reading. Most literature despises heuristics, but he asserts intuition proves superior because optimization is sometimes mathematically impossible or exposed to sampling error. He often uses the example of Harry Markowitz, who won a Nobel Prize in Economics in 1990 for his work on Modern Portfolio Theory. Markowitz discovered a method for determining the “optimal” mix of assets. However, Markowitz himself did not follow his Nobel prize-winning mean-variance theory but instead used a 1N heuristic by spreading his dollars equally across N number of investments. He concluded that his 1N strategy would perform better than a mean-optimization application unless the mean-optimization model had 500 years to compete.  Our intuition is more likely to be accurate if it is preceded by rigorous analysis and introspection. And simple rules are more effective at communicating winning strategies in complex environments. When coaching a child’s soccer team, it is far easier teaching a few basic principles, than articulating the nuances of every possible situation. 5. Decisions are not evaluated in ways that help us reduce mistakes in the future. Our tendency is to only critique decisions where the desired outcome was not achieved while uncritically accepting positive outcomes even if luck, or another factor, produced the desired result. At the end of the day I understand all we care about are results, but good processes are more indicative of future success than good results. 6. Success is ill-defined. In some cases this is relatively straightforward. If the outcome is binary, either it did, or did not happen, success is easy to identify. But this is more difficult in situations where the outcome can take a range of potential values, or when individuals differ on what the values should be. 7. We should care a lot more about calibration. Confidence, not just a decision, should be recorded and to be clear, decisions should be recorded. Next time you have a major decision, ask yourself how confident you are that the desired outcome will be achieved. Are you 50 confident? 90? Write it down. This helps with calibration. For all decisions in which you are 50 confident, half should be successes. And you should be right nine out of ten times for all decisions in which you are 90 confident. If you are 100 confident, you should never be wrong. If you don’t know anything about a specific subject then you should be no more confident than a coin flip. It’s amazing how we will assign high confidence to an event we know nothing about. Turns out this idea is pretty helpful. Let’s say someone brings an idea to you and you know nothing about it. Your default should be 5050; you might as well flip a coin. Then you just need to worry about the costspayouts. 8. Probabilities are one thing, payouts are another. You might feel 5050 about your chances but you need to know your payouts if you are right. This is where the expected value comes in handy. It’s the probability of being right multiplied by the payout if you are right, plus the probability of being wrong multiplied by the cost. E .50x  .50y. Say someone on your team has an idea for a project and you decided there is a 50 chance that it succeeds and, if it does, you double your money, if it doesn’t, you lose what you invested. If the project required 10mm, then the expected outcome is calculated as .5020  .500  10, or 10mm. If you repeat this process a number of times, approving only projects with a 2:1 payout and 50 probability of success you would likely end up with the same amount you started with. Binary outcomes that have a 5050 probability should have a double-or-nothing payout. This is even more helpful given 7 above. If you were tracking this employee’s calibration you would have a sense as to whether their forecasts are accurate. As a team member or manager, you would want to know if a specific employee is 90 confident all the time but only 50 accurate. More importantly, you would want to know if a certain team member is usually right when they express 90 or 100 confidence. Use a Brier Score to track colleagues but provide an environment to encourage discussion and openness. 9. We really are overconfident. Starting from the assumption that we are probably only 50 accurate is not a bad idea. Phil Tetlock, a professor at UPenn, Team Leader for the Good Judgment Project and author of Expert Political Judgment: How Good Is It? How Can We Know?, suggested political pundits are about 53 accurate regarding political forecasts while CXO Advisory tracks investment gurus and finds they are, in aggregate, about 48 accurate. These are experts making predictions about their core area of expertise. Consider the rate of divorce in the U.S., currently around 40-50, as additional evidence that sometimes we don’t know as much as we think. Experts are helpful in explaining a specific discipline but they are less helpful in dynamic environments. If you need something fixed, like a car, a clock or an appliance then experts can be very helpful. Same for tax and accounting advice. It’s not because this stuff is simple, it’s because the environment is static. 10. Improving estimations of probabilities and payouts is about polishing our 1 subject matter expertise and 2 cognitive processing abilities. Learning more about a given subject reduces uncertainty and allows us to move from the lazy 5050 forecast. Say you travel to Arizona and get stung by a scorpion. Rather than assume a 50 probability of death you can do a quick internet search and learn no one has died from a scorpion bite in Arizona since the 1960s. Overly simplistic, but, you get the picture. Second, data needs to be interpreted in a cogent way. Let’s say you work in asset management and one of your portfolio managers has made three investments that returned -5, -12 and 22. What can you say about the manager other than two of the three investments lost money? Does the information allow you to claim the portfolio manager is a bad manager? Does the information allow you to claim you can confidently predict hisher average rate of return? Unless you’ve had some statistics, it might not be entirely clear what clinical conclusions you can draw. What if you flipped a coin three times and came up with tails on two of them? That wouldn’t seem so strange. Two-thirds is the same as 66. If you tossed the coin one-hundred times and got 66 tails, that would be a little more interesting. The more observations, the higher our confidence should be. A 95 confidence interval for the portfolio manager’s average return would be a range between -43 and 45. Is that enough to take action? 11. Bayesian analysis is more useful than we think. Bayesian updating helps direct given falsetrue positives and falsetrue negatives. It’s the probability of a hypothesis given some observed data. For example, what’s the likelihood of X this new hire will place in the top 10 of the firm given Y they graduated from an Ivy League school? A certain percentage of employees are top-performing employees, some Ivy League grads will be top-performers others not and some non-Ivy League grads will be top-performers others not. If I’m staring at a random employee trying to guess whether they are a top-performing employee all I have are the starting odds, and, if only the top 10 qualify, I know my chances are 1 in 10. But I can update my odds if supplied information regarding their education. Here’s another example. What is the likelihood a project will be successful X given it missed one of the first two milestones Y?. There are lots of helpful resources online if you want to learn more but think of it this way hat tip to Kalid Azad at Better Explained; original odds x the evidence adjustment  your new odds. The actual equation is more complicated but that is the intuition behind it. Bayesian analysis has its naysayers. In the examples provided, the prior odds of success are known, or could easily be obtained, but this isn’t always true. Most of the time subjective prior probabilities are required and this type of tomfoolery is generally discouraged. There are ways around that, but no time to explain it here. 12. A word about crowds. Is there a wisdom of crowds? Some say yes, others say no. My view is that crowds can be very useful if individual members of the crowd are able to vote independently or if the environment is such that there are few repercussions for voicing disagreement. Otherwise, I think signaling effects from seeing how others are “voting” is too much evolutionary force to overcome with sheer rational willpower. Our earliest ancestors ran when the rest of the tribe ran. Not doing so might have resulted in an untimely demise. 13. Analyze your own motives. Jonathan Haidt, author of The Righteous Mind: Why Good People Are Divided by Politics and Religion, is credited with teaching that logic isn’t used to find truth, it’s used to win arguments. Logic may not be the only source of truth and I have no basis for that claim. Keep this in mind as it has to do with the role of intuition in decision making. Just a few closing thoughts. We are pretty hard on ourselves. My process is to make the best decisions I can, realizing not all of them will be optimal. I have a method to track my decisions and to score how accurate I am. Sometimes I use heuristics, but I try to keep those to within my area of competency, as Munger says. I don’t do lists of pros and cons because I feel like I’m just trying to convince myself, either way. If I have to make a big decision, in an unfamiliar area, I try to learn as much as I can about the issue on my own and from experts, assess how much randomness could be present, formulate my thesis, look for contradictory information, try and build downside protection risking as little as possible and watch for signals that may indicate a likely outcome. Many of my decisions have not worked out, but most of them have. As the world changes, so will my process, and I look forward to that. Have something to say? Become a member: join the slack conversation and chat with Mark directly. ",
			"tokens": 2932,
			"chunks": [
				{
					"article_title": "13 Practical Ideas That Have Helped Me Make Better Decisions",
					"article_url": "https://fs.blog/practical-ideas-better-decisions/",
					"content": " This article is a collaboration between Mark Steed and myself. He did most of the work. Mark was a participant at the last Re:Think Decision Making event as well as a member of the Good Judgment Project. I asked him to put together something on making better predictions. This is the result. We all face decisions. Sometimes we think hard about a specific decision, other times, we make decisions without thinking. If you’ve studied the genre you’ve probably read Taleb, Tversky, Kahneman, Gladwell, Ariely, Munger, Tetlock, Mauboussin andor Thaler. These pioneers write a lot about “rationality” and “biases” Rationality dictates the selection of the best choice among however many options. Biases of a cognitive or emotional nature creep in and are capable of preventing the identification of the “rational” choice. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "13 Practical Ideas That Have Helped Me Make Better Decisions",
					"article_url": "https://fs.blog/practical-ideas-better-decisions/",
					"content": "These biases can exist in our DNA or can be formed through life experiences. The mentioned authors consider biases extensively, and, lucky for us, their writings are eye-opening and entertaining. Rather than rehash what brighter minds have discussed, I’ll focus on practical ideas that have helped me make better decisions. I think of this as a list of “lessons learned so far” from my work in asset management and as a forecaster for the Good Judgment Project. I’ve held back on submitting this given the breadth and depth of the FS readers, but, rather than expect perfection, I wanted to put something on the table because I suspect many of you have useful ideas that will help move the conversation forward. 1. This is a messy business. Studying decision science can easily motivate self-loathing. There are over one-hundred cognitive biases that might prevent us from making calculated and “rational” decisions. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "13 Practical Ideas That Have Helped Me Make Better Decisions",
					"article_url": "https://fs.blog/practical-ideas-better-decisions/",
					"content": "What, you can’t create a decision tree with 124 decision nodes, complete with assorted probabilities in split seconds? I asked around, and it turns out, not many people can. Since there is no way to eliminate all the potential cognitive biases and I don’t possess the mental faculties of Dr. Spock or C-3PO, I might as well live with the fact that some decisions will be more elegant than others. 2. We live and work in dynamic environments. Dynamic environments adapt. The opposite of dynamic environments are static environments. Financial markets, geopolitical events, team sports, etc. are examples of dynamic “environments” because relationships between agents evolve and problems are often unpredictable. Changes from one period are conditional on what happened the previous period. Casinos are more representative of static environments. Not casinos necessarily, but the games inside. ",
					"content_token": 175,
					"embedding": []
				},
				{
					"article_title": "13 Practical Ideas That Have Helped Me Make Better Decisions",
					"article_url": "https://fs.blog/practical-ideas-better-decisions/",
					"content": "If you play Roulette, your odds of winning are always the same and it doesn’t matter what happened the previous turn. 3. Good explanatory models are not necessarily good predictive models. Dynamic environments have a habit of desecrating rigid models. While blindly following an elegant model may be ill-advised, strong explanatory models are excellent guideposts when paired with sound judgment and intuition. Just as I’m not comfortable with the automatic pilot flying a plane without a human in the cockpit, I’m also not comfortable with a human flying a plane without the help of technology. It has been said before, people make models better and models make people better. 4. ",
					"content_token": 139,
					"embedding": []
				},
				{
					"article_title": "13 Practical Ideas That Have Helped Me Make Better Decisions",
					"article_url": "https://fs.blog/practical-ideas-better-decisions/",
					"content": "Instinct is not always irrational.  The rule of thumb, otherwise known as heuristics, provide better results than more complicated analytical techniques. Gerd Gigerenzer, is the thought leader and his book Risk Savvy: How to Make Good Decisions is worth reading. Most literature despises heuristics, but he asserts intuition proves superior because optimization is sometimes mathematically impossible or exposed to sampling error. He often uses the example of Harry Markowitz, who won a Nobel Prize in Economics in 1990 for his work on Modern Portfolio Theory. Markowitz discovered a method for determining the “optimal” mix of assets. However, Markowitz himself did not follow his Nobel prize-winning mean-variance theory but instead used a 1N heuristic by spreading his dollars equally across N number of investments. He concluded that his 1N strategy would perform better than a mean-optimization application unless the mean-optimization model had 500 years to compete.  Our intuition is more likely to be accurate if it is preceded by rigorous analysis and introspection. ",
					"content_token": 228,
					"embedding": []
				},
				{
					"article_title": "13 Practical Ideas That Have Helped Me Make Better Decisions",
					"article_url": "https://fs.blog/practical-ideas-better-decisions/",
					"content": "And simple rules are more effective at communicating winning strategies in complex environments. When coaching a child’s soccer team, it is far easier teaching a few basic principles, than articulating the nuances of every possible situation. 5. Decisions are not evaluated in ways that help us reduce mistakes in the future. Our tendency is to only critique decisions where the desired outcome was not achieved while uncritically accepting positive outcomes even if luck, or another factor, produced the desired result. At the end of the day I understand all we care about are results, but good processes are more indicative of future success than good results. 6. Success is ill-defined. In some cases this is relatively straightforward. If the outcome is binary, either it did, or did not happen, success is easy to identify. But this is more difficult in situations where the outcome can take a range of potential values, or when individuals differ on what the values should be. 7. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "13 Practical Ideas That Have Helped Me Make Better Decisions",
					"article_url": "https://fs.blog/practical-ideas-better-decisions/",
					"content": "We should care a lot more about calibration. Confidence, not just a decision, should be recorded and to be clear, decisions should be recorded. Next time you have a major decision, ask yourself how confident you are that the desired outcome will be achieved. Are you 50 confident? 90? Write it down. This helps with calibration. For all decisions in which you are 50 confident, half should be successes. And you should be right nine out of ten times for all decisions in which you are 90 confident. If you are 100 confident, you should never be wrong. If you don’t know anything about a specific subject then you should be no more confident than a coin flip. It’s amazing how we will assign high confidence to an event we know nothing about. Turns out this idea is pretty helpful. Let’s say someone brings an idea to you and you know nothing about it. Your default should be 5050; you might as well flip a coin. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "13 Practical Ideas That Have Helped Me Make Better Decisions",
					"article_url": "https://fs.blog/practical-ideas-better-decisions/",
					"content": "Then you just need to worry about the costspayouts. 8. Probabilities are one thing, payouts are another. You might feel 5050 about your chances but you need to know your payouts if you are right. This is where the expected value comes in handy. It’s the probability of being right multiplied by the payout if you are right, plus the probability of being wrong multiplied by the cost. E .50x  .50y. Say someone on your team has an idea for a project and you decided there is a 50 chance that it succeeds and, if it does, you double your money, if it doesn’t, you lose what you invested. If the project required 10mm, then the expected outcome is calculated as .5020  .500  10, or 10mm. ",
					"content_token": 169,
					"embedding": []
				},
				{
					"article_title": "13 Practical Ideas That Have Helped Me Make Better Decisions",
					"article_url": "https://fs.blog/practical-ideas-better-decisions/",
					"content": "If you repeat this process a number of times, approving only projects with a 2:1 payout and 50 probability of success you would likely end up with the same amount you started with. Binary outcomes that have a 5050 probability should have a double-or-nothing payout. This is even more helpful given 7 above. If you were tracking this employee’s calibration you would have a sense as to whether their forecasts are accurate. As a team member or manager, you would want to know if a specific employee is 90 confident all the time but only 50 accurate. More importantly, you would want to know if a certain team member is usually right when they express 90 or 100 confidence. Use a Brier Score to track colleagues but provide an environment to encourage discussion and openness. 9. We really are overconfident. Starting from the assumption that we are probably only 50 accurate is not a bad idea. ",
					"content_token": 183,
					"embedding": []
				},
				{
					"article_title": "13 Practical Ideas That Have Helped Me Make Better Decisions",
					"article_url": "https://fs.blog/practical-ideas-better-decisions/",
					"content": "Phil Tetlock, a professor at UPenn, Team Leader for the Good Judgment Project and author of Expert Political Judgment: How Good Is It? How Can We Know?, suggested political pundits are about 53 accurate regarding political forecasts while CXO Advisory tracks investment gurus and finds they are, in aggregate, about 48 accurate. These are experts making predictions about their core area of expertise. Consider the rate of divorce in the U.S., currently around 40-50, as additional evidence that sometimes we don’t know as much as we think. Experts are helpful in explaining a specific discipline but they are less helpful in dynamic environments. If you need something fixed, like a car, a clock or an appliance then experts can be very helpful. Same for tax and accounting advice. It’s not because this stuff is simple, it’s because the environment is static. 10. ",
					"content_token": 181,
					"embedding": []
				},
				{
					"article_title": "13 Practical Ideas That Have Helped Me Make Better Decisions",
					"article_url": "https://fs.blog/practical-ideas-better-decisions/",
					"content": "Improving estimations of probabilities and payouts is about polishing our 1 subject matter expertise and 2 cognitive processing abilities. Learning more about a given subject reduces uncertainty and allows us to move from the lazy 5050 forecast. Say you travel to Arizona and get stung by a scorpion. Rather than assume a 50 probability of death you can do a quick internet search and learn no one has died from a scorpion bite in Arizona since the 1960s. Overly simplistic, but, you get the picture. Second, data needs to be interpreted in a cogent way. Let’s say you work in asset management and one of your portfolio managers has made three investments that returned -5, -12 and 22. ",
					"content_token": 146,
					"embedding": []
				},
				{
					"article_title": "13 Practical Ideas That Have Helped Me Make Better Decisions",
					"article_url": "https://fs.blog/practical-ideas-better-decisions/",
					"content": "What can you say about the manager other than two of the three investments lost money? Does the information allow you to claim the portfolio manager is a bad manager? Does the information allow you to claim you can confidently predict hisher average rate of return? Unless you’ve had some statistics, it might not be entirely clear what clinical conclusions you can draw. What if you flipped a coin three times and came up with tails on two of them? That wouldn’t seem so strange. Two-thirds is the same as 66. If you tossed the coin one-hundred times and got 66 tails, that would be a little more interesting. The more observations, the higher our confidence should be. A 95 confidence interval for the portfolio manager’s average return would be a range between -43 and 45. Is that enough to take action? 11. ",
					"content_token": 175,
					"embedding": []
				},
				{
					"article_title": "13 Practical Ideas That Have Helped Me Make Better Decisions",
					"article_url": "https://fs.blog/practical-ideas-better-decisions/",
					"content": "Bayesian analysis is more useful than we think. Bayesian updating helps direct given falsetrue positives and falsetrue negatives. It’s the probability of a hypothesis given some observed data. For example, what’s the likelihood of X this new hire will place in the top 10 of the firm given Y they graduated from an Ivy League school? A certain percentage of employees are top-performing employees, some Ivy League grads will be top-performers others not and some non-Ivy League grads will be top-performers others not. If I’m staring at a random employee trying to guess whether they are a top-performing employee all I have are the starting odds, and, if only the top 10 qualify, I know my chances are 1 in 10. But I can update my odds if supplied information regarding their education. Here’s another example. ",
					"content_token": 187,
					"embedding": []
				},
				{
					"article_title": "13 Practical Ideas That Have Helped Me Make Better Decisions",
					"article_url": "https://fs.blog/practical-ideas-better-decisions/",
					"content": "What is the likelihood a project will be successful X given it missed one of the first two milestones Y? There are lots of helpful resources online if you want to learn more but think of it this way hat tip to Kalid Azad at Better Explained; original odds x the evidence adjustment  your new odds. The actual equation is more complicated but that is the intuition behind it. Bayesian analysis has its naysayers. In the examples provided, the prior odds of success are known, or could easily be obtained, but this isn’t always true. Most of the time subjective prior probabilities are required and this type of tomfoolery is generally discouraged. There are ways around that, but no time to explain it here. 12. A word about crowds. Is there a wisdom of crowds? Some say yes, others say no. ",
					"content_token": 175,
					"embedding": []
				},
				{
					"article_title": "13 Practical Ideas That Have Helped Me Make Better Decisions",
					"article_url": "https://fs.blog/practical-ideas-better-decisions/",
					"content": "My view is that crowds can be very useful if individual members of the crowd are able to vote independently or if the environment is such that there are few repercussions for voicing disagreement. Otherwise, I think signaling effects from seeing how others are “voting” is too much evolutionary force to overcome with sheer rational willpower. Our earliest ancestors ran when the rest of the tribe ran. Not doing so might have resulted in an untimely demise. 13. Analyze your own motives. Jonathan Haidt, author of The Righteous Mind: Why Good People Are Divided by Politics and Religion, is credited with teaching that logic isn’t used to find truth, it’s used to win arguments. Logic may not be the only source of truth and I have no basis for that claim. Keep this in mind as it has to do with the role of intuition in decision making. Just a few closing thoughts. We are pretty hard on ourselves. ",
					"content_token": 194,
					"embedding": []
				},
				{
					"article_title": "13 Practical Ideas That Have Helped Me Make Better Decisions",
					"article_url": "https://fs.blog/practical-ideas-better-decisions/",
					"content": "My process is to make the best decisions I can, realizing not all of them will be optimal. I have a method to track my decisions and to score how accurate I am. Sometimes I use heuristics, but I try to keep those to within my area of competency, as Munger says. I don’t do lists of pros and cons because I feel like I’m just trying to convince myself, either way. If I have to make a big decision, in an unfamiliar area, I try to learn as much as I can about the issue on my own and from experts, assess how much randomness could be present, formulate my thesis, look for contradictory information, try and build downside protection risking as little as possible and watch for signals that may indicate a likely outcome. Many of my decisions have not worked out, but most of them have. As the world changes, so will my process, and I look forward to that. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "13 Practical Ideas That Have Helped Me Make Better Decisions",
					"article_url": "https://fs.blog/practical-ideas-better-decisions/",
					"content": "Have something to say? Become a member: join the slack conversation and chat with Mark directly.",
					"content_token": 22,
					"embedding": []
				}
			]
		},
		{
			"title": "40 Books that Improve your Ability to Make Decisions",
			"url": "https://fs.blog/books-on-decision-making/",
			"content": "Who can you ask for book recommendations on decision making? At Re:Think Decision Making, I asked a crowd that one former ivy league professor called “the best public crowd he’s ever seen” what they would recommend reading. These people are paid to make decisions for a living and want to find every edge they can. So when I asked them what books on decision making influenced them, you can bet they had a lot to say. Here’s the list in no particular order: 1. Decisive: How to Make Better Choices in Life and Work By: Chip  Dan Heath Research has shown time and time again how irrational humans are in our thinking. We’re overconfident. We seek out information that supports us and downplay information that doesn’t. We get distracted by short-term emotions. When it comes to making choices, it seems, our brains are flawed instruments. Unfortunately, merely being aware of these shortcomings doesn’t fix the problem, any more than knowing that we are nearsighted helps us to see. Well researched and well written, this book offers a 4 step process to help overcome our natural biases and make better decisions. On a side, if you’ve read Switch or Made to Stick you know how fun and easy a Heath brothers book is to read. This one is no different. 2. How to Measure Anything By: Douglas Hubbard Peter Drucker famously said, “What gets measured, gets managed.” But how do you measure things as nebulous as customer satisfaction, organizational flexibility or the ROI of technology? Written by recognized expert Douglas Hubbardcreator of Applied Information EconomicsHow to Measure Anything illustrates how the author has used his approach across various industries and how any problem, no matter how difficult, ill defined, or uncertain can lend itself to measurement and therefore improvement using proven methods. 3. How to Make Sense of Any Mess: Information Architecture for Everybody By: Abby Covert According to the author, every “mess” has a similar structure. Whether we’re dealing with a crisis at work or at home, find ourselves in a muck with other people, or are trying to make sense of the deluge of information all around us, this book offers a 7 step process for making sense of it all. No mess is too big once you know how to properly tackle one. 4. Wiser: Getting Beyond Groupthink to Make Groups Smarter By: Cass Sunstein  Reid Hastie If you work with groups of people in any way, this is a great read with lots of useful nuggets. We tend to assume that a group of bright minds working together to solve a problem would yield the best outcome, but research has shown that isn’t always the case. In fact, we tend to sabotage our own results by giving the most weight to the positions stated first, shared the loudest, or held in common with the rest of the group. In Wiser, you’ll not only learn how to avoid the pitfalls that plague so many meetings today, but how to get the best out of those participating, so your collective decision making becomes more effective, more productive, and a better investment of time. 5. The Surprising Power of Liberating Structures: Simple Rules to Unleash A Culture of Innovation By: Henri Lipmanowicz  Keith McCandless Whether you are a teacher, a manager, a parent, or a leader in any way, you know how frustrating it can be when the individuals you’re trying to lead aren’t fully engaged. It’s bad for the organization, it’s bad for productivity, and quite frankly, it’s bad for the individual. The Surprising Power of Liberating Structures explores practical methods to help people get engaged and invested in what they’re doing  and feel personal satisfaction from doing it. 6. Gamestorming: A Playbook for Innovators, Rulebreakers, and Changemakers By: Dave Gray, Sunni Brown  James Macanufo If your work environment isn’t one where employees feel safe to share their ideas and interact freely with one another, you can’t expect to accomplish anything significant. You’ll always be chugging along at less than full capacity. That’s where this book comes in. It provides over 80 games that are specifically designed to break down barriers, foster communication, and get the creative juices flowing. 7. The Righteous Mind: Why Good People are Divided by Politics and Religion By: Jonathan Haidt Think you’re absolutely right on the hot political, social or religious debate of the day? Before you get into it with your brother-in-law over Thanksgiving dinner, make sure you read this book. Jonathan Haidt does a masterful job of showing that the other side isn’t as crazy as we think, and in fact, we’re all a bit more crazy than we’d like to admit. He draws on decades of research to show that what we consider to be moral judgments are not formed by sound reasoning, but by intuition. Understanding why and how that happens is critical to understanding each other. And a necessary part of having an opinion.  8. Yes or No: The Guide to Better Decisions By: Spencer Johnson Who Moved My Cheese? gets a lot of love, but Spencer Johnson’s book on decision making deserves way more attention than it gets. In my opinion, it’s his best book. And it’s short, practical and easy to apply. You could read this over your lunch break and be a better thinker before you even finish your sandwich. 9. The Little Book of Talent By: Daniel Coyle This is a great companion piece to the Talent Code by the same author, but definitely stands on its own. Where that book is more about the science and research behind developing talent, The Little Book of Talent gives you the “how to” with over 50 specific exercises you can start using today to improve whatever skill you’re working on  whether it’s art, music, sports, or cooking eggs. This book will help you get better, faster. 10. The Worry Solution: Using Breakthrough Brain Science to Turn Stress and Anxiety into Confidence and Happiness By: Martin Rossman Seneca once said, “He who suffers before it is necessary suffers more than is necessary.” Often, that unnecessary suffering comes from excessive worrying. I get it, there’s plenty to worry about today  kids, finances, your career, relationships  the list is endless. This book offers practical and actionable steps to get worry under control, so it stops adding unnecessary stress and anxiety to your life. 11. Shantaram: A Novel By: Gregory David Roberts One of the only novels on the list, Shantaram is less of a book on how to make decisions, but rather a fascinating case study on how the direction of our life is inextricably tied to the decisions we make. At nearly 1000 pages, this is not an afternoon read, but it is a thrilling ride that doesn’t slow down once it starts rolling. From the inside cover: Shantaram is narrated by Lin, an escaped convict with a false passport who flees maximum security prison in Australia for the teeming streets of a city where he can disappear. Burning slums and five-star hotels, romantic love and prison agonies, criminal wars and Bollywood films, spiritual gurus and mujahideen guerrillasthis huge novel has the world of human experience in its reach, and a passionate love for India at its heart. Based on the life of the author, it is by any measure the debut of an extraordinary voice in literature. 12. The Art of Living By: Epictetus One of the most influential Stoic thinkers, Epictetus was born into slavery about 55 ce in the eastern outreaches of the Roman Empire. Once freed, he established a school of Stoic philosophy, stressing that human beings cannot control life, only their responses to it. By putting into practice the ninety-three witty, wise, and razor-sharp instructions that make up The Art of Living, you’ll learn to meet the challenges of everyday life successfully and to face life’s inevitable losses and disappointments with grace. 13. The Education of a Value Investor By: Guy Spier This book packs a lot into its pages. It’s both a priceless education in value investing, and a riveting story of personal transformation. Among other valuable lessons, you’ll discover how a 600,000 lunch with Warren Buffet turned out to be one of the best and high yielding investments author Guy Spier ever made. 14. Devil Take the Hindmost: a History of Financial Speculation By: Edward Chancellor Before you drop a dime into that hot tech stock your co-worker is raving about, pick up this book. The author takes a hard look at both the psychological and economic forces that drive people to “bet” their money in markets; how markets are made, unmade, manipulated; and who wins when speculation runs rampant. 15. Click: The Art and Science of Getting from Impasse to Insight By: Eve Grodnitzky Wouldn’t it be nice if we could be inspired on demand? Get a fresh jolt of energy, insights and creativity when we’ve hit the wall? According to author Eve Grodnitsky, we can. In Click, she provides a 7 step methodology to take someone from “impasse to insight.” Drawing on the latest research and her own analysis of hundreds of real-life insight stories, Dr. Grodnitzky explains how insight actually works and how to have more of these eureka moments at work and in life. 16. The Dictator’s Handbook: Why Bad Behavior is Almost Always Good Politics By: Bruce Bueno de Mesquita The authors of this book make a bold claim: leaders do whatever keeps them in power, regardless of the national interest. And while there are clear differences between a liberal democracy and a dictatorship, the common thread through both is the same  scratch the right backs, and keep the people in the dark. This is an entertaining, yet at times unsettling, manual for gaining and preserving power  akin to Machiavelli’s The Prince.  17. The Back of the Napkin  How to Solve Problems and Sell Ideas By: Dan Roan Have you ever had a hard time expressing a complex idea to someone? In this book, author Dan Roan suggests using fewer words and more pictures. He shows how a few simple drawings done the right way can clarify any problem or sell any idea to your audience  whether that’s one person or a full auditorium. 18. Crossing to Safety By: Wallace Stegner One of only three novels on the list. From the inside flap: Called a “magnificently crafted story . . . brimming with wisdom” by Howard Frank Mosher in The Washington Post Book World, Crossing to Safety has, since its publication in 1987, established itself as one of the greatest and most cherished American novels of the twentieth century. Tracing the lives, loves, and aspirations of two couples who move between Vermont and Wisconsin, it is a work of quiet majesty, deep compassion, and powerful insight into the alchemy of friendship and marriage. 19. Paradox of Choice: Why More is Less By: Barry Schwartz No matter what you’re in the market for, you have options. Lots of them. Where to invest your money, how to order your coffee, what to wear, and don’t even get me started on the menu at the Cheesecake Factory. In Paradox of Choice, Schwartz makes the counter intuitive case that too many options can actually be a bad thing  and eliminating choices can reduce the stress, anxiety, and busyness of our lives. He offers 11 practical steps to limit choices to a manageable number, have the discipline to focus on the ones that are important, and derive greater satisfaction from the choices you have to make. 20. Streetlights and Shadows: Searching for the Keys to Adaptive Decision Making By: Gary Klein When making an important decision, should you go with your gut or lean more on logic and statistics? The answer may not be as clear cut as you’d expect, and each situation requires its own approach. In Streetlights and Shadows, Gary Klein debunks the conventional wisdom about how to make decisions. He takes ten commonly accepted claims about decision making and shows that they are better suited for the laboratory than for life  and what we should do instead. 21. The Social Animal By: David Brooks The Social Animal weaves the narrative of a fictional American couple from birth to old age with the most recent research on social and cognitive science to illustrate how we develop during different stages of our lives. Brooks paints a new and refreshing view of humanity and what it really means to be successful. 22. The Laws of Simplicity By: John Maeda In this short but engaging read, graphic designer and computer scientist Maeda proposes ten laws for simplifying complex systems in business and life but mostly focuses on product design. Maeda’s upbeat explanations break down the power of less  fewer features, fewer buttons and fewer distractions  while providing practical strategies for harnessing that power. 23. Nudge: Improving Decisions about Health, Wealth and Happiness By: Richard H. Thaler By now, it shouldn’t surprise you to learn that humans are inherently bad at making decisions. And only through understanding and being aware of our biases can we ever hope to get better at it. This is a well written and easy to read book, written by Richard Thaler who happens to be a Nobel Prize winner. If you want to improve your own decision making, and also learn how to “nudge” those you care about towards making better choices as well, grab this book. 24. Reminiscences of a Stock Operator By: Edwin Lefevre  Roger Lowenstein First published in 1923, Reminiscences of a Stock Operator is perhaps the most widely read, highly recommended investment book ever. And after nearly 100 years on the shelves, it’s just as relevant today as it was when it was first written. Generations of readers have found that it has more to teach them about markets and people than years of hands-on experience. 25. This Will Make You Smarter By: John Brockman “What scientific concept would improve everybody’s cognitive toolkit?” This is the question John Brockman posed to the world’s most influential thinkers. This book is a collection of their answers. Daniel Kahneman, Nassim Nicholas Taleb, Richard Dawkins, Brian Eno, Steven Pinker, Lisa Randall  the list goes on and on. You’ll definitely pick up something new and immediately useful in this book. 26. A More Beautiful Question: The Power of Inquiry to Spark Breakthrough Ideas By: Warren Berger In A More Beautiful Question, Warren Berger makes the compelling argument that our outcomes are directly tied to the quality of questions we’re willing to ask. By showing how to approach questioning with an open, curious mind and a willingness to work through a series of “Why,” “What if,” and “How” queries, Berger offers an inspiring framework of how we can all arrive at better solutions, fresh possibilities, and greater success in business and life. Pairs nicely with this podcast interview. ; 27. Red Notice: A True Story of High Finance, Murder, and One Man’s Fight for Justice By: Bill Browden I’ve talked about this book before and it remains high on my personal recommendation list. It’s hard to believe this story recounts actual events  it reads just like a fictional crime thriller and was difficult for me to put down. If you’re into conspiracies, crime, and politics  run for office. Just kidding, get this book. 28. The Man who Mistook his Wife for a Hat By: Oliver Sacks This book is a collection of some of the most bizarre, fascinating, and at times heartbreaking stories of people afflicted with a variety of neurological disorders. We learn about patients who are no longer able to recognize people and common objects; who are stricken with violent tics and grimaces or who shout involuntary obscenities; whose limbs have become alien; and who have been dismissed as retarded yet are gifted with uncanny artistic or mathematical talents. 29. Imprudent King: A New Life of Philip II By: Geoffrey Parker Philip II is not only the most famous king in Spanish history, but one of the most famous monarchs in English history: the man who married Mary Tudor and later launched the Spanish Armada against her sister Elizabeth I. This book examines Philip’s long apprenticeship; his three principal interests work, play, and religion; and the major political, military, and personal challenges he faced during his long reign. Parker offers fresh insights into the causes of Philip’s leadership failures: was his empire simply too big to manage, or would a monarch with different talents and temperament have fared better? 30. Seeking Wisdom By: Peter Bevelin Inspired by the wisdom of Charlie Munger, Seeking Wisdom is a compendium of the big ideas that shape the way we see and interact with the world. This book is one of my personal favorites and has had a massive impact on how I think and view reality. Get it. 31. Mastery By: Robert Greene Robert Greene insists that we all have it within us to be masters. And in Mastery, he provides the formula. The same formula that was used by great historical figures such as Charles Darwin, Mozart, Paul Graham and Henry Ford. 32. Synchronicity: The Innes Path of Leadership By: Joseph Jaworski “Synchronicity” is the term used to describe the feeling that everything in life  the ups, the downs, the disasters and the triumphs, seem to work together for your good. Author Joseph Jaworski argues that the right state of mind will make you the kind of person who can enlist the cooperation of fate and take advantage of synchronicity, creating the conditions for “predictable miracles.” 33. The Culture Map: Breaking Through the Invisible Boundaries of Global Business By: Erin Meyer Americans precede anything negative with three nice comments; French, Dutch, Israelis, and Germans get straight to the point; Latin Americans and Asians are steeped in hierarchy; Scandinavians think the best boss is just one of the crowd. It’s no surprise that when they try and talk to each other, chaos breaks out. This is the book to help you navigate those tricky and potentially awkward misunderstandings. 34. Ubiquity: Why Catastrophes Happen By: Mark Buchanan Critically acclaimed science journalist, Mark Buchanan tells the fascinating story of the discovery that there is a natural structure of instability woven into the fabric of our world, which explains why catastrophes  both natural and human  happen. 35. Family Fortunes By: Bill Bonner In Family Fortunes, father-and-son team Bill and Will Bonner present a radical new way to look at family money along with the practical advice you need to build  and maintain  multi-generational wealth. Filled with invaluable advice for making money and keeping it in the family, the book illustrates why family money is the most dynamic, forward-looking capital in the world, and how your family can cash in on it for generations to come. 36. Influence: The Psychology of Persuasion By: Robert Cialdini Considered by many to be the Bible of persuasion, Dr. Cialdini’s Influence was one of the first books to explore the irrationality of human decision making and helped put the field of behavioral economics on the map. Through dozens of fascinating real life studies, you’ll learn the six universal principles, how to use them to become a skilled persuaderand how to defend yourself against them. 37. Antifragile: Things That Gain from Disorder By: Nassim Nicholas Taleb Fragile systems break under stress, robust systems resist it, and antifragile systems benefit from it. That’s the premise of Taleb’s groundbreaking work, Antifragile. That we should not only prepare for risk, uncertainty and chaos, but invite it, is a revolutionary idea, but Taleb makes a strong case. Throughout the book, he explores the state of politics, urban planning, finances, economics and medicine to illustrate the necessity of building antifragile systems if we want to thrive in this world. 38. Poor Charlie’s Almanack: The Wit and Wisdom of Charles T. Munger By: Peter D. Kaufman  Charlie T. Munger Pound for pound, one of the most important books I’ve ever read, and one that has had a profound impact on my thinking. It should be no surprise to readers of FS that Charlie Munger and Warren Buffet are the two people who have influenced me the most, and this book is a collection of much of the wisdom that attracted me to their philosophies on life, investing, and how I look at the world. And yes, while the book is a little pricier than most, if it were 20x the price, it would still be an amazing value. 39. The Brain that Changes Itself By: Norman Doidge For centuries it was thought that the brain stopped developing after a period of time, and that it was a very rigid process. In this book, Norman Doidge explores what scientists call “neuroplasticity” and how nearly everything we once believed about the brain is wrong. The brain is fluid, constantly remapping and rewiring to make its job more efficient. Dr. Doidge shares powerful stories of people who relearn to speak after a stroke, overcome debilitating vertigo, even a blind man who learns to “see.” As it turns out, you can teach an old dog new tricks. 40. The Great Mental Models, Volume 1: General Thinking Concepts A thorough understanding of these 9 models will, without a doubt, improve the way you approach problems, consider opportunities, and make difficult decisions. And there you have it  a list of books on decision making that should give you a great starting point. Let us know if there was a book we missed that needs to be on the list! ",
			"tokens": 4661,
			"chunks": [
				{
					"article_title": "40 Books that Improve your Ability to Make Decisions",
					"article_url": "https://fs.blog/books-on-decision-making/",
					"content": "Who can you ask for book recommendations on decision making? At Re:Think Decision Making, I asked a crowd that one former ivy league professor called “the best public crowd he’s ever seen” what they would recommend reading. These people are paid to make decisions for a living and want to find every edge they can. So when I asked them what books on decision making influenced them, you can bet they had a lot to say. Here’s the list in no particular order: 1. Decisive: How to Make Better Choices in Life and Work By: Chip  Dan Heath Research has shown time and time again how irrational humans are in our thinking. We’re overconfident. We seek out information that supports us and downplay information that doesn’t. We get distracted by short-term emotions. When it comes to making choices, it seems, our brains are flawed instruments. ",
					"content_token": 192,
					"embedding": []
				},
				{
					"article_title": "40 Books that Improve your Ability to Make Decisions",
					"article_url": "https://fs.blog/books-on-decision-making/",
					"content": "Unfortunately, merely being aware of these shortcomings doesn’t fix the problem, any more than knowing that we are nearsighted helps us to see. Well researched and well written, this book offers a 4 step process to help overcome our natural biases and make better decisions. On a side, if you’ve read Switch or Made to Stick you know how fun and easy a Heath brothers book is to read. This one is no different. 2. How to Measure Anything By: Douglas Hubbard Peter Drucker famously said, “What gets measured, gets managed.” But how do you measure things as nebulous as customer satisfaction, organizational flexibility or the ROI of technology? Written by recognized expert Douglas Hubbardcreator of Applied Information EconomicsHow to Measure Anything illustrates how the author has used his approach across various industries and how any problem, no matter how difficult, ill defined, or uncertain can lend itself to measurement and therefore improvement using proven methods. 3. ",
					"content_token": 194,
					"embedding": []
				},
				{
					"article_title": "40 Books that Improve your Ability to Make Decisions",
					"article_url": "https://fs.blog/books-on-decision-making/",
					"content": "How to Make Sense of Any Mess: Information Architecture for Everybody By: Abby Covert According to the author, every “mess” has a similar structure. Whether we’re dealing with a crisis at work or at home, find ourselves in a muck with other people, or are trying to make sense of the deluge of information all around us, this book offers a 7 step process for making sense of it all. No mess is too big once you know how to properly tackle one. 4. Wiser: Getting Beyond Groupthink to Make Groups Smarter By: Cass Sunstein  Reid Hastie If you work with groups of people in any way, this is a great read with lots of useful nuggets. We tend to assume that a group of bright minds working together to solve a problem would yield the best outcome, but research has shown that isn’t always the case. ",
					"content_token": 184,
					"embedding": []
				},
				{
					"article_title": "40 Books that Improve your Ability to Make Decisions",
					"article_url": "https://fs.blog/books-on-decision-making/",
					"content": "In fact, we tend to sabotage our own results by giving the most weight to the positions stated first, shared the loudest, or held in common with the rest of the group. In Wiser, you’ll not only learn how to avoid the pitfalls that plague so many meetings today, but how to get the best out of those participating, so your collective decision making becomes more effective, more productive, and a better investment of time. 5. The Surprising Power of Liberating Structures: Simple Rules to Unleash A Culture of Innovation By: Henri Lipmanowicz  Keith McCandless Whether you are a teacher, a manager, a parent, or a leader in any way, you know how frustrating it can be when the individuals you’re trying to lead aren’t fully engaged. It’s bad for the organization, it’s bad for productivity, and quite frankly, it’s bad for the individual. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "40 Books that Improve your Ability to Make Decisions",
					"article_url": "https://fs.blog/books-on-decision-making/",
					"content": "The Surprising Power of Liberating Structures explores practical methods to help people get engaged and invested in what they’re doing  and feel personal satisfaction from doing it. 6. Gamestorming: A Playbook for Innovators, Rulebreakers, and Changemakers By: Dave Gray, Sunni Brown  James Macanufo If your work environment isn’t one where employees feel safe to share their ideas and interact freely with one another, you can’t expect to accomplish anything significant. You’ll always be chugging along at less than full capacity. That’s where this book comes in. It provides over 80 games that are specifically designed to break down barriers, foster communication, and get the creative juices flowing. 7. ",
					"content_token": 157,
					"embedding": []
				},
				{
					"article_title": "40 Books that Improve your Ability to Make Decisions",
					"article_url": "https://fs.blog/books-on-decision-making/",
					"content": "The Righteous Mind: Why Good People are Divided by Politics and Religion By: Jonathan Haidt Think you’re absolutely right on the hot political, social or religious debate of the day? Before you get into it with your brother-in-law over Thanksgiving dinner, make sure you read this book. Jonathan Haidt does a masterful job of showing that the other side isn’t as crazy as we think, and in fact, we’re all a bit more crazy than we’d like to admit. He draws on decades of research to show that what we consider to be moral judgments are not formed by sound reasoning, but by intuition. Understanding why and how that happens is critical to understanding each other. And a necessary part of having an opinion.  8. ",
					"content_token": 164,
					"embedding": []
				},
				{
					"article_title": "40 Books that Improve your Ability to Make Decisions",
					"article_url": "https://fs.blog/books-on-decision-making/",
					"content": "Yes or No: The Guide to Better Decisions By: Spencer Johnson Who Moved My Cheese? gets a lot of love, but Spencer Johnson’s book on decision making deserves way more attention than it gets. In my opinion, it’s his best book. And it’s short, practical and easy to apply. You could read this over your lunch break and be a better thinker before you even finish your sandwich. 9. The Little Book of Talent By: Daniel Coyle This is a great companion piece to the Talent Code by the same author, but definitely stands on its own. Where that book is more about the science and research behind developing talent, The Little Book of Talent gives you the “how to” with over 50 specific exercises you can start using today to improve whatever skill you’re working on  whether it’s art, music, sports, or cooking eggs. This book will help you get better, faster. 10. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "40 Books that Improve your Ability to Make Decisions",
					"article_url": "https://fs.blog/books-on-decision-making/",
					"content": "The Worry Solution: Using Breakthrough Brain Science to Turn Stress and Anxiety into Confidence and Happiness By: Martin Rossman Seneca once said, “He who suffers before it is necessary suffers more than is necessary.” Often, that unnecessary suffering comes from excessive worrying. I get it, there’s plenty to worry about today  kids, finances, your career, relationships  the list is endless. This book offers practical and actionable steps to get worry under control, so it stops adding unnecessary stress and anxiety to your life. 11. Shantaram: A Novel By: Gregory David Roberts One of the only novels on the list, Shantaram is less of a book on how to make decisions, but rather a fascinating case study on how the direction of our life is inextricably tied to the decisions we make. At nearly 1000 pages, this is not an afternoon read, but it is a thrilling ride that doesn’t slow down once it starts rolling. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "40 Books that Improve your Ability to Make Decisions",
					"article_url": "https://fs.blog/books-on-decision-making/",
					"content": "From the inside cover: Shantaram is narrated by Lin, an escaped convict with a false passport who flees maximum security prison in Australia for the teeming streets of a city where he can disappear. Burning slums and five-star hotels, romantic love and prison agonies, criminal wars and Bollywood films, spiritual gurus and mujahideen guerrillasthis huge novel has the world of human experience in its reach, and a passionate love for India at its heart. Based on the life of the author, it is by any measure the debut of an extraordinary voice in literature. 12. The Art of Living By: Epictetus One of the most influential Stoic thinkers, Epictetus was born into slavery about 55 ce in the eastern outreaches of the Roman Empire. Once freed, he established a school of Stoic philosophy, stressing that human beings cannot control life, only their responses to it. ",
					"content_token": 187,
					"embedding": []
				},
				{
					"article_title": "40 Books that Improve your Ability to Make Decisions",
					"article_url": "https://fs.blog/books-on-decision-making/",
					"content": "By putting into practice the ninety-three witty, wise, and razor-sharp instructions that make up The Art of Living, you’ll learn to meet the challenges of everyday life successfully and to face life’s inevitable losses and disappointments with grace. 13. The Education of a Value Investor By: Guy Spier This book packs a lot into its pages. It’s both a priceless education in value investing, and a riveting story of personal transformation. Among other valuable lessons, you’ll discover how a 600,000 lunch with Warren Buffet turned out to be one of the best and high yielding investments author Guy Spier ever made. 14. Devil Take the Hindmost: a History of Financial Speculation By: Edward Chancellor Before you drop a dime into that hot tech stock your co-worker is raving about, pick up this book. ",
					"content_token": 178,
					"embedding": []
				},
				{
					"article_title": "40 Books that Improve your Ability to Make Decisions",
					"article_url": "https://fs.blog/books-on-decision-making/",
					"content": "The author takes a hard look at both the psychological and economic forces that drive people to “bet” their money in markets; how markets are made, unmade, manipulated; and who wins when speculation runs rampant. 15. Click: The Art and Science of Getting from Impasse to Insight By: Eve Grodnitzky Wouldn’t it be nice if we could be inspired on demand? Get a fresh jolt of energy, insights and creativity when we’ve hit the wall? According to author Eve Grodnitsky, we can. In Click, she provides a 7 step methodology to take someone from “impasse to insight.” Drawing on the latest research and her own analysis of hundreds of real-life insight stories, Dr. Grodnitzky explains how insight actually works and how to have more of these eureka moments at work and in life. 16. ",
					"content_token": 185,
					"embedding": []
				},
				{
					"article_title": "40 Books that Improve your Ability to Make Decisions",
					"article_url": "https://fs.blog/books-on-decision-making/",
					"content": "The Dictator’s Handbook: Why Bad Behavior is Almost Always Good Politics By: Bruce Bueno de Mesquita The authors of this book make a bold claim: leaders do whatever keeps them in power, regardless of the national interest. And while there are clear differences between a liberal democracy and a dictatorship, the common thread through both is the same  scratch the right backs, and keep the people in the dark. This is an entertaining, yet at times unsettling, manual for gaining and preserving power  akin to Machiavelli’s The Prince.  17. The Back of the Napkin  How to Solve Problems and Sell Ideas By: Dan Roan Have you ever had a hard time expressing a complex idea to someone? In this book, author Dan Roan suggests using fewer words and more pictures. ",
					"content_token": 169,
					"embedding": []
				},
				{
					"article_title": "40 Books that Improve your Ability to Make Decisions",
					"article_url": "https://fs.blog/books-on-decision-making/",
					"content": "He shows how a few simple drawings done the right way can clarify any problem or sell any idea to your audience  whether that’s one person or a full auditorium. 18. Crossing to Safety By: Wallace Stegner One of only three novels on the list. From the inside flap: Called a “magnificently crafted story    brimming with wisdom” by Howard Frank Mosher in The Washington Post Book World, Crossing to Safety has, since its publication in 1987, established itself as one of the greatest and most cherished American novels of the twentieth century. Tracing the lives, loves, and aspirations of two couples who move between Vermont and Wisconsin, it is a work of quiet majesty, deep compassion, and powerful insight into the alchemy of friendship and marriage. 19. Paradox of Choice: Why More is Less By: Barry Schwartz No matter what you’re in the market for, you have options. Lots of them. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "40 Books that Improve your Ability to Make Decisions",
					"article_url": "https://fs.blog/books-on-decision-making/",
					"content": "Where to invest your money, how to order your coffee, what to wear, and don’t even get me started on the menu at the Cheesecake Factory. In Paradox of Choice, Schwartz makes the counter intuitive case that too many options can actually be a bad thing  and eliminating choices can reduce the stress, anxiety, and busyness of our lives. He offers 11 practical steps to limit choices to a manageable number, have the discipline to focus on the ones that are important, and derive greater satisfaction from the choices you have to make. 20. Streetlights and Shadows: Searching for the Keys to Adaptive Decision Making By: Gary Klein When making an important decision, should you go with your gut or lean more on logic and statistics? The answer may not be as clear cut as you’d expect, and each situation requires its own approach. In Streetlights and Shadows, Gary Klein debunks the conventional wisdom about how to make decisions. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "40 Books that Improve your Ability to Make Decisions",
					"article_url": "https://fs.blog/books-on-decision-making/",
					"content": "He takes ten commonly accepted claims about decision making and shows that they are better suited for the laboratory than for life  and what we should do instead. 21. The Social Animal By: David Brooks The Social Animal weaves the narrative of a fictional American couple from birth to old age with the most recent research on social and cognitive science to illustrate how we develop during different stages of our lives. Brooks paints a new and refreshing view of humanity and what it really means to be successful. 22. The Laws of Simplicity By: John Maeda In this short but engaging read, graphic designer and computer scientist Maeda proposes ten laws for simplifying complex systems in business and life but mostly focuses on product design. Maeda’s upbeat explanations break down the power of less  fewer features, fewer buttons and fewer distractions  while providing practical strategies for harnessing that power. 23. Nudge: Improving Decisions about Health, Wealth and Happiness By: Richard H. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "40 Books that Improve your Ability to Make Decisions",
					"article_url": "https://fs.blog/books-on-decision-making/",
					"content": "Thaler By now, it shouldn’t surprise you to learn that humans are inherently bad at making decisions. And only through understanding and being aware of our biases can we ever hope to get better at it. This is a well written and easy to read book, written by Richard Thaler who happens to be a Nobel Prize winner. If you want to improve your own decision making, and also learn how to “nudge” those you care about towards making better choices as well, grab this book. 24. Reminiscences of a Stock Operator By: Edwin Lefevre  Roger Lowenstein First published in 1923, Reminiscences of a Stock Operator is perhaps the most widely read, highly recommended investment book ever. And after nearly 100 years on the shelves, it’s just as relevant today as it was when it was first written. ",
					"content_token": 178,
					"embedding": []
				},
				{
					"article_title": "40 Books that Improve your Ability to Make Decisions",
					"article_url": "https://fs.blog/books-on-decision-making/",
					"content": "Generations of readers have found that it has more to teach them about markets and people than years of hands-on experience. 25. This Will Make You Smarter By: John Brockman “What scientific concept would improve everybody’s cognitive toolkit?” This is the question John Brockman posed to the world’s most influential thinkers. This book is a collection of their answers. Daniel Kahneman, Nassim Nicholas Taleb, Richard Dawkins, Brian Eno, Steven Pinker, Lisa Randall  the list goes on and on. You’ll definitely pick up something new and immediately useful in this book. 26. A More Beautiful Question: The Power of Inquiry to Spark Breakthrough Ideas By: Warren Berger In A More Beautiful Question, Warren Berger makes the compelling argument that our outcomes are directly tied to the quality of questions we’re willing to ask. ",
					"content_token": 181,
					"embedding": []
				},
				{
					"article_title": "40 Books that Improve your Ability to Make Decisions",
					"article_url": "https://fs.blog/books-on-decision-making/",
					"content": "By showing how to approach questioning with an open, curious mind and a willingness to work through a series of “Why,” “What if,” and “How” queries, Berger offers an inspiring framework of how we can all arrive at better solutions, fresh possibilities, and greater success in business and life. Pairs nicely with this podcast interview. ; 27. Red Notice: A True Story of High Finance, Murder, and One Man’s Fight for Justice By: Bill Browden I’ve talked about this book before and it remains high on my personal recommendation list. It’s hard to believe this story recounts actual events  it reads just like a fictional crime thriller and was difficult for me to put down. If you’re into conspiracies, crime, and politics  run for office. Just kidding, get this book. 28. ",
					"content_token": 183,
					"embedding": []
				},
				{
					"article_title": "40 Books that Improve your Ability to Make Decisions",
					"article_url": "https://fs.blog/books-on-decision-making/",
					"content": "The Man who Mistook his Wife for a Hat By: Oliver Sacks This book is a collection of some of the most bizarre, fascinating, and at times heartbreaking stories of people afflicted with a variety of neurological disorders. We learn about patients who are no longer able to recognize people and common objects; who are stricken with violent tics and grimaces or who shout involuntary obscenities; whose limbs have become alien; and who have been dismissed as retarded yet are gifted with uncanny artistic or mathematical talents. 29. Imprudent King: A New Life of Philip II By: Geoffrey Parker Philip II is not only the most famous king in Spanish history, but one of the most famous monarchs in English history: the man who married Mary Tudor and later launched the Spanish Armada against her sister Elizabeth I. ",
					"content_token": 165,
					"embedding": []
				},
				{
					"article_title": "40 Books that Improve your Ability to Make Decisions",
					"article_url": "https://fs.blog/books-on-decision-making/",
					"content": "This book examines Philip’s long apprenticeship; his three principal interests work, play, and religion; and the major political, military, and personal challenges he faced during his long reign. Parker offers fresh insights into the causes of Philip’s leadership failures: was his empire simply too big to manage, or would a monarch with different talents and temperament have fared better? 30. Seeking Wisdom By: Peter Bevelin Inspired by the wisdom of Charlie Munger, Seeking Wisdom is a compendium of the big ideas that shape the way we see and interact with the world. This book is one of my personal favorites and has had a massive impact on how I think and view reality. Get it. 31. Mastery By: Robert Greene Robert Greene insists that we all have it within us to be masters. And in Mastery, he provides the formula. The same formula that was used by great historical figures such as Charles Darwin, Mozart, Paul Graham and Henry Ford. 32. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "40 Books that Improve your Ability to Make Decisions",
					"article_url": "https://fs.blog/books-on-decision-making/",
					"content": "Synchronicity: The Innes Path of Leadership By: Joseph Jaworski “Synchronicity” is the term used to describe the feeling that everything in life  the ups, the downs, the disasters and the triumphs, seem to work together for your good. Author Joseph Jaworski argues that the right state of mind will make you the kind of person who can enlist the cooperation of fate and take advantage of synchronicity, creating the conditions for “predictable miracles.” 33. The Culture Map: Breaking Through the Invisible Boundaries of Global Business By: Erin Meyer Americans precede anything negative with three nice comments; French, Dutch, Israelis, and Germans get straight to the point; Latin Americans and Asians are steeped in hierarchy; Scandinavians think the best boss is just one of the crowd. It’s no surprise that when they try and talk to each other, chaos breaks out. ",
					"content_token": 194,
					"embedding": []
				},
				{
					"article_title": "40 Books that Improve your Ability to Make Decisions",
					"article_url": "https://fs.blog/books-on-decision-making/",
					"content": "This is the book to help you navigate those tricky and potentially awkward misunderstandings. 34. Ubiquity: Why Catastrophes Happen By: Mark Buchanan Critically acclaimed science journalist, Mark Buchanan tells the fascinating story of the discovery that there is a natural structure of instability woven into the fabric of our world, which explains why catastrophes  both natural and human  happen. 35. Family Fortunes By: Bill Bonner In Family Fortunes, father-and-son team Bill and Will Bonner present a radical new way to look at family money along with the practical advice you need to build  and maintain  multi-generational wealth. Filled with invaluable advice for making money and keeping it in the family, the book illustrates why family money is the most dynamic, forward-looking capital in the world, and how your family can cash in on it for generations to come. 36. ",
					"content_token": 186,
					"embedding": []
				},
				{
					"article_title": "40 Books that Improve your Ability to Make Decisions",
					"article_url": "https://fs.blog/books-on-decision-making/",
					"content": "Influence: The Psychology of Persuasion By: Robert Cialdini Considered by many to be the Bible of persuasion, Dr. Cialdini’s Influence was one of the first books to explore the irrationality of human decision making and helped put the field of behavioral economics on the map. Through dozens of fascinating real life studies, you’ll learn the six universal principles, how to use them to become a skilled persuaderand how to defend yourself against them. 37. Antifragile: Things That Gain from Disorder By: Nassim Nicholas Taleb Fragile systems break under stress, robust systems resist it, and antifragile systems benefit from it. That’s the premise of Taleb’s groundbreaking work, Antifragile. That we should not only prepare for risk, uncertainty and chaos, but invite it, is a revolutionary idea, but Taleb makes a strong case. ",
					"content_token": 192,
					"embedding": []
				},
				{
					"article_title": "40 Books that Improve your Ability to Make Decisions",
					"article_url": "https://fs.blog/books-on-decision-making/",
					"content": "Throughout the book, he explores the state of politics, urban planning, finances, economics and medicine to illustrate the necessity of building antifragile systems if we want to thrive in this world. 38. Poor Charlie’s Almanack: The Wit and Wisdom of Charles T. Munger By: Peter D. Kaufman  Charlie T. Munger Pound for pound, one of the most important books I’ve ever read, and one that has had a profound impact on my thinking. It should be no surprise to readers of FS that Charlie Munger and Warren Buffet are the two people who have influenced me the most, and this book is a collection of much of the wisdom that attracted me to their philosophies on life, investing, and how I look at the world. And yes, while the book is a little pricier than most, if it were 20x the price, it would still be an amazing value. 39. ",
					"content_token": 192,
					"embedding": []
				},
				{
					"article_title": "40 Books that Improve your Ability to Make Decisions",
					"article_url": "https://fs.blog/books-on-decision-making/",
					"content": "The Brain that Changes Itself By: Norman Doidge For centuries it was thought that the brain stopped developing after a period of time, and that it was a very rigid process. In this book, Norman Doidge explores what scientists call “neuroplasticity” and how nearly everything we once believed about the brain is wrong. The brain is fluid, constantly remapping and rewiring to make its job more efficient. Dr. Doidge shares powerful stories of people who relearn to speak after a stroke, overcome debilitating vertigo, even a blind man who learns to “see.” As it turns out, you can teach an old dog new tricks. 40. The Great Mental Models, Volume 1: General Thinking Concepts A thorough understanding of these 9 models will, without a doubt, improve the way you approach problems, consider opportunities, and make difficult decisions. ",
					"content_token": 183,
					"embedding": []
				},
				{
					"article_title": "40 Books that Improve your Ability to Make Decisions",
					"article_url": "https://fs.blog/books-on-decision-making/",
					"content": "And there you have it  a list of books on decision making that should give you a great starting point. Let us know if there was a book we missed that needs to be on the list!",
					"content_token": 40,
					"embedding": []
				}
			]
		},
		{
			"title": "The Inside View and Making Better Decisions",
			"url": "https://fs.blog/inside-view-michael-mauboussin/",
			"content": "When we don’t think about the process we use to make decisions, they tend to get worse over time as we fail to learn from experience. Often, we make decisions based on the information that is easiest to access. Let’s learn how to take the outside view and make better decisions.  In his book Think Twice: Harnessing the Power of Counterintuition, Michael Mauboussin discusses how we can “fall victim to simplified mental routines that prevent us from coping with the complex realities inherent in important judgment calls.” One of those routines is the inside view, which we’re going to talk about in this article but first let’s get a bit of context. No one wakes up thinking, “I am going to make bad decisions today.” Yet we all make them. What is particularly surprising is some of the biggest mistakes are made by people who are, by objective standards, very intelligent. Smart people make big, dumb, and consequential mistakes.  Mental flexibility, introspection, and the ability to properly calibrate evidence are at the core of rational thinking and are largely absent on IQ tests. Smart people make poor decisions because they have the same factory settings on their mental software as the rest of us, and that software isn’t designed to cope with many of today’s problems. We don’t spend enough time thinking and learning from the process. Generally, we’re pretty ambivalent about the process by which we make decisions.  typical decision makers allocate only 25 percent of their time to thinking about the problem properly and learning from experience. Most spend their time gathering information, which feels like progress and appears diligent to superiors. But information without context is falsely empowering. That reminds me of what Daniel Kahneman wrote in Thinking, Fast and Slow: A remarkable aspect of your mental life is that you are rarely stumped  The normal state of your mind is that you have intuitive feelings and opinions about almost everything that comes your way. You like or dislike people long before you know much about them; you trust or distrust strangers without knowing why; you feel that an enterprise is bound to succeed without analyzing it. Context comes from broad understanding  looking at the problem from the outside in and not the inside out. When we make a decision, we’re not really gathering and contextualizing information as much as trying to satisfice our existing intuition; The very thing a good decision process should help root out. Think about it this way, every time you make a decision, you’re saying you understand something. Most of us stop there. But understanding is not enough; you need to test that your understanding is correct, which comes through feedback and reflection. Then you need to update your understanding. This is the learning loop. So why are we so quick to assume we understand? Ego Induced Blindness We tend to favor the inside view over the outside view. An inside view considers a problem by focusing on the specific task and by using information that is close at hand, and makes predictions based on that narrow and unique set of inputs. These inputs may include anecdotal evidence and fallacious perceptions. This is the approach that most people use in building models of the future and is indeed common for all forms of planning.  The outside view asks if there are similar situations that can provide a statistical basis for making a decision. Rather than seeing a problem as unique, the outside view wants to know if others have faced comparable problems and, if so, what happened. The outside view is an unnatural way to think, precisely because it forces people to set aside all the cherished information they have gathered. When the inside view is more positive than the outside view, you’re saying knowingly or, more likely, unknowingly that this time is different. Our brains are all too happy to help us construct this argument. Mauboussin argues that we embrace the inside view for a few primary reasons. First, we’re optimistic by nature. Second, is the “illusion of optimism” we see our future as brighter than that of others. Finally, it is the illusion of control we think that chance events are subject to our control. One interesting point is that while we’re bad at looking at the outside view when it comes to ourselves, we’re better at it when it comes to other people. In fact, the planning fallacy embodies a broader principle. When people are forced to look at similar situations and see the frequency of success, they tend to predict more accurately. If you want to know how something is going to turn out for you, look at how it turned out for others in the same situation. Daniel Gilbert, a psychologist at Harvard University, ponders why people don’t rely more on the outside view, “Given the impressive power of this simple technique, we should expect people to go out of their way to use it. But they don’t.” The reason is most people think of themselves as different, and better, than those around them. So it’s mostly ego. I’m better than the people tackling this problem before me. We see the differences between situations and use those as rationalizations as to why things are different this time. Consider this: We incorrectly think that differences are more valuable than similarities. After all, anyone can see what’s the same but it takes true insight to see what’s different, right? We’re all so busy trying to find differences that we forget to pay attention to what is the same. Incorporating the Outside View In Think Twice, Mauboussin distills the work of Kahneman and Tversky into four steps and adds some commentary. 1. Select a Reference Class Find a group of situations, or a reference class, that is broad enough to be statistically significant but narrow enough to be useful in analyzing the decision that you face. The task is generally as much art as science, and is certainly trickier for problems that few people have dealt with before. But for decisions that are commoneven if they are not common for you identifying a reference class is straightforward. Mind the details. Take the example of mergers and acquisitions. We know that the shareholders of acquiring companies lose money in most mergers and acquisitions. But a closer look at the data reveals that the market responds more favorably to cash deals and those done at small premiums than to deals financed with stock at large premiums. So companies can improve their chances of making money from an acquisition by knowing what deals tend to succeed. 2. Assess the distribution of outcomes. Once you have a reference class, take a close look at the rate of success and failure.  Study the distribution and note the average outcome, the most common outcome, and extreme successes or failures.  Two other issues are worth mentioning. The statistical rate of success and failure must be reasonably stable over time for a reference class to be valid. If the properties of the system change, drawing inference from past data can be misleading. This is an important issue in personal finance, where advisers make asset allocation recommendations for their clients based on historical statistics. Because the statistical properties of markets shift over time, an investor can end up with the wrong mix of assets. Also keep an eye out for systems where small perturbations can lead to large-scale change. Since cause and effect are difficult to pin down in these systems, drawing on past experiences is more difficult. Businesses driven by hit products, like movies or books, are good examples. Producers and publishers have a notoriously difficult time anticipating results, because success and failure is based largely on social influence, an inherently unpredictable phenomenon. 3. Make a prediction. With the data from your reference class in hand, including an awareness of the distribution of outcomes, you are in a position to make a forecast. The idea is to estimate your chances of success and failure. For all the reasons that I’ve discussed, the chances are good that your prediction will be too optimistic. Sometimes when you find the right reference class, you see the success rate is not very high. So to improve your chance of success, you have to do something different than everyone else. 4. Assess the reliability of your prediction and fine-tune. How good we are at making decisions depends a great deal on what we are trying to predict. Weather forecasters, for instance, do a pretty good job of predicting what the temperature will be tomorrow. Book publishers, on the other hand, are poor at picking winners, with the exception of those books from a handful of best-selling authors. The worse the record of successful prediction is, the more you should adjust your prediction toward the mean or other relevant statistical measure. When cause and effect is clear, you can have more confidence in your forecast.  The main lesson we can take from this is that we tend to focus on what’s different whereas the best decisions often focus on just the opposite: what’s the same. While this situation seems a little different, it’s almost always the same. As Charlie Munger has said: “if you notice, the plots are very similar. The same plot comes back time after time.” Particulars may vary but, unless those particulars are the variables that govern the outcome of the situation, the pattern remains. If we’re going to focus on what’s different rather than what’s the same, you’d best be sure the variables you’re clinging to matter. Article Summary “You can reduce the number of mistakes you make by thinking about problems more clearly.“ Most decision-makers don’t spend enough time on the process of making decisions or learning from their mistakes. Feedback and reflection are necessary components to learn from experience. When you think this time is different, you’re saying you will succeed where others have failed. To better incorporate a broader view, you can select a reference class, assess the distribution of outcomes, make a prediction, and calibrate your accuracy. We tend to focus on what’s different, whereas many of the best decisions focus on what’s the same.  ",
			"tokens": 2086,
			"chunks": [
				{
					"article_title": "The Inside View and Making Better Decisions",
					"article_url": "https://fs.blog/inside-view-michael-mauboussin/",
					"content": "When we don’t think about the process we use to make decisions, they tend to get worse over time as we fail to learn from experience. Often, we make decisions based on the information that is easiest to access. Let’s learn how to take the outside view and make better decisions.  In his book Think Twice: Harnessing the Power of Counterintuition, Michael Mauboussin discusses how we can “fall victim to simplified mental routines that prevent us from coping with the complex realities inherent in important judgment calls.” One of those routines is the inside view, which we’re going to talk about in this article but first let’s get a bit of context. No one wakes up thinking, “I am going to make bad decisions today.” Yet we all make them. What is particularly surprising is some of the biggest mistakes are made by people who are, by objective standards, very intelligent. ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "The Inside View and Making Better Decisions",
					"article_url": "https://fs.blog/inside-view-michael-mauboussin/",
					"content": "Smart people make big, dumb, and consequential mistakes.  Mental flexibility, introspection, and the ability to properly calibrate evidence are at the core of rational thinking and are largely absent on IQ tests. Smart people make poor decisions because they have the same factory settings on their mental software as the rest of us, and that software isn’t designed to cope with many of today’s problems. We don’t spend enough time thinking and learning from the process. Generally, we’re pretty ambivalent about the process by which we make decisions.  typical decision makers allocate only 25 percent of their time to thinking about the problem properly and learning from experience. Most spend their time gathering information, which feels like progress and appears diligent to superiors. But information without context is falsely empowering. ",
					"content_token": 163,
					"embedding": []
				},
				{
					"article_title": "The Inside View and Making Better Decisions",
					"article_url": "https://fs.blog/inside-view-michael-mauboussin/",
					"content": "That reminds me of what Daniel Kahneman wrote in Thinking, Fast and Slow: A remarkable aspect of your mental life is that you are rarely stumped  The normal state of your mind is that you have intuitive feelings and opinions about almost everything that comes your way. You like or dislike people long before you know much about them; you trust or distrust strangers without knowing why; you feel that an enterprise is bound to succeed without analyzing it. Context comes from broad understanding  looking at the problem from the outside in and not the inside out. When we make a decision, we’re not really gathering and contextualizing information as much as trying to satisfice our existing intuition; The very thing a good decision process should help root out. Think about it this way, every time you make a decision, you’re saying you understand something. Most of us stop there. But understanding is not enough; you need to test that your understanding is correct, which comes through feedback and reflection. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "The Inside View and Making Better Decisions",
					"article_url": "https://fs.blog/inside-view-michael-mauboussin/",
					"content": "Then you need to update your understanding. This is the learning loop. So why are we so quick to assume we understand? Ego Induced Blindness We tend to favor the inside view over the outside view. An inside view considers a problem by focusing on the specific task and by using information that is close at hand, and makes predictions based on that narrow and unique set of inputs. These inputs may include anecdotal evidence and fallacious perceptions. This is the approach that most people use in building models of the future and is indeed common for all forms of planning.  The outside view asks if there are similar situations that can provide a statistical basis for making a decision. Rather than seeing a problem as unique, the outside view wants to know if others have faced comparable problems and, if so, what happened. The outside view is an unnatural way to think, precisely because it forces people to set aside all the cherished information they have gathered. ",
					"content_token": 189,
					"embedding": []
				},
				{
					"article_title": "The Inside View and Making Better Decisions",
					"article_url": "https://fs.blog/inside-view-michael-mauboussin/",
					"content": "When the inside view is more positive than the outside view, you’re saying knowingly or, more likely, unknowingly that this time is different. Our brains are all too happy to help us construct this argument. Mauboussin argues that we embrace the inside view for a few primary reasons. First, we’re optimistic by nature. Second, is the “illusion of optimism” we see our future as brighter than that of others. Finally, it is the illusion of control we think that chance events are subject to our control. One interesting point is that while we’re bad at looking at the outside view when it comes to ourselves, we’re better at it when it comes to other people. In fact, the planning fallacy embodies a broader principle. When people are forced to look at similar situations and see the frequency of success, they tend to predict more accurately. ",
					"content_token": 184,
					"embedding": []
				},
				{
					"article_title": "The Inside View and Making Better Decisions",
					"article_url": "https://fs.blog/inside-view-michael-mauboussin/",
					"content": "If you want to know how something is going to turn out for you, look at how it turned out for others in the same situation. Daniel Gilbert, a psychologist at Harvard University, ponders why people don’t rely more on the outside view, “Given the impressive power of this simple technique, we should expect people to go out of their way to use it. But they don’t.” The reason is most people think of themselves as different, and better, than those around them. So it’s mostly ego. I’m better than the people tackling this problem before me. We see the differences between situations and use those as rationalizations as to why things are different this time. Consider this: We incorrectly think that differences are more valuable than similarities. ",
					"content_token": 163,
					"embedding": []
				},
				{
					"article_title": "The Inside View and Making Better Decisions",
					"article_url": "https://fs.blog/inside-view-michael-mauboussin/",
					"content": "After all, anyone can see what’s the same but it takes true insight to see what’s different, right? We’re all so busy trying to find differences that we forget to pay attention to what is the same. Incorporating the Outside View In Think Twice, Mauboussin distills the work of Kahneman and Tversky into four steps and adds some commentary. 1. Select a Reference Class Find a group of situations, or a reference class, that is broad enough to be statistically significant but narrow enough to be useful in analyzing the decision that you face. The task is generally as much art as science, and is certainly trickier for problems that few people have dealt with before. But for decisions that are commoneven if they are not common for you identifying a reference class is straightforward. Mind the details. Take the example of mergers and acquisitions. We know that the shareholders of acquiring companies lose money in most mergers and acquisitions. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "The Inside View and Making Better Decisions",
					"article_url": "https://fs.blog/inside-view-michael-mauboussin/",
					"content": "But a closer look at the data reveals that the market responds more favorably to cash deals and those done at small premiums than to deals financed with stock at large premiums. So companies can improve their chances of making money from an acquisition by knowing what deals tend to succeed. 2. Assess the distribution of outcomes. Once you have a reference class, take a close look at the rate of success and failure.  Study the distribution and note the average outcome, the most common outcome, and extreme successes or failures.  Two other issues are worth mentioning. The statistical rate of success and failure must be reasonably stable over time for a reference class to be valid. If the properties of the system change, drawing inference from past data can be misleading. This is an important issue in personal finance, where advisers make asset allocation recommendations for their clients based on historical statistics. Because the statistical properties of markets shift over time, an investor can end up with the wrong mix of assets. ",
					"content_token": 194,
					"embedding": []
				},
				{
					"article_title": "The Inside View and Making Better Decisions",
					"article_url": "https://fs.blog/inside-view-michael-mauboussin/",
					"content": "Also keep an eye out for systems where small perturbations can lead to large-scale change. Since cause and effect are difficult to pin down in these systems, drawing on past experiences is more difficult. Businesses driven by hit products, like movies or books, are good examples. Producers and publishers have a notoriously difficult time anticipating results, because success and failure is based largely on social influence, an inherently unpredictable phenomenon. 3. Make a prediction. With the data from your reference class in hand, including an awareness of the distribution of outcomes, you are in a position to make a forecast. The idea is to estimate your chances of success and failure. For all the reasons that I’ve discussed, the chances are good that your prediction will be too optimistic. Sometimes when you find the right reference class, you see the success rate is not very high. So to improve your chance of success, you have to do something different than everyone else. 4. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "The Inside View and Making Better Decisions",
					"article_url": "https://fs.blog/inside-view-michael-mauboussin/",
					"content": "Assess the reliability of your prediction and fine-tune. How good we are at making decisions depends a great deal on what we are trying to predict. Weather forecasters, for instance, do a pretty good job of predicting what the temperature will be tomorrow. Book publishers, on the other hand, are poor at picking winners, with the exception of those books from a handful of best-selling authors. The worse the record of successful prediction is, the more you should adjust your prediction toward the mean or other relevant statistical measure. When cause and effect is clear, you can have more confidence in your forecast.  The main lesson we can take from this is that we tend to focus on what’s different whereas the best decisions often focus on just the opposite: what’s the same. While this situation seems a little different, it’s almost always the same. As Charlie Munger has said: “if you notice, the plots are very similar. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "The Inside View and Making Better Decisions",
					"article_url": "https://fs.blog/inside-view-michael-mauboussin/",
					"content": "The same plot comes back time after time.” Particulars may vary but, unless those particulars are the variables that govern the outcome of the situation, the pattern remains. If we’re going to focus on what’s different rather than what’s the same, you’d best be sure the variables you’re clinging to matter. Article Summary “You can reduce the number of mistakes you make by thinking about problems more clearly.“ Most decision-makers don’t spend enough time on the process of making decisions or learning from their mistakes. Feedback and reflection are necessary components to learn from experience. When you think this time is different, you’re saying you will succeed where others have failed. To better incorporate a broader view, you can select a reference class, assess the distribution of outcomes, make a prediction, and calibrate your accuracy. ",
					"content_token": 184,
					"embedding": []
				},
				{
					"article_title": "The Inside View and Making Better Decisions",
					"article_url": "https://fs.blog/inside-view-michael-mauboussin/",
					"content": "We tend to focus on what’s different, whereas many of the best decisions focus on what’s the same.",
					"content_token": 26,
					"embedding": []
				}
			]
		},
		{
			"title": "Kyle Bass: How Freediving Enables Better Decision Making",
			"url": "https://fs.blog/kyle-bass-freediving/",
			"content": "Below find an excerpt taken from an interview between Raoul Pal and Kyle Bass a hedge fund manager based out of Texas. What resonates with me here is the need to find a way out of a world where we are pulled in a thousand different directions and find an internal quiet. In turn these quiet and intimate moments with ourselves enable us to excel. Pal was asking about how Bass keeps balance in his life. Kyle Bass: I’ve searched for that my whole life. I found it about six years ago. My favorite thing in the world is to do freediving and spearfishing. I know you live on an island. I could do that if I wasn’t running this firm, meaning as a lifestyle choice. I have a little Hemingway in me. Raoul Pal: What is it about spearfishing and freediving that you like? I don’t spearfish. Freediving, I’ve had lessons in, and it’s a fascinating thing because it’s very internal. Kyle: It’s internal. It’s a beautiful thing. It’s like when you think about the greatest battles in the world, they’ve always been civil wars, just like I think the greatest battles you and I fight are in our head. It’s between ourselves. The biggest battles that most people fight are with themselves. When I was in college, I helped pay for college through  I had a diving and an academic scholarship. I was, primarily, a springboard diver. That was, I would say, 80 percent mental, 20 percent physical, even though it looks all physical. It’s you versus yourself. It’s you convincing yourself that you can do this, and do it as well or better than anyone else. Freediving, very similar. It’s you knowing yourself. It’s you teaching yourself how to regulate your heart rate. It’s how to control your emotions. It’s made me better at controlling my emotions in the office. Raoul: It’s kind of where I was going to get to this. Kyle: The beautiful part of freediving for me and spearfishing is the day-to-day “grind” that we go through. My phone rings 247. I take that back. I turn my phone off at night, so there’s only a select few that can get through at night.  But during the day, I’m pulled in a thousand different directions. Regardless of how much I try to control my path through the day, things pop up. You have people everywhere pulling you 50 different ways. The moment I go underwater in the ocean, it’s Zen-like for me. My phone can’t ring. No one can bother me. I’m typically there with people that I want to be there with, my team. I always dive with a team. Then it’s me versus myself. It literally is Zen-like, and I’ve gotten so much better at being calm that I go 8-10 hours a day. Raoul: Wow. Because a lot of people do the similar thing with yoga, and actually, yoga and freediving have a lot in common. Kyle: Do they? Raoul: Yeah. Lots of the great freedivers now learn yoga to understand how to control their body and control their minds. Kyle: I have a problem with yoga. My mind drifts. When I’m freediving, I’m focused. I’m focused on the potential threats, because I primarily do it all in the Bahamas, so we see sharks every day. I’m not that afraid of sharks. I respect them. The difference, for me, between yoga and freediving is in yoga you’re sitting there, and you’re in a solitary moment, and you’re trying to focus on things mentally. But  I don’t know, I need the freediving aspect of it to be really centered.  That’s how I get centered.  Raoul: Yeah, you have a physical focus then, as well. Kyle: Yeah. I’m always searching for the next great hogfish, or grouper, or lobster to eat that night. We eat what we shoot. It’s a beautiful, beautiful cycle that I go through, and I can do it for weeks on end.  Raoul: When did you take up freediving, and how did it change you in terms of how you work? Kyle: It didn’t, initially. It was just something I’d always wanted to do. I found a young man on an island in the Bahamas. I asked around and said, “Who’s the best spearfisherman on the island?” Everybody said, “It’s Dave. It’s Dave. It’s Dave.” This 17-year-old kid who had been bitten by sharks on his hand. He had been cut up on his foot by a propeller, and he’s just a great kid. Over the years, he’s become my boat captain. He’s now, I guess, 23 years old. We’ve been partners now for six years. Every moment, every chance I get for vacation, that’s where I go. Raoul: As I said, you’ve actually noticed that whole process of learning that spill into your work, and it makes you calmer in how think about things? Kyle: Yeah. You have to stay focused. If you trade on emotion, you lose every time. Every time. If you can divorce yourself of that, especially those real extreme and extremist, those emotions you feel, you have to go the other way. You have to. ",
			"tokens": 1230,
			"chunks": [
				{
					"article_title": "Kyle Bass: How Freediving Enables Better Decision Making",
					"article_url": "https://fs.blog/kyle-bass-freediving/",
					"content": "Below find an excerpt taken from an interview between Raoul Pal and Kyle Bass a hedge fund manager based out of Texas. What resonates with me here is the need to find a way out of a world where we are pulled in a thousand different directions and find an internal quiet. In turn these quiet and intimate moments with ourselves enable us to excel. Pal was asking about how Bass keeps balance in his life. Kyle Bass: I’ve searched for that my whole life. I found it about six years ago. My favorite thing in the world is to do freediving and spearfishing. I know you live on an island. I could do that if I wasn’t running this firm, meaning as a lifestyle choice. I have a little Hemingway in me. Raoul Pal: What is it about spearfishing and freediving that you like? I don’t spearfish. ",
					"content_token": 186,
					"embedding": []
				},
				{
					"article_title": "Kyle Bass: How Freediving Enables Better Decision Making",
					"article_url": "https://fs.blog/kyle-bass-freediving/",
					"content": "Freediving, I’ve had lessons in, and it’s a fascinating thing because it’s very internal. Kyle: It’s internal. It’s a beautiful thing. It’s like when you think about the greatest battles in the world, they’ve always been civil wars, just like I think the greatest battles you and I fight are in our head. It’s between ourselves. The biggest battles that most people fight are with themselves. When I was in college, I helped pay for college through  I had a diving and an academic scholarship. I was, primarily, a springboard diver. That was, I would say, 80 percent mental, 20 percent physical, even though it looks all physical. It’s you versus yourself. It’s you convincing yourself that you can do this, and do it as well or better than anyone else. Freediving, very similar. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "Kyle Bass: How Freediving Enables Better Decision Making",
					"article_url": "https://fs.blog/kyle-bass-freediving/",
					"content": "It’s you knowing yourself. It’s you teaching yourself how to regulate your heart rate. It’s how to control your emotions. It’s made me better at controlling my emotions in the office. Raoul: It’s kind of where I was going to get to this. Kyle: The beautiful part of freediving for me and spearfishing is the day-to-day “grind” that we go through. My phone rings 247. I take that back. I turn my phone off at night, so there’s only a select few that can get through at night.  But during the day, I’m pulled in a thousand different directions. Regardless of how much I try to control my path through the day, things pop up. You have people everywhere pulling you 50 different ways. The moment I go underwater in the ocean, it’s Zen-like for me. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "Kyle Bass: How Freediving Enables Better Decision Making",
					"article_url": "https://fs.blog/kyle-bass-freediving/",
					"content": "My phone can’t ring. No one can bother me. I’m typically there with people that I want to be there with, my team. I always dive with a team. Then it’s me versus myself. It literally is Zen-like, and I’ve gotten so much better at being calm that I go 8-10 hours a day. Raoul: Wow. Because a lot of people do the similar thing with yoga, and actually, yoga and freediving have a lot in common. Kyle: Do they? Raoul: Yeah. Lots of the great freedivers now learn yoga to understand how to control their body and control their minds. Kyle: I have a problem with yoga. My mind drifts. When I’m freediving, I’m focused. I’m focused on the potential threats, because I primarily do it all in the Bahamas, so we see sharks every day. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "Kyle Bass: How Freediving Enables Better Decision Making",
					"article_url": "https://fs.blog/kyle-bass-freediving/",
					"content": "I’m not that afraid of sharks. I respect them. The difference, for me, between yoga and freediving is in yoga you’re sitting there, and you’re in a solitary moment, and you’re trying to focus on things mentally. But  I don’t know, I need the freediving aspect of it to be really centered.  That’s how I get centered.  Raoul: Yeah, you have a physical focus then, as well. Kyle: Yeah. I’m always searching for the next great hogfish, or grouper, or lobster to eat that night. We eat what we shoot. It’s a beautiful, beautiful cycle that I go through, and I can do it for weeks on end.  Raoul: When did you take up freediving, and how did it change you in terms of how you work? Kyle: It didn’t, initially. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "Kyle Bass: How Freediving Enables Better Decision Making",
					"article_url": "https://fs.blog/kyle-bass-freediving/",
					"content": "It was just something I’d always wanted to do. I found a young man on an island in the Bahamas. I asked around and said, “Who’s the best spearfisherman on the island?” Everybody said, “It’s Dave. It’s Dave. It’s Dave.” This 17-year-old kid who had been bitten by sharks on his hand. He had been cut up on his foot by a propeller, and he’s just a great kid. Over the years, he’s become my boat captain. He’s now, I guess, 23 years old. We’ve been partners now for six years. Every moment, every chance I get for vacation, that’s where I go. ",
					"content_token": 170,
					"embedding": []
				},
				{
					"article_title": "Kyle Bass: How Freediving Enables Better Decision Making",
					"article_url": "https://fs.blog/kyle-bass-freediving/",
					"content": "Raoul: As I said, you’ve actually noticed that whole process of learning that spill into your work, and it makes you calmer in how think about things? Kyle: Yeah. You have to stay focused. If you trade on emotion, you lose every time. Every time. If you can divorce yourself of that, especially those real extreme and extremist, those emotions you feel, you have to go the other way. You have to.",
					"content_token": 92,
					"embedding": []
				}
			]
		},
		{
			"title": "Seymour Schulich on Deals, Business, Decisions and Life",
			"url": "https://fs.blog/seymour-schulich-business-axioms/",
			"content": "Seymour Schulich, one of Canada’s most successful businessmen and author of Get Smarter: Life and Business Lessons offers some indispensable business wisdom.   Business is a means to an end not an end in itself. Nobody on his or her deathbed says, “I wish I had spent more time in the office.” Never quit a job unless you have another job. My father taught me this great truth. You are perceived as more valuable if you are working than if you’re unemployed. You may feel staying employed doesn’t give you the time or latitude to seek a better job. This is a dangerous delusiondon’t succumb to it. Always ask the question “If this decision is wrong, is it going to be painful or fatal?” Company builders and business leaders keep away from “bet the company” investments. Keep away from advisorsconsultants. If they knew how to make money, they would. These folks are like the fellow who knows a thousand ways to make love but doesn’t know any women. The best test of a deal’s true attraction is to ask your partners, employees, directors, family, and so on, “Would you put your own money in this deal?” It’s amazing how often the answer to this question is, “No! This is good for the company, but I’ll take a pass.” These deals are invariably losers. Always have at least two people from your side present at any negotiating or deal-making sessions. This gives you time to think, plus an ally with whom to compare perceptions. Never confront or threaten people or institutions who have more power than you. Examples: police, customs agents, the sec, Ontario Securities Commission, tax agents of the government, or politicians. In dealing with the media, never forget to qualify your statements with “not for attribution” and “off the record” where appropriate. Journalists value their contacts and will usually respect a source’s desires. In negotiations, always try to get the other party to name its asking price. It may often be far lower than your maximum offer. If the other party won’t name a price, start very low. You can always go up. Almost everything in life is easier to get into than get out of. Never bid against yourself. Only raise your bid to top a real counter bid, not an imaginary one.   Image source ",
			"tokens": 515,
			"chunks": [
				{
					"article_title": "Seymour Schulich on Deals, Business, Decisions and Life",
					"article_url": "https://fs.blog/seymour-schulich-business-axioms/",
					"content": "Seymour Schulich, one of Canada’s most successful businessmen and author of Get Smarter: Life and Business Lessons offers some indispensable business wisdom.   Business is a means to an end not an end in itself. Nobody on his or her deathbed says, “I wish I had spent more time in the office.” Never quit a job unless you have another job. My father taught me this great truth. You are perceived as more valuable if you are working than if you’re unemployed. You may feel staying employed doesn’t give you the time or latitude to seek a better job. This is a dangerous delusiondon’t succumb to it. Always ask the question “If this decision is wrong, is it going to be painful or fatal?” Company builders and business leaders keep away from “bet the company” investments. Keep away from advisorsconsultants. ",
					"content_token": 192,
					"embedding": []
				},
				{
					"article_title": "Seymour Schulich on Deals, Business, Decisions and Life",
					"article_url": "https://fs.blog/seymour-schulich-business-axioms/",
					"content": "If they knew how to make money, they would. These folks are like the fellow who knows a thousand ways to make love but doesn’t know any women. The best test of a deal’s true attraction is to ask your partners, employees, directors, family, and so on, “Would you put your own money in this deal?” It’s amazing how often the answer to this question is, “No! This is good for the company, but I’ll take a pass.” These deals are invariably losers. Always have at least two people from your side present at any negotiating or deal-making sessions. This gives you time to think, plus an ally with whom to compare perceptions. Never confront or threaten people or institutions who have more power than you. Examples: police, customs agents, the sec, Ontario Securities Commission, tax agents of the government, or politicians. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "Seymour Schulich on Deals, Business, Decisions and Life",
					"article_url": "https://fs.blog/seymour-schulich-business-axioms/",
					"content": "In dealing with the media, never forget to qualify your statements with “not for attribution” and “off the record” where appropriate. Journalists value their contacts and will usually respect a source’s desires. In negotiations, always try to get the other party to name its asking price. It may often be far lower than your maximum offer. If the other party won’t name a price, start very low. You can always go up. Almost everything in life is easier to get into than get out of. Never bid against yourself. Only raise your bid to top a real counter bid, not an imaginary one.   Image source",
					"content_token": 134,
					"embedding": []
				}
			]
		},
		{
			"title": "Produce More by Removing More: The Disciplined Pursuit of Essentialism",
			"url": "https://fs.blog/produce-removing/",
			"content": "Aristotle talked about three kinds of work: theoretical, practical, and poetical. The first searches for truth. The second is practical with an objective around action. The third, however, is lost in our modern culture. The philosopher Martin Heidegger called this “bringing-forth.” In his book Essentialism: The Disciplined Pursuit of Less, Greg McKeown describes this as an essentialist trait. This is how the essentialist approaches execution: “An Essentialist produces morebrings forth more by removing more instead of doing more.” We rarely have the time to think through what we’re doing. And there is a lot of organizational pressure to be seen as doing something new. The problem is that we think of execution in terms of addition rather than subtraction. The way to increase the production speed is to add more people. The way to get more sales is to add more salespeople. The way to do more, you need more  people, money, power. And there is a lot of evidence to support this type of thinking. At least, at first. Eventually, you add add add until your organization seeps with bureaucracy, slows to an inevitable crawl, centralizes even the smallest decisions, and loses market share. The road to hell is paved with good intentions with curbs of ego. Rather than focusing on what to add, McKeown argues that we should focus on “constraints or obstacles” that need to be removed. It isn’t about adding, it’s about subtracting. I found this interesting to think about in the context of Ben Horowitz’s distinction between good and bad organizations. But how can we re-orient around what to remove? Essentialism: The Disciplined Pursuit of Less offers three ways: 1. Be Clear About The Essential Intent We can’t know what obstacles to remove until we are clear on the desired outcome. When we don’t know what we’re really trying to achieve, all change is arbitrary. So ask yourself, “How will we know when we are done?” 2. Identify the “Slowest Hiker” Instead of just jumping into the project, take a few minutes to think. Ask yourself, “What are all the obstacles standing between me and getting this done?” and “What is keeping me from completing this?” Make a list of these obstacles. They might include: not having the information you need, your energy level, your desire for perfection. Prioritize the list using the question, “What is the obstacle that, if removed, would make the majority of other obstacles disappear?” When identifying your “slowest hiker,” one important thing to keep in mind is that even activities that are “productive” like doing research, or e-mailing people for information, or rewriting the report in order to get it perfect the first time around can be obstacles. Remember, the desired goal is to get a draft of the report finished. Anything slowing down the execution of that goal should be questioned. The slowest hiker is a reference to Herbie in the business parable The Goal by Eliyahu Goldratt. More generally it can be thought of as the question what is keeping you back from achieving what you want? “By systematically identifying and removing this constraint,” McKeown writes, “you’ll be able to significantly reduce the friction keeping you from executing what is essential.” 3. Remove the Obstacle  The “slowest hiker” could even be another person whether it’s a boss who won’t give the green light on a project, the finance department who won’t approve the budget, or a client who won’t sign on the dotted line. To reduce the friction with another person, apply the “catch more flies with honey” approach. Send him an e-mail, but instead of asking if he has done the work for you which obviously he hasn’t, go and see him. Ask him, “What obstacles or bottlenecks are holding you back from achieving X, and how can I help remove these?” Instead of pestering him, offer sincerely to support him. You will get a warmer reply than you would by just e-mailing him another demand. If you’re a manager or team lead, another thing starts to happen when you start removing obstacles. Not only does the output of the team increase but you’ll find that people like working with you a lot more. Essentialism: The Disciplined Pursuit of Less will help you sift the signal from the noise and focus on what really matters. ",
			"tokens": 992,
			"chunks": [
				{
					"article_title": "Produce More by Removing More: The Disciplined Pursuit of Essentialism",
					"article_url": "https://fs.blog/produce-removing/",
					"content": "Aristotle talked about three kinds of work: theoretical, practical, and poetical. The first searches for truth. The second is practical with an objective around action. The third, however, is lost in our modern culture. The philosopher Martin Heidegger called this “bringing-forth.” In his book Essentialism: The Disciplined Pursuit of Less, Greg McKeown describes this as an essentialist trait. This is how the essentialist approaches execution: “An Essentialist produces morebrings forth more by removing more instead of doing more.” We rarely have the time to think through what we’re doing. And there is a lot of organizational pressure to be seen as doing something new. The problem is that we think of execution in terms of addition rather than subtraction. The way to increase the production speed is to add more people. The way to get more sales is to add more salespeople. ",
					"content_token": 194,
					"embedding": []
				},
				{
					"article_title": "Produce More by Removing More: The Disciplined Pursuit of Essentialism",
					"article_url": "https://fs.blog/produce-removing/",
					"content": "The way to do more, you need more  people, money, power. And there is a lot of evidence to support this type of thinking. At least, at first. Eventually, you add add add until your organization seeps with bureaucracy, slows to an inevitable crawl, centralizes even the smallest decisions, and loses market share. The road to hell is paved with good intentions with curbs of ego. Rather than focusing on what to add, McKeown argues that we should focus on “constraints or obstacles” that need to be removed. It isn’t about adding, it’s about subtracting. I found this interesting to think about in the context of Ben Horowitz’s distinction between good and bad organizations. But how can we re-orient around what to remove? Essentialism: The Disciplined Pursuit of Less offers three ways: 1. ",
					"content_token": 184,
					"embedding": []
				},
				{
					"article_title": "Produce More by Removing More: The Disciplined Pursuit of Essentialism",
					"article_url": "https://fs.blog/produce-removing/",
					"content": "Be Clear About The Essential Intent We can’t know what obstacles to remove until we are clear on the desired outcome. When we don’t know what we’re really trying to achieve, all change is arbitrary. So ask yourself, “How will we know when we are done?” 2. Identify the “Slowest Hiker” Instead of just jumping into the project, take a few minutes to think. Ask yourself, “What are all the obstacles standing between me and getting this done?” and “What is keeping me from completing this?” Make a list of these obstacles. They might include: not having the information you need, your energy level, your desire for perfection. ",
					"content_token": 153,
					"embedding": []
				},
				{
					"article_title": "Produce More by Removing More: The Disciplined Pursuit of Essentialism",
					"article_url": "https://fs.blog/produce-removing/",
					"content": "Prioritize the list using the question, “What is the obstacle that, if removed, would make the majority of other obstacles disappear?” When identifying your “slowest hiker,” one important thing to keep in mind is that even activities that are “productive” like doing research, or e-mailing people for information, or rewriting the report in order to get it perfect the first time around can be obstacles. Remember, the desired goal is to get a draft of the report finished. Anything slowing down the execution of that goal should be questioned. The slowest hiker is a reference to Herbie in the business parable The Goal by Eliyahu Goldratt. ",
					"content_token": 146,
					"embedding": []
				},
				{
					"article_title": "Produce More by Removing More: The Disciplined Pursuit of Essentialism",
					"article_url": "https://fs.blog/produce-removing/",
					"content": "More generally it can be thought of as the question what is keeping you back from achieving what you want? “By systematically identifying and removing this constraint,” McKeown writes, “you’ll be able to significantly reduce the friction keeping you from executing what is essential.” 3. Remove the Obstacle  The “slowest hiker” could even be another person whether it’s a boss who won’t give the green light on a project, the finance department who won’t approve the budget, or a client who won’t sign on the dotted line. To reduce the friction with another person, apply the “catch more flies with honey” approach. Send him an e-mail, but instead of asking if he has done the work for you which obviously he hasn’t, go and see him. ",
					"content_token": 182,
					"embedding": []
				},
				{
					"article_title": "Produce More by Removing More: The Disciplined Pursuit of Essentialism",
					"article_url": "https://fs.blog/produce-removing/",
					"content": "Ask him, “What obstacles or bottlenecks are holding you back from achieving X, and how can I help remove these?” Instead of pestering him, offer sincerely to support him. You will get a warmer reply than you would by just e-mailing him another demand. If you’re a manager or team lead, another thing starts to happen when you start removing obstacles. Not only does the output of the team increase but you’ll find that people like working with you a lot more. Essentialism: The Disciplined Pursuit of Less will help you sift the signal from the noise and focus on what really matters.",
					"content_token": 137,
					"embedding": []
				}
			]
		},
		{
			"title": "A Simple Way to Improve the Pro-Con List to Make Better Decisions",
			"url": "https://fs.blog/seymour-schulich-the-decision-maker/",
			"content": "The first chapter in Seymour Schulichs book, Get Smarter: Life and Business Lessons, offers a decision tool that adds to the simple pro-and-con list that many of us have used to make decisions. Schulich, a self-made billionaire, is one of Canada’s richest and best-known businessmen. I learned this tool in a practical mathematics course more than fifty years ago and have used it for virtually every major decision of my adult life. It has never let me down and it will serve you well, too. You all know the simple pro-and-con list? The one where you divide the page in two and simply list out all the pros and cons. Well, the Decision-Maker adds a twist to that. Here’s how it works. On one sheet of paper, list all the positive things you can about the issue in question, then give each one a score from zero to tenthe higher the score, the more important it is to you. On another sheet, list the negative points, and score them from zero to tenonly this time, ten means it’s a major drawback. Suppose you are thinking of buying a house, and you tour one that’s in your price range, except the owners have painted every room to look like a giant banana. If you really hate yellow and can’t stand the thought of lifting a paint brush, you might give “ugly yellow house” a ten, and if it’s not that big a deal, maybe a two or a three. Now add up the scores. But here’s the rule. If the positive score is at least double the negative score, you should do itwhatever “it” is. But if the positives don’t outweigh the negatives by that two-to-one ratio, don’t do it, or at least think twice about it. Yes that sounds simple. I agree. But I also don’t think that things need to be complicated in order to be effective. The Decision-Maker is designed not to allow one or two factors to sway a major life decision in a disproportionate way. It forces you to strip away the emotion and really examine the relative importance of each pointwhich, of course, is why it works so well. This tool works for groups too. When we were considering whether to sell our royalty company, Franco-Nevada, to Newmont Mining, Franco’s executive team produced a collective Decision-Maker. We listed all the pros and cons, then the top four executives assigned their own point scores to each. We averaged them, the positives far outweighed the negatives, and we sold the company. ",
			"tokens": 558,
			"chunks": [
				{
					"article_title": "A Simple Way to Improve the Pro-Con List to Make Better Decisions",
					"article_url": "https://fs.blog/seymour-schulich-the-decision-maker/",
					"content": "The first chapter in Seymour Schulichs book, Get Smarter: Life and Business Lessons, offers a decision tool that adds to the simple pro-and-con list that many of us have used to make decisions. Schulich, a self-made billionaire, is one of Canada’s richest and best-known businessmen. I learned this tool in a practical mathematics course more than fifty years ago and have used it for virtually every major decision of my adult life. It has never let me down and it will serve you well, too. You all know the simple pro-and-con list? The one where you divide the page in two and simply list out all the pros and cons. Well, the Decision-Maker adds a twist to that. Here’s how it works. ",
					"content_token": 164,
					"embedding": []
				},
				{
					"article_title": "A Simple Way to Improve the Pro-Con List to Make Better Decisions",
					"article_url": "https://fs.blog/seymour-schulich-the-decision-maker/",
					"content": "On one sheet of paper, list all the positive things you can about the issue in question, then give each one a score from zero to tenthe higher the score, the more important it is to you. On another sheet, list the negative points, and score them from zero to tenonly this time, ten means it’s a major drawback. Suppose you are thinking of buying a house, and you tour one that’s in your price range, except the owners have painted every room to look like a giant banana. If you really hate yellow and can’t stand the thought of lifting a paint brush, you might give “ugly yellow house” a ten, and if it’s not that big a deal, maybe a two or a three. Now add up the scores. But here’s the rule. If the positive score is at least double the negative score, you should do itwhatever “it” is. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "A Simple Way to Improve the Pro-Con List to Make Better Decisions",
					"article_url": "https://fs.blog/seymour-schulich-the-decision-maker/",
					"content": "But if the positives don’t outweigh the negatives by that two-to-one ratio, don’t do it, or at least think twice about it. Yes that sounds simple. I agree. But I also don’t think that things need to be complicated in order to be effective. The Decision-Maker is designed not to allow one or two factors to sway a major life decision in a disproportionate way. It forces you to strip away the emotion and really examine the relative importance of each pointwhich, of course, is why it works so well. This tool works for groups too. When we were considering whether to sell our royalty company, Franco-Nevada, to Newmont Mining, Franco’s executive team produced a collective Decision-Maker. We listed all the pros and cons, then the top four executives assigned their own point scores to each. We averaged them, the positives far outweighed the negatives, and we sold the company.",
					"content_token": 196,
					"embedding": []
				}
			]
		},
		{
			"title": "Atul Gawande: The Building Industry’s Strategy for Getting Things Right in Complexity",
			"url": "https://fs.blog/atul-gawande-complexity/",
			"content": "Checklists establish a higher level of baseline performance.  A useful reminder from Atul Gawande, in The Checklist Manifesto: In a complex environment, experts are up against two main difficulties. The first is the fallibility of human memory and attention, especially when it comes to mundane, routine matters that are easily overlooked under the strain of more pressing events. When you’ve got a patient throwing up and an upset family member asking you what’s going on, it can be easy to forget that you have not checked her pulse. Faulty memory and distraction are a particular danger in what engineers call all-or-none processes: whether running to the store to buy ingredients for a cake, preparing an airplane for takeoff, or evaluating a sick person in the hospital, if you miss just one key thing, you might as well not have made the effort at all. A further difficulty, just as insidious, is that people can lull themselves into skipping steps even when they remember them. In complex processes, after all, certain steps don’t always matter.  “This has never been a problem before,” people say. Until one day it is. Checklists seem to provide protection against such failures. They remind us of the minimum necessary steps and make them explicit. They not only offer the possibility of verification but also instill a kind of discipline of higher performance.  How you employ the checklist is also important. In the face of complexity, most organizations tend to centralize decisions, which reduces the risk for egregious error. The costs of this approach are high too. Most employees loathe feeling like they need a hall pass to use the washroom. That’s why these next comments were so inspiring. There is a particularly tantalizing aspect to the building industry’s strategy for getting things right in complex situations: it’s that it gives people power. In response to risk, most authorities tend to centralize power and decision making. That’s usually what checklists are aboutdictating instructions to the workers below to ensure they do things the way we want. Indeed, the first building checklist I saw, the construction schedule on the right-hand wall of O’Sullivan’s conference room, was exactly that. It spelled out to the tiniest detail every critical step the tradesmen were expected to follow and whenwhich is logical if you’re confronted with simple and routine problems; you want the forcing function. But the list on O’Sullivan’s other wall revealed an entirely different philosophy about power and what should happen to it when you’re confronted with complex, nonroutine problemssuch as what to do when a difficult, potentially dangerous, and unanticipated anomaly suddenly appears on the fourteenth floor of a thirty-two-story skyscraper under construction. The philosophy is that you push the power of decision making out to the periphery and away from the center. You give people the room to adapt, based on their experience and expertise. All you ask is that they talk to one another and take responsibility. That is what works.  The strategy is unexpectedly democratic, and it has become standard nowadays, O’Sullivan told me, even in building inspections. The inspectors do not recompute the wind-force calculations or decide whether the joints in a given building should be bolted or welded, he said. Determining whether a structure like Russia Wharf or my hospital’s new wing is built to code and fit for occupancy involves more knowledge and complexity than any one inspector could possibly have. So although inspectors do what they can to oversee a building’s construction, mostly they make certain the builders have the proper checks in place and then have them sign affidavits attesting that they themselves have ensured that the structure is up to code. Inspectors disperse the power and the responsibility. “It makes sense,” O’Sullivan said. “The inspectors have more troubles with the safety of a two-room addition from a do-it-yourselfer than they do with projects like ours. So that’s where they focus their efforts.” Also, I suspect, at least some authorities have recognized that when they don’t let go of authority they fail. ",
			"tokens": 873,
			"chunks": [
				{
					"article_title": "Atul Gawande: The Building Industry’s Strategy for Getting Things Right in Complexity",
					"article_url": "https://fs.blog/atul-gawande-complexity/",
					"content": "Checklists establish a higher level of baseline performance.  A useful reminder from Atul Gawande, in The Checklist Manifesto: In a complex environment, experts are up against two main difficulties. The first is the fallibility of human memory and attention, especially when it comes to mundane, routine matters that are easily overlooked under the strain of more pressing events. When you’ve got a patient throwing up and an upset family member asking you what’s going on, it can be easy to forget that you have not checked her pulse. Faulty memory and distraction are a particular danger in what engineers call all-or-none processes: whether running to the store to buy ingredients for a cake, preparing an airplane for takeoff, or evaluating a sick person in the hospital, if you miss just one key thing, you might as well not have made the effort at all. ",
					"content_token": 179,
					"embedding": []
				},
				{
					"article_title": "Atul Gawande: The Building Industry’s Strategy for Getting Things Right in Complexity",
					"article_url": "https://fs.blog/atul-gawande-complexity/",
					"content": "A further difficulty, just as insidious, is that people can lull themselves into skipping steps even when they remember them. In complex processes, after all, certain steps don’t always matter.  “This has never been a problem before,” people say. Until one day it is. Checklists seem to provide protection against such failures. They remind us of the minimum necessary steps and make them explicit. They not only offer the possibility of verification but also instill a kind of discipline of higher performance.  How you employ the checklist is also important. In the face of complexity, most organizations tend to centralize decisions, which reduces the risk for egregious error. The costs of this approach are high too. Most employees loathe feeling like they need a hall pass to use the washroom. That’s why these next comments were so inspiring. ",
					"content_token": 175,
					"embedding": []
				},
				{
					"article_title": "Atul Gawande: The Building Industry’s Strategy for Getting Things Right in Complexity",
					"article_url": "https://fs.blog/atul-gawande-complexity/",
					"content": "There is a particularly tantalizing aspect to the building industry’s strategy for getting things right in complex situations: it’s that it gives people power. In response to risk, most authorities tend to centralize power and decision making. That’s usually what checklists are aboutdictating instructions to the workers below to ensure they do things the way we want. Indeed, the first building checklist I saw, the construction schedule on the right-hand wall of O’Sullivan’s conference room, was exactly that. It spelled out to the tiniest detail every critical step the tradesmen were expected to follow and whenwhich is logical if you’re confronted with simple and routine problems; you want the forcing function. ",
					"content_token": 152,
					"embedding": []
				},
				{
					"article_title": "Atul Gawande: The Building Industry’s Strategy for Getting Things Right in Complexity",
					"article_url": "https://fs.blog/atul-gawande-complexity/",
					"content": "But the list on O’Sullivan’s other wall revealed an entirely different philosophy about power and what should happen to it when you’re confronted with complex, nonroutine problemssuch as what to do when a difficult, potentially dangerous, and unanticipated anomaly suddenly appears on the fourteenth floor of a thirty-two-story skyscraper under construction. The philosophy is that you push the power of decision making out to the periphery and away from the center. You give people the room to adapt, based on their experience and expertise. All you ask is that they talk to one another and take responsibility. That is what works.  The strategy is unexpectedly democratic, and it has become standard nowadays, O’Sullivan told me, even in building inspections. The inspectors do not recompute the wind-force calculations or decide whether the joints in a given building should be bolted or welded, he said. ",
					"content_token": 187,
					"embedding": []
				},
				{
					"article_title": "Atul Gawande: The Building Industry’s Strategy for Getting Things Right in Complexity",
					"article_url": "https://fs.blog/atul-gawande-complexity/",
					"content": "Determining whether a structure like Russia Wharf or my hospital’s new wing is built to code and fit for occupancy involves more knowledge and complexity than any one inspector could possibly have. So although inspectors do what they can to oversee a building’s construction, mostly they make certain the builders have the proper checks in place and then have them sign affidavits attesting that they themselves have ensured that the structure is up to code. Inspectors disperse the power and the responsibility. “It makes sense,” O’Sullivan said. “The inspectors have more troubles with the safety of a two-room addition from a do-it-yourselfer than they do with projects like ours. So that’s where they focus their efforts.” Also, I suspect, at least some authorities have recognized that when they don’t let go of authority they fail.",
					"content_token": 183,
					"embedding": []
				}
			]
		},
		{
			"title": "The Relationship Between Design and Planning",
			"url": "https://fs.blog/counterinsurgency-field-manual/",
			"content": "While I’m not all that interested in military doctrine and tactics in and of themselves, I am interested in complex systems, how the weak win wars, and the lessons military leaders offer for example, see the lessons of William McRaven and Stanley McChrystal. This is how I found myself flipping through The U.S. Army  Marine Corps Counterinsurgency Field Manual, which was written to facilitate a common understanding of the problems inherent in counterinsurgency campaigns. There was a fascinating section on the difference between designing and planning that caused me to pause and reflect. While both activities seek to formulate ways to bring about preferable futures, they are cognitively different. Planning applies established procedures to solve a largely understood problem within an accepted framework. Design inquires into the nature of a problem to conceive a framework for solving that problem. In general, planning is problem solving, while design is problem setting. Where planning focuses on generating a plana series of executable actionsdesign focuses on learning about the nature of an unfamiliar problem. When situations do not conform to established frames of reference  when the hardest part of the problem is figuring out what the problem isplanning alone is inadequate and design becomes essential. In these situations, absent a design process to engage the problem’s essential nature, planners default to doctrinal norms; they develop plans based on the familiar rather than an understanding of the real situation. Design provides a means to conceptualize and hypothesize about the underlying causes and dynamics that explain an unfamiliar problem. Design provides a means to gain understanding of a complex problem and insights towards achieving a workable solution. To better understand the multifaceted problems, many of us face today it helps to talk with people who have different perspectives. This helps achieve better situational understanding. At best this can point the way to solutions and at worst, this should help with learning what to avoid. Often we skip the information gathering phase because it’s a lot of work. A lot of conversations. However, this process helps us become informed rather than just opinionated. The underlying premise is this: when participants achieve a level of understanding such that the situation no longer appears complex, they can exercise logic and intuition effectively. As a result, design focuses on framing the problem rather than developing courses of action. Just as you can never step in the same river twice, design is not something you do once and walk away. It’s an ongoing inquiry into the nature of problems and the various factors and relationships to help improve understanding. Constantly assessing the situation from a design perspective, helps gauge the effectiveness of the planning and subsequent actions. If you don’t periodically reassess the situation, you might be solving a problem that no longer exists. The U.S. Army  Marine Corps Counterinsurgency Field Manual is full of other thought-provoking content. ",
			"tokens": 579,
			"chunks": [
				{
					"article_title": "The Relationship Between Design and Planning",
					"article_url": "https://fs.blog/counterinsurgency-field-manual/",
					"content": "While I’m not all that interested in military doctrine and tactics in and of themselves, I am interested in complex systems, how the weak win wars, and the lessons military leaders offer for example, see the lessons of William McRaven and Stanley McChrystal. This is how I found myself flipping through The U.S. Army  Marine Corps Counterinsurgency Field Manual, which was written to facilitate a common understanding of the problems inherent in counterinsurgency campaigns. There was a fascinating section on the difference between designing and planning that caused me to pause and reflect. While both activities seek to formulate ways to bring about preferable futures, they are cognitively different. Planning applies established procedures to solve a largely understood problem within an accepted framework. Design inquires into the nature of a problem to conceive a framework for solving that problem. In general, planning is problem solving, while design is problem setting. ",
					"content_token": 185,
					"embedding": []
				},
				{
					"article_title": "The Relationship Between Design and Planning",
					"article_url": "https://fs.blog/counterinsurgency-field-manual/",
					"content": "Where planning focuses on generating a plana series of executable actionsdesign focuses on learning about the nature of an unfamiliar problem. When situations do not conform to established frames of reference  when the hardest part of the problem is figuring out what the problem isplanning alone is inadequate and design becomes essential. In these situations, absent a design process to engage the problem’s essential nature, planners default to doctrinal norms; they develop plans based on the familiar rather than an understanding of the real situation. Design provides a means to conceptualize and hypothesize about the underlying causes and dynamics that explain an unfamiliar problem. Design provides a means to gain understanding of a complex problem and insights towards achieving a workable solution. To better understand the multifaceted problems, many of us face today it helps to talk with people who have different perspectives. This helps achieve better situational understanding. At best this can point the way to solutions and at worst, this should help with learning what to avoid. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "The Relationship Between Design and Planning",
					"article_url": "https://fs.blog/counterinsurgency-field-manual/",
					"content": "Often we skip the information gathering phase because it’s a lot of work. A lot of conversations. However, this process helps us become informed rather than just opinionated. The underlying premise is this: when participants achieve a level of understanding such that the situation no longer appears complex, they can exercise logic and intuition effectively. As a result, design focuses on framing the problem rather than developing courses of action. Just as you can never step in the same river twice, design is not something you do once and walk away. It’s an ongoing inquiry into the nature of problems and the various factors and relationships to help improve understanding. Constantly assessing the situation from a design perspective, helps gauge the effectiveness of the planning and subsequent actions. If you don’t periodically reassess the situation, you might be solving a problem that no longer exists. The U.S. Army  Marine Corps Counterinsurgency Field Manual is full of other thought-provoking content.",
					"content_token": 198,
					"embedding": []
				}
			]
		},
		{
			"title": "What makes Warren Buffett a great investor? Intelligence or Discipline?",
			"url": "https://fs.blog/what-makes-warren-buffett-a-great-investor/",
			"content": "I thought this excerpt from Warren Buffett’s 2011 interview in India was relevant to not only investing but also decision making. A member of the audience says to Buffett: “As we all know, you are an extremely intelligent person. At the same time, you are very disciplined with your investing approach. What makes Warren Buffett a great investor? Is it the intelligence or the discipline?” Here is Warren’s response. Warren: The good news I can tell you is that to be a great investor you don’t have to have a terrific IQ. If you’ve got 160 IQ, sell 30 points to somebody else because you won’t need it in investing. What you do need is the right temperament. You need to be able to detach yourself from the views of others or the opinions of others. You need to be able to look at the facts about a business, about an industry, and evaluate a business unaffected by what other people think. That is very difficult for most people. Most people have, sometimes, a herd mentality which can, under certain circumstances, develop into delusional behavior. You saw that in the Internet craze and so on. I’m sure everybody in this room has the intelligence to do extremely well in investments. Moderator: They’re all 160 IQs. Warren: They don’t need it. I’m disappointed they haven’t sold off some already. The 160s won’t beat the 130s at all necessarily. They may, but they do not have a big edge. The ones that have the edge are the ones who really have the temperament to look at a business, look at an industry and not care what the person next to them thinks about it, not care what they read about it in the newspaper, not care what they hear about it on the television, not listen to people who say, “This is going to happen,” or, “That’s going to happen.” You have to come to your own conclusions, and you have to do it based on facts that are available. If you don’t have enough facts to reach a conclusion, you forget it. You go on to the next one. You have to also have the willingness to walk away from things that other people think are very simple. A lot of people don’t have that. I don’t know why it is. I’ve been asked a lot of times whether that was something that you’re born with or something you learn. I’m not sure I know the answer. Temperament’s important. Moderator: That’s very good advice, to be detached from all the noise. You shouldn’t go with the herd. Warren: If you don’t know the answer yourself don’t expect somebody else to tell you. If you don’t know the answer yourself and somebody else says they know the answer, don’t let that fact push you into coming to a conclusion about something that you don’t know enough to come to a conclusion on. Stocks go up and down, there is no game where the odds are in your favor. But to win at this game, and most people can’t, you need discipline to form your own opinions and the right temperament. Pascal said it best: “All men’s miseries derive from not being able to sit in a quiet room alone.” Warren: If you look at the typical stock on the New York Stock Exchange, its high will be, perhaps, for the last 12 months will be 150 percent of its low so they’re bobbing all over the place. All you have to do is sit there and wait until something is really attractive that you understand. And you can forget about everything else. That is a wonderful game to play in. There’s almost nothing where the game is stacked in your favor like the stock market. What happens is people start listening to everybody talk on television or whatever it may be or read the paper, and they take what is a fundamental advantage and turn it into a disadvantage. There’s no easier game than stocks. You have to be sure you don’t play it too often. You need the discipline to say no. Ajit: The discipline to say no, if you have that and you’re not willing to let people steamroll you into saying yes. If you have that discipline, that’s more than 50 percent of the battle. Warren: Don’t do anything in life where, if somebody asks you the reason why you are doing it, the answer is “Everybody else is doing it.” I mean, if you cancel that as a rationale for doing an activity in life, you’ll live a better life whether it’s in the stock market or any place else. I’ve seen more dumb things, and sometimes even illegal things, justified rationalized on the basis of “Everybody else is doing it.” You don’t need to do what everybody else is doing. It’s maddening, during the Internet craze when the bubble was going on. Here’s your neighbor who’s got an IQ of 50 points below you, and he’s making all this easy money and your wife is telling you “This jerk next door is making money, and you’re smarter than he is. Why aren’t you making money?” You have to forget about all those things. You have to do what works, what you understand, and if you don’t understand it and somebody else is doing it, don’t get envious or anything of the sort. Just go on and wait until you find something you understand. From this video. ",
			"tokens": 1217,
			"chunks": [
				{
					"article_title": "What makes Warren Buffett a great investor? Intelligence or Discipline?",
					"article_url": "https://fs.blog/what-makes-warren-buffett-a-great-investor/",
					"content": "I thought this excerpt from Warren Buffett’s 2011 interview in India was relevant to not only investing but also decision making. A member of the audience says to Buffett: “As we all know, you are an extremely intelligent person. At the same time, you are very disciplined with your investing approach. What makes Warren Buffett a great investor? Is it the intelligence or the discipline?” Here is Warren’s response. Warren: The good news I can tell you is that to be a great investor you don’t have to have a terrific IQ. If you’ve got 160 IQ, sell 30 points to somebody else because you won’t need it in investing. What you do need is the right temperament. You need to be able to detach yourself from the views of others or the opinions of others. You need to be able to look at the facts about a business, about an industry, and evaluate a business unaffected by what other people think. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "What makes Warren Buffett a great investor? Intelligence or Discipline?",
					"article_url": "https://fs.blog/what-makes-warren-buffett-a-great-investor/",
					"content": "That is very difficult for most people. Most people have, sometimes, a herd mentality which can, under certain circumstances, develop into delusional behavior. You saw that in the Internet craze and so on. I’m sure everybody in this room has the intelligence to do extremely well in investments. Moderator: They’re all 160 IQs. Warren: They don’t need it. I’m disappointed they haven’t sold off some already. The 160s won’t beat the 130s at all necessarily. They may, but they do not have a big edge. ",
					"content_token": 125,
					"embedding": []
				},
				{
					"article_title": "What makes Warren Buffett a great investor? Intelligence or Discipline?",
					"article_url": "https://fs.blog/what-makes-warren-buffett-a-great-investor/",
					"content": "The ones that have the edge are the ones who really have the temperament to look at a business, look at an industry and not care what the person next to them thinks about it, not care what they read about it in the newspaper, not care what they hear about it on the television, not listen to people who say, “This is going to happen,” or, “That’s going to happen.” You have to come to your own conclusions, and you have to do it based on facts that are available. If you don’t have enough facts to reach a conclusion, you forget it. You go on to the next one. You have to also have the willingness to walk away from things that other people think are very simple. A lot of people don’t have that. I don’t know why it is. ",
					"content_token": 180,
					"embedding": []
				},
				{
					"article_title": "What makes Warren Buffett a great investor? Intelligence or Discipline?",
					"article_url": "https://fs.blog/what-makes-warren-buffett-a-great-investor/",
					"content": "I’ve been asked a lot of times whether that was something that you’re born with or something you learn. I’m not sure I know the answer. Temperament’s important. Moderator: That’s very good advice, to be detached from all the noise. You shouldn’t go with the herd. Warren: If you don’t know the answer yourself don’t expect somebody else to tell you. If you don’t know the answer yourself and somebody else says they know the answer, don’t let that fact push you into coming to a conclusion about something that you don’t know enough to come to a conclusion on. Stocks go up and down, there is no game where the odds are in your favor. But to win at this game, and most people can’t, you need discipline to form your own opinions and the right temperament. ",
					"content_token": 194,
					"embedding": []
				},
				{
					"article_title": "What makes Warren Buffett a great investor? Intelligence or Discipline?",
					"article_url": "https://fs.blog/what-makes-warren-buffett-a-great-investor/",
					"content": "Pascal said it best: “All men’s miseries derive from not being able to sit in a quiet room alone.” Warren: If you look at the typical stock on the New York Stock Exchange, its high will be, perhaps, for the last 12 months will be 150 percent of its low so they’re bobbing all over the place. All you have to do is sit there and wait until something is really attractive that you understand. And you can forget about everything else. That is a wonderful game to play in. There’s almost nothing where the game is stacked in your favor like the stock market. What happens is people start listening to everybody talk on television or whatever it may be or read the paper, and they take what is a fundamental advantage and turn it into a disadvantage. There’s no easier game than stocks. You have to be sure you don’t play it too often. ",
					"content_token": 194,
					"embedding": []
				},
				{
					"article_title": "What makes Warren Buffett a great investor? Intelligence or Discipline?",
					"article_url": "https://fs.blog/what-makes-warren-buffett-a-great-investor/",
					"content": "You need the discipline to say no. Ajit: The discipline to say no, if you have that and you’re not willing to let people steamroll you into saying yes. If you have that discipline, that’s more than 50 percent of the battle. Warren: Don’t do anything in life where, if somebody asks you the reason why you are doing it, the answer is “Everybody else is doing it.” I mean, if you cancel that as a rationale for doing an activity in life, you’ll live a better life whether it’s in the stock market or any place else. I’ve seen more dumb things, and sometimes even illegal things, justified rationalized on the basis of “Everybody else is doing it.” You don’t need to do what everybody else is doing. It’s maddening, during the Internet craze when the bubble was going on. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "What makes Warren Buffett a great investor? Intelligence or Discipline?",
					"article_url": "https://fs.blog/what-makes-warren-buffett-a-great-investor/",
					"content": "Here’s your neighbor who’s got an IQ of 50 points below you, and he’s making all this easy money and your wife is telling you “This jerk next door is making money, and you’re smarter than he is. Why aren’t you making money?” You have to forget about all those things. You have to do what works, what you understand, and if you don’t understand it and somebody else is doing it, don’t get envious or anything of the sort. Just go on and wait until you find something you understand. From this video.",
					"content_token": 131,
					"embedding": []
				}
			]
		},
		{
			"title": "Ruth Chang: How to Make Hard Choices",
			"url": "https://fs.blog/ruth-chang-hard-choices/",
			"content": "Ruth Chang is a philosopher at Rutgers University with an interesting background. After graduating with a J.D. from Harvard Law School and dipping her toe into the legal world, she went off to Oxford University to study philosophy. Her work focuses on how we make the decisions that shape our lives. In her recent TED talk video below, she talks about how we make hard choices and in the process offers a framework for making decisions consistent with who we truly are. “Far from being sources of agony and dread, hard choices are precious opportunities for us to celebrate what is special about the human condition, that the reasons that govern our choices as correct or incorrect sometimes run out, and it is here, in the space of hard choices, that we have the power to create reasons for ourselves to become the distinctive people that we are. And that’s why hard choices are not a curse but a godsend.”  Ruth Chang How to Make Hard Choices What makes a hard choice hard is the way alternatives relate. In any easy choice, one alternative is better than the other. In a hard choice, one alternative is better in some ways, the other alternative is better in other ways, and neither is better than the other overall. You agonize over whether to stay in your current job in the city or uproot your life for more challenging work in the country because staying is better in some ways, moving is better in others, and neither is better than the other overall. We shouldn’t think that all hard choices are big. Let’s say you’re deciding what to have for breakfast. You could have high fiber bran cereal or a chocolate donut. Suppose what matters in the choice is tastiness and healthfulness. The cereal is better for you, the donut tastes way better, but neither is better than the other overall, a hard choice. Realizing that small choices can also be hard may make big hard choices seem less intractable. After all, we manage to figure out what to have for breakfast, so maybe we can figure out whether to stay in the city or uproot for the new job in the country. In hard choices we tend to prefer the safest option.  I can tell you that fear of the unknown, while a common motivational default in dealing with hard choices, rests on a misconception of them. It’s a mistake to think that in hard choices, one alternative really is better than the other, but we’re too stupid to know which, and since we don’t know which, we might as well take the least risky option. Even taking two alternatives side by side with full information, a choice can still be hard. Hard choices are hard not because of us or our ignorance; they’re hard because there is no best option. Now, if there’s no best option, if the scales don’t tip in favor of one alternative over another, then surely the alternatives must be equally good, so maybe the right thing to say in hard choices is that they’re between equally good options. That can’t be right. If alternatives are equally good, you should just flip a coin between them, and it seems a mistake to think, here’s how you should decide between careers, places to live, people to marry: Flip a coin. There’s another reason for thinking that hard choices aren’t choices between equally good options. Our search for physics like exactitude and our desire to quantify everything into scientific thinking combine to lead us astray. We unwittingly assume that values like justice, beauty, kindness, are akin to scientific quantities, like length, mass and weight. Take any comparative question not involving value, such as which of two suitcases is heavier? There are only three possibilities. The weight of one is greater, lesser or equal to the weight of the other. Properties like weight can be represented by real numbers  one, two, three and so on  and there are only three possible comparisons between any two real numbers. One number is greater, lesser, or equal to the other. Not so with values. As post-Enlightenment creatures, we tend to assume that scientific thinking holds the key to everything of importance in our world, but the world of value is different from the world of science. The stuff of the one world can be quantified by real numbers. The stuff of the other world can’t. Another way to see things is that they are in the same ball-park. This is what happens in hard choices, the alternatives are “on a par.” When alternatives are on a par, it may matter very much which you choose, but one alternative isn’t better than the other. Rather, the alternatives are in the same neighborhood of value, in the same league of value, while at the same time being very different in kind of value. That’s why the choice is hard. We create reasons. Understanding hard choices in this way uncovers something about ourselves we didn’t know. Each of us has the power to create reasons. Imagine a world in which every choice you face is an easy choice, that is, there’s always a best alternative. If there’s a best alternative, then that’s the one you should choose, because part of being rational is doing the better thing rather than the worse thing, choosing what you have most reason to choose.  A world full of only easy choices would enslave us to reasons.  However when alternatives are on a par, the reasons given to us, the ones that determine whether we’re making a mistake, are silent as to what to do. It’s here, in the space of hard choices, that we get to exercise our normative power, the power to create reasons for yourself  When we choose between options that are on a par, we can do something really rather remarkable. We can put our very selves behind an option.  This response in hard choices is a rational response, but it’s not dictated by reasons given to us. Rather, it’s supported by reasons created by us. When we create reasons for ourselves to become this kind of person rather than that, we wholeheartedly become the people that we are. You might say that we become the authors of our own lives. When you face hard choices you need to look inside yourself.  Instead of looking for reasons out there, we should be looking for reasons in here: Who am I to be? You might decide to be a pink sock-wearing, cereal-loving, country-living banker, and I might decide to be a black sock-wearing, urban, donut-loving artist. What we do in hard choices is very much up to each of us. If you don’t exercise your normative powers you become a drifter. Drifters allow the world to write the story of their lives. They let mechanisms of reward and punishment  pats on the head, fear, the easiness of an option  to determine what they do. So the lesson of hard choices reflect on what you can put your agency behind, on what you can be for, and through hard choices, become that person. Hard choices are part of what makes us human. Far from being sources of agony and dread, hard choices are precious opportunities for us to celebrate what is special about the human condition, that the reasons that govern our choices as correct or incorrect sometimes run out, and it is here, in the space of hard choices, that we have the power to create reasons for ourselves to become the distinctive people that we are. And that’s why hard choices are not a curse but a godsend. Here is Ruth’s full TED talk:  ",
			"tokens": 1599,
			"chunks": [
				{
					"article_title": "Ruth Chang: How to Make Hard Choices",
					"article_url": "https://fs.blog/ruth-chang-hard-choices/",
					"content": "Ruth Chang is a philosopher at Rutgers University with an interesting background. After graduating with a J.D. from Harvard Law School and dipping her toe into the legal world, she went off to Oxford University to study philosophy. Her work focuses on how we make the decisions that shape our lives. In her recent TED talk video below, she talks about how we make hard choices and in the process offers a framework for making decisions consistent with who we truly are. “Far from being sources of agony and dread, hard choices are precious opportunities for us to celebrate what is special about the human condition, that the reasons that govern our choices as correct or incorrect sometimes run out, and it is here, in the space of hard choices, that we have the power to create reasons for ourselves to become the distinctive people that we are. ",
					"content_token": 167,
					"embedding": []
				},
				{
					"article_title": "Ruth Chang: How to Make Hard Choices",
					"article_url": "https://fs.blog/ruth-chang-hard-choices/",
					"content": "And that’s why hard choices are not a curse but a godsend.”  Ruth Chang How to Make Hard Choices What makes a hard choice hard is the way alternatives relate. In any easy choice, one alternative is better than the other. In a hard choice, one alternative is better in some ways, the other alternative is better in other ways, and neither is better than the other overall. You agonize over whether to stay in your current job in the city or uproot your life for more challenging work in the country because staying is better in some ways, moving is better in others, and neither is better than the other overall. We shouldn’t think that all hard choices are big. Let’s say you’re deciding what to have for breakfast. You could have high fiber bran cereal or a chocolate donut. Suppose what matters in the choice is tastiness and healthfulness. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "Ruth Chang: How to Make Hard Choices",
					"article_url": "https://fs.blog/ruth-chang-hard-choices/",
					"content": "The cereal is better for you, the donut tastes way better, but neither is better than the other overall, a hard choice. Realizing that small choices can also be hard may make big hard choices seem less intractable. After all, we manage to figure out what to have for breakfast, so maybe we can figure out whether to stay in the city or uproot for the new job in the country. In hard choices we tend to prefer the safest option.  I can tell you that fear of the unknown, while a common motivational default in dealing with hard choices, rests on a misconception of them. It’s a mistake to think that in hard choices, one alternative really is better than the other, but we’re too stupid to know which, and since we don’t know which, we might as well take the least risky option. Even taking two alternatives side by side with full information, a choice can still be hard. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "Ruth Chang: How to Make Hard Choices",
					"article_url": "https://fs.blog/ruth-chang-hard-choices/",
					"content": "Hard choices are hard not because of us or our ignorance; they’re hard because there is no best option. Now, if there’s no best option, if the scales don’t tip in favor of one alternative over another, then surely the alternatives must be equally good, so maybe the right thing to say in hard choices is that they’re between equally good options. That can’t be right. If alternatives are equally good, you should just flip a coin between them, and it seems a mistake to think, here’s how you should decide between careers, places to live, people to marry: Flip a coin. There’s another reason for thinking that hard choices aren’t choices between equally good options. Our search for physics like exactitude and our desire to quantify everything into scientific thinking combine to lead us astray. ",
					"content_token": 180,
					"embedding": []
				},
				{
					"article_title": "Ruth Chang: How to Make Hard Choices",
					"article_url": "https://fs.blog/ruth-chang-hard-choices/",
					"content": "We unwittingly assume that values like justice, beauty, kindness, are akin to scientific quantities, like length, mass and weight. Take any comparative question not involving value, such as which of two suitcases is heavier? There are only three possibilities. The weight of one is greater, lesser or equal to the weight of the other. Properties like weight can be represented by real numbers  one, two, three and so on  and there are only three possible comparisons between any two real numbers. One number is greater, lesser, or equal to the other. Not so with values. As post-Enlightenment creatures, we tend to assume that scientific thinking holds the key to everything of importance in our world, but the world of value is different from the world of science. The stuff of the one world can be quantified by real numbers. The stuff of the other world can’t. Another way to see things is that they are in the same ball-park. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "Ruth Chang: How to Make Hard Choices",
					"article_url": "https://fs.blog/ruth-chang-hard-choices/",
					"content": "This is what happens in hard choices, the alternatives are “on a par.” When alternatives are on a par, it may matter very much which you choose, but one alternative isn’t better than the other. Rather, the alternatives are in the same neighborhood of value, in the same league of value, while at the same time being very different in kind of value. That’s why the choice is hard. We create reasons. Understanding hard choices in this way uncovers something about ourselves we didn’t know. Each of us has the power to create reasons. Imagine a world in which every choice you face is an easy choice, that is, there’s always a best alternative. If there’s a best alternative, then that’s the one you should choose, because part of being rational is doing the better thing rather than the worse thing, choosing what you have most reason to choose. ",
					"content_token": 194,
					"embedding": []
				},
				{
					"article_title": "Ruth Chang: How to Make Hard Choices",
					"article_url": "https://fs.blog/ruth-chang-hard-choices/",
					"content": " A world full of only easy choices would enslave us to reasons.  However when alternatives are on a par, the reasons given to us, the ones that determine whether we’re making a mistake, are silent as to what to do. It’s here, in the space of hard choices, that we get to exercise our normative power, the power to create reasons for yourself  When we choose between options that are on a par, we can do something really rather remarkable. We can put our very selves behind an option.  This response in hard choices is a rational response, but it’s not dictated by reasons given to us. Rather, it’s supported by reasons created by us. When we create reasons for ourselves to become this kind of person rather than that, we wholeheartedly become the people that we are. You might say that we become the authors of our own lives. When you face hard choices you need to look inside yourself. ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "Ruth Chang: How to Make Hard Choices",
					"article_url": "https://fs.blog/ruth-chang-hard-choices/",
					"content": " Instead of looking for reasons out there, we should be looking for reasons in here: Who am I to be? You might decide to be a pink sock-wearing, cereal-loving, country-living banker, and I might decide to be a black sock-wearing, urban, donut-loving artist. What we do in hard choices is very much up to each of us. If you don’t exercise your normative powers you become a drifter. Drifters allow the world to write the story of their lives. They let mechanisms of reward and punishment  pats on the head, fear, the easiness of an option  to determine what they do. So the lesson of hard choices reflect on what you can put your agency behind, on what you can be for, and through hard choices, become that person. Hard choices are part of what makes us human. ",
					"content_token": 182,
					"embedding": []
				},
				{
					"article_title": "Ruth Chang: How to Make Hard Choices",
					"article_url": "https://fs.blog/ruth-chang-hard-choices/",
					"content": "Far from being sources of agony and dread, hard choices are precious opportunities for us to celebrate what is special about the human condition, that the reasons that govern our choices as correct or incorrect sometimes run out, and it is here, in the space of hard choices, that we have the power to create reasons for ourselves to become the distinctive people that we are. And that’s why hard choices are not a curse but a godsend. Here is Ruth’s full TED talk:",
					"content_token": 99,
					"embedding": []
				}
			]
		},
		{
			"title": "Miracles Happen — The Simple Heuristic That Saved 150 Lives",
			"url": "https://fs.blog/gerd-gigerenzer-risk-savvy/",
			"content": "“In an uncertain world, statistical thinking and risk communication alone are not sufficient. Good rules of thumb are essential for good decisions.”  Three minutes after taking off from LaGuardia airport in New York City, US Airways Flight 1549 ran into a flock of Canada geese. At 2800 feet, passengers and crew heard loud bangs as the geese collided with the engines rendering them both inoperable. Gerd Gigerenzer picks up the story in his book Risk Savvy: How to Make Good Decisions: When it dawned on the passengers that they were gliding toward the ground , it grew quiet on the plane. No panic, only silent prayer. Captain Chesley Sullenberger called air traffic control: “Hit birds. We’ve lost thrust in both engines. We’re turning back towards LaGuardia.” But landing short of the airport would have catastrophic consequences, for passengers, crew , and the people living below. The captain and the copilot had to make a good judgment. Could the plane actually make it to LaGuardia, or would they have to try something more risky, such as a water landing in the Hudson River? One might expect the pilots to have measured speed, wind, altitude, and distance and fed this information into a calculator. Instead, they simply used a rule of thumb: Fix your gaze on the tower: If the tower rises in your windshield, you won’t make it. No estimation of the trajectory of the gliding plane is necessary. No time is wasted. And the rule is immune to calculation errors. In the words of copilot Jeffrey Skiles: “It’s not so much a mathematical calculation as visual, in that when you are flying in an airplane, things that a point that you can’t reach will actually rise in your windshield. A point that you are going to overfly will descend in your windshield.” This time the point they were trying to reach did not descend but rose. They went for the Hudson. In the cabin, the passengers were not aware of what was going on in the cockpit. All they heard was: “This is the captain: Brace for impact.” Flight attendants shouted: “Heads down! Stay down!” Passengers and crew later recalled that they were trying to grasp what death would be like, and the anguish of their kids, husbands, and wives. Then the impact happened, and the plane stopped. When passengers opened the emergency doors, sunlight streamed in. Everyone got up and rushed toward the openings. Only one passenger headed to the overhead bin to get her carry-on but was immediately stopped. The wings of the floating but slowly sinking plane were packed with people in life jackets hoping to be rescued. Then they saw the ferry coming. Everyone survived. All this happened within the three minutes between the geese hitting the plane and the ditch in the river. During that time, the pilots began to run through the dual-engine failure checklist, a three-page list designed to be used at thirty thousand feet, not at three thousand feet: turn the ignition on, reset flight control computer, and so on. But they could not finish it. Nor did they have time to even start on the ditching checklist. While the evacuation was underway, Skiles remained in the cockpit and went through the evacuation checklist to safeguard against potential fire hazards and other dangers. Sullenberger went back to check on passengers and left the cabin only after making sure that no one was left behind. It was the combination of teamwork, checklists, and smart rules of thumb that made the miracle possible.  Say what? They used a heuristic? Heuristics enable us to make fast, highly but not perfectly accurate decisions without taking too much time and searching for information. Heuristics allow us to focus on only a few pieces of information and ignore the rest. “Experts,” Gigerenzer writes, “often search for less information than novices do.” We do the same thing, intuitively, to catch a baseball  the gaze heuristic. Fix your gaze on an object, and adjust your speed so that the angle of gaze remains constant. Professionals and amateurs alike rely on this rule.  If a fly ball comes in high, the player fixates his eyes on the ball, starts running, and adjusts his running speed so that the angle of gaze remains constant. The player does not need to calculate the trajectory of the ball. To select the right parabola, the player’s brain would have to estimate the ball’s initial distance, velocity, and angle, which is not a simple feat. And to make things more complicated, real-life balls do not fly in parabolas . Wind, air resistance, and spin affect their paths. Even the most sophisticated robots or computers today cannot correctly estimate a landing point during the few seconds a ball soars through the air. The gaze heuristic solves this problem by guiding the player toward the landing point, not by calculating it mathematically . That’s why players don’t know exactly where the ball will land, and often run into walls and over the stands in their pursuit. The gaze heuristic is an example of how the mind can discover simple solutions to very complex problems.  The broader point of Gigerenzer’s book is that while rational thinking works well for risks, you need a combination of rational and heuristic thinking to make decisions under uncertainty. ",
			"tokens": 1135,
			"chunks": [
				{
					"article_title": "Miracles Happen — The Simple Heuristic That Saved 150 Lives",
					"article_url": "https://fs.blog/gerd-gigerenzer-risk-savvy/",
					"content": "“In an uncertain world, statistical thinking and risk communication alone are not sufficient. Good rules of thumb are essential for good decisions.”  Three minutes after taking off from LaGuardia airport in New York City, US Airways Flight 1549 ran into a flock of Canada geese. At 2800 feet, passengers and crew heard loud bangs as the geese collided with the engines rendering them both inoperable. Gerd Gigerenzer picks up the story in his book Risk Savvy: How to Make Good Decisions: When it dawned on the passengers that they were gliding toward the ground , it grew quiet on the plane. No panic, only silent prayer. Captain Chesley Sullenberger called air traffic control: “Hit birds. We’ve lost thrust in both engines. ",
					"content_token": 167,
					"embedding": []
				},
				{
					"article_title": "Miracles Happen — The Simple Heuristic That Saved 150 Lives",
					"article_url": "https://fs.blog/gerd-gigerenzer-risk-savvy/",
					"content": "We’re turning back towards LaGuardia.” But landing short of the airport would have catastrophic consequences, for passengers, crew , and the people living below. The captain and the copilot had to make a good judgment. Could the plane actually make it to LaGuardia, or would they have to try something more risky, such as a water landing in the Hudson River? One might expect the pilots to have measured speed, wind, altitude, and distance and fed this information into a calculator. Instead, they simply used a rule of thumb: Fix your gaze on the tower: If the tower rises in your windshield, you won’t make it. No estimation of the trajectory of the gliding plane is necessary. No time is wasted. And the rule is immune to calculation errors. ",
					"content_token": 164,
					"embedding": []
				},
				{
					"article_title": "Miracles Happen — The Simple Heuristic That Saved 150 Lives",
					"article_url": "https://fs.blog/gerd-gigerenzer-risk-savvy/",
					"content": "In the words of copilot Jeffrey Skiles: “It’s not so much a mathematical calculation as visual, in that when you are flying in an airplane, things that a point that you can’t reach will actually rise in your windshield. A point that you are going to overfly will descend in your windshield.” This time the point they were trying to reach did not descend but rose. They went for the Hudson. In the cabin, the passengers were not aware of what was going on in the cockpit. All they heard was: “This is the captain: Brace for impact.” Flight attendants shouted: “Heads down! Stay down!” Passengers and crew later recalled that they were trying to grasp what death would be like, and the anguish of their kids, husbands, and wives. Then the impact happened, and the plane stopped. When passengers opened the emergency doors, sunlight streamed in. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "Miracles Happen — The Simple Heuristic That Saved 150 Lives",
					"article_url": "https://fs.blog/gerd-gigerenzer-risk-savvy/",
					"content": "Everyone got up and rushed toward the openings. Only one passenger headed to the overhead bin to get her carry-on but was immediately stopped. The wings of the floating but slowly sinking plane were packed with people in life jackets hoping to be rescued. Then they saw the ferry coming. Everyone survived. All this happened within the three minutes between the geese hitting the plane and the ditch in the river. During that time, the pilots began to run through the dual-engine failure checklist, a three-page list designed to be used at thirty thousand feet, not at three thousand feet: turn the ignition on, reset flight control computer, and so on. But they could not finish it. Nor did they have time to even start on the ditching checklist. While the evacuation was underway, Skiles remained in the cockpit and went through the evacuation checklist to safeguard against potential fire hazards and other dangers. ",
					"content_token": 181,
					"embedding": []
				},
				{
					"article_title": "Miracles Happen — The Simple Heuristic That Saved 150 Lives",
					"article_url": "https://fs.blog/gerd-gigerenzer-risk-savvy/",
					"content": "Sullenberger went back to check on passengers and left the cabin only after making sure that no one was left behind. It was the combination of teamwork, checklists, and smart rules of thumb that made the miracle possible.  Say what? They used a heuristic? Heuristics enable us to make fast, highly but not perfectly accurate decisions without taking too much time and searching for information. Heuristics allow us to focus on only a few pieces of information and ignore the rest. “Experts,” Gigerenzer writes, “often search for less information than novices do.” We do the same thing, intuitively, to catch a baseball  the gaze heuristic. Fix your gaze on an object, and adjust your speed so that the angle of gaze remains constant. Professionals and amateurs alike rely on this rule. ",
					"content_token": 177,
					"embedding": []
				},
				{
					"article_title": "Miracles Happen — The Simple Heuristic That Saved 150 Lives",
					"article_url": "https://fs.blog/gerd-gigerenzer-risk-savvy/",
					"content": " If a fly ball comes in high, the player fixates his eyes on the ball, starts running, and adjusts his running speed so that the angle of gaze remains constant. The player does not need to calculate the trajectory of the ball. To select the right parabola, the player’s brain would have to estimate the ball’s initial distance, velocity, and angle, which is not a simple feat. And to make things more complicated, real-life balls do not fly in parabolas  Wind, air resistance, and spin affect their paths. Even the most sophisticated robots or computers today cannot correctly estimate a landing point during the few seconds a ball soars through the air. The gaze heuristic solves this problem by guiding the player toward the landing point, not by calculating it mathematically  That’s why players don’t know exactly where the ball will land, and often run into walls and over the stands in their pursuit. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "Miracles Happen — The Simple Heuristic That Saved 150 Lives",
					"article_url": "https://fs.blog/gerd-gigerenzer-risk-savvy/",
					"content": "The gaze heuristic is an example of how the mind can discover simple solutions to very complex problems.  The broader point of Gigerenzer’s book is that while rational thinking works well for risks, you need a combination of rational and heuristic thinking to make decisions under uncertainty.",
					"content_token": 58,
					"embedding": []
				}
			]
		},
		{
			"title": "Certainty Is an Illusion",
			"url": "https://fs.blog/certainty-is-an-illusion/",
			"content": "We all try to avoid uncertainty, even if it means being wrong. We take comfort in certainty, and we demand it of others, even when we know it’s impossible. Gerd Gigerenzer argues in Risk Savvy: How to Make Good Decisions that life would be pretty dull without uncertainty. If we knew everything about the future with certainty, our lives would be drained of emotion. No surprise and pleasure, no joy or thrill we knew it all along. The first kiss, the first proposal, the birth of a healthy child would be about as exciting as last year’s weather report. If our world ever turned certain, life would be mind-numbingly dull. The Illusion of Certainty We demand certainty of others. We ask our bankers, doctors, and political leaders among others to give it to us. What they deliver, however, is the illusion of certainty. We feel comfortable with this. Many of us smile at old-fashioned fortune-tellers. But when the soothsayers work with computer algorithms rather than tarot cards, we take their predictions seriously and are prepared to pay for them. The most astounding part is our collective amnesia: Most of us are still anxious to see stock market predictions even if they have been consistently wrong year after year. Technology changes how we see things – it amplifies the illusion of certainty. When an astrologer calculates an expert horoscope for you and foretells that you will develop a serious illness and might even die at age forty-nine, will you tremble when the date approaches? Some 4 percent of Germans would; they believe that an expert horoscope is absolutely certain.  But when technology is involved, the illusion of certainty is amplified. Forty-four percent of people surveyed think that the result of a screening mammogram is certain. In fact, mammograms fail to detect about ten percent of cancers, and the younger the women being tested, the more error-prone the results, because their breasts are denser. “Not understanding a new technology is one thing,” Gigerenzer writes, “believing that it delivers certainty is another.” It’s best to remember Ben Franklin: “In this world, nothing can be said to be certain, except death and taxes.” The Security Blanket Where does our need for certainty come from? People with a high need for certainty are more prone to stereotypes than others and are less inclined to remember information that contradicts their stereotypes. They find ambiguity confusing and have a desire to plan out their lives rationally. First get a degree, a car, and then a career, find the most perfect partner, buy a home, and have beautiful babies. But then the economy breaks down, the job is lost, the partner has an affair with someone else, and one finds oneself packing boxes to move to a cheaper place. In an uncertain world, we cannot plan everything ahead. Here, we can only cross each bridge when we come to it, not beforehand. The very desire to plan and organize everything may be part of the problem, not the solution. There is a Yiddish joke: “Do you know how to make God laugh? Tell him your plans.” To be sure, illusions have their function. Small children often need security blankets to soothe their fears. Yet for the mature adult, a high need for certainty can be a dangerous thing. It prevents us from learning to face the uncertainty pervading our lives. As hard as we try, we cannot make our lives risk-free the way we make our milk fat-free. At the same time, a psychological need is not entirely to blame for the illusion of certainty. Manufacturers of certainty play a crucial role in cultivating the illusion. They delude us into thinking that our future is predictable, as long as the right technology is at hand. Risk and Uncertainty Two magnificently dressed young women sit upright on their chairs, calmly facing each other. Yet neither takes notice of the other. Fortuna, the fickle, wheel-toting goddess of chance, sits blindfolded on the left while human figures desperately climb, cling to, or tumble off the wheel in her hand. Sapientia, the calculating and vain deity of science, gazes into a hand-mirror, lost in admiration of herself. These two allegorical figures depict a long-standing polarity: Fortuna brings good or bad luck, depending on her mood, but science promises certainty. Fortuna, the wheel-toting goddess of chance left, facing Sapientia, the divine goddess of science right. Source: Risk Savvy: How to Make Good Decisions This sixteenth-century woodcut was carved a century before one of the greatest revolutions in human thinking, the “probabilistic revolution,” colloquially known as the taming of chance. Its domestication began in the mid-seventeenth century. Since then, Fortuna’s opposition to Sapientia has evolved into an intimate relationship, not without attempts to snatch each other’s possessions. Science sought to liberate people from Fortuna’s wheel, to banish belief in fate, and replace chances with causes. Fortuna struck back by undermining science itself with chance and creating the vast empire of probability and statistics. After their struggles, neither remained the same: Fortuna was tamed, and science lost its certainty. Source: Risk Savvy: How to Make Good Decisions We explore more of the difference between risk and uncertainty, but the diagram above helps simplify things. The value of heuristics The twilight of uncertainty comes in different shades and degrees. Beginning in the seventeenth century, the probabilistic revolution gave humankind the skills of statistical thinking to triumph over Fortuna, but these skills were designed for the palest shade of uncertainty, a world of known risk, in short, risk. I use this term for a world where all alternatives, consequences, and probabilities are known. Lotteries and games of chance are examples. Most of the time, however, we live in a changing world where some of these are unknown: where we face unknown risks, or uncertainty. The world of uncertainty is huge compared to that of risk.  In an uncertain world, it is impossible to determine the optimal course of action by calculating the exact risks. We have to deal with “unknown unknowns.” Surprises happen. Even when calculation does not provide a clear answer, however, we have to make decisions. Thankfully we can do much better than frantically clinging to and tumbling off Fortuna’s wheel. Fortuna and Sapientia had a second brainchild alongside mathematical probability, which is often passed over: rules of thumb, known in scientific language as heuristics. How decisions change based on riskuncertainty When making decisions, the two sets of mental tools are required: 1. RISK: If risks are known, good decisions require logic and statistical thinking. 2. UNCERTAINTY: If some risks are unknown, good decisions also require intuition and smart rules of thumb. Most of the time we need a combination of the two.  Risk Savvy: How to Make Good Decisions is a great read throughout.",
			"tokens": 1491,
			"chunks": [
				{
					"article_title": "Certainty Is an Illusion",
					"article_url": "https://fs.blog/certainty-is-an-illusion/",
					"content": "We all try to avoid uncertainty, even if it means being wrong. We take comfort in certainty, and we demand it of others, even when we know it’s impossible. Gerd Gigerenzer argues in Risk Savvy: How to Make Good Decisions that life would be pretty dull without uncertainty. If we knew everything about the future with certainty, our lives would be drained of emotion. No surprise and pleasure, no joy or thrill we knew it all along. The first kiss, the first proposal, the birth of a healthy child would be about as exciting as last year’s weather report. If our world ever turned certain, life would be mind-numbingly dull. The Illusion of Certainty We demand certainty of others. We ask our bankers, doctors, and political leaders among others to give it to us. What they deliver, however, is the illusion of certainty. We feel comfortable with this. ",
					"content_token": 189,
					"embedding": []
				},
				{
					"article_title": "Certainty Is an Illusion",
					"article_url": "https://fs.blog/certainty-is-an-illusion/",
					"content": "Many of us smile at old-fashioned fortune-tellers. But when the soothsayers work with computer algorithms rather than tarot cards, we take their predictions seriously and are prepared to pay for them. The most astounding part is our collective amnesia: Most of us are still anxious to see stock market predictions even if they have been consistently wrong year after year. Technology changes how we see things – it amplifies the illusion of certainty. When an astrologer calculates an expert horoscope for you and foretells that you will develop a serious illness and might even die at age forty-nine, will you tremble when the date approaches? Some 4 percent of Germans would; they believe that an expert horoscope is absolutely certain.  But when technology is involved, the illusion of certainty is amplified. Forty-four percent of people surveyed think that the result of a screening mammogram is certain. ",
					"content_token": 183,
					"embedding": []
				},
				{
					"article_title": "Certainty Is an Illusion",
					"article_url": "https://fs.blog/certainty-is-an-illusion/",
					"content": "In fact, mammograms fail to detect about ten percent of cancers, and the younger the women being tested, the more error-prone the results, because their breasts are denser. “Not understanding a new technology is one thing,” Gigerenzer writes, “believing that it delivers certainty is another.” It’s best to remember Ben Franklin: “In this world, nothing can be said to be certain, except death and taxes.” The Security Blanket Where does our need for certainty come from? People with a high need for certainty are more prone to stereotypes than others and are less inclined to remember information that contradicts their stereotypes. They find ambiguity confusing and have a desire to plan out their lives rationally. First get a degree, a car, and then a career, find the most perfect partner, buy a home, and have beautiful babies. ",
					"content_token": 183,
					"embedding": []
				},
				{
					"article_title": "Certainty Is an Illusion",
					"article_url": "https://fs.blog/certainty-is-an-illusion/",
					"content": "But then the economy breaks down, the job is lost, the partner has an affair with someone else, and one finds oneself packing boxes to move to a cheaper place. In an uncertain world, we cannot plan everything ahead. Here, we can only cross each bridge when we come to it, not beforehand. The very desire to plan and organize everything may be part of the problem, not the solution. There is a Yiddish joke: “Do you know how to make God laugh? Tell him your plans.” To be sure, illusions have their function. Small children often need security blankets to soothe their fears. Yet for the mature adult, a high need for certainty can be a dangerous thing. It prevents us from learning to face the uncertainty pervading our lives. As hard as we try, we cannot make our lives risk-free the way we make our milk fat-free. ",
					"content_token": 184,
					"embedding": []
				},
				{
					"article_title": "Certainty Is an Illusion",
					"article_url": "https://fs.blog/certainty-is-an-illusion/",
					"content": "At the same time, a psychological need is not entirely to blame for the illusion of certainty. Manufacturers of certainty play a crucial role in cultivating the illusion. They delude us into thinking that our future is predictable, as long as the right technology is at hand. Risk and Uncertainty Two magnificently dressed young women sit upright on their chairs, calmly facing each other. Yet neither takes notice of the other. Fortuna, the fickle, wheel-toting goddess of chance, sits blindfolded on the left while human figures desperately climb, cling to, or tumble off the wheel in her hand. Sapientia, the calculating and vain deity of science, gazes into a hand-mirror, lost in admiration of herself. These two allegorical figures depict a long-standing polarity: Fortuna brings good or bad luck, depending on her mood, but science promises certainty. ",
					"content_token": 186,
					"embedding": []
				},
				{
					"article_title": "Certainty Is an Illusion",
					"article_url": "https://fs.blog/certainty-is-an-illusion/",
					"content": "Fortuna, the wheel-toting goddess of chance left, facing Sapientia, the divine goddess of science right. Source: Risk Savvy: How to Make Good Decisions This sixteenth-century woodcut was carved a century before one of the greatest revolutions in human thinking, the “probabilistic revolution,” colloquially known as the taming of chance. Its domestication began in the mid-seventeenth century. Since then, Fortuna’s opposition to Sapientia has evolved into an intimate relationship, not without attempts to snatch each other’s possessions. Science sought to liberate people from Fortuna’s wheel, to banish belief in fate, and replace chances with causes. Fortuna struck back by undermining science itself with chance and creating the vast empire of probability and statistics. After their struggles, neither remained the same: Fortuna was tamed, and science lost its certainty. ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "Certainty Is an Illusion",
					"article_url": "https://fs.blog/certainty-is-an-illusion/",
					"content": "Source: Risk Savvy: How to Make Good Decisions We explore more of the difference between risk and uncertainty, but the diagram above helps simplify things. The value of heuristics The twilight of uncertainty comes in different shades and degrees. Beginning in the seventeenth century, the probabilistic revolution gave humankind the skills of statistical thinking to triumph over Fortuna, but these skills were designed for the palest shade of uncertainty, a world of known risk, in short, risk. I use this term for a world where all alternatives, consequences, and probabilities are known. Lotteries and games of chance are examples. Most of the time, however, we live in a changing world where some of these are unknown: where we face unknown risks, or uncertainty. The world of uncertainty is huge compared to that of risk.  In an uncertain world, it is impossible to determine the optimal course of action by calculating the exact risks. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "Certainty Is an Illusion",
					"article_url": "https://fs.blog/certainty-is-an-illusion/",
					"content": "We have to deal with “unknown unknowns.” Surprises happen. Even when calculation does not provide a clear answer, however, we have to make decisions. Thankfully we can do much better than frantically clinging to and tumbling off Fortuna’s wheel. Fortuna and Sapientia had a second brainchild alongside mathematical probability, which is often passed over: rules of thumb, known in scientific language as heuristics. How decisions change based on riskuncertainty When making decisions, the two sets of mental tools are required: 1. RISK: If risks are known, good decisions require logic and statistical thinking. 2. UNCERTAINTY: If some risks are unknown, good decisions also require intuition and smart rules of thumb. Most of the time we need a combination of the two.  Risk Savvy: How to Make Good Decisions is a great read throughout.",
					"content_token": 185,
					"embedding": []
				}
			]
		},
		{
			"title": "How Complex Systems Fail",
			"url": "https://fs.blog/how-complex-systems-fail/",
			"content": "A bit of a preface to this post. Please read the definition of Antifragile first. While the article below is interesting, the reader should read with a critical mind. Complexity solved’ with increased complexity generally only creates a lot of hidden risks, slowness, or fragility. A short treatise on the nature of failure; how failure is evaluated; how failure is attributed to proximate cause; and the resulting new understanding of patient safety by Richard I. Cook. 1. Complex systems are intrinsically hazardous systems All of the interesting systems e.g. transportation, healthcare, power generation are inherently and unavoidably hazardous by their own nature. The frequency of hazard exposure can sometimes be changed but the processes involved in the system are themselves intrinsically and irreducibly hazardous. It is the presence of these hazards that drives the creation of defenses against hazard that characterize these systems. 2. Complex systems are heavily and successfully defended against failure The high consequences of failure lead over time to the construction of multiple layers of defense against failure. These defenses include obvious technical components e.g. backup systems, safety’ features of equipment and human components e.g. training, knowledge but also a variety of organizational, institutional, and regulatory defenses e.g. policies and procedures, certification, work rules, team training. The effect of these measures is to provide a series of shields that normally divert operations away from accidents. 3. Catastrophe requires multiple failures – single point failures are not enough The array of defenses works. System operations are generally successful. Overt catastrophic failure occurs when small, apparently innocuous failures join to create opportunity for a systemic accident. Each of these small failures is necessary to cause catastrophe but only the combination is sufficient to permit failure. Put another way, there are many more failure opportunities than overt system accidents. Most initial failure trajectories are blocked by designed system safety components. Trajectories that reach the operational level are mostly blocked, usually by practitioners. 4. Complex systems contain changing mixtures of failures latent within them The complexity of these systems makes it impossible for them to run without multiple flaws being present. Because these are individually insufficient to cause failure they are regarded as minor factors during operations. Eradication of all latent failures is limited primarily by economic cost but also because it is difficult before the fact to see how such failures might contribute to an accident. The failures change constantly because of changing technology, work organization, and efforts to eradicate failures. 5. Complex systems run in degraded mode A corollary to the preceding point is that complex systems run as broken systems. The system continues to function because it contains so many redundancies and because people can make it function, despite the presence of many flaws. After accident reviews nearly always note that the system has a history of prior proto-accidents’ that nearly generated catastrophe. Arguments that these degraded conditions should have been recognized before the overt accident are usually predicated on nave notions of system performance. System operations are dynamic, with components organizational, human, technical failing and being replaced continuously. 6. Catastrophe is always just around the corner Complex systems possess potential for catastrophic failure. Human practitioners are nearly always in close physical and temporal proximity to these potential failures – disaster can occur at any time and in nearly any place. The potential for catastrophic outcome is a hallmark of complex systems. It is impossible to eliminate the potential for such catastrophic failure; the potential for such failure is always present by the system’s own nature. 7. Post-accident attribution to a root cause’ is fundamentally wrong Because overt failure requires multiple faults, there is no isolated cause’ of an accident. There are multiple contributors to accidents. Each of these is necessarily insufficient in itself to create an accident. Only jointly are these causes sufficient to create an accident. Indeed, it is the linking of these causes together that creates the circumstances required for the accident. Thus, no isolation of the root cause’ of an accident is possible. The evaluations based on such reasoning as root cause’ do not reflect a technical understanding of the nature of failure but rather the social, cultural need to blame specific, localized forces or events for outcomes. 8. Hindsight biases post-accident assessments of human performance Knowledge of the outcome makes it seem that events leading to the outcome should have appeared more salient to practitioners at the time than was actually the case. This means that ex post facto accident analysis of human performance is inaccurate. The outcome knowledge poisons the ability of after-accident observers to recreate the view of practitioners before the accident of those same factors. It seems that practitioners “should have known” that the factors would “inevitably” lead to an accident. Hindsight bias remains the primary obstacle to accident investigation, especially when expert human performance is involved. 9. Human operators have dual roles: as producers  as defenders against failure The system practitioners operate the system in order to produce its desired product and also work to forestall accidents. This dynamic quality of system operation, the balancing of demands for production against the possibility of incipient failure is unavoidable. Outsiders rarely acknowledge the duality of this role. In non-accident filled times, the production role is emphasized. After accidents, the defense against failure role is emphasized. At either time, the outsider’s view misapprehends the operator’s constant, simultaneous engagement with both roles. 10. All practitioner actions are gambles After accidents, the overt failure often appears to have been inevitable and the practitioner’s actions as blunders or deliberate willful disregard of certain impending failure. But all practitioner actions are actually gambles, that is, acts that take place in the face of uncertain outcomes. The degree of uncertainty may change from moment to moment. That practitioner actions are gambles appears clear after accidents; in general, post hoc analysis regards these gambles as poor ones. But the converse: that successful outcomes are also the result of gambles; is not widely appreciated. 11. Actions at the sharp end resolve all ambiguity Organizations are ambiguous, often intentionally, about the relationship between production targets, efficient use of resources, economy and costs of operations, and acceptable risks of low and high consequence accidents. All ambiguity is resolved by actions of practitioners at the sharp end of the system. After an accident, practitioner actions may be regarded as errors’ or violations’ but these evaluations are heavily biased by hindsight and ignore the other driving forces, especially production pressure. 12. Human practitioners are the adaptable element of complex systems Practitioners and first line management actively adapt the system to maximize production and minimize accidents. These adaptations often occur on a moment by moment basis. Some of these adaptations include: 1 Restructuring the system in order to reduce exposure of vulnerable parts to failure. 2 Concentrating critical resources in areas of expected high demand. 3 Providing pathways for retreat or recovery from expected and unexpected faults. 4 Establishing means for early detection of changed system performance in order to allow graceful cutbacks in production or other means of increasing resiliency. 13. Human expertise in complex systems is constantly changing Complex systems require substantial human expertise in their operation and management. This expertise changes in character as technology changes but it also changes because of the need to replace experts who leave. In every case, training and refinement of skill and expertise is one part of the function of the system itself. At any moment, therefore, a given complex system will contain practitioners and trainees with varying degrees of expertise. Critical issues related to expertise arise from 1 the need to use scarce expertise as a resource for the most difficult or demanding production needs and 2 the need to develop expertise for future use. 14. Change introduces new forms of failure The low rate of overt accidents in reliable systems may encourage changes, especially the use of new technology, to decrease the number of low consequence but high frequency failures. These changes maybe actually create opportunities for new, low frequency but high consequence failures. When new technologies are used to eliminate well understood system failures or to gain high precision performance they often introduce new pathways to large scale, catastrophic failures. Not uncommonly, these new, rare catastrophes have even greater impact than those eliminated by the new technology. These new forms of failure are difficult to see before the fact; attention is paid mostly to the putative beneficial characteristics of the changes. Because these new, high consequence accidents occur at a low rate, multiple system changes may occur before an accident, making it hard to see the contribution of technology to the failure. 15. Views of cause’ limit the effectiveness of defenses against future events Post-accident remedies for “human error” are usually predicated on obstructing activities that can “cause” accidents. These end-of-the-chain measures do little to reduce the likelihood of further accidents. In fact that likelihood of an identical accident is already extraordinarily low because the pattern of latent failures changes constantly. Instead of increasing safety, post-accident remedies usually increase the coupling and complexity of the system. This increases the potential number of latent failures and also makes the detection and blocking of accident trajectories more difficult. 16. Safety is a characteristic of systems and not of their components Safety is an emergent property of systems; it does not reside in a person, device or department of an organization or system. Safety cannot be purchased or manufactured; it is not a feature that is separate from the other components of the system. This means that safety cannot be manipulated like a feedstock or raw material. The state of safety in any system is always dynamic; continuous systemic change insures that hazard and its management are constantly changing. 17. People continuously create safety Failure free operations are the result of activities of people who work to keep the system within the boundaries of tolerable performance. These activities are, for the most part, part of normal operations and superficially straightforward. But because system operations are never trouble free, human practitioner adaptations to changing conditions actually create safety from moment to moment. These adaptations often amount to just the selection of a well-rehearsed routine from a store of available responses; sometimes, however, the adaptations are novel combinations or de novo creations of new approaches. 18. Failure free operations require experience with failure Recognizing hazard and successfully manipulating system operations to remain inside the tolerable performance boundaries requires intimate contact with failure. More robust system performance is likely to arise in systems where operators can discern the “edge of the envelope”. This is where system performance begins to deteriorate, becomes difficult to predict, or cannot be readily recovered. In intrinsically hazardous systems, operators are expected to encounter and appreciate hazards in ways that lead to overall performance that is desirable. Improved safety depends on providing operators with calibrated views of the hazards. It also depends on providing calibration about how their actions move system performance towards or away from the edge of the envelope. Here is a video of Richard talking about how complex systems don’t fail.  ",
			"tokens": 2222,
			"chunks": [
				{
					"article_title": "How Complex Systems Fail",
					"article_url": "https://fs.blog/how-complex-systems-fail/",
					"content": "A bit of a preface to this post. Please read the definition of Antifragile first. While the article below is interesting, the reader should read with a critical mind. Complexity solved’ with increased complexity generally only creates a lot of hidden risks, slowness, or fragility. A short treatise on the nature of failure; how failure is evaluated; how failure is attributed to proximate cause; and the resulting new understanding of patient safety by Richard I. Cook. 1. Complex systems are intrinsically hazardous systems All of the interesting systems e.g. transportation, healthcare, power generation are inherently and unavoidably hazardous by their own nature. The frequency of hazard exposure can sometimes be changed but the processes involved in the system are themselves intrinsically and irreducibly hazardous. It is the presence of these hazards that drives the creation of defenses against hazard that characterize these systems. 2. ",
					"content_token": 183,
					"embedding": []
				},
				{
					"article_title": "How Complex Systems Fail",
					"article_url": "https://fs.blog/how-complex-systems-fail/",
					"content": "Complex systems are heavily and successfully defended against failure The high consequences of failure lead over time to the construction of multiple layers of defense against failure. These defenses include obvious technical components e.g. backup systems, safety’ features of equipment and human components e.g. training, knowledge but also a variety of organizational, institutional, and regulatory defenses e.g. policies and procedures, certification, work rules, team training. The effect of these measures is to provide a series of shields that normally divert operations away from accidents. 3. Catastrophe requires multiple failures – single point failures are not enough The array of defenses works. System operations are generally successful. Overt catastrophic failure occurs when small, apparently innocuous failures join to create opportunity for a systemic accident. Each of these small failures is necessary to cause catastrophe but only the combination is sufficient to permit failure. Put another way, there are many more failure opportunities than overt system accidents. Most initial failure trajectories are blocked by designed system safety components. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "How Complex Systems Fail",
					"article_url": "https://fs.blog/how-complex-systems-fail/",
					"content": "Trajectories that reach the operational level are mostly blocked, usually by practitioners. 4. Complex systems contain changing mixtures of failures latent within them The complexity of these systems makes it impossible for them to run without multiple flaws being present. Because these are individually insufficient to cause failure they are regarded as minor factors during operations. Eradication of all latent failures is limited primarily by economic cost but also because it is difficult before the fact to see how such failures might contribute to an accident. The failures change constantly because of changing technology, work organization, and efforts to eradicate failures. 5. Complex systems run in degraded mode A corollary to the preceding point is that complex systems run as broken systems. The system continues to function because it contains so many redundancies and because people can make it function, despite the presence of many flaws. After accident reviews nearly always note that the system has a history of prior proto-accidents’ that nearly generated catastrophe. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "How Complex Systems Fail",
					"article_url": "https://fs.blog/how-complex-systems-fail/",
					"content": "Arguments that these degraded conditions should have been recognized before the overt accident are usually predicated on nave notions of system performance. System operations are dynamic, with components organizational, human, technical failing and being replaced continuously. 6. Catastrophe is always just around the corner Complex systems possess potential for catastrophic failure. Human practitioners are nearly always in close physical and temporal proximity to these potential failures – disaster can occur at any time and in nearly any place. The potential for catastrophic outcome is a hallmark of complex systems. It is impossible to eliminate the potential for such catastrophic failure; the potential for such failure is always present by the system’s own nature. 7. Post-accident attribution to a root cause’ is fundamentally wrong Because overt failure requires multiple faults, there is no isolated cause’ of an accident. There are multiple contributors to accidents. Each of these is necessarily insufficient in itself to create an accident. Only jointly are these causes sufficient to create an accident. ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "How Complex Systems Fail",
					"article_url": "https://fs.blog/how-complex-systems-fail/",
					"content": "Indeed, it is the linking of these causes together that creates the circumstances required for the accident. Thus, no isolation of the root cause’ of an accident is possible. The evaluations based on such reasoning as root cause’ do not reflect a technical understanding of the nature of failure but rather the social, cultural need to blame specific, localized forces or events for outcomes. 8. Hindsight biases post-accident assessments of human performance Knowledge of the outcome makes it seem that events leading to the outcome should have appeared more salient to practitioners at the time than was actually the case. This means that ex post facto accident analysis of human performance is inaccurate. The outcome knowledge poisons the ability of after-accident observers to recreate the view of practitioners before the accident of those same factors. It seems that practitioners “should have known” that the factors would “inevitably” lead to an accident. ",
					"content_token": 185,
					"embedding": []
				},
				{
					"article_title": "How Complex Systems Fail",
					"article_url": "https://fs.blog/how-complex-systems-fail/",
					"content": "Hindsight bias remains the primary obstacle to accident investigation, especially when expert human performance is involved. 9. Human operators have dual roles: as producers  as defenders against failure The system practitioners operate the system in order to produce its desired product and also work to forestall accidents. This dynamic quality of system operation, the balancing of demands for production against the possibility of incipient failure is unavoidable. Outsiders rarely acknowledge the duality of this role. In non-accident filled times, the production role is emphasized. After accidents, the defense against failure role is emphasized. At either time, the outsider’s view misapprehends the operator’s constant, simultaneous engagement with both roles. 10. All practitioner actions are gambles After accidents, the overt failure often appears to have been inevitable and the practitioner’s actions as blunders or deliberate willful disregard of certain impending failure. ",
					"content_token": 182,
					"embedding": []
				},
				{
					"article_title": "How Complex Systems Fail",
					"article_url": "https://fs.blog/how-complex-systems-fail/",
					"content": "But all practitioner actions are actually gambles, that is, acts that take place in the face of uncertain outcomes. The degree of uncertainty may change from moment to moment. That practitioner actions are gambles appears clear after accidents; in general, post hoc analysis regards these gambles as poor ones. But the converse: that successful outcomes are also the result of gambles; is not widely appreciated. 11. Actions at the sharp end resolve all ambiguity Organizations are ambiguous, often intentionally, about the relationship between production targets, efficient use of resources, economy and costs of operations, and acceptable risks of low and high consequence accidents. All ambiguity is resolved by actions of practitioners at the sharp end of the system. After an accident, practitioner actions may be regarded as errors’ or violations’ but these evaluations are heavily biased by hindsight and ignore the other driving forces, especially production pressure. 12. ",
					"content_token": 180,
					"embedding": []
				},
				{
					"article_title": "How Complex Systems Fail",
					"article_url": "https://fs.blog/how-complex-systems-fail/",
					"content": "Human practitioners are the adaptable element of complex systems Practitioners and first line management actively adapt the system to maximize production and minimize accidents. These adaptations often occur on a moment by moment basis. Some of these adaptations include: 1 Restructuring the system in order to reduce exposure of vulnerable parts to failure. 2 Concentrating critical resources in areas of expected high demand. 3 Providing pathways for retreat or recovery from expected and unexpected faults. 4 Establishing means for early detection of changed system performance in order to allow graceful cutbacks in production or other means of increasing resiliency. 13. Human expertise in complex systems is constantly changing Complex systems require substantial human expertise in their operation and management. This expertise changes in character as technology changes but it also changes because of the need to replace experts who leave. In every case, training and refinement of skill and expertise is one part of the function of the system itself. ",
					"content_token": 185,
					"embedding": []
				},
				{
					"article_title": "How Complex Systems Fail",
					"article_url": "https://fs.blog/how-complex-systems-fail/",
					"content": "At any moment, therefore, a given complex system will contain practitioners and trainees with varying degrees of expertise. Critical issues related to expertise arise from 1 the need to use scarce expertise as a resource for the most difficult or demanding production needs and 2 the need to develop expertise for future use. 14. Change introduces new forms of failure The low rate of overt accidents in reliable systems may encourage changes, especially the use of new technology, to decrease the number of low consequence but high frequency failures. These changes maybe actually create opportunities for new, low frequency but high consequence failures. When new technologies are used to eliminate well understood system failures or to gain high precision performance they often introduce new pathways to large scale, catastrophic failures. Not uncommonly, these new, rare catastrophes have even greater impact than those eliminated by the new technology. These new forms of failure are difficult to see before the fact; attention is paid mostly to the putative beneficial characteristics of the changes. ",
					"content_token": 194,
					"embedding": []
				},
				{
					"article_title": "How Complex Systems Fail",
					"article_url": "https://fs.blog/how-complex-systems-fail/",
					"content": "Because these new, high consequence accidents occur at a low rate, multiple system changes may occur before an accident, making it hard to see the contribution of technology to the failure. 15. Views of cause’ limit the effectiveness of defenses against future events Post-accident remedies for “human error” are usually predicated on obstructing activities that can “cause” accidents. These end-of-the-chain measures do little to reduce the likelihood of further accidents. In fact that likelihood of an identical accident is already extraordinarily low because the pattern of latent failures changes constantly. Instead of increasing safety, post-accident remedies usually increase the coupling and complexity of the system. This increases the potential number of latent failures and also makes the detection and blocking of accident trajectories more difficult. 16. Safety is a characteristic of systems and not of their components Safety is an emergent property of systems; it does not reside in a person, device or department of an organization or system. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "How Complex Systems Fail",
					"article_url": "https://fs.blog/how-complex-systems-fail/",
					"content": "Safety cannot be purchased or manufactured; it is not a feature that is separate from the other components of the system. This means that safety cannot be manipulated like a feedstock or raw material. The state of safety in any system is always dynamic; continuous systemic change insures that hazard and its management are constantly changing. 17. People continuously create safety Failure free operations are the result of activities of people who work to keep the system within the boundaries of tolerable performance. These activities are, for the most part, part of normal operations and superficially straightforward. But because system operations are never trouble free, human practitioner adaptations to changing conditions actually create safety from moment to moment. These adaptations often amount to just the selection of a well-rehearsed routine from a store of available responses; sometimes, however, the adaptations are novel combinations or de novo creations of new approaches. 18. ",
					"content_token": 180,
					"embedding": []
				},
				{
					"article_title": "How Complex Systems Fail",
					"article_url": "https://fs.blog/how-complex-systems-fail/",
					"content": "Failure free operations require experience with failure Recognizing hazard and successfully manipulating system operations to remain inside the tolerable performance boundaries requires intimate contact with failure. More robust system performance is likely to arise in systems where operators can discern the “edge of the envelope” This is where system performance begins to deteriorate, becomes difficult to predict, or cannot be readily recovered. In intrinsically hazardous systems, operators are expected to encounter and appreciate hazards in ways that lead to overall performance that is desirable. Improved safety depends on providing operators with calibrated views of the hazards. It also depends on providing calibration about how their actions move system performance towards or away from the edge of the envelope. Here is a video of Richard talking about how complex systems don’t fail.",
					"content_token": 150,
					"embedding": []
				}
			]
		},
		{
			"title": "The Ability To Focus And Make The Best Move When There Are No Good Moves",
			"url": "https://fs.blog/the-ability-to-focus-and-make-the-best-move-when-there-are-no-good-moves/",
			"content": "“The indeterminate future is somehow one in which probability and statistics are the dominant modalities for making sense of the world.”  Decisions, where outcomes and therefore probabilities are unknown, are often the hardest. The default method of problem-solving often falls short. Sometimes you have to play the odds and sometimes you have to play the calculus. There are several different frameworks one could use to get a handle on the indeterminate vs. determinate question. The math version is calculus vs. statistics. In a determinate world, calculus dominates. You can calculate specific things precisely and deterministically. When you send a rocket to the moon, you have to calculate precisely where it is at all times. It’s not like some iterative startup where you launch the rocket and figure things out step by step. Do you make it to the moon? To Jupiter? Do you just get lost in space? There were lots of companies in the ’90s that had launch parties but no landing parties. But the indeterminate future is somehow one in which probability and statistics are the dominant modality for making sense of the world. Bell curves and random walks define what the future is going to look like. The standard pedagogical argument is that high schools should get rid of calculus and replace it with statistics, which is really important and actually useful. There has been a powerful shift toward the idea that statistical ways of thinking are going to drive the future. With calculus, you can calculate things far into the future. You can even calculate planetary locations years or decades from now. But there are no specifics in probability and statisticsonly distributions. In these domains, all you can know about the future is that you can’t know it. You cannot dominate the future; antitheories dominate instead. The Larry Summers line about the economy was something like, “I don’t know what’s going to happen, but anyone who says he knows what will happen doesn’t know what he’s talking about.” Today, all prophets are false prophets. That can only be true if people take a statistical view of the future.  Peter Thiel And this quote from The Hard Thing About Hard Things: Building a Business When There Are No Easy Answers by Ben Horowitz: I learned one important lesson: Startup CEOs should not play the odds. When you are building a company, you must believe there is an answer and you cannot pay attention to your odds of finding it. You just have to find it. It matters not whether your chances are nine in ten or one in a thousand; your task is the same.  I don’t believe in statistics. I believe in calculus.  People always ask me, “What’s the secret to being a successful CEO?” Sadly, there is no secret, but if there is one skill that stands out, it’s the ability to focus and make the best move when there are no good moves. It’s the moments where you feel most like hiding or dying that you can make the biggest difference as a CEO. In the rest of this chapter, I offer some lessons on how to make it through the struggle without quitting or throwing up too much.  I follow the first principle of the Bushidothe way of the warrior: keep death in mind at all times. If a warrior keeps death in mind at all times and lives as though each day might be his last, he will conduct himself properly in all his actions. Similarly, if a CEO keeps the following lessons in mind, she will maintain the proper focus when hiring, training , and building her culture. It’s interesting to me that the skill that stands out to Horowitz is one that we can use to teach how to think and one Tyler Cowen feels is in short supply. Cowen says: The more information that’s out there, the greater the returns to just being willing to sit down and apply yourself. Information isn’t what’s scarce; it’s the willingness to do something with it. ",
			"tokens": 838,
			"chunks": [
				{
					"article_title": "The Ability To Focus And Make The Best Move When There Are No Good Moves",
					"article_url": "https://fs.blog/the-ability-to-focus-and-make-the-best-move-when-there-are-no-good-moves/",
					"content": "“The indeterminate future is somehow one in which probability and statistics are the dominant modalities for making sense of the world.”  Decisions, where outcomes and therefore probabilities are unknown, are often the hardest. The default method of problem-solving often falls short. Sometimes you have to play the odds and sometimes you have to play the calculus. There are several different frameworks one could use to get a handle on the indeterminate vs. determinate question. The math version is calculus vs. statistics. In a determinate world, calculus dominates. You can calculate specific things precisely and deterministically. When you send a rocket to the moon, you have to calculate precisely where it is at all times. It’s not like some iterative startup where you launch the rocket and figure things out step by step. ",
					"content_token": 171,
					"embedding": []
				},
				{
					"article_title": "The Ability To Focus And Make The Best Move When There Are No Good Moves",
					"article_url": "https://fs.blog/the-ability-to-focus-and-make-the-best-move-when-there-are-no-good-moves/",
					"content": "Do you make it to the moon? To Jupiter? Do you just get lost in space? There were lots of companies in the ’90s that had launch parties but no landing parties. But the indeterminate future is somehow one in which probability and statistics are the dominant modality for making sense of the world. Bell curves and random walks define what the future is going to look like. The standard pedagogical argument is that high schools should get rid of calculus and replace it with statistics, which is really important and actually useful. There has been a powerful shift toward the idea that statistical ways of thinking are going to drive the future. With calculus, you can calculate things far into the future. You can even calculate planetary locations years or decades from now. But there are no specifics in probability and statisticsonly distributions. In these domains, all you can know about the future is that you can’t know it. You cannot dominate the future; antitheories dominate instead. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "The Ability To Focus And Make The Best Move When There Are No Good Moves",
					"article_url": "https://fs.blog/the-ability-to-focus-and-make-the-best-move-when-there-are-no-good-moves/",
					"content": "The Larry Summers line about the economy was something like, “I don’t know what’s going to happen, but anyone who says he knows what will happen doesn’t know what he’s talking about.” Today, all prophets are false prophets. That can only be true if people take a statistical view of the future.  Peter Thiel And this quote from The Hard Thing About Hard Things: Building a Business When There Are No Easy Answers by Ben Horowitz: I learned one important lesson: Startup CEOs should not play the odds. When you are building a company, you must believe there is an answer and you cannot pay attention to your odds of finding it. You just have to find it. It matters not whether your chances are nine in ten or one in a thousand; your task is the same.  I don’t believe in statistics. I believe in calculus. ",
					"content_token": 186,
					"embedding": []
				},
				{
					"article_title": "The Ability To Focus And Make The Best Move When There Are No Good Moves",
					"article_url": "https://fs.blog/the-ability-to-focus-and-make-the-best-move-when-there-are-no-good-moves/",
					"content": " People always ask me, “What’s the secret to being a successful CEO?” Sadly, there is no secret, but if there is one skill that stands out, it’s the ability to focus and make the best move when there are no good moves. It’s the moments where you feel most like hiding or dying that you can make the biggest difference as a CEO. In the rest of this chapter, I offer some lessons on how to make it through the struggle without quitting or throwing up too much.  I follow the first principle of the Bushidothe way of the warrior: keep death in mind at all times. If a warrior keeps death in mind at all times and lives as though each day might be his last, he will conduct himself properly in all his actions. Similarly, if a CEO keeps the following lessons in mind, she will maintain the proper focus when hiring, training , and building her culture. ",
					"content_token": 194,
					"embedding": []
				},
				{
					"article_title": "The Ability To Focus And Make The Best Move When There Are No Good Moves",
					"article_url": "https://fs.blog/the-ability-to-focus-and-make-the-best-move-when-there-are-no-good-moves/",
					"content": "It’s interesting to me that the skill that stands out to Horowitz is one that we can use to teach how to think and one Tyler Cowen feels is in short supply. Cowen says: The more information that’s out there, the greater the returns to just being willing to sit down and apply yourself. Information isn’t what’s scarce; it’s the willingness to do something with it.",
					"content_token": 89,
					"embedding": []
				}
			]
		},
		{
			"title": "The Default-Thinking Method of Problem Solving",
			"url": "https://fs.blog/the-default-thinking-method-of-problem-solving/",
			"content": "You’ve been here before. It’s Monday morning and you walk into the office only to have your boss call an urgent meeting to “streamline processes.” You haven’t thought about this enough to have an opinion but you go anyway. You know how to deal with this. You’ve done it before. You turn on your default brain and start solving the problem. You build a hypothesis to determine the problem, find some data to analyze, and presto out comes some efficiency. Most of the time this works well enough, but not always. Sometimesmore often than we’d like to admitthings change: markets shift and consumers behave in unpredictable ways. Now we’re rudderless. In the wonderful book The Moment of Clarity: Using the Human Sciences to Solve Your Toughest Business Problems, the authors write: We are forever in the midst of change, but not all of it is seismic. It’s vital for a business to understand the difference between the uncertainties present on an average day and the uncertainties of a major cultural shift.  Business issues can be categorized along a problem scale within three levels of complexity . This framework is useful for distinguishing very complex problems from those that are actually manageable. The Three Levels of Business Problems 1. A clear-enough future with a relatively predictable business environment. You know what the problem is, and you can apply a proven algorithm to fix it. “If I invest  1 in media spending for advertising, I know that I will get something like  1.5 back because of market stimulation.” “The industry has average admin costs of 8 percent of total revenue. Mine are 10 percent. We should cut that back.” 2. Alternative futures with a set of options available. You have a feel for the problem and might have seen something like it before. It makes sense to test your hunch as a hypothesis. For example, “Our sales numbers are down even when we invest in more salespeople, but we have seen the same pattern in the European Union and China. We might be hiring too many new salespeople too quickly and expecting them to deliver the same payback that the existing salespeople are delivering.” 3. High level of uncertainty, with no understanding of the problem. You simply don’t know what the problem is, let alone the solution. You can see that something is wrong, but have no clear idea about what to do. For example, “Our media division is losing business to internet start-ups,” “We are investing more in customer service, but our customers are becoming increasingly dissatisfied with us,” and “We are designing products that seem right for the marketplace, but the marketplace isn’t interested.” Most of our problems tend to be in 1 or 2. Uncertainty, remember, happens when we fail to know the range of possible outcomes and, correspondingly, their probabilities. These are really messy problems. Solving the problems of 1 and 2 are generally much easier. We use default thinking. The default problem-solving model has its roots in what can be called instrumental rationalism. At the heart of the model is the belief that business problems can be solved through objective and scientific analysis and that evidence and facts should prevail over opinions and preferences. To get to the right answer, so the thinking goes, you should adhere to the following principles of problem solving: 1. All business uncertainties are defined as problems. Something in the past caused the problem, and the facts should be analyzed to clarify what the problem is and how to solve it. 2. Problems are deconstructed into quantifiable and formal problem statements issues. For example, “Why is our profitability falling?” 3. Each problem is atomized into the smallest possible bits that can be analyzed separately for example, breaking down the causes of profitability into logical issues. This analysis would include “issue trees” for all the hundreds of potential levers for either decreasing costs or growing revenue customer segments, markets, market share, price, sales channels, operations, new business development, etc. 4. A list of hypotheses to explain the cause of the problem is generated. For example, “We can increase profitability by lowering the cost of our operations.” 5. Data is gathered and processed to test each hypothesis all possible stones are turned and no data source is left untouched. 6. Induction and deduction are used to test hypotheses, clarify the problem, and find the areas of intervention with the highest impact, or what is commonly called “bang for the buck.” 7. A well-organized structure of the analysis is deployed to build a logical and fact-based argument of what should be done. The structure is built like a pyramid that develops the supporting facts, some subconclusions, and an overall conclusion and then ends with a prioritized list of interventions to which the company should adhere. 8. All proposed actions are described as manageable work streams or must-win battles for which a responsible committee, or person, is assigned. 9. Performance metrics and a proposed time frame with follow-up monitoring are put in place for each committee to complete the task. 10. When all work streams have been completed, the problem is solved. When done correctly by competent people, this can be a thing of beauty. This is, in part, why we hire consultants like myself, McKinsey, or Bain. We believe they can solve any problem. The idea that management is a type of science with a repeatable formula in the face of any problem is not a new idea. “It can be traced back to the nineteenth century, when positivism, the prevalent philosophy of the day, argued that you could objectively measure reality.” The founding father of the idea of management science, if there was one, Frederick Winslow Taylor. Taylor left a prestigious education at Harvard to work at steel companies throughout Pennsylvania. Whereas most manufacturing and factory plants had cobbled together their organization through rules of thumb and common sense, Taylor was the quintessential positivist, seeking scientifically validated measurements, or properties. He followed workers, clicking his stopwatch every time they started and stopped, measuring the time it took to complete each discrete action of hauling their large iron ore loads. Through his enormously successful tenure at steel companies, he extracted generalized principles of management that he used to create the world’s first business case study. It wasn’t long before a partnership between Harvard’s School of Applied Science and its brand-new business school came calling. Might Taylor bring together his experience into something the school could teach its young students about productivity? Taylorism, based on the following premise, was born: To work according to scientific laws, the management must take over and perform much of the work which is now left to the men; almost every act of the workman should be preceded by one or more preparatory acts of the management which enable him to do his work better and quicker than he otherwise could.  Today’s problems seem infinitely more complex than counting iron ore hauls and yet we still attack them with the same general approach of Taylorism. This is what most MBAs, including mine, taught: people work harder with the right incentives, optimize and perfect workflow, analyze every movement looking for efficiencies, remove discretion when possible because that creates variance, etc. Of course we’ve evolved Taylorism, today we call it “lean” and “six sigma” and whatever else. For most of us, default thinking is so familiar to us the very air we breathe that we are no longer able to explain it or even to see it. For that reason, if we really want to understand why we continue to get people wrong, we need to unpack the fundamental assumptions that make up the culture of most of our days. Is this really how we approach problems? What are the assumptions we’re making when we take this approach? Assumption 1: People Are Rational And Fully Informed One of the unintentional consequences of solving problems by testing logical hypotheses is that you are forced to assume that people are rational decision makers: aware of their needs, fully informed of all their choices, and capable of making the best choice. The reason is simple: it is very difficult to test a hypothesis about things that you can’t measure objectively. It’s even harder to test something that is deeply personal, cannot be decoded into explicit descriptions, and requires a lot of interpretation. Think about the question “Are you a good parent?” or “Do you have good taste?” A simple answer misses most of what matters about parenting and good taste. To deal with this problem, companies base their problem solving on what can objectively be described, quantified, and analyzed without too much interpretation. So we default to measuring perceptions and desires, more specifically, we end up with people’s perceptions of reality. There is nothing wrong with this but it is limited and we should be aware of its limitations. These are not the only two aspects of humanity that matter. And even if they were, the way default thinking solves problems rarely offers us any understanding of how they work. We find some spurious relationship and assume causation when, in reality, it’s merely a correlation. When it changes we have no idea why. We’re more complex than that. Most recent studies evaluating how people buy reveal us to be far more chaotic creatures. We rarely know what we want. We almost never fully grasp the market and, most important, we almost always buy something at a different price than what we thought we would. Even studies of people with written shopping lists milk, eggs, apples, etc. reveal that they find themselves far astray from their original intentions once they reach the grocery store. We do this because intentions are relatively easy to study. But as Dr. House says, “everybody lies.” People think they cook a lot, but they really don’t. It’s not that they want to lie to other people; they are simply lying to themselves. There is often a wealth of distance between what people say and what people do. It’s not that people don’t care about anything. They just don’t care as much as most companies assume that they do. And most often, people couldn’t care less. When they buy one kind of chocolate bar rather than another, it is rarely because they have a strong brand preference. More often than not, it is because the chocolate was closer on the counter, it had a color that fit the mood, or it simply came packaged as a “two for one.” The good news for companies is that we buy a lot of stuff. The bad news is that we don’t always know why. Assumption 2: Tomorrow Will Look Like Today A good example of this attitude can be found in a 2006 article in the McKinsey Quarterly. In identifying trends that will shape the business environment, the article says that management itself will shift from an art to a science: Long gone is the day of the “gut instinct” management style. Today’s business leaders are adopting algorithmic decision-making techniques and using highly sophisticated software to run their organizations. Scientific management is moving from a skill that creates competitive advantage to an ante that gives companies the right to play the game. We’re bombarded with the word “science.” When thought leaders use the word science to describe a business discipline like marketing, retail design, negotiation skill, or strategy, we are led to believe that these disciplines can be predicated on scientific truths. Does the science of shopping have the same universal laws as Darwin’s theory of natural selection? This is part of the reason we trick ourselves. Rarely do we have to ask, “Where does the hypothesis come from?” But by assuming that the hypothesis is based on some kind of universal law, we fool ourselves into believing that the assumptions of the current moment will also hold true in the future. In these situations, the idea that management is a kind of natural science blinds us rather than enlightens us. Assumption 3: Hypotheses are Objective and Unbiased Here is a great example: In the toy industry, the dominating idea is that children have a short attention span and need toys that stimulate their desire for instant traction. A toy, it is assumed, must grab the attention of the child in the store, and he or she should not need any skills to play with it. Another assumption is that physical toys are losing ground to digital toys because the former are too tedious and not stimulating enough. In reality, when you study children and if you read the majority of academic literature about childrenyou will probably reach the opposite conclusion: children are highly motivated by play experiences that require skill and mastery and that can give them a sense of hierarchy and accomplishment. Digital play is gaining in popularity precisely because it requires a very sophisticated skill set; it can be played for thousands of hours and it gives the players clear feedback with levels and hierarchies. Over time, companies and people create “commonsense” ideas about the world and how it works. We take things as given and rarely challenge them. The French anthropologist Pierre Bourdieu coined the term habitus to describe the somehow hidden but always present dispositions that shape our perceptions, thoughts, and actions. In his view, many things that we regard as common sense are in fact shaped by the social context we are in. Over time we learn what is normal and taken as a given through our social interaction with the world our family, our society, our friends, our work and our perceptions become a kind of automatic understanding of the world. This understanding enables us to act normally without really thinking about it. Over time, companies similarly create commonsense ideas about the world. Certain things are simply taken as a given, no longer contested: for example, the idea that designers and engineers will never see eye-to-eye, or that open offices provide more opportunities for collaboration. This is one reason consultants can be effective, they come in with a different understanding and offer opinionsintentionally or not – that challenge some of these commonsensical views. In terms of default thinking: A company might think that it has created an objective set of possible hypotheses to test. But in reality each hypothesis is always based on something . Very often, that thing is a product of culture, not of science. And once our assumptions are firmly rooted in our cultural understanding, they have a way of becoming ever more entrenched. Then confirmation bias kicks in. We look for opinions, ideas, and facts that support our beliefs. In the end, our hypotheses are “almost never based on objective truth.” How could it be otherwise? But of course, the point is to know the limitations of the tools we’re working with and hope that awareness allows us to make better decisions by using better tools. In Leo Tolstoy’s nonfiction magnum opus The Kingdom of God Is Within You, he writes: “The most difficult subjects can be explained to the most slow-witted man if he has not formed any idea of them already; but the simplest thing cannot be made clear to the most intelligent man if he is firmly persuaded that he knows already, without a shadow of doubt, what is laid before him.” If you can’t question assumptions at your company, you probably can’t question anything. Assumption 4: Numbers Are the Only Truth “Not everything that can be counted counts, and not everything that counts can be counted.”  Albert Einstein The heart of default problem solving is quantitative analysis. It has become so dominant that companies tend to forget that the world consists not only of quantities but also of qualities. Roger Martin, the dean of Rothman School of Management, argues that companies will simply lack ability to find the full potential of growth opportunities if they only focus on quantitative models: “The greatest weakness of the quantitative approach is that it decontextualizes human behavior, removing an event from its real-world setting and ignoring the effects of variables not included in the model.” Default thinking catalogs the world into properties: how big is the market, how many people will buy our products, how many people know our brand, which category is growing fastest, which geography is the most profitable, which customers have the highest loyalty and what technologies have the highest adoption. Yes, all of those have a numbers side, but they also have a qualitative side that might also shed light on things. If you know that a certain percent of your customers are happy with their interactions with your company, that’s different than knowing what the experience of interacting with your company is like. Both of those things are needed to inform decisions. Numbers are great for covering your ass, so they tend to trump anything else. Numbers however, limit ideas and solutions to only one right answer. For obvious reasons, the past does not include data on things that haven’t happened or ideas that have not yet been imagined. As a result, data analysis of the future tends to underestimate or even ignore past events or conditions that can’t be measured while overestimating those that can. Nowhere is this more visible than in business case studies. “In our view,” the authors write,” the quantitative obsession leads to a sorely diminished approach to future planning. It tends to be conservative rather than creative because it implicitly favors what can be measured over what cannot.” Assumption 5: Language Needs to be Dehumanizing Business and management science has become a world in itself, and the language of business has become increasingly technical, introverted, and coded. You don’t fire people anymore; you “right-size the organization.” You don’t do the easiest things first; you “pick the low-hanging fruit.” You don’t look at where you sell your products; you “evaluate your channel mix.” You don’t promote people; you “leverage your human resources.” You don’t give people a bonus check; you “incentivize.” You don’t do stuff; you “execute.” You “synergize, optimize, leverage, simplify, utilize, transform, enhance, and reengineer.” You avoid “boiling the ocean, missing the paradigm shift, having tunnel vision, and increasing complexity.” You make sure that “resources are allocated to leverage synergies across organizational boundaries and with a customer-centric mind-set that can secure a premium position while targeting white spots in the blue ocean to ensure that there is bang for the buck.” It can become almost poetic. Talk about jargon. The German philosopher Jrgen Habermas has developed an extensive analysis of what happens when technical language outstrips the language of everyday life. He argues that the change from a normal, everyday language to a technical, specific language suggests a shift in power. When technical language conquers simple language of the every day, it is a sign that the system is gaining ground and everyday human reality, what he calls the lifeworld, is losing ground. He goes so far as to call this shift a colonization of the lifeworld; everyday life being colonized by a force of bureaucratization and rationalization that it cannot defend itself against. Such a shift leads to a far more systematic, rule-based, and technical idea of the world. It widens the gap between who we really are and the systems that we have become.    Of course, default thinking doesn’t always work. You know you’ve stepped out of default thinking space when leaders say, “think outside the box.” Problems arise when you try to solve the third type of problem where there is a high level of uncertainty with the same thinking you use to fix problems in one and two. If you enjoyed this post, you’d love the book The Moment of Clarity: Using the Human Sciences to Solve Your Toughest Business Problems. ",
			"tokens": 4154,
			"chunks": [
				{
					"article_title": "The Default-Thinking Method of Problem Solving",
					"article_url": "https://fs.blog/the-default-thinking-method-of-problem-solving/",
					"content": "You’ve been here before. It’s Monday morning and you walk into the office only to have your boss call an urgent meeting to “streamline processes.” You haven’t thought about this enough to have an opinion but you go anyway. You know how to deal with this. You’ve done it before. You turn on your default brain and start solving the problem. You build a hypothesis to determine the problem, find some data to analyze, and presto out comes some efficiency. Most of the time this works well enough, but not always. Sometimesmore often than we’d like to admitthings change: markets shift and consumers behave in unpredictable ways. Now we’re rudderless. In the wonderful book The Moment of Clarity: Using the Human Sciences to Solve Your Toughest Business Problems, the authors write: We are forever in the midst of change, but not all of it is seismic. ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "The Default-Thinking Method of Problem Solving",
					"article_url": "https://fs.blog/the-default-thinking-method-of-problem-solving/",
					"content": "It’s vital for a business to understand the difference between the uncertainties present on an average day and the uncertainties of a major cultural shift.  Business issues can be categorized along a problem scale within three levels of complexity  This framework is useful for distinguishing very complex problems from those that are actually manageable. The Three Levels of Business Problems 1. A clear-enough future with a relatively predictable business environment. You know what the problem is, and you can apply a proven algorithm to fix it. “If I invest  1 in media spending for advertising, I know that I will get something like  1.5 back because of market stimulation.” “The industry has average admin costs of 8 percent of total revenue. Mine are 10 percent. We should cut that back.” 2. Alternative futures with a set of options available. You have a feel for the problem and might have seen something like it before. It makes sense to test your hunch as a hypothesis. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "The Default-Thinking Method of Problem Solving",
					"article_url": "https://fs.blog/the-default-thinking-method-of-problem-solving/",
					"content": "For example, “Our sales numbers are down even when we invest in more salespeople, but we have seen the same pattern in the European Union and China. We might be hiring too many new salespeople too quickly and expecting them to deliver the same payback that the existing salespeople are delivering.” 3. High level of uncertainty, with no understanding of the problem. You simply don’t know what the problem is, let alone the solution. You can see that something is wrong, but have no clear idea about what to do. For example, “Our media division is losing business to internet start-ups,” “We are investing more in customer service, but our customers are becoming increasingly dissatisfied with us,” and “We are designing products that seem right for the marketplace, but the marketplace isn’t interested.” Most of our problems tend to be in 1 or 2. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "The Default-Thinking Method of Problem Solving",
					"article_url": "https://fs.blog/the-default-thinking-method-of-problem-solving/",
					"content": "Uncertainty, remember, happens when we fail to know the range of possible outcomes and, correspondingly, their probabilities. These are really messy problems. Solving the problems of 1 and 2 are generally much easier. We use default thinking. The default problem-solving model has its roots in what can be called instrumental rationalism. At the heart of the model is the belief that business problems can be solved through objective and scientific analysis and that evidence and facts should prevail over opinions and preferences. To get to the right answer, so the thinking goes, you should adhere to the following principles of problem solving: 1. All business uncertainties are defined as problems. Something in the past caused the problem, and the facts should be analyzed to clarify what the problem is and how to solve it. 2. Problems are deconstructed into quantifiable and formal problem statements issues. For example, “Why is our profitability falling?” 3. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "The Default-Thinking Method of Problem Solving",
					"article_url": "https://fs.blog/the-default-thinking-method-of-problem-solving/",
					"content": "Each problem is atomized into the smallest possible bits that can be analyzed separately for example, breaking down the causes of profitability into logical issues. This analysis would include “issue trees” for all the hundreds of potential levers for either decreasing costs or growing revenue customer segments, markets, market share, price, sales channels, operations, new business development, etc. 4. A list of hypotheses to explain the cause of the problem is generated. For example, “We can increase profitability by lowering the cost of our operations.” 5. Data is gathered and processed to test each hypothesis all possible stones are turned and no data source is left untouched. 6. Induction and deduction are used to test hypotheses, clarify the problem, and find the areas of intervention with the highest impact, or what is commonly called “bang for the buck.” 7. A well-organized structure of the analysis is deployed to build a logical and fact-based argument of what should be done. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "The Default-Thinking Method of Problem Solving",
					"article_url": "https://fs.blog/the-default-thinking-method-of-problem-solving/",
					"content": "The structure is built like a pyramid that develops the supporting facts, some subconclusions, and an overall conclusion and then ends with a prioritized list of interventions to which the company should adhere. 8. All proposed actions are described as manageable work streams or must-win battles for which a responsible committee, or person, is assigned. 9. Performance metrics and a proposed time frame with follow-up monitoring are put in place for each committee to complete the task. 10. When all work streams have been completed, the problem is solved. When done correctly by competent people, this can be a thing of beauty. This is, in part, why we hire consultants like myself, McKinsey, or Bain. We believe they can solve any problem. The idea that management is a type of science with a repeatable formula in the face of any problem is not a new idea. ",
					"content_token": 177,
					"embedding": []
				},
				{
					"article_title": "The Default-Thinking Method of Problem Solving",
					"article_url": "https://fs.blog/the-default-thinking-method-of-problem-solving/",
					"content": "“It can be traced back to the nineteenth century, when positivism, the prevalent philosophy of the day, argued that you could objectively measure reality.” The founding father of the idea of management science, if there was one, Frederick Winslow Taylor. Taylor left a prestigious education at Harvard to work at steel companies throughout Pennsylvania. Whereas most manufacturing and factory plants had cobbled together their organization through rules of thumb and common sense, Taylor was the quintessential positivist, seeking scientifically validated measurements, or properties. He followed workers, clicking his stopwatch every time they started and stopped, measuring the time it took to complete each discrete action of hauling their large iron ore loads. Through his enormously successful tenure at steel companies, he extracted generalized principles of management that he used to create the world’s first business case study. It wasn’t long before a partnership between Harvard’s School of Applied Science and its brand-new business school came calling. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "The Default-Thinking Method of Problem Solving",
					"article_url": "https://fs.blog/the-default-thinking-method-of-problem-solving/",
					"content": "Might Taylor bring together his experience into something the school could teach its young students about productivity? Taylorism, based on the following premise, was born: To work according to scientific laws, the management must take over and perform much of the work which is now left to the men; almost every act of the workman should be preceded by one or more preparatory acts of the management which enable him to do his work better and quicker than he otherwise could.  Today’s problems seem infinitely more complex than counting iron ore hauls and yet we still attack them with the same general approach of Taylorism. This is what most MBAs, including mine, taught: people work harder with the right incentives, optimize and perfect workflow, analyze every movement looking for efficiencies, remove discretion when possible because that creates variance, etc. Of course we’ve evolved Taylorism, today we call it “lean” and “six sigma” and whatever else. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "The Default-Thinking Method of Problem Solving",
					"article_url": "https://fs.blog/the-default-thinking-method-of-problem-solving/",
					"content": "For most of us, default thinking is so familiar to us the very air we breathe that we are no longer able to explain it or even to see it. For that reason, if we really want to understand why we continue to get people wrong, we need to unpack the fundamental assumptions that make up the culture of most of our days. Is this really how we approach problems? What are the assumptions we’re making when we take this approach? Assumption 1: People Are Rational And Fully Informed One of the unintentional consequences of solving problems by testing logical hypotheses is that you are forced to assume that people are rational decision makers: aware of their needs, fully informed of all their choices, and capable of making the best choice. The reason is simple: it is very difficult to test a hypothesis about things that you can’t measure objectively. ",
					"content_token": 174,
					"embedding": []
				},
				{
					"article_title": "The Default-Thinking Method of Problem Solving",
					"article_url": "https://fs.blog/the-default-thinking-method-of-problem-solving/",
					"content": "It’s even harder to test something that is deeply personal, cannot be decoded into explicit descriptions, and requires a lot of interpretation. Think about the question “Are you a good parent?” or “Do you have good taste?” A simple answer misses most of what matters about parenting and good taste. To deal with this problem, companies base their problem solving on what can objectively be described, quantified, and analyzed without too much interpretation. So we default to measuring perceptions and desires, more specifically, we end up with people’s perceptions of reality. There is nothing wrong with this but it is limited and we should be aware of its limitations. These are not the only two aspects of humanity that matter. And even if they were, the way default thinking solves problems rarely offers us any understanding of how they work. We find some spurious relationship and assume causation when, in reality, it’s merely a correlation. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "The Default-Thinking Method of Problem Solving",
					"article_url": "https://fs.blog/the-default-thinking-method-of-problem-solving/",
					"content": "When it changes we have no idea why. We’re more complex than that. Most recent studies evaluating how people buy reveal us to be far more chaotic creatures. We rarely know what we want. We almost never fully grasp the market and, most important, we almost always buy something at a different price than what we thought we would. Even studies of people with written shopping lists milk, eggs, apples, etc. reveal that they find themselves far astray from their original intentions once they reach the grocery store. We do this because intentions are relatively easy to study. But as Dr. House says, “everybody lies.” People think they cook a lot, but they really don’t. It’s not that they want to lie to other people; they are simply lying to themselves. There is often a wealth of distance between what people say and what people do. It’s not that people don’t care about anything. ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "The Default-Thinking Method of Problem Solving",
					"article_url": "https://fs.blog/the-default-thinking-method-of-problem-solving/",
					"content": "They just don’t care as much as most companies assume that they do. And most often, people couldn’t care less. When they buy one kind of chocolate bar rather than another, it is rarely because they have a strong brand preference. More often than not, it is because the chocolate was closer on the counter, it had a color that fit the mood, or it simply came packaged as a “two for one.” The good news for companies is that we buy a lot of stuff. The bad news is that we don’t always know why. Assumption 2: Tomorrow Will Look Like Today A good example of this attitude can be found in a 2006 article in the McKinsey Quarterly. In identifying trends that will shape the business environment, the article says that management itself will shift from an art to a science: Long gone is the day of the “gut instinct” management style. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "The Default-Thinking Method of Problem Solving",
					"article_url": "https://fs.blog/the-default-thinking-method-of-problem-solving/",
					"content": "Today’s business leaders are adopting algorithmic decision-making techniques and using highly sophisticated software to run their organizations. Scientific management is moving from a skill that creates competitive advantage to an ante that gives companies the right to play the game. We’re bombarded with the word “science.” When thought leaders use the word science to describe a business discipline like marketing, retail design, negotiation skill, or strategy, we are led to believe that these disciplines can be predicated on scientific truths. Does the science of shopping have the same universal laws as Darwin’s theory of natural selection? This is part of the reason we trick ourselves. Rarely do we have to ask, “Where does the hypothesis come from?” But by assuming that the hypothesis is based on some kind of universal law, we fool ourselves into believing that the assumptions of the current moment will also hold true in the future. ",
					"content_token": 188,
					"embedding": []
				},
				{
					"article_title": "The Default-Thinking Method of Problem Solving",
					"article_url": "https://fs.blog/the-default-thinking-method-of-problem-solving/",
					"content": "In these situations, the idea that management is a kind of natural science blinds us rather than enlightens us. Assumption 3: Hypotheses are Objective and Unbiased Here is a great example: In the toy industry, the dominating idea is that children have a short attention span and need toys that stimulate their desire for instant traction. A toy, it is assumed, must grab the attention of the child in the store, and he or she should not need any skills to play with it. Another assumption is that physical toys are losing ground to digital toys because the former are too tedious and not stimulating enough. In reality, when you study children and if you read the majority of academic literature about childrenyou will probably reach the opposite conclusion: children are highly motivated by play experiences that require skill and mastery and that can give them a sense of hierarchy and accomplishment. ",
					"content_token": 174,
					"embedding": []
				},
				{
					"article_title": "The Default-Thinking Method of Problem Solving",
					"article_url": "https://fs.blog/the-default-thinking-method-of-problem-solving/",
					"content": "Digital play is gaining in popularity precisely because it requires a very sophisticated skill set; it can be played for thousands of hours and it gives the players clear feedback with levels and hierarchies. Over time, companies and people create “commonsense” ideas about the world and how it works. We take things as given and rarely challenge them. The French anthropologist Pierre Bourdieu coined the term habitus to describe the somehow hidden but always present dispositions that shape our perceptions, thoughts, and actions. In his view, many things that we regard as common sense are in fact shaped by the social context we are in. Over time we learn what is normal and taken as a given through our social interaction with the world our family, our society, our friends, our work and our perceptions become a kind of automatic understanding of the world. This understanding enables us to act normally without really thinking about it. Over time, companies similarly create commonsense ideas about the world. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "The Default-Thinking Method of Problem Solving",
					"article_url": "https://fs.blog/the-default-thinking-method-of-problem-solving/",
					"content": "Certain things are simply taken as a given, no longer contested: for example, the idea that designers and engineers will never see eye-to-eye, or that open offices provide more opportunities for collaboration. This is one reason consultants can be effective, they come in with a different understanding and offer opinionsintentionally or not – that challenge some of these commonsensical views. In terms of default thinking: A company might think that it has created an objective set of possible hypotheses to test. But in reality each hypothesis is always based on something  Very often, that thing is a product of culture, not of science. And once our assumptions are firmly rooted in our cultural understanding, they have a way of becoming ever more entrenched. Then confirmation bias kicks in. We look for opinions, ideas, and facts that support our beliefs. ",
					"content_token": 166,
					"embedding": []
				},
				{
					"article_title": "The Default-Thinking Method of Problem Solving",
					"article_url": "https://fs.blog/the-default-thinking-method-of-problem-solving/",
					"content": "In the end, our hypotheses are “almost never based on objective truth.” How could it be otherwise? But of course, the point is to know the limitations of the tools we’re working with and hope that awareness allows us to make better decisions by using better tools. In Leo Tolstoy’s nonfiction magnum opus The Kingdom of God Is Within You, he writes: “The most difficult subjects can be explained to the most slow-witted man if he has not formed any idea of them already; but the simplest thing cannot be made clear to the most intelligent man if he is firmly persuaded that he knows already, without a shadow of doubt, what is laid before him.” If you can’t question assumptions at your company, you probably can’t question anything. ",
					"content_token": 171,
					"embedding": []
				},
				{
					"article_title": "The Default-Thinking Method of Problem Solving",
					"article_url": "https://fs.blog/the-default-thinking-method-of-problem-solving/",
					"content": "Assumption 4: Numbers Are the Only Truth “Not everything that can be counted counts, and not everything that counts can be counted.”  Albert Einstein The heart of default problem solving is quantitative analysis. It has become so dominant that companies tend to forget that the world consists not only of quantities but also of qualities. Roger Martin, the dean of Rothman School of Management, argues that companies will simply lack ability to find the full potential of growth opportunities if they only focus on quantitative models: “The greatest weakness of the quantitative approach is that it decontextualizes human behavior, removing an event from its real-world setting and ignoring the effects of variables not included in the model.” Default thinking catalogs the world into properties: how big is the market, how many people will buy our products, how many people know our brand, which category is growing fastest, which geography is the most profitable, which customers have the highest loyalty and what technologies have the highest adoption. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "The Default-Thinking Method of Problem Solving",
					"article_url": "https://fs.blog/the-default-thinking-method-of-problem-solving/",
					"content": "Yes, all of those have a numbers side, but they also have a qualitative side that might also shed light on things. If you know that a certain percent of your customers are happy with their interactions with your company, that’s different than knowing what the experience of interacting with your company is like. Both of those things are needed to inform decisions. Numbers are great for covering your ass, so they tend to trump anything else. Numbers however, limit ideas and solutions to only one right answer. For obvious reasons, the past does not include data on things that haven’t happened or ideas that have not yet been imagined. As a result, data analysis of the future tends to underestimate or even ignore past events or conditions that can’t be measured while overestimating those that can. Nowhere is this more visible than in business case studies. “In our view,” the authors write,” the quantitative obsession leads to a sorely diminished approach to future planning. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "The Default-Thinking Method of Problem Solving",
					"article_url": "https://fs.blog/the-default-thinking-method-of-problem-solving/",
					"content": "It tends to be conservative rather than creative because it implicitly favors what can be measured over what cannot.” Assumption 5: Language Needs to be Dehumanizing Business and management science has become a world in itself, and the language of business has become increasingly technical, introverted, and coded. ",
					"content_token": 61,
					"embedding": []
				},
				{
					"article_title": "The Default-Thinking Method of Problem Solving",
					"article_url": "https://fs.blog/the-default-thinking-method-of-problem-solving/",
					"content": "You don’t fire people anymore; you “right-size the organization.” You don’t do the easiest things first; you “pick the low-hanging fruit.” You don’t look at where you sell your products; you “evaluate your channel mix.” You don’t promote people; you “leverage your human resources.” You don’t give people a bonus check; you “incentivize.” You don’t do stuff; you “execute.” You “synergize, optimize, leverage, simplify, utilize, transform, enhance, and reengineer.” You avoid “boiling the ocean, missing the paradigm shift, having tunnel vision, and increasing complexity.” You make sure that “resources are allocated to leverage synergies across organizational boundaries and with a customer-centric mind-set that can secure a premium position while targeting white spots in the blue ocean to ensure that there is bang for the buck.” It can become almost poetic. ",
					"content_token": 229,
					"embedding": []
				},
				{
					"article_title": "The Default-Thinking Method of Problem Solving",
					"article_url": "https://fs.blog/the-default-thinking-method-of-problem-solving/",
					"content": "Talk about jargon. The German philosopher Jrgen Habermas has developed an extensive analysis of what happens when technical language outstrips the language of everyday life. He argues that the change from a normal, everyday language to a technical, specific language suggests a shift in power. When technical language conquers simple language of the every day, it is a sign that the system is gaining ground and everyday human reality, what he calls the lifeworld, is losing ground. He goes so far as to call this shift a colonization of the lifeworld; everyday life being colonized by a force of bureaucratization and rationalization that it cannot defend itself against. Such a shift leads to a far more systematic, rule-based, and technical idea of the world. It widens the gap between who we really are and the systems that we have become.    Of course, default thinking doesn’t always work. ",
					"content_token": 186,
					"embedding": []
				},
				{
					"article_title": "The Default-Thinking Method of Problem Solving",
					"article_url": "https://fs.blog/the-default-thinking-method-of-problem-solving/",
					"content": "You know you’ve stepped out of default thinking space when leaders say, “think outside the box.” Problems arise when you try to solve the third type of problem where there is a high level of uncertainty with the same thinking you use to fix problems in one and two. If you enjoyed this post, you’d love the book The Moment of Clarity: Using the Human Sciences to Solve Your Toughest Business Problems.",
					"content_token": 92,
					"embedding": []
				}
			]
		},
		{
			"title": "Sensemaking as a Complement to Default Thinking",
			"url": "https://fs.blog/the-moment-of-clarity/",
			"content": "Most of the time we devise strategies in the default mode of problem-solving, prioritizing maximum growth and profit through rational and logical analysis. But we already know that rational and logical analysis doesn’t always result in the best decisions. In The Moment of Clarity: Using the Human Sciences to Solve Your Toughest Business Problems Christian Madsbjerg and Mikkel Rasmussen write: The ideal is to turn strategy work into a rigorous discipline with the use of deductive logic, a well-structured hypothesis, and a thorough collection of evidence and data. Such problem solving has dominated most research and teaching in business schools over the last decades and has formed the guiding principles of many global management consultancies. Slowly but steadily, this mind-set has gained dominance in business culture over the last thirty years. Today it is the unspoken default tool for solving all problems. This mindset is almost scientific in the quest for precision.  learn from past examples to create a hypothesis you can test with numbers. As it uses inductive reasoning for its foundation, it is enormously successful at analyzing information extrapolated from a known set of data from the past. Default thinking helps us create efficiencies, optimize resources, balance product portfolios, increase productivity, invest in markets with the shortest and biggest payback , cut operational complexity, and generally get more bang for the buck. In short, it works extraordinarily well when the business challenge demands an increase in the productivity of a system. But this method often falls short. And one area where it falls short is people’s behavior. “When it comes to cultural shifts, the use of a hypothesis based on past examples will give us a false sense of confidence, sending us astray into unknown waters with the wrong map,” the authors write. Certain problems benefit from a linear and rational approach, while other, less straightforward challengesnavigating in a fogbenefit from the problem solving utilized in the human sciences like philosophy, history, the arts, and anthropology. We call this problem-solving method sensemaking. Sensemaking is really about finding how things are experienced through culture. The hard sciences involving mathematics and universal laws tell us the way things are and tend to take the main spotlight when we discuss our understanding of the world. This tendency is so common, we often disregard the wide range of sciences that are used to shed light on other phenomena, or the way things are experienced in culture. If default thinking shows us what exists in the foreground e.g., “we are losing our market share in competitive athletic apparel”, the human sciences investigate the invisible background the layered nuance behind what we perceive e.g., “well -being, not competition , is the main motivating factor for many people participating in sports”.  How we experience the world may be as important as, or more important than the hard, objective facts about the world. This is especially true for the specific set of problems where past data or scenarios no longer seem relevant. Default thinking and sensemaking are complementary tools. How default thinking and sensemaking complement one another. Source: The Moment of Clarity But we tend to see leadership more in the default thinking way, which makes perfect sense. Who doesn’t want to be hypothesis-driven, quantitative, and linear in their approach to solving problems? Most of these things are visible, which has an added benefit too. But if this is the only tool in our toolbox we’re going to fall short. The difference between decision-makers and sensemakers. Source: The Moment of Clarity It was perfectly rational, yet wrong, for the steel companies in The Innovator’s Dilemma to cede low-margin market share to the mini-mills. This is the decision we’d all make if we look at it through the lens of finance and default thinking. In my interview with Forbes last year, I elaborated on this concept as well with the example of a textile company. It’s only when you approach problems through different lenses that you can solve them. The Moment of Clarity: Using the Human Sciences to Solve Your Toughest Business Problems goes on to explain how humanities help solved some of our toughest business problems. ",
			"tokens": 860,
			"chunks": [
				{
					"article_title": "Sensemaking as a Complement to Default Thinking",
					"article_url": "https://fs.blog/the-moment-of-clarity/",
					"content": "Most of the time we devise strategies in the default mode of problem-solving, prioritizing maximum growth and profit through rational and logical analysis. But we already know that rational and logical analysis doesn’t always result in the best decisions. In The Moment of Clarity: Using the Human Sciences to Solve Your Toughest Business Problems Christian Madsbjerg and Mikkel Rasmussen write: The ideal is to turn strategy work into a rigorous discipline with the use of deductive logic, a well-structured hypothesis, and a thorough collection of evidence and data. Such problem solving has dominated most research and teaching in business schools over the last decades and has formed the guiding principles of many global management consultancies. Slowly but steadily, this mind-set has gained dominance in business culture over the last thirty years. Today it is the unspoken default tool for solving all problems. This mindset is almost scientific in the quest for precision. ",
					"content_token": 189,
					"embedding": []
				},
				{
					"article_title": "Sensemaking as a Complement to Default Thinking",
					"article_url": "https://fs.blog/the-moment-of-clarity/",
					"content": " learn from past examples to create a hypothesis you can test with numbers. As it uses inductive reasoning for its foundation, it is enormously successful at analyzing information extrapolated from a known set of data from the past. Default thinking helps us create efficiencies, optimize resources, balance product portfolios, increase productivity, invest in markets with the shortest and biggest payback , cut operational complexity, and generally get more bang for the buck. In short, it works extraordinarily well when the business challenge demands an increase in the productivity of a system. But this method often falls short. And one area where it falls short is people’s behavior. “When it comes to cultural shifts, the use of a hypothesis based on past examples will give us a false sense of confidence, sending us astray into unknown waters with the wrong map,” the authors write. ",
					"content_token": 173,
					"embedding": []
				},
				{
					"article_title": "Sensemaking as a Complement to Default Thinking",
					"article_url": "https://fs.blog/the-moment-of-clarity/",
					"content": "Certain problems benefit from a linear and rational approach, while other, less straightforward challengesnavigating in a fogbenefit from the problem solving utilized in the human sciences like philosophy, history, the arts, and anthropology. We call this problem-solving method sensemaking. Sensemaking is really about finding how things are experienced through culture. The hard sciences involving mathematics and universal laws tell us the way things are and tend to take the main spotlight when we discuss our understanding of the world. This tendency is so common, we often disregard the wide range of sciences that are used to shed light on other phenomena, or the way things are experienced in culture. If default thinking shows us what exists in the foreground e.g., “we are losing our market share in competitive athletic apparel”, the human sciences investigate the invisible background the layered nuance behind what we perceive e.g., “well -being, not competition , is the main motivating factor for many people participating in sports” ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "Sensemaking as a Complement to Default Thinking",
					"article_url": "https://fs.blog/the-moment-of-clarity/",
					"content": " How we experience the world may be as important as, or more important than the hard, objective facts about the world. This is especially true for the specific set of problems where past data or scenarios no longer seem relevant. Default thinking and sensemaking are complementary tools. How default thinking and sensemaking complement one another. Source: The Moment of Clarity But we tend to see leadership more in the default thinking way, which makes perfect sense. Who doesn’t want to be hypothesis-driven, quantitative, and linear in their approach to solving problems? Most of these things are visible, which has an added benefit too. But if this is the only tool in our toolbox we’re going to fall short. The difference between decision-makers and sensemakers. Source: The Moment of Clarity It was perfectly rational, yet wrong, for the steel companies in The Innovator’s Dilemma to cede low-margin market share to the mini-mills. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "Sensemaking as a Complement to Default Thinking",
					"article_url": "https://fs.blog/the-moment-of-clarity/",
					"content": "This is the decision we’d all make if we look at it through the lens of finance and default thinking. In my interview with Forbes last year, I elaborated on this concept as well with the example of a textile company. It’s only when you approach problems through different lenses that you can solve them. The Moment of Clarity: Using the Human Sciences to Solve Your Toughest Business Problems goes on to explain how humanities help solved some of our toughest business problems.",
					"content_token": 99,
					"embedding": []
				}
			]
		},
		{
			"title": "Nassim Taleb on the Notion of Alternative Histories",
			"url": "https://fs.blog/nassim-taleb-alternative-history/",
			"content": "We see what’s visible and available. Often this is nothing more than randomness and yet we wrap a narrative around it. The trader who is rich must know what he is doing. A good outcome means we made the right decisions, right? Not so quick. If we were wise we would not judge the quality of a decision on its outcome. There are alternative histories worth considering.  Writing in Fooled by Randomness: The Hidden Role of Chance in Life and in the Markets, Nassim Taleb hits on the notion of alternative histories. Taleb argues that we should judge people by the costs of the alternative, that is if history played out in another way. These “substitute courses of events are called alternative histories.” Taleb writes: Clearly, the quality of a decision cannot be solely judged based on its outcome, but such a point seems to be voiced only by people who fail those who succeed attribute their success to the quality of their decision.  One can illustrate the strange concept of alternative histories as follows. Imagine an eccentric and bored tycoon offering you  10 million to play Russian roulette, i.e., to put a revolver containing one bullet in the six available chambers to your head and pull the trigger. Each realization would count as one history, for a total of six possible histories of equal probabilities. Five out of these six histories would lead to enrichment; one would lead to a statistic, that is, an obituary with an embarrassing but certainly original cause of death. The problem is that only one of the histories is observed in reality; and the winner of  10 million would elicit the admiration and praise of some fatuous journalist the very same ones who unconditionally admire the Forbes 500 billionaires. Like almost every executive I have encountered during an eighteen-year career on Wall Street the role of such executives in my view being no more than a judge of results delivered in a random manner, the public observes the external signs of wealth without even having a glimpse at the source we call such source the generator. Consider the possibility that the Russian roulette winner would be used as a role model by his family, friends, and neighbors. While the remaining five histories are not observable, the wise and thoughtful person could easily make a guess as to their attributes. It requires some thoughtfulness and personal courage. In addition, in time, if the roulette-betting fool keeps playing the game, the bad histories will tend to catch up with him. Thus, if a twenty-five-year-old played Russian roulette, say, once a year, there would be a very slim possibility of his surviving until his fiftieth birthday but, if there are enough players, say thousands of twenty-five-year-old players, we can expect to see a handful of extremely rich survivors and a very large cemetery.  The reader can see my unusual notion of alternative accounting:  10 million earned through Russian roulette does not have the same value as  10 million earned through the diligent and artful practice of dentistry. They are the same, can buy the same goods, except that one’s dependence on randomness is greater than the other. Reality is different than roulette. Consider that in the example above, while the result is unknown you know the odds, most of life is dealing with uncertainty. Bullets are infrequent, “like a revolver that would have hundreds, even thousands, of chambers instead of six.” After a while you forget about the bullet. You can’t see the chamber and we generally think of risk in terms of what is visible. Interestingly this is the core of the black swan, which is really the induction problem. No amount of evidence can allow the inference that something is true whereas one counterexample can refute a conclusion. This idea is also related to the “denigration of history,” where we think things that happen to others would not happen to us. ",
			"tokens": 806,
			"chunks": [
				{
					"article_title": "Nassim Taleb on the Notion of Alternative Histories",
					"article_url": "https://fs.blog/nassim-taleb-alternative-history/",
					"content": "We see what’s visible and available. Often this is nothing more than randomness and yet we wrap a narrative around it. The trader who is rich must know what he is doing. A good outcome means we made the right decisions, right? Not so quick. If we were wise we would not judge the quality of a decision on its outcome. There are alternative histories worth considering.  Writing in Fooled by Randomness: The Hidden Role of Chance in Life and in the Markets, Nassim Taleb hits on the notion of alternative histories. Taleb argues that we should judge people by the costs of the alternative, that is if history played out in another way. These “substitute courses of events are called alternative histories.” Taleb writes: Clearly, the quality of a decision cannot be solely judged based on its outcome, but such a point seems to be voiced only by people who fail those who succeed attribute their success to the quality of their decision. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "Nassim Taleb on the Notion of Alternative Histories",
					"article_url": "https://fs.blog/nassim-taleb-alternative-history/",
					"content": " One can illustrate the strange concept of alternative histories as follows. Imagine an eccentric and bored tycoon offering you  10 million to play Russian roulette, i.e., to put a revolver containing one bullet in the six available chambers to your head and pull the trigger. Each realization would count as one history, for a total of six possible histories of equal probabilities. Five out of these six histories would lead to enrichment; one would lead to a statistic, that is, an obituary with an embarrassing but certainly original cause of death. The problem is that only one of the histories is observed in reality; and the winner of  10 million would elicit the admiration and praise of some fatuous journalist the very same ones who unconditionally admire the Forbes 500 billionaires. ",
					"content_token": 154,
					"embedding": []
				},
				{
					"article_title": "Nassim Taleb on the Notion of Alternative Histories",
					"article_url": "https://fs.blog/nassim-taleb-alternative-history/",
					"content": "Like almost every executive I have encountered during an eighteen-year career on Wall Street the role of such executives in my view being no more than a judge of results delivered in a random manner, the public observes the external signs of wealth without even having a glimpse at the source we call such source the generator. Consider the possibility that the Russian roulette winner would be used as a role model by his family, friends, and neighbors. While the remaining five histories are not observable, the wise and thoughtful person could easily make a guess as to their attributes. It requires some thoughtfulness and personal courage. In addition, in time, if the roulette-betting fool keeps playing the game, the bad histories will tend to catch up with him. ",
					"content_token": 150,
					"embedding": []
				},
				{
					"article_title": "Nassim Taleb on the Notion of Alternative Histories",
					"article_url": "https://fs.blog/nassim-taleb-alternative-history/",
					"content": "Thus, if a twenty-five-year-old played Russian roulette, say, once a year, there would be a very slim possibility of his surviving until his fiftieth birthday but, if there are enough players, say thousands of twenty-five-year-old players, we can expect to see a handful of extremely rich survivors and a very large cemetery.  The reader can see my unusual notion of alternative accounting:  10 million earned through Russian roulette does not have the same value as  10 million earned through the diligent and artful practice of dentistry. They are the same, can buy the same goods, except that one’s dependence on randomness is greater than the other. Reality is different than roulette. Consider that in the example above, while the result is unknown you know the odds, most of life is dealing with uncertainty. ",
					"content_token": 177,
					"embedding": []
				},
				{
					"article_title": "Nassim Taleb on the Notion of Alternative Histories",
					"article_url": "https://fs.blog/nassim-taleb-alternative-history/",
					"content": "Bullets are infrequent, “like a revolver that would have hundreds, even thousands, of chambers instead of six.” After a while you forget about the bullet. You can’t see the chamber and we generally think of risk in terms of what is visible. Interestingly this is the core of the black swan, which is really the induction problem. No amount of evidence can allow the inference that something is true whereas one counterexample can refute a conclusion. This idea is also related to the “denigration of history,” where we think things that happen to others would not happen to us.",
					"content_token": 128,
					"embedding": []
				}
			]
		},
		{
			"title": "Creating a Decision Journal: Template And Example Included",
			"url": "https://fs.blog/decision-journal/",
			"content": "We all make decisions. And yet few of us think about what we can learn from our past decisions to make smarter decisions in the future. A decision journal helps you learn from past decisions, think through current decisions, and avoid problems before they happen.  In this article we’ll cover: Your Product is Decisions What is a Decision Journal A Decision Journal Template An Example Decision Tips on Using a Decision Journal Ok, let’s dig in. Your Product is Decisions In most organizations your product is decisions. By and large, your success will be the sum of the decisions you make over your career. The problem is it’s not easy to get better at making decisions. Bosses would be the easy solution to helping you improve. After all, they have the best view of the problem and you. They should be able to point out strengths and weaknesses in your decision process as well as your judgment. All of this is known at the time you made the decision. This is hard and subjective and requires people doing a lot of thinking. So bosses tend to default to resulting, a process by which the outcome of the decision is attached to the process used to make that decision. Under resulting good outcomes are the product of good decisions and bad outcomes are the product of bad decisions. The problem isn’t that people don’t want to get better at decisions, it’s the system that’s preventing them from doing so. Even if we can’t get our boss to help us make better decisions we can take things into our own hands. The way to test the quality of your decisions is to test the process by which you make them. Daniel Kahneman, Nobel Prize winner and dean of biases, argues that using a decision journal is the best solution. Kahneman said: Go down to a local drugstore and buy a very cheap notebook and start keeping track of your decisions. And the specific idea is whenever you’re making a consequential decision, something going in or out of the portfolio, just take a moment to think, write down what you expect to happen, why you expect it to happen and then actually, and this is optional, but probably a great idea, is write down how you feel about the situation, both physically and even emotionally. Just, how do you feel? I feel tired. I feel good, or this stock is really draining me. Whatever you think. The key to doing this is that it prevents something called hindsight bias, which is no matter what happens in the world, we tend to look back on our decision-making process, and we tilt it in a way that looks more favorable to us, right? So we have a bias to explain what has happened. A decision journal helps you collect accurate and honest feedback on what you were thinking at the time you made the decision. This feedback helps you see when you were stupid and lucky as well as when you were smart and unlucky. Finally, you can get the feedback you need to make better decisions. The key to understanding the limits to our knowledge see circle of competence is to check the results of our decisions against what we thought was going to happen and why we thought it was going to happen. That feedback loop is incredibly powerful because our minds won’t provide it by themselves. I’ll give you the spoiler right now. We don’t know as much as we think we know. We’re fooled into thinking that we understand something when we don’t and we have no means to correct ourselves. Our minds revise history to preserve our view of ourselves. The story that we tell ourselves conflates the cause and effect of a decision we made and the actual outcome. The best cure for this revising is the decision journal. What is a Decision Journal? You can think of a decision journal as quality control for our thinking  something like what we’d find in a manufacturing plant or a restaurant. Using a decision journal is simple but not easy. Implementing one requires discipline and humility. Not all decisions need to be journaled. Decisions of consequence should be logged with the basics of the situation, what you expect to happen, and why. You should write in your decision journal before you make the decision official. Writing is the process where you realize that you don’t know what you think you know. Writing about your decision forces you to explain your thinking. If we write about the decision after we make it, it’s often too late to do anything about it. Write your decision down sleep on it and read it with fresh eyes in the morning. Often you’ll find that what you wrote doesn’t make sense. Catching mistakes before you make a decision saves you time and money. A Decision Journal Template The key question is what information to include in your decision journal. Here’s the template we use at FS. Click for PDF Whenever you’re making a consequential decision, either individually or as part of a group, you take a moment and write down: The situation or context The problem statement or frame The variables that govern the situation The complications or complexity as you see it Alternatives that were seriously considered and why they were not chosen think: the work required to have an opinion A paragraph explaining the range of outcomes A paragraph explaining what you expect to happen and the reasoning and actual probabilities you assign to each projected outcome The degree of confidence matters, a lot. The time of day you’re making the decision and how you feel physically and mentally If you’re tired, for example, write it down. You have to make this part your own. I’ve seen others include: What’s the primary thesis What is the expected outcomes What are the second and third-order consequences What is the worst-case scenario and why that’s ok What is the potential upside beyond the core thesis What emotions am I experiencing What is the opportunity cost by doing this what am I not doing What unique advantages or insights do I have in this situation Who is the best person to make this decision What does this look like in 5 weeks, 5 months, 5 years? An Example Decision Perhaps an example will help illustrate. Here’s a real decision that I made using the FS decision journal template. Tips on Using a Decision Journal Here are some tips to keep in mind as you implement your decision journal. Your decision journal can be tailored to the situation and context. Specific decisions might include trade-offs, second-order effects, weighting criteria, or other relevant factors. These examples are only to get you started. We can’t improve our thinking if we can’t see it. Don’t spend too much time on the brief and obvious insights. Often our first thoughts represent the thinking of someone else and not our own thinking. Any decision you’re journaling is inherently complex and may involve non-linear systems. In such a world, small effects can cause disproportionate responses whereas bigger ones might have no impact. Remember that causality is complex, especially in complex domains. Two common ways people wiggle out of their own decisions are hindsight bias and jargon. It’s hard to remember what we knew at the time and what were thinking. Hindsight makes things far more explainable and changes our story. A decision journal helps combat this by recording what you knew and what you thought at the time. When you look at your own handwriting you come face to face with the person you were when you made the decision. There is nowhere to hide. The words we use are also important. When we use vague terms, we give ourselves wiggle room. If we want to get better at making decisions we can’t give ourselves wiggle room. Be clear. Be direct. Be simple. An 8-year-old should understand what decision you’re making and why.  A decision journal that sits on the shelf is less useful than one that gets reviewed. Every six months or so pick it up and look at your past decisions, update entries with what actually happened, and spend time thinking about your process. Realizing where you make mistakes, how you make them, what types of decisions you’re bad at, etc., helps you make better decisions going forward. When you start to identify patterns, you can change your decision process to help account for the things you miss. Just because you had a bad outcome doesn’t mean you made a bad decision. You might have made the right decision which, in our sense, means that used a good process and still had a bad outcome. We call that a bad break. When you use a decision journal, you’ll discover two things right away. First, you’re right a lot of the time. Second, it’s often for the wrong reasons. Discovering how lucky you are can be somewhat humbling. This is where the learning begins.",
			"tokens": 1837,
			"chunks": [
				{
					"article_title": "Creating a Decision Journal: Template And Example Included",
					"article_url": "https://fs.blog/decision-journal/",
					"content": "We all make decisions. And yet few of us think about what we can learn from our past decisions to make smarter decisions in the future. A decision journal helps you learn from past decisions, think through current decisions, and avoid problems before they happen.  In this article we’ll cover: Your Product is Decisions What is a Decision Journal A Decision Journal Template An Example Decision Tips on Using a Decision Journal Ok, let’s dig in. Your Product is Decisions In most organizations your product is decisions. By and large, your success will be the sum of the decisions you make over your career. The problem is it’s not easy to get better at making decisions. Bosses would be the easy solution to helping you improve. After all, they have the best view of the problem and you. They should be able to point out strengths and weaknesses in your decision process as well as your judgment. All of this is known at the time you made the decision. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "Creating a Decision Journal: Template And Example Included",
					"article_url": "https://fs.blog/decision-journal/",
					"content": "This is hard and subjective and requires people doing a lot of thinking. So bosses tend to default to resulting, a process by which the outcome of the decision is attached to the process used to make that decision. Under resulting good outcomes are the product of good decisions and bad outcomes are the product of bad decisions. The problem isn’t that people don’t want to get better at decisions, it’s the system that’s preventing them from doing so. Even if we can’t get our boss to help us make better decisions we can take things into our own hands. The way to test the quality of your decisions is to test the process by which you make them. Daniel Kahneman, Nobel Prize winner and dean of biases, argues that using a decision journal is the best solution. Kahneman said: Go down to a local drugstore and buy a very cheap notebook and start keeping track of your decisions. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "Creating a Decision Journal: Template And Example Included",
					"article_url": "https://fs.blog/decision-journal/",
					"content": "And the specific idea is whenever you’re making a consequential decision, something going in or out of the portfolio, just take a moment to think, write down what you expect to happen, why you expect it to happen and then actually, and this is optional, but probably a great idea, is write down how you feel about the situation, both physically and even emotionally. Just, how do you feel? I feel tired. I feel good, or this stock is really draining me. Whatever you think. The key to doing this is that it prevents something called hindsight bias, which is no matter what happens in the world, we tend to look back on our decision-making process, and we tilt it in a way that looks more favorable to us, right? So we have a bias to explain what has happened. A decision journal helps you collect accurate and honest feedback on what you were thinking at the time you made the decision. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "Creating a Decision Journal: Template And Example Included",
					"article_url": "https://fs.blog/decision-journal/",
					"content": "This feedback helps you see when you were stupid and lucky as well as when you were smart and unlucky. Finally, you can get the feedback you need to make better decisions. The key to understanding the limits to our knowledge see circle of competence is to check the results of our decisions against what we thought was going to happen and why we thought it was going to happen. That feedback loop is incredibly powerful because our minds won’t provide it by themselves. I’ll give you the spoiler right now. We don’t know as much as we think we know. We’re fooled into thinking that we understand something when we don’t and we have no means to correct ourselves. Our minds revise history to preserve our view of ourselves. The story that we tell ourselves conflates the cause and effect of a decision we made and the actual outcome. The best cure for this revising is the decision journal. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "Creating a Decision Journal: Template And Example Included",
					"article_url": "https://fs.blog/decision-journal/",
					"content": "What is a Decision Journal? You can think of a decision journal as quality control for our thinking  something like what we’d find in a manufacturing plant or a restaurant. Using a decision journal is simple but not easy. Implementing one requires discipline and humility. Not all decisions need to be journaled. Decisions of consequence should be logged with the basics of the situation, what you expect to happen, and why. You should write in your decision journal before you make the decision official. Writing is the process where you realize that you don’t know what you think you know. Writing about your decision forces you to explain your thinking. If we write about the decision after we make it, it’s often too late to do anything about it. Write your decision down sleep on it and read it with fresh eyes in the morning. Often you’ll find that what you wrote doesn’t make sense. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "Creating a Decision Journal: Template And Example Included",
					"article_url": "https://fs.blog/decision-journal/",
					"content": "Catching mistakes before you make a decision saves you time and money. A Decision Journal Template The key question is what information to include in your decision journal. Here’s the template we use at FS. Click for PDF Whenever you’re making a consequential decision, either individually or as part of a group, you take a moment and write down: The situation or context The problem statement or frame The variables that govern the situation The complications or complexity as you see it Alternatives that were seriously considered and why they were not chosen think: the work required to have an opinion A paragraph explaining the range of outcomes A paragraph explaining what you expect to happen and the reasoning and actual probabilities you assign to each projected outcome The degree of confidence matters, a lot. The time of day you’re making the decision and how you feel physically and mentally If you’re tired, for example, write it down. You have to make this part your own. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "Creating a Decision Journal: Template And Example Included",
					"article_url": "https://fs.blog/decision-journal/",
					"content": "I’ve seen others include: What’s the primary thesis What is the expected outcomes What are the second and third-order consequences What is the worst-case scenario and why that’s ok What is the potential upside beyond the core thesis What emotions am I experiencing What is the opportunity cost by doing this what am I not doing What unique advantages or insights do I have in this situation Who is the best person to make this decision What does this look like in 5 weeks, 5 months, 5 years? An Example Decision Perhaps an example will help illustrate. Here’s a real decision that I made using the FS decision journal template. Tips on Using a Decision Journal Here are some tips to keep in mind as you implement your decision journal. Your decision journal can be tailored to the situation and context. Specific decisions might include trade-offs, second-order effects, weighting criteria, or other relevant factors. These examples are only to get you started. ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "Creating a Decision Journal: Template And Example Included",
					"article_url": "https://fs.blog/decision-journal/",
					"content": "We can’t improve our thinking if we can’t see it. Don’t spend too much time on the brief and obvious insights. Often our first thoughts represent the thinking of someone else and not our own thinking. Any decision you’re journaling is inherently complex and may involve non-linear systems. In such a world, small effects can cause disproportionate responses whereas bigger ones might have no impact. Remember that causality is complex, especially in complex domains. Two common ways people wiggle out of their own decisions are hindsight bias and jargon. It’s hard to remember what we knew at the time and what were thinking. Hindsight makes things far more explainable and changes our story. A decision journal helps combat this by recording what you knew and what you thought at the time. When you look at your own handwriting you come face to face with the person you were when you made the decision. There is nowhere to hide. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "Creating a Decision Journal: Template And Example Included",
					"article_url": "https://fs.blog/decision-journal/",
					"content": "The words we use are also important. When we use vague terms, we give ourselves wiggle room. If we want to get better at making decisions we can’t give ourselves wiggle room. Be clear. Be direct. Be simple. An 8-year-old should understand what decision you’re making and why.  A decision journal that sits on the shelf is less useful than one that gets reviewed. Every six months or so pick it up and look at your past decisions, update entries with what actually happened, and spend time thinking about your process. Realizing where you make mistakes, how you make them, what types of decisions you’re bad at, etc., helps you make better decisions going forward. When you start to identify patterns, you can change your decision process to help account for the things you miss. ",
					"content_token": 172,
					"embedding": []
				},
				{
					"article_title": "Creating a Decision Journal: Template And Example Included",
					"article_url": "https://fs.blog/decision-journal/",
					"content": "Just because you had a bad outcome doesn’t mean you made a bad decision. You might have made the right decision which, in our sense, means that used a good process and still had a bad outcome. We call that a bad break. When you use a decision journal, you’ll discover two things right away. First, you’re right a lot of the time. Second, it’s often for the wrong reasons. Discovering how lucky you are can be somewhat humbling. This is where the learning begins.",
					"content_token": 113,
					"embedding": []
				}
			]
		},
		{
			"title": "Daniel Kahneman’s Favorite Approach For Making Better Decisions",
			"url": "https://fs.blog/kahneman-better-decisions/",
			"content": "Bob Sutton’s book, Scaling Up Excellence: Getting to More Without Settling for Less, contains an interesting section towards the end on looking back from the future, which talks about “a mind trick that goads and guides people to act on what they know and, in turn, amplifies their odds of success.” We build on Nobel winner Daniel Kahneman’s favorite approach for making better decisions. This may sound weird, but it’s a form of imaginary time travel. It’s called the premortem. And, while it may be Kahneman’s favorite, he didn’t come up with it. A fellow by the name of Gary Klein invented the premortem technique. A premortem works something like this. When you’re on the verge of making a decision, not just any decision but a big decision, you call a meeting. At the meeting, you ask each member of your team to imagine that it’s a year later. Split them into two groups. Have one group imagine that the effort was an unmitigated disaster. Have the other pretend it was a roaring success. Ask each member to work independently and generate reasons, or better yet, write a story, about why the success or failure occurred. Instruct them to be as detailed as possible, and, as Klein emphasizes, to identify causes that they wouldn’t usually mention “for fear of being impolite.” Next, have each person in the “failure” group read their list or story aloud, and record and collate the reasons. Repeat this process with the “success” group. Finally use the reasons from both groups to strengthen your  plan. If you uncover overwhelming and impassible roadblocks, then go back to the drawing board. Premortems encourage people to use “prospective hindsight,” or, more accurately, to talk in “future perfect tense.” Instead of thinking, “we will devote the next six months to implementing a new HR software initiative,” for example, we travel to the future and think, “we have devoted six months to implementing a new HR software package.” You imagine that a concrete success or failure has occurred and look “back from the future” to tell a story about the causes.  Pretending that a success or failure has already occurredand looking back and inventing the details of why it happenedseems almost absurdly simple. Yet renowned scholars including Kahneman, Klein, and Karl Weick supply compelling logic and evidence that this approach generates better decisions, predictions, and plans. Their work suggests several reasons why.  1. This approach helps people overcome blind spots As  upcoming events become more distant, people develop more grandiose and vague plans and overlook the nitty-gritty daily details required to achieve their long-term goals. 2. This approach helps people bridge short-term and long-term thinking Weick argues that this shift is effective, in part, because it is far easier to imagine the detailed causes of a single outcome than to imagine multiple outcomes and try to explain why each may have occurred. Beyond that, analyzing a single event as if it has already occurred rather than pretending it might occur makes it seem more concrete and likely to actually happen, which motivates people to devote more attention to explaining it. 3. Looking back dampens excessive optimism As Kahneman and other researchers show, most people overestimate the chances that good things will happen to them and underestimate the odds that they will face failures, delays, and setbacks. Kahneman adds that “in general, organizations really don’t like pessimists” and that when naysayers raise risks and drawbacks, they are viewed as “almost disloyal.” Max Bazerman, a Harvard professor, believes that we’re less prone to irrational optimism when we predict the fate of projects that are not our own. For example, when it comes to friends’ home renovation projects, most people estimate the costs will run 25 to 50 percent over budget. When it comes to our projects; however, they will be “completed on time and near the project costs.” 4. A premortem challenges the illusion of consensus Most times, not everyone on a team agrees with the course of action. Even when you have enough cognitive diversity in the room, people still keep their mouths shut because people in power tend to reward people who agree with them while punishing those who dare to speak up with a dissenting view. The resulting corrosive conformity is evident when people don’t raise private doubts, known risks, and inconvenient facts. In contrast, as Klein explains, a premortem can create a competition where members feel accountable for raising obstacles that others haven’t. “The whole dynamic changes from trying to avoid anything that might disrupt harmony to trying to surface potential problems.” ",
			"tokens": 1017,
			"chunks": [
				{
					"article_title": "Daniel Kahneman’s Favorite Approach For Making Better Decisions",
					"article_url": "https://fs.blog/kahneman-better-decisions/",
					"content": "Bob Sutton’s book, Scaling Up Excellence: Getting to More Without Settling for Less, contains an interesting section towards the end on looking back from the future, which talks about “a mind trick that goads and guides people to act on what they know and, in turn, amplifies their odds of success.” We build on Nobel winner Daniel Kahneman’s favorite approach for making better decisions. This may sound weird, but it’s a form of imaginary time travel. It’s called the premortem. And, while it may be Kahneman’s favorite, he didn’t come up with it. A fellow by the name of Gary Klein invented the premortem technique. A premortem works something like this. When you’re on the verge of making a decision, not just any decision but a big decision, you call a meeting. ",
					"content_token": 189,
					"embedding": []
				},
				{
					"article_title": "Daniel Kahneman’s Favorite Approach For Making Better Decisions",
					"article_url": "https://fs.blog/kahneman-better-decisions/",
					"content": "At the meeting, you ask each member of your team to imagine that it’s a year later. Split them into two groups. Have one group imagine that the effort was an unmitigated disaster. Have the other pretend it was a roaring success. Ask each member to work independently and generate reasons, or better yet, write a story, about why the success or failure occurred. Instruct them to be as detailed as possible, and, as Klein emphasizes, to identify causes that they wouldn’t usually mention “for fear of being impolite.” Next, have each person in the “failure” group read their list or story aloud, and record and collate the reasons. Repeat this process with the “success” group. Finally use the reasons from both groups to strengthen your  plan. If you uncover overwhelming and impassible roadblocks, then go back to the drawing board. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "Daniel Kahneman’s Favorite Approach For Making Better Decisions",
					"article_url": "https://fs.blog/kahneman-better-decisions/",
					"content": "Premortems encourage people to use “prospective hindsight,” or, more accurately, to talk in “future perfect tense.” Instead of thinking, “we will devote the next six months to implementing a new HR software initiative,” for example, we travel to the future and think, “we have devoted six months to implementing a new HR software package.” You imagine that a concrete success or failure has occurred and look “back from the future” to tell a story about the causes.  Pretending that a success or failure has already occurredand looking back and inventing the details of why it happenedseems almost absurdly simple. Yet renowned scholars including Kahneman, Klein, and Karl Weick supply compelling logic and evidence that this approach generates better decisions, predictions, and plans. Their work suggests several reasons why.  1. ",
					"content_token": 181,
					"embedding": []
				},
				{
					"article_title": "Daniel Kahneman’s Favorite Approach For Making Better Decisions",
					"article_url": "https://fs.blog/kahneman-better-decisions/",
					"content": "This approach helps people overcome blind spots As  upcoming events become more distant, people develop more grandiose and vague plans and overlook the nitty-gritty daily details required to achieve their long-term goals. 2. This approach helps people bridge short-term and long-term thinking Weick argues that this shift is effective, in part, because it is far easier to imagine the detailed causes of a single outcome than to imagine multiple outcomes and try to explain why each may have occurred. Beyond that, analyzing a single event as if it has already occurred rather than pretending it might occur makes it seem more concrete and likely to actually happen, which motivates people to devote more attention to explaining it. 3. Looking back dampens excessive optimism As Kahneman and other researchers show, most people overestimate the chances that good things will happen to them and underestimate the odds that they will face failures, delays, and setbacks. ",
					"content_token": 186,
					"embedding": []
				},
				{
					"article_title": "Daniel Kahneman’s Favorite Approach For Making Better Decisions",
					"article_url": "https://fs.blog/kahneman-better-decisions/",
					"content": "Kahneman adds that “in general, organizations really don’t like pessimists” and that when naysayers raise risks and drawbacks, they are viewed as “almost disloyal.” Max Bazerman, a Harvard professor, believes that we’re less prone to irrational optimism when we predict the fate of projects that are not our own. For example, when it comes to friends’ home renovation projects, most people estimate the costs will run 25 to 50 percent over budget. When it comes to our projects; however, they will be “completed on time and near the project costs.” 4. A premortem challenges the illusion of consensus Most times, not everyone on a team agrees with the course of action. Even when you have enough cognitive diversity in the room, people still keep their mouths shut because people in power tend to reward people who agree with them while punishing those who dare to speak up with a dissenting view. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "Daniel Kahneman’s Favorite Approach For Making Better Decisions",
					"article_url": "https://fs.blog/kahneman-better-decisions/",
					"content": "The resulting corrosive conformity is evident when people don’t raise private doubts, known risks, and inconvenient facts. In contrast, as Klein explains, a premortem can create a competition where members feel accountable for raising obstacles that others haven’t. “The whole dynamic changes from trying to avoid anything that might disrupt harmony to trying to surface potential problems.”",
					"content_token": 77,
					"embedding": []
				}
			]
		},
		{
			"title": "Just In Time Information Gathering",
			"url": "https://fs.blog/just-in-time-information/",
			"content": "We’re becoming more like factories. Just-in-time is a production strategy aimed at, among other things, reducing the need for excess inventory. Parts are supplied only when needed in the amount needed. While it makes a business more capital efficient, it also makes it more fragile. We’ve adopted a similar strategy for information gathering. We’re so consumed by noise and busy work that the only time we really seek out signal is when we need it the most: right before we make a decision. This creates a host of problems. The worst time to look for information is when we need it to make a decision. When we do that we’re more likely to see what’s unique and miss the historical context. We’re also more likely to be biased by what is available. And searching for information at the time of need is an indication that you have no idea what you’re doing. “Pattern recognition,” says Alice Schroeder, “creates an impulse always to connect new knowledge to old and to primarily be interested in new knowledge that genuinely builds on the old.” It helps knowledge snowball. If we can’t connect the current situation to something we already understand, we might reason that it is not in our circle of competence and thus we shouldn’t be drawing conclusions. If we can, however, connect it to something we previously understood then we’re less likely to draw conclusions on the basis of “this time is different.” There is merit to thinking about information gathering as a logistics problem. ",
			"tokens": 328,
			"chunks": [
				{
					"article_title": "Just In Time Information Gathering",
					"article_url": "https://fs.blog/just-in-time-information/",
					"content": "We’re becoming more like factories. Just-in-time is a production strategy aimed at, among other things, reducing the need for excess inventory. Parts are supplied only when needed in the amount needed. While it makes a business more capital efficient, it also makes it more fragile. We’ve adopted a similar strategy for information gathering. We’re so consumed by noise and busy work that the only time we really seek out signal is when we need it the most: right before we make a decision. This creates a host of problems. The worst time to look for information is when we need it to make a decision. When we do that we’re more likely to see what’s unique and miss the historical context. We’re also more likely to be biased by what is available. And searching for information at the time of need is an indication that you have no idea what you’re doing. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "Just In Time Information Gathering",
					"article_url": "https://fs.blog/just-in-time-information/",
					"content": "“Pattern recognition,” says Alice Schroeder, “creates an impulse always to connect new knowledge to old and to primarily be interested in new knowledge that genuinely builds on the old.” It helps knowledge snowball. If we can’t connect the current situation to something we already understand, we might reason that it is not in our circle of competence and thus we shouldn’t be drawing conclusions. If we can, however, connect it to something we previously understood then we’re less likely to draw conclusions on the basis of “this time is different.” There is merit to thinking about information gathering as a logistics problem.",
					"content_token": 135,
					"embedding": []
				}
			]
		},
		{
			"title": "This Time is Different: The Four Most Costly Words Ever Spoken",
			"url": "https://fs.blog/this-time-is-different/",
			"content": "When we look at situations we’re always looking for what’s unique. We should, however, give more thought to similarities. “This time is different” could be the 4 most costly words ever spoken. It’s not the words that are costly so much as the conclusions they encourage us to draw. We incorrectly think that differences are more valuable than similarities. After all, anyone can see what’s the same but it takes true insight to see what’s different, right? We’re all so busy trying to find differences that we forget to pay attention to what is the same. Imagine sitting in a meeting where people are about to make the same mistake they made last year on the same decision. Let’s say, for example, Jack has a history of messing up the annual tax returns. He’s a good guy. He’s nice to everyone. In fact, he buys everyone awesome Christmas presents. But the last three yearsthe period he’s been in charge of tax returnshave been nothing short of a disaster causing more work for you and your department. The assignment for the tax return comes up and Jack is once again nominated. Before you have a chance to voice your concerns, one of your co-workers speaks up: “I know Jack has dropped the ball on this assignment in the past but I think this time is different. He’s been working hard to make sure he’s better organized.” That’s all it takes. Conversation over  everyone is focused on what’s unique about this time and it’s unlikely, despite ample evidence, that you’ll be able to convince them otherwise. In part, people want to believe in Jack because he’s a nice guy. In part, we’re all focused on why this time is different and we’ll ignore evidence to the contrary. Focusing on what’s different makes it easy to forget historical context. We lose touch with the base rate. We only see the evidence that supports our view confirmation bias. We become optimistic and overconfident. History provides context. And what history shows us is that no matter how unique things are today there are a lot of similarities with the past. Consider investors and the dotcom bubble. Collectively people saw this as unprecedented and unique, a massive transformation that was unparalleled. That reasoning, combined with a blindness to what was the same about this situation and previous ones, encouraged us to draw conclusions that proved costly. We reasoned that everything would change and everyone who owned internet companies would prosper and the old non-internet companies would quickly go into bankruptcy. All of a sudden profits didn’t matter. Nor did revenue. They would come in time, we hoped. Market share mattered no matter how costly it was to acquire. More than that, if you didn’t buy now you’d miss out. These companies would take over the world and you’d be left out. We got so caught up in what was different that we forgot to see what was the same. And there were historical parallels: Automobiles, Radio, Television, and Airplanes to name a few. At the time these innovations completely transformed the world as well. You can consider them the dotcoms of yesteryear. And how did these massively transformational industries end up for investors? At one time there were allegedly over 70 different auto manufacturing operations in the United States. Only 3 of them survived and a few of those even required government funds. If you catch yourself reasoning based on “this time is different” remember that you are probably speculating. While you may be right, odds are, this time is not different. You just haven’t looked for the similarities. ",
			"tokens": 783,
			"chunks": [
				{
					"article_title": "This Time is Different: The Four Most Costly Words Ever Spoken",
					"article_url": "https://fs.blog/this-time-is-different/",
					"content": "When we look at situations we’re always looking for what’s unique. We should, however, give more thought to similarities. “This time is different” could be the 4 most costly words ever spoken. It’s not the words that are costly so much as the conclusions they encourage us to draw. We incorrectly think that differences are more valuable than similarities. After all, anyone can see what’s the same but it takes true insight to see what’s different, right? We’re all so busy trying to find differences that we forget to pay attention to what is the same. Imagine sitting in a meeting where people are about to make the same mistake they made last year on the same decision. Let’s say, for example, Jack has a history of messing up the annual tax returns. He’s a good guy. He’s nice to everyone. In fact, he buys everyone awesome Christmas presents. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "This Time is Different: The Four Most Costly Words Ever Spoken",
					"article_url": "https://fs.blog/this-time-is-different/",
					"content": "But the last three yearsthe period he’s been in charge of tax returnshave been nothing short of a disaster causing more work for you and your department. The assignment for the tax return comes up and Jack is once again nominated. Before you have a chance to voice your concerns, one of your co-workers speaks up: “I know Jack has dropped the ball on this assignment in the past but I think this time is different. He’s been working hard to make sure he’s better organized.” That’s all it takes. Conversation over  everyone is focused on what’s unique about this time and it’s unlikely, despite ample evidence, that you’ll be able to convince them otherwise. In part, people want to believe in Jack because he’s a nice guy. ",
					"content_token": 176,
					"embedding": []
				},
				{
					"article_title": "This Time is Different: The Four Most Costly Words Ever Spoken",
					"article_url": "https://fs.blog/this-time-is-different/",
					"content": "In part, we’re all focused on why this time is different and we’ll ignore evidence to the contrary. Focusing on what’s different makes it easy to forget historical context. We lose touch with the base rate. We only see the evidence that supports our view confirmation bias. We become optimistic and overconfident. History provides context. And what history shows us is that no matter how unique things are today there are a lot of similarities with the past. Consider investors and the dotcom bubble. Collectively people saw this as unprecedented and unique, a massive transformation that was unparalleled. That reasoning, combined with a blindness to what was the same about this situation and previous ones, encouraged us to draw conclusions that proved costly. We reasoned that everything would change and everyone who owned internet companies would prosper and the old non-internet companies would quickly go into bankruptcy. All of a sudden profits didn’t matter. Nor did revenue. ",
					"content_token": 194,
					"embedding": []
				},
				{
					"article_title": "This Time is Different: The Four Most Costly Words Ever Spoken",
					"article_url": "https://fs.blog/this-time-is-different/",
					"content": "They would come in time, we hoped. Market share mattered no matter how costly it was to acquire. More than that, if you didn’t buy now you’d miss out. These companies would take over the world and you’d be left out. We got so caught up in what was different that we forgot to see what was the same. And there were historical parallels: Automobiles, Radio, Television, and Airplanes to name a few. At the time these innovations completely transformed the world as well. You can consider them the dotcoms of yesteryear. And how did these massively transformational industries end up for investors? At one time there were allegedly over 70 different auto manufacturing operations in the United States. Only 3 of them survived and a few of those even required government funds. If you catch yourself reasoning based on “this time is different” remember that you are probably speculating. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "This Time is Different: The Four Most Costly Words Ever Spoken",
					"article_url": "https://fs.blog/this-time-is-different/",
					"content": "While you may be right, odds are, this time is not different. You just haven’t looked for the similarities.",
					"content_token": 26,
					"embedding": []
				}
			]
		},
		{
			"title": "Antigone: Better Decisions Through Literature",
			"url": "https://fs.blog/antigone/",
			"content": "I recently picked up Sophocles’s Antigone. Sophocles wrote more than 100 plays in his lifetime, but only seven complete tragedies remain. In Antigone, Polynices, son of Oedipus, went to war with his brother, Eteocles, the ruler of Thebes, for control of the city. These two kill each other, and their uncle, Creon, assumes control of the city. Creon regards Polynices as a traitor. Accordingly, he denies his body a decent burial. He warns that anyone ignoring this edict shall be put to death. Creon’s position is understandable. He’s trying to establish order, punish a traitor, and gain political authority. Yet he proceeds in ignorance, in the sense that he does not see the possible outcomes that may arise from his edict. Antigone is the sister of Polynices and Eteocles. She’s clearly upset with this and defies Creon’s order to give her brother a proper burial. Antigone is convinced that Creon is wrong. To her, he’s defying the authority of the gods and overstepping. Antigone is arrested and confesses. Creon orders her death by sealing her in a cave, entombed alive. Tiresias, the blind prophet, warns Creon. “Think, thou dost walk on fortune’s razor-edge.” He predicts that if Creon doesn’t change his mind and permit the burial of Polynices, the gods will curse Thebes. Disaster, of course, will naturally follow. Creon recognizes the error of his ways and realizes he made a mistake. He orders Antigone to be freed and Polynices a proper burial. Alas, this wouldn’t quite be a tragedy if things worked out so neatly. Antigone has already hung herself. Her fianc, who also happens to be Creon’s son, blames his father for her death. He tries to kill his father but accidentally ends up killing himself. Creon’s wife, Eurydice, hears of her son’s death and commits suicide. So what exactly can we learn from all of this? Creon is reluctant to change the status quo. While he may not have foreseen Antigone’s reaction or its consequences as warned by the prophet, he refuses, until it is too late, to change his mind. He’s powerful. He’s the ruler. He needs to be seen as decisive, and he likely views changing his mind as a loss of status rather than a gain of compassion. Yet it is more complicated than this. “Should Creon change his stance and lose authority and influence,” he would have committed an error of commission, weighted more heavily, ceteris paribus, than doing nothing, and having bad things happen,” explain Devjani Roy and Richard Zeckhauser in their paper Ignorance: Lessons from the Laboratory of Literature. In the end, Sophocles advises us, “All men make mistakes, but a good man yields when he knows his course is wrong and repairs the evil. The only crime is pride.” Ego can help, and it can hurt. It helps you when it drives you and those around you to be better. However, when it causes you to ignore feedback or rest on your convictions in the face of evidence, it becomes a problem. If you’re curious, I’d recommend you give Antigone a read. It’s short, only 50 pages or so, and will give you an unconventional lens on decision making. ",
			"tokens": 776,
			"chunks": [
				{
					"article_title": "Antigone: Better Decisions Through Literature",
					"article_url": "https://fs.blog/antigone/",
					"content": "I recently picked up Sophocles’s Antigone. Sophocles wrote more than 100 plays in his lifetime, but only seven complete tragedies remain. In Antigone, Polynices, son of Oedipus, went to war with his brother, Eteocles, the ruler of Thebes, for control of the city. These two kill each other, and their uncle, Creon, assumes control of the city. Creon regards Polynices as a traitor. Accordingly, he denies his body a decent burial. He warns that anyone ignoring this edict shall be put to death. Creon’s position is understandable. He’s trying to establish order, punish a traitor, and gain political authority. Yet he proceeds in ignorance, in the sense that he does not see the possible outcomes that may arise from his edict. Antigone is the sister of Polynices and Eteocles. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "Antigone: Better Decisions Through Literature",
					"article_url": "https://fs.blog/antigone/",
					"content": "She’s clearly upset with this and defies Creon’s order to give her brother a proper burial. Antigone is convinced that Creon is wrong. To her, he’s defying the authority of the gods and overstepping. Antigone is arrested and confesses. Creon orders her death by sealing her in a cave, entombed alive. Tiresias, the blind prophet, warns Creon. “Think, thou dost walk on fortune’s razor-edge.” He predicts that if Creon doesn’t change his mind and permit the burial of Polynices, the gods will curse Thebes. Disaster, of course, will naturally follow. Creon recognizes the error of his ways and realizes he made a mistake. He orders Antigone to be freed and Polynices a proper burial. Alas, this wouldn’t quite be a tragedy if things worked out so neatly. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "Antigone: Better Decisions Through Literature",
					"article_url": "https://fs.blog/antigone/",
					"content": "Antigone has already hung herself. Her fianc, who also happens to be Creon’s son, blames his father for her death. He tries to kill his father but accidentally ends up killing himself. Creon’s wife, Eurydice, hears of her son’s death and commits suicide. So what exactly can we learn from all of this? Creon is reluctant to change the status quo. While he may not have foreseen Antigone’s reaction or its consequences as warned by the prophet, he refuses, until it is too late, to change his mind. He’s powerful. He’s the ruler. He needs to be seen as decisive, and he likely views changing his mind as a loss of status rather than a gain of compassion. Yet it is more complicated than this. ",
					"content_token": 176,
					"embedding": []
				},
				{
					"article_title": "Antigone: Better Decisions Through Literature",
					"article_url": "https://fs.blog/antigone/",
					"content": "“Should Creon change his stance and lose authority and influence,” he would have committed an error of commission, weighted more heavily, ceteris paribus, than doing nothing, and having bad things happen,” explain Devjani Roy and Richard Zeckhauser in their paper Ignorance: Lessons from the Laboratory of Literature. In the end, Sophocles advises us, “All men make mistakes, but a good man yields when he knows his course is wrong and repairs the evil. The only crime is pride.” Ego can help, and it can hurt. It helps you when it drives you and those around you to be better. However, when it causes you to ignore feedback or rest on your convictions in the face of evidence, it becomes a problem. If you’re curious, I’d recommend you give Antigone a read. ",
					"content_token": 185,
					"embedding": []
				},
				{
					"article_title": "Antigone: Better Decisions Through Literature",
					"article_url": "https://fs.blog/antigone/",
					"content": "It’s short, only 50 pages or so, and will give you an unconventional lens on decision making.",
					"content_token": 23,
					"embedding": []
				}
			]
		},
		{
			"title": "The Two Types of Ignorance",
			"url": "https://fs.blog/two-types-of-ignorance/",
			"content": "The first category of ignorance is when we do not know we are ignorant. This is primary ignorance. The second category of ignorance is when we recognize our ignorance.  This article builds on Decisions Under Uncertainty. In fact, consider this a continuation. Think of how we make decisions in organizations  we often do what standard decision theory would ask of us. We create a powerpoint that identifies the future desired state, identify what might happen, attach weighted probabilities to outcomes, and make a choice. Perfectly rational. Right? One of the problems with this approach is the risk charts and matrices that accompany this analysis. In my experience, these charts are rarely discussed in detail and become more about checking the I thought about risk’ box than anything else. We conveniently pin things into categories of low, medium, or high risk with a corresponding “impact” scale. What gets most of the attention is high-risk, high-impact. Perhaps deservedly so. But you have to ask yourself, how did we arrive at these arbitrary scales? Is one person’s look at risk the same as someone else’s? Are there hidden incentives to nudge risk one way or another? What biases come into play? Often we can’t even identify everything. Rarely do people ever go back and look at what happened and how accurate those “risk” tables were. From the ones I’ve seen, the “low risk” stuff happens a lot more often than people imagined. And a lot of things happen that never even made the chart in the first place. On the occasion when people do go back, and I’ve seen this firsthand, hindsight bias creeps in. “Oh, we discussed that, but it didn’t make it in the document. But we knew about it.” Yes, of course, you did. Ignorant and Unknowing We’re largely ignorant, that is, we operate in a state of the world where some possible outcomes are unknown. However, we’ve prepared for a world where outcomes and probabilities can be estimated. There is a mismatch between our training and reality. You can’t even hope to accurately estimate probabilities if the range of outcomes is unknown. The Two Types of Ignorance The first category is when we do not know we are ignorant. This is primary ignorance. The second category is when we recognize our ignorance. This is called recognized ignorance. Empty Suits and Fragilistas are almost always ignorant and unknowing. In Antifragile, Nassim Taleb writes: The Empty SuitFragilista defaults to thinking that what he doesn’t see is not there, or what he does not understand does not exist. At the core, he tends to mistake the unknown for the nonexistent. That my friends is primary ignorance. And it’s not limited to empty suits and fragilistas. Consider Anna Karenina: Primary ignorance ruins the life of one of fiction’s most famous characters, Anna Karenina. Readers of Anna Karenina 18772004 know that, in this novel, a train bookends bad news. Anna alights from one train as the novel begins and throws herself under another one as it ends. As she enters the glittering world of pre-Revolutionary Saint Petersburg, Anna catches the eye of the aristocratic bachelor Count Vronsky and quickly falls under his spell. But there is a problem: she is married to the rising politician Karenin, the two have a son Seryozha, and society will not take kindly to the conspicuous adultery of a prominent citizen. Indulging in an extra-marital affair, especially when one’s husband is a respected member of society, promotes the likelihood of unpleasant events. But her passion for Vronsky dulls Anna’s capacities for self-awareness. She becomes pregnant out of wedlock, a disastrous condition for a woman in nineteenth-century Russia. Anna consistently displays an unfortunate propensity to take action without recognizing that a terrible consequential outcome is possible. That is, she operates in primary ignorance. Anna demonstrates all the characteristics of primary ignorance. She fails to consider all the possible scenarios that will occur from her impulsive decision making. She risks her marriage with Karenin, a kind if undemonstrative husband, who is willing to forgive and even offers to raise her illegitimate child as his own. Leaving Seryozha with Karenin, she and Vronsky escape to Italy and then to his Russian country estate. Ultimately, she finds that while Vronsky continues to be accepted socially, living his life exactly as he pleases, the door of society slams shut in her face. No one will associate with her and she is insulted as an adulterer wherever she goes. It is only when she is completely isolated socially and cut off from her beloved son that Anna recognizes the dangers of primary ignorance: she risked her family and her reputation for too little.  She realizes she was ignorant of the possible outcomes that jumping headlong into an illicit relationship would bring. Ignorance, primary or recognized, is only important if the expected consequences are significant. Otherwise, we can be ignorant without consequence. While human irrationality factors into all decisions, it hits us most when we are unknowingly ignorant. Rational decision making becomes harder as we move along the continuum: outcomes are known  risk  uncertaintyignorance. If we can not consider all possible outcomes, preventing failure becomes nearly impossible. Further complicating matters, situations of ignorance often take years to play out. Joy and Zeckhauser write: One could argue  that a rational decision maker should always consider the possibility of ignorance, thus ruling out primary ignorance. But that is a level of rationality that very few achieve. If we could do this we’d always be in the space of recognized ignorance, better, at least, than primary ignorance. “Fortunately,” write Joy and Zeckhauser, “there is a group of highly perceptive chroniclers of human decision-making who observe individuals and follow their paths, often over years or decades. They are the individuals who write fiction: plays, novels, and short stories describing imagined events and people or fictional characters.” Joy and Zeckhauser argue these works have “deep insights” into the way we approach decisions, “both great and small.” In the Poetics, a classical treatise on the principles of literary theory, Aristotle argues that art imitates life. We refer here to Aristotle’s ideas of mimesis, or imitation. Aristotle claims one of art’s functions is the representation of reality. “Art” here includes creative products of the human imagination and, therefore, any work of fiction. Indeed, a crevice, not a canyon, separates faction and fiction. For centuries, authors have attempted to depict situations of ignorance. In Greek literature, Sophocle’s King Oedipus and Creon, and Homer’s Odysseus all seek forecasting skills of the blind prophet Tiresias who is doomed by Zeus to “speak the truth no man may believe.” For its status as one of literature’s most enduring love stories, Jane Austen’s Pride and Prejudice begins rather unpromisingly: the hero and the heroine cannot stand each another. The arrogant Mr. Darcy claims Elizabeth Bennet is “not handsome enough to tempt me”; Elizabeth offers the equally withering riposte that she “may safely promise  never to dance with him.” Were we to encounter them after these early skirmishes, we like Elizabeth and Darcy themselves would be ignorant of the possibility of an ultimate romance. In Gustave Flaubert’s Madame Bovary 18562004, Charles Bovary is a stolid rural doctor who is ignorant of the true character of the woman he is marrying. Dazzled by her youth and beauty, he ends up with an adulterous wife who plunges him into debt. His wife Emma, the titular “Madame Bovary,” is equally ignorant of the true character of her husband. Her head filled with romantic fantasies, she yearns for a sophisticated partner and the glamor of city life, but finds herself trapped in a somnolent marriage with a rustic man. K., the land surveyor and protagonist of Franz Kafka’s The Castle, attempts, repeatedly and unsuccessfully, to gain access to the mysterious authorities of a castle but is frustrated by an authoritarian bureaucracy and by ambiguous responses that defy rational interpretation. He begins and ends the novel as does the reader in ignorance. Joy and Zeckhauser use stories to study ignorance, which makes sense. Stories offer “simulations of the social world,” according to Psychologists Raymond Mar and Keith Oatley, through abstraction, simplification, and compression. Stories afford us a kind of flight simulator. We can test run new things and observe and learn, with little economic or social cost. Joy and Zeckhauser believe “that characters in great works of literature reproduce the behavioral propensities of real-life individuals.” While we’ll likely never uncover situations as fascinating as we find in stories, this doesn’t mean they are not a useful tool for learning about choice and consequence. “In a sense,” Joy and Zeckhauser write, “this is why great literature will never get dated: these stories observe the details of human behavior, and present such behavior awash with all the anguish and the splendor that is the lot of the human predicament. As Steven Pinker notes in How The Mind Works: Characters in a fictitious world do exactly what our intelligence allows us to do in the real world. We watch what happens to them and mentally take notes on the outcomes of the strategies and tactics they use in pursuing their goals. If we assume, we live in a world where we are, to some extent, ignorant then the best course is “thoughtful action or prudent information gathering.” Yet, when you look at the stories, “we frequently act in ways that violate such advice.” So reading fiction can help us adapt and deal with the world of uncertainty. Read part three of this series: Avoiding Ignorance. ",
			"tokens": 2133,
			"chunks": [
				{
					"article_title": "The Two Types of Ignorance",
					"article_url": "https://fs.blog/two-types-of-ignorance/",
					"content": "The first category of ignorance is when we do not know we are ignorant. This is primary ignorance. The second category of ignorance is when we recognize our ignorance.  This article builds on Decisions Under Uncertainty. In fact, consider this a continuation. Think of how we make decisions in organizations  we often do what standard decision theory would ask of us. We create a powerpoint that identifies the future desired state, identify what might happen, attach weighted probabilities to outcomes, and make a choice. Perfectly rational. Right? One of the problems with this approach is the risk charts and matrices that accompany this analysis. In my experience, these charts are rarely discussed in detail and become more about checking the I thought about risk’ box than anything else. We conveniently pin things into categories of low, medium, or high risk with a corresponding “impact” scale. What gets most of the attention is high-risk, high-impact. Perhaps deservedly so. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "The Two Types of Ignorance",
					"article_url": "https://fs.blog/two-types-of-ignorance/",
					"content": "But you have to ask yourself, how did we arrive at these arbitrary scales? Is one person’s look at risk the same as someone else’s? Are there hidden incentives to nudge risk one way or another? What biases come into play? Often we can’t even identify everything. Rarely do people ever go back and look at what happened and how accurate those “risk” tables were. From the ones I’ve seen, the “low risk” stuff happens a lot more often than people imagined. And a lot of things happen that never even made the chart in the first place. On the occasion when people do go back, and I’ve seen this firsthand, hindsight bias creeps in. “Oh, we discussed that, but it didn’t make it in the document. But we knew about it.” Yes, of course, you did. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "The Two Types of Ignorance",
					"article_url": "https://fs.blog/two-types-of-ignorance/",
					"content": "Ignorant and Unknowing We’re largely ignorant, that is, we operate in a state of the world where some possible outcomes are unknown. However, we’ve prepared for a world where outcomes and probabilities can be estimated. There is a mismatch between our training and reality. You can’t even hope to accurately estimate probabilities if the range of outcomes is unknown. The Two Types of Ignorance The first category is when we do not know we are ignorant. This is primary ignorance. The second category is when we recognize our ignorance. This is called recognized ignorance. Empty Suits and Fragilistas are almost always ignorant and unknowing. In Antifragile, Nassim Taleb writes: The Empty SuitFragilista defaults to thinking that what he doesn’t see is not there, or what he does not understand does not exist. At the core, he tends to mistake the unknown for the nonexistent. That my friends is primary ignorance. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "The Two Types of Ignorance",
					"article_url": "https://fs.blog/two-types-of-ignorance/",
					"content": "And it’s not limited to empty suits and fragilistas. Consider Anna Karenina: Primary ignorance ruins the life of one of fiction’s most famous characters, Anna Karenina. Readers of Anna Karenina 18772004 know that, in this novel, a train bookends bad news. Anna alights from one train as the novel begins and throws herself under another one as it ends. As she enters the glittering world of pre-Revolutionary Saint Petersburg, Anna catches the eye of the aristocratic bachelor Count Vronsky and quickly falls under his spell. But there is a problem: she is married to the rising politician Karenin, the two have a son Seryozha, and society will not take kindly to the conspicuous adultery of a prominent citizen. Indulging in an extra-marital affair, especially when one’s husband is a respected member of society, promotes the likelihood of unpleasant events. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "The Two Types of Ignorance",
					"article_url": "https://fs.blog/two-types-of-ignorance/",
					"content": "But her passion for Vronsky dulls Anna’s capacities for self-awareness. She becomes pregnant out of wedlock, a disastrous condition for a woman in nineteenth-century Russia. Anna consistently displays an unfortunate propensity to take action without recognizing that a terrible consequential outcome is possible. That is, she operates in primary ignorance. Anna demonstrates all the characteristics of primary ignorance. She fails to consider all the possible scenarios that will occur from her impulsive decision making. She risks her marriage with Karenin, a kind if undemonstrative husband, who is willing to forgive and even offers to raise her illegitimate child as his own. Leaving Seryozha with Karenin, she and Vronsky escape to Italy and then to his Russian country estate. Ultimately, she finds that while Vronsky continues to be accepted socially, living his life exactly as he pleases, the door of society slams shut in her face. ",
					"content_token": 188,
					"embedding": []
				},
				{
					"article_title": "The Two Types of Ignorance",
					"article_url": "https://fs.blog/two-types-of-ignorance/",
					"content": "No one will associate with her and she is insulted as an adulterer wherever she goes. It is only when she is completely isolated socially and cut off from her beloved son that Anna recognizes the dangers of primary ignorance: she risked her family and her reputation for too little.  She realizes she was ignorant of the possible outcomes that jumping headlong into an illicit relationship would bring. Ignorance, primary or recognized, is only important if the expected consequences are significant. Otherwise, we can be ignorant without consequence. While human irrationality factors into all decisions, it hits us most when we are unknowingly ignorant. Rational decision making becomes harder as we move along the continuum: outcomes are known  risk  uncertaintyignorance. If we can not consider all possible outcomes, preventing failure becomes nearly impossible. Further complicating matters, situations of ignorance often take years to play out. ",
					"content_token": 176,
					"embedding": []
				},
				{
					"article_title": "The Two Types of Ignorance",
					"article_url": "https://fs.blog/two-types-of-ignorance/",
					"content": "Joy and Zeckhauser write: One could argue  that a rational decision maker should always consider the possibility of ignorance, thus ruling out primary ignorance. But that is a level of rationality that very few achieve. If we could do this we’d always be in the space of recognized ignorance, better, at least, than primary ignorance. “Fortunately,” write Joy and Zeckhauser, “there is a group of highly perceptive chroniclers of human decision-making who observe individuals and follow their paths, often over years or decades. They are the individuals who write fiction: plays, novels, and short stories describing imagined events and people or fictional characters.” Joy and Zeckhauser argue these works have “deep insights” into the way we approach decisions, “both great and small.” In the Poetics, a classical treatise on the principles of literary theory, Aristotle argues that art imitates life. ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "The Two Types of Ignorance",
					"article_url": "https://fs.blog/two-types-of-ignorance/",
					"content": "We refer here to Aristotle’s ideas of mimesis, or imitation. Aristotle claims one of art’s functions is the representation of reality. “Art” here includes creative products of the human imagination and, therefore, any work of fiction. Indeed, a crevice, not a canyon, separates faction and fiction. For centuries, authors have attempted to depict situations of ignorance. In Greek literature, Sophocle’s King Oedipus and Creon, and Homer’s Odysseus all seek forecasting skills of the blind prophet Tiresias who is doomed by Zeus to “speak the truth no man may believe.” For its status as one of literature’s most enduring love stories, Jane Austen’s Pride and Prejudice begins rather unpromisingly: the hero and the heroine cannot stand each another. The arrogant Mr. ",
					"content_token": 185,
					"embedding": []
				},
				{
					"article_title": "The Two Types of Ignorance",
					"article_url": "https://fs.blog/two-types-of-ignorance/",
					"content": "Darcy claims Elizabeth Bennet is “not handsome enough to tempt me”; Elizabeth offers the equally withering riposte that she “may safely promise  never to dance with him.” Were we to encounter them after these early skirmishes, we like Elizabeth and Darcy themselves would be ignorant of the possibility of an ultimate romance. In Gustave Flaubert’s Madame Bovary 18562004, Charles Bovary is a stolid rural doctor who is ignorant of the true character of the woman he is marrying. Dazzled by her youth and beauty, he ends up with an adulterous wife who plunges him into debt. His wife Emma, the titular “Madame Bovary,” is equally ignorant of the true character of her husband. ",
					"content_token": 167,
					"embedding": []
				},
				{
					"article_title": "The Two Types of Ignorance",
					"article_url": "https://fs.blog/two-types-of-ignorance/",
					"content": "Her head filled with romantic fantasies, she yearns for a sophisticated partner and the glamor of city life, but finds herself trapped in a somnolent marriage with a rustic man. K., the land surveyor and protagonist of Franz Kafka’s The Castle, attempts, repeatedly and unsuccessfully, to gain access to the mysterious authorities of a castle but is frustrated by an authoritarian bureaucracy and by ambiguous responses that defy rational interpretation. He begins and ends the novel as does the reader in ignorance. Joy and Zeckhauser use stories to study ignorance, which makes sense. Stories offer “simulations of the social world,” according to Psychologists Raymond Mar and Keith Oatley, through abstraction, simplification, and compression. Stories afford us a kind of flight simulator. We can test run new things and observe and learn, with little economic or social cost. ",
					"content_token": 179,
					"embedding": []
				},
				{
					"article_title": "The Two Types of Ignorance",
					"article_url": "https://fs.blog/two-types-of-ignorance/",
					"content": "Joy and Zeckhauser believe “that characters in great works of literature reproduce the behavioral propensities of real-life individuals.” While we’ll likely never uncover situations as fascinating as we find in stories, this doesn’t mean they are not a useful tool for learning about choice and consequence. “In a sense,” Joy and Zeckhauser write, “this is why great literature will never get dated: these stories observe the details of human behavior, and present such behavior awash with all the anguish and the splendor that is the lot of the human predicament. As Steven Pinker notes in How The Mind Works: Characters in a fictitious world do exactly what our intelligence allows us to do in the real world. We watch what happens to them and mentally take notes on the outcomes of the strategies and tactics they use in pursuing their goals. ",
					"content_token": 182,
					"embedding": []
				},
				{
					"article_title": "The Two Types of Ignorance",
					"article_url": "https://fs.blog/two-types-of-ignorance/",
					"content": "If we assume, we live in a world where we are, to some extent, ignorant then the best course is “thoughtful action or prudent information gathering.” Yet, when you look at the stories, “we frequently act in ways that violate such advice.” So reading fiction can help us adapt and deal with the world of uncertainty. Read part three of this series: Avoiding Ignorance.",
					"content_token": 86,
					"embedding": []
				}
			]
		},
		{
			"title": "Your Product is Decisions",
			"url": "https://fs.blog/your-product-is-decisions/",
			"content": " If you asked people what they produce on a daily basis, most would say email or meetings. Even the ones who offered a deeper answer would probably think of these first. It is natural to think this way if you’re a knowledge worker. Natural and incorrect.     In a conversation with journalist Jason Zweig, Nobel Laureate Daniel Kahneman argues that knowledge workers produce decisions. And the quality of those decisions varies widely.     At many financial institutions the product is decisions. They produce decisions. And there ought to be something that is equivalent to the quality control you find in manufacturing. Now you can’t control the product itself; test the product. But you can test the process by which the product was created. So there are questions you can ask about the process by which a judgment was made or a decision was made. And one of these aspects is going to be the quality and quantity of the information on which the judgment was based. And if you isolate that as one of the issues you are going to focus on, it’s not the quality of the story you can make, it’s actually Where does the evidence come from?’, What do we really know?’ It’s when you ask those questions that you work out that, actually, you know very little and that you told yourself a coherent story on the basis of inadequate information.    Kahneman doesn’t feel individuals can go back and objectively assess their own decisions. This is, however, something organizations can do. Most, however, will choose not to because it is too painful.    Most organizations don’t use a consistent process or framework to make important decisions. Yet we know that the process by which you come to a decision is the most important thing. It’s not about more information. Process matters more than the analysis. We also know that when you don’t use a consistent process you make it hard to improve.    If your product is decisions, you might be curious as to how we can improve our ability to make them::    Know your circle of competence. This is how Ted Williams excelled.When operating within your circle of competence, use a double filter for making decisions.Avoid using vague and ambiguous terms.Keep a decision journal.Ignore outcome when evaluating decisions.    Kahneman’s book, Thinking, Fast and Slow, is a must-read.    Still curious? Check out the ultimate guide to making smart decisions.  ",
			"tokens": 526,
			"chunks": [
				{
					"article_title": "Your Product is Decisions",
					"article_url": "https://fs.blog/your-product-is-decisions/",
					"content": " If you asked people what they produce on a daily basis, most would say email or meetings. Even the ones who offered a deeper answer would probably think of these first. It is natural to think this way if you’re a knowledge worker. Natural and incorrect.     In a conversation with journalist Jason Zweig, Nobel Laureate Daniel Kahneman argues that knowledge workers produce decisions. And the quality of those decisions varies widely.     At many financial institutions the product is decisions. They produce decisions. And there ought to be something that is equivalent to the quality control you find in manufacturing. Now you can’t control the product itself; test the product. But you can test the process by which the product was created. So there are questions you can ask about the process by which a judgment was made or a decision was made. And one of these aspects is going to be the quality and quantity of the information on which the judgment was based. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "Your Product is Decisions",
					"article_url": "https://fs.blog/your-product-is-decisions/",
					"content": "And if you isolate that as one of the issues you are going to focus on, it’s not the quality of the story you can make, it’s actually Where does the evidence come from?’, What do we really know?’ It’s when you ask those questions that you work out that, actually, you know very little and that you told yourself a coherent story on the basis of inadequate information.    Kahneman doesn’t feel individuals can go back and objectively assess their own decisions. This is, however, something organizations can do. Most, however, will choose not to because it is too painful.    Most organizations don’t use a consistent process or framework to make important decisions. Yet we know that the process by which you come to a decision is the most important thing. It’s not about more information. Process matters more than the analysis. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "Your Product is Decisions",
					"article_url": "https://fs.blog/your-product-is-decisions/",
					"content": "We also know that when you don’t use a consistent process you make it hard to improve.    If your product is decisions, you might be curious as to how we can improve our ability to make them::    Know your circle of competence. This is how Ted Williams excelled.When operating within your circle of competence, use a double filter for making decisions.Avoid using vague and ambiguous terms.Keep a decision journal.Ignore outcome when evaluating decisions.    Kahneman’s book, Thinking, Fast and Slow, is a must-read.    Still curious? Check out the ultimate guide to making smart decisions.",
					"content_token": 136,
					"embedding": []
				}
			]
		},
		{
			"title": "Decisions Under Uncertainty",
			"url": "https://fs.blog/decisions-under-uncertainty/",
			"content": "If you’re a knowledge worker you make decisions every day. In fact, whether you realize it or not, decisions are your job. Decisions are how you make a living. Of course, not every decision is easy. Decisions tend to fall into different categories.  The way we approach the actual decision should vary based on category. Here are a few basic categories that decisions fall into. There are decisions where:  Outcomes are known. In this case, the range of outcomes is known and the individual outcome is also known. This is the easiest way to make decisions. If I hold out my hand and drop a ball, it will fall to the ground. I know this with near certainty. Outcomes are unknown, but probabilities are known. In this case, the range of outcomes are known but the individual outcome is unknown. This is risk. Think of this as going to Vegas and gambling. Before you set foot at the table, all of the outcomes are known as are the probabilities of each. No outcome surprises an objective third party. Outcomes are unknown and probabilities are unknown. In this case, the distribution of outcomes are unknown and the individual outcomes are necessarily unknown. This is uncertainty.  We often think we’re making decisions in 2 but we’re really operating in 3. The difference may seem trivial but it makes a world of difference. Decisions Under Uncertainty Ignorance is a state of the world where some possible outcomes are unknown: when we’ve moved from 2 to 3. One way to realize how ignorant we are is to look back, read some old newspapers, and see how often the world did something that wasn’t even imagined. Some examples include the Arab Spring, the collapse of the Soviet Union, the financial meltdown. We’re prepared for a world much like 2  the world of risk, with known outcomes and probability that can be estimated, yet we live in a world with a closer resemblance to 3. Read part two of this series: Two types of ignorance. References: Ignorance: Lessons from the Laboratory of Literature Joy and Zeckhauser. ",
			"tokens": 447,
			"chunks": [
				{
					"article_title": "Decisions Under Uncertainty",
					"article_url": "https://fs.blog/decisions-under-uncertainty/",
					"content": "If you’re a knowledge worker you make decisions every day. In fact, whether you realize it or not, decisions are your job. Decisions are how you make a living. Of course, not every decision is easy. Decisions tend to fall into different categories.  The way we approach the actual decision should vary based on category. Here are a few basic categories that decisions fall into. There are decisions where:  Outcomes are known. In this case, the range of outcomes is known and the individual outcome is also known. This is the easiest way to make decisions. If I hold out my hand and drop a ball, it will fall to the ground. I know this with near certainty. Outcomes are unknown, but probabilities are known. In this case, the range of outcomes are known but the individual outcome is unknown. This is risk. Think of this as going to Vegas and gambling. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "Decisions Under Uncertainty",
					"article_url": "https://fs.blog/decisions-under-uncertainty/",
					"content": "Before you set foot at the table, all of the outcomes are known as are the probabilities of each. No outcome surprises an objective third party. Outcomes are unknown and probabilities are unknown. In this case, the distribution of outcomes are unknown and the individual outcomes are necessarily unknown. This is uncertainty.  We often think we’re making decisions in 2 but we’re really operating in 3. The difference may seem trivial but it makes a world of difference. Decisions Under Uncertainty Ignorance is a state of the world where some possible outcomes are unknown: when we’ve moved from 2 to 3. One way to realize how ignorant we are is to look back, read some old newspapers, and see how often the world did something that wasn’t even imagined. Some examples include the Arab Spring, the collapse of the Soviet Union, the financial meltdown. ",
					"content_token": 184,
					"embedding": []
				},
				{
					"article_title": "Decisions Under Uncertainty",
					"article_url": "https://fs.blog/decisions-under-uncertainty/",
					"content": "We’re prepared for a world much like 2  the world of risk, with known outcomes and probability that can be estimated, yet we live in a world with a closer resemblance to 3. Read part two of this series: Two types of ignorance. References: Ignorance: Lessons from the Laboratory of Literature Joy and Zeckhauser.",
					"content_token": 71,
					"embedding": []
				}
			]
		},
		{
			"title": "More Information Doesn’t Mean Better Decisions",
			"url": "https://fs.blog/more-information-decisions/",
			"content": "We tend to think that if we only had more information, we’d make better decisions. The world, however, doesn’t always work that way. Paradoxically, More information often means that we make worse decisions.  When you want to make a good decision, your first action is most likely to collect more information. If you know more about the situation, you can make better judgments. Right? Not always. Paradoxically, more information can lead us to make worse decisions. One of the reasons we make worse decisions with more information is that we pursue information that appears relevant but isn’t. The harder the information is to findthat is, the more work we have to do to find it and the more exclusive is itthe more psychology tells us that we’ll put too much value on that information. In part, this happens because of our bias toward commitment and consistency; we’ve spent time and effort seeking out that information, so mentally, we feel obliged to use it. This nudges us toward decisions we otherwise wouldn’t have made. We also over-value information that is easily obtainable, thinking that it possesses unique insights when, in fact, it’s nothing more than you’d find on the first page of Google. A little knowledge truly is a dangerous thing.  And yet, another reason we love irrelevant information is that we really lack fundamental understanding. If we don’t understand something, we won’t have a firm grasp of the fundamental variables that govern the situation and how they interact, so we’ll look for new variables. When you’re not sure how to weigh one attribute compared with another, you end up searching for a reason. Often this mountain of new information  even if easily obtainable – is largely irrelevant to the situation. The problem is we don’t know it is irrelevant. “The result is that peculiar feeling of inward unrest known as indecision. Fortunately, it is too familiar to need description, for to describe it would be impossible. As long as it lasts, with the various objects before the attention, we are said to deliberate; and when finally the original suggestion either prevails and makes the movement take place, or gets definitively quenched by its antagonists, we are said to decide, or to utter our voluntary fiat in favor of one or the other course. The reinforcing and inhibiting ideas meanwhile are termed the reasons or motives by which the decision is brought about.”  William James Decisions Decisions are hard to make. In part, this is because of conflict and uncertainty. We are uncertain of the consequences of our actions and have difficulty making tradeoffs between attributes. Just as knowledge can make decision making easier, a lack of knowledge compounds the problem. When faced with two choices of equal alternatives, Slovic 1975, 1990 suggests we make choices based on what’s easy to explain and justify. Sounds logical, right, why flip a coin when I can come up with a reason. Sometimes we weigh the pros and cons. Subconsciously, when deciding for something, we focus on the pros, and when we decide against something, we focus on the reasons for rejection. This has the added advantage of giving us a good story to tell but causes problems when there are no striking positive or negative aspects to help make the decision. When we can’t find a compelling reason to do something or avoid something, we are left in a state of conflict. So we search for more information. “Seeking new alternatives usually requires additional time and effort and may involve the risk of losing the previously available options.”  Amos Tversky and Shafir The implications of my cobbled together theory seem worth considering. If our current choices don’t give us a convincing reason to opt for a choice, we’ll likely seek out additional information rather than questioning our understanding. When we do seek out additional information, we’re really just looking for a compelling rationale for choosing one alternative over another. The more we look for a new rationale to make decisions, the further we are from understanding. The harder we look, the more we’ll find. The more we find, the more we’ll miss-weigh what we find. The more we miss-weigh, the more likely we are to make a poor decision.  So the next time you find yourself seeking out hard-to-find esoteric information to give yourself an edge in that important decision, think hard about whether you understand the fundamentals of the situation. The more esoteric information you seek the further you move from the likely variables that will govern the outcomes of the situation. ",
			"tokens": 960,
			"chunks": [
				{
					"article_title": "More Information Doesn’t Mean Better Decisions",
					"article_url": "https://fs.blog/more-information-decisions/",
					"content": "We tend to think that if we only had more information, we’d make better decisions. The world, however, doesn’t always work that way. Paradoxically, More information often means that we make worse decisions.  When you want to make a good decision, your first action is most likely to collect more information. If you know more about the situation, you can make better judgments. Right? Not always. Paradoxically, more information can lead us to make worse decisions. One of the reasons we make worse decisions with more information is that we pursue information that appears relevant but isn’t. The harder the information is to findthat is, the more work we have to do to find it and the more exclusive is itthe more psychology tells us that we’ll put too much value on that information. ",
					"content_token": 170,
					"embedding": []
				},
				{
					"article_title": "More Information Doesn’t Mean Better Decisions",
					"article_url": "https://fs.blog/more-information-decisions/",
					"content": "In part, this happens because of our bias toward commitment and consistency; we’ve spent time and effort seeking out that information, so mentally, we feel obliged to use it. This nudges us toward decisions we otherwise wouldn’t have made. We also over-value information that is easily obtainable, thinking that it possesses unique insights when, in fact, it’s nothing more than you’d find on the first page of Google. A little knowledge truly is a dangerous thing.  And yet, another reason we love irrelevant information is that we really lack fundamental understanding. If we don’t understand something, we won’t have a firm grasp of the fundamental variables that govern the situation and how they interact, so we’ll look for new variables. When you’re not sure how to weigh one attribute compared with another, you end up searching for a reason. ",
					"content_token": 187,
					"embedding": []
				},
				{
					"article_title": "More Information Doesn’t Mean Better Decisions",
					"article_url": "https://fs.blog/more-information-decisions/",
					"content": "Often this mountain of new information  even if easily obtainable – is largely irrelevant to the situation. The problem is we don’t know it is irrelevant. “The result is that peculiar feeling of inward unrest known as indecision. Fortunately, it is too familiar to need description, for to describe it would be impossible. As long as it lasts, with the various objects before the attention, we are said to deliberate; and when finally the original suggestion either prevails and makes the movement take place, or gets definitively quenched by its antagonists, we are said to decide, or to utter our voluntary fiat in favor of one or the other course. The reinforcing and inhibiting ideas meanwhile are termed the reasons or motives by which the decision is brought about.”  William James Decisions Decisions are hard to make. In part, this is because of conflict and uncertainty. We are uncertain of the consequences of our actions and have difficulty making tradeoffs between attributes. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "More Information Doesn’t Mean Better Decisions",
					"article_url": "https://fs.blog/more-information-decisions/",
					"content": "Just as knowledge can make decision making easier, a lack of knowledge compounds the problem. When faced with two choices of equal alternatives, Slovic 1975, 1990 suggests we make choices based on what’s easy to explain and justify. Sounds logical, right, why flip a coin when I can come up with a reason. Sometimes we weigh the pros and cons. Subconsciously, when deciding for something, we focus on the pros, and when we decide against something, we focus on the reasons for rejection. This has the added advantage of giving us a good story to tell but causes problems when there are no striking positive or negative aspects to help make the decision. When we can’t find a compelling reason to do something or avoid something, we are left in a state of conflict. So we search for more information. ",
					"content_token": 168,
					"embedding": []
				},
				{
					"article_title": "More Information Doesn’t Mean Better Decisions",
					"article_url": "https://fs.blog/more-information-decisions/",
					"content": "“Seeking new alternatives usually requires additional time and effort and may involve the risk of losing the previously available options.”  Amos Tversky and Shafir The implications of my cobbled together theory seem worth considering. If our current choices don’t give us a convincing reason to opt for a choice, we’ll likely seek out additional information rather than questioning our understanding. When we do seek out additional information, we’re really just looking for a compelling rationale for choosing one alternative over another. The more we look for a new rationale to make decisions, the further we are from understanding. The harder we look, the more we’ll find. The more we find, the more we’ll miss-weigh what we find. The more we miss-weigh, the more likely we are to make a poor decision. ",
					"content_token": 178,
					"embedding": []
				},
				{
					"article_title": "More Information Doesn’t Mean Better Decisions",
					"article_url": "https://fs.blog/more-information-decisions/",
					"content": "So the next time you find yourself seeking out hard-to-find esoteric information to give yourself an edge in that important decision, think hard about whether you understand the fundamentals of the situation. The more esoteric information you seek the further you move from the likely variables that will govern the outcomes of the situation.",
					"content_token": 61,
					"embedding": []
				}
			]
		},
		{
			"title": "William Morris: Adventures in Decision-Making",
			"url": "https://fs.blog/what-type-of-decision-maker-are-you/",
			"content": "This isn’t my advice, it comes from the 1973 book How to Get Rich Slowly, But Almost Surely: Adventures in Decision-Making by William Morris. “It’s foolish,” Morris writes, “to suppose that anyone could give you a set of rules for making  decisions which you would actually follow. Something of greater subtlety, but also of greater practicality is involved.” It’s useful to make judgments about the quality and effectiveness of your decision making. Only when you look at how you make decisions, will actual behavioral changes result. You’ve got to begin by appreciating your own self-image by seeing your own style, and by becoming conscious of what you ordinarily do without the slightest self-consciousness. Then compensation and change will begin to occur, almost entirely without effort on your part. So, let’s take a precise look at our behavior in the way we make decisions. How do we make decisions? Here are some questions to ask Keep in mind that one style of deciding isn’t necessarily better than another: To what extent is your style of decision making intuitive, implicit and private? To what extend is it analytical, explicit, and open? To what degree are you tolerant of ambiguity in a decision situation? Can you decide in the face of ambiguous notions about objectives or ambiguous statements of the alternative courses of action? Some studies suggest that experienced decision makers are highly tolerate of ambiguity and capable of resolving it in their own special ways. Similarly, to what degree are you tolerant of uncertainty as to the consequences of various actions? Some of us require considerable information and assurances before we will act, others are far more willing to act on the basis of limited information and substantial uncertainty. We should not imagine that one such style is always “better” than the other. How reasonable is your hindsight? How effectively do you learn from your past decisions? Are you given to regretting decisions which turn out badly or do you suppress these feelings and look to the future? Do you distinguish clearly between a good decision which depends on reason and logic, and a good result or outcome which always depends to some degree on chance, luck and circumstances beyond your control. How much cognitive effort to you invest in a decision? Some decision makers are careful and deliberate thinkers, others tend to proceed “off the top of their heads” or “by the seat of their pants.” To what degree do you seek external aids or outside help in deciding? To what extent is there a need for coherence between your beliefs, your actions, and your objectives? We may seek coherence by becoming more optimistic about a course of action after we have chosen it, than before. Sometimes we adopt the belief that what we have become committed to is the best possible course of action, while we had no such conviction prior to our commitment. We achieve coherence or reduce “cognitive dissonance” by revising our preconceptions. How sensitive are your unaided decision making ability to conditions of stress? There is considerable evidence that most of us become distinctly poorer decision makers when we are under stress or pressure. To what extent are your perceptions and thoughts influenced, not so much by the external world, as by our own needs and desires. One of the great discoveries of modern psychology is that what we see and what we think are influenced subconsciously by our needs and tensions. To what degree are your clear about your own decision making processes? How much self-knowledge or self-consciousness do you have in this connection? It is well established that we seldom understand very well the reasons we do what we do, or the goals we are striving to attain. To what degree are your perceptions of the external world distorted because of distortions shared by your associates? Science is full of instances of socially shared distortions, often going about under the heading of “common sense.” Indeed, one of the best definitions of common sense pictures it as that kind of sense which tells us when we look out of the window that the world is flat. To what degree do you abstract or simplify the external world in making a decision? To what degree do you rely on rules of thumb or platitudes for disposing of decision problems? To what degree do you look ahead in a decision? Is the planning horizon in the relatively near, or relatively distant future? One of the skills of a good chess player is his ability to look ahead to the future consequences of his moves. The ability of computers to play chess is rather directly related to their “look-ahead” ability. When things are looking very bad, how good are you at remaining clam and free from a slight panicky feeling? How much experience do you have in living with the consequences of you choices? Have you made some “big” decisions? How strong is your desire to get immediate, remarkable results when you make a decision? What can you say about your ability to see the facts, the data, both sides of a question, when you are confronted with an emotionally charged decision situation? How do you rate yourself in terms of self-confidence and respect for your own abilities? How capable are you of filtering through the giving structure to large volumes of information? Do you have a tendency to write down important considerations when you have to make a decision of some consequence?  Via How to Get Rich Slowly. ",
			"tokens": 1097,
			"chunks": [
				{
					"article_title": "William Morris: Adventures in Decision-Making",
					"article_url": "https://fs.blog/what-type-of-decision-maker-are-you/",
					"content": "This isn’t my advice, it comes from the 1973 book How to Get Rich Slowly, But Almost Surely: Adventures in Decision-Making by William Morris. “It’s foolish,” Morris writes, “to suppose that anyone could give you a set of rules for making  decisions which you would actually follow. Something of greater subtlety, but also of greater practicality is involved.” It’s useful to make judgments about the quality and effectiveness of your decision making. Only when you look at how you make decisions, will actual behavioral changes result. You’ve got to begin by appreciating your own self-image by seeing your own style, and by becoming conscious of what you ordinarily do without the slightest self-consciousness. Then compensation and change will begin to occur, almost entirely without effort on your part. So, let’s take a precise look at our behavior in the way we make decisions. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "William Morris: Adventures in Decision-Making",
					"article_url": "https://fs.blog/what-type-of-decision-maker-are-you/",
					"content": "How do we make decisions? Here are some questions to ask Keep in mind that one style of deciding isn’t necessarily better than another: To what extent is your style of decision making intuitive, implicit and private? To what extend is it analytical, explicit, and open? To what degree are you tolerant of ambiguity in a decision situation? Can you decide in the face of ambiguous notions about objectives or ambiguous statements of the alternative courses of action? Some studies suggest that experienced decision makers are highly tolerate of ambiguity and capable of resolving it in their own special ways. Similarly, to what degree are you tolerant of uncertainty as to the consequences of various actions? Some of us require considerable information and assurances before we will act, others are far more willing to act on the basis of limited information and substantial uncertainty. We should not imagine that one such style is always “better” than the other. ",
					"content_token": 181,
					"embedding": []
				},
				{
					"article_title": "William Morris: Adventures in Decision-Making",
					"article_url": "https://fs.blog/what-type-of-decision-maker-are-you/",
					"content": "How reasonable is your hindsight? How effectively do you learn from your past decisions? Are you given to regretting decisions which turn out badly or do you suppress these feelings and look to the future? Do you distinguish clearly between a good decision which depends on reason and logic, and a good result or outcome which always depends to some degree on chance, luck and circumstances beyond your control. How much cognitive effort to you invest in a decision? Some decision makers are careful and deliberate thinkers, others tend to proceed “off the top of their heads” or “by the seat of their pants.” To what degree do you seek external aids or outside help in deciding? To what extent is there a need for coherence between your beliefs, your actions, and your objectives? We may seek coherence by becoming more optimistic about a course of action after we have chosen it, than before. ",
					"content_token": 181,
					"embedding": []
				},
				{
					"article_title": "William Morris: Adventures in Decision-Making",
					"article_url": "https://fs.blog/what-type-of-decision-maker-are-you/",
					"content": "Sometimes we adopt the belief that what we have become committed to is the best possible course of action, while we had no such conviction prior to our commitment. We achieve coherence or reduce “cognitive dissonance” by revising our preconceptions. How sensitive are your unaided decision making ability to conditions of stress? There is considerable evidence that most of us become distinctly poorer decision makers when we are under stress or pressure. To what extent are your perceptions and thoughts influenced, not so much by the external world, as by our own needs and desires. One of the great discoveries of modern psychology is that what we see and what we think are influenced subconsciously by our needs and tensions. To what degree are your clear about your own decision making processes? How much self-knowledge or self-consciousness do you have in this connection? It is well established that we seldom understand very well the reasons we do what we do, or the goals we are striving to attain. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "William Morris: Adventures in Decision-Making",
					"article_url": "https://fs.blog/what-type-of-decision-maker-are-you/",
					"content": "To what degree are your perceptions of the external world distorted because of distortions shared by your associates? Science is full of instances of socially shared distortions, often going about under the heading of “common sense.” Indeed, one of the best definitions of common sense pictures it as that kind of sense which tells us when we look out of the window that the world is flat. To what degree do you abstract or simplify the external world in making a decision? To what degree do you rely on rules of thumb or platitudes for disposing of decision problems? To what degree do you look ahead in a decision? Is the planning horizon in the relatively near, or relatively distant future? One of the skills of a good chess player is his ability to look ahead to the future consequences of his moves. The ability of computers to play chess is rather directly related to their “look-ahead” ability. ",
					"content_token": 183,
					"embedding": []
				},
				{
					"article_title": "William Morris: Adventures in Decision-Making",
					"article_url": "https://fs.blog/what-type-of-decision-maker-are-you/",
					"content": "When things are looking very bad, how good are you at remaining clam and free from a slight panicky feeling? How much experience do you have in living with the consequences of you choices? Have you made some “big” decisions? How strong is your desire to get immediate, remarkable results when you make a decision? What can you say about your ability to see the facts, the data, both sides of a question, when you are confronted with an emotionally charged decision situation? How do you rate yourself in terms of self-confidence and respect for your own abilities? How capable are you of filtering through the giving structure to large volumes of information? Do you have a tendency to write down important considerations when you have to make a decision of some consequence?  Via How to Get Rich Slowly.",
					"content_token": 161,
					"embedding": []
				}
			]
		},
		{
			"title": "Swing for Success: Mastering Your Circle of Competence with Ted Williams’ Winning Strategy",
			"url": "https://fs.blog/make-better-decisions/",
			"content": " Ted Williams 1918-2002 was arguably the greatest hitter in baseball history. He was the last player to break the revered .400 barriera remarkable achievement in any era.     How did he do it, and what can we learn from him to improve our decision-making?    Admittedly, I’m not a diehard baseball fan, but Ted Williams’ book, The Science of Hitting, piqued my interest. It contains a compelling illustration of him at-bat, with the strike zone divided into 77 distinct squares.    Source: The Science of Hitting   Williams recognized that waiting for a pitch in his sweet spot significantly increased his chances of getting a hit. Being patient and waiting for the right opportunity, offered a 40 hit rate. Impatience, on the other hand, could lower his success rate to a mere 23-25.    Williams understood that average batters turned into great batters if they waited for the right pitch, and even the best batters turned into average ones if they swung at the wrong pitch.      A good hitter can hit a pitch that is over the plate three times better than a great hitter with a questionable ball in a tough spot.     According to baseball legend Rogers Hornsby, the most crucial factor for a hitter is getting a good ball to hit. Williams took this advice to heart, meticulously dividing the strike zone into 77 baseball-sized spaces, and understanding which pitches yielded the highest odds of success for him.    The Zone of Opportunity    We all possess a zone of opportunity, where the odds are in our favor. This is your Circle of Competence, your “sweet spot.”     The most important thing about your circle of competence is knowing where it starts and stops. While simple, it’s not easy. As Richard Feynman once said, “the first principle is that you must not fool yourself, and you are the easiest person to fool.”    A common mistake is to confuse familiarity with understanding. Deep fluency takes a lot of work. If you want to test your understanding of something or learn something new, try this approach.    “It’s not a competency if you don’t know the edge of it.” Charlie munger    Warren Buffett understands sticking to what you understand rather than chasing what’s new and exciting. He writes:     If we have a strength, it is in recognizing when we are well within our cycle of competence and when we are approaching the perimeter. Predicting the long term economics of companies that operate in fast-changing industries is simply far beyond our perimeter. If others claim predictive skills in those industriesand seem to have claims validated by the behaviour of the stock market we neither envy not emulate them. Instead, we just stick with what we understand. If we stray, we will have done so inadvertently, not because we got restless and substituted hope for rationality.       Unlike Williams, Buffett can’t be called “out” on strikes if he resists pitches that are barely in the strike zone. He can, quite literally, wait for the perfect pitchlooking at thousands of different investments before finding one that is just right.     If straying from our core competence decreases our success rate, what can we do to improve our odds?    When you are operating outside of your area of understanding, focusing on positioning rather than predicting is crucial. Two ways to achieve this are by increasing the margin of safety and ensuring circumstances don’t force us into a bad decision.    By learning from Ted Williams and understanding our Circle of Competence, we can make better decisions and increase our odds of success in various domains. ",
			"tokens": 791,
			"chunks": [
				{
					"article_title": "Swing for Success: Mastering Your Circle of Competence with Ted Williams’ Winning Strategy",
					"article_url": "https://fs.blog/make-better-decisions/",
					"content": " Ted Williams 1918-2002 was arguably the greatest hitter in baseball history. He was the last player to break the revered .400 barriera remarkable achievement in any era.     How did he do it, and what can we learn from him to improve our decision-making?    Admittedly, I’m not a diehard baseball fan, but Ted Williams’ book, The Science of Hitting, piqued my interest. It contains a compelling illustration of him at-bat, with the strike zone divided into 77 distinct squares.    Source: The Science of Hitting   Williams recognized that waiting for a pitch in his sweet spot significantly increased his chances of getting a hit. Being patient and waiting for the right opportunity, offered a 40 hit rate. Impatience, on the other hand, could lower his success rate to a mere 23-25. ",
					"content_token": 183,
					"embedding": []
				},
				{
					"article_title": "Swing for Success: Mastering Your Circle of Competence with Ted Williams’ Winning Strategy",
					"article_url": "https://fs.blog/make-better-decisions/",
					"content": "   Williams understood that average batters turned into great batters if they waited for the right pitch, and even the best batters turned into average ones if they swung at the wrong pitch.      A good hitter can hit a pitch that is over the plate three times better than a great hitter with a questionable ball in a tough spot.     According to baseball legend Rogers Hornsby, the most crucial factor for a hitter is getting a good ball to hit. Williams took this advice to heart, meticulously dividing the strike zone into 77 baseball-sized spaces, and understanding which pitches yielded the highest odds of success for him.    The Zone of Opportunity    We all possess a zone of opportunity, where the odds are in our favor. This is your Circle of Competence, your “sweet spot.”     The most important thing about your circle of competence is knowing where it starts and stops. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "Swing for Success: Mastering Your Circle of Competence with Ted Williams’ Winning Strategy",
					"article_url": "https://fs.blog/make-better-decisions/",
					"content": "While simple, it’s not easy. As Richard Feynman once said, “the first principle is that you must not fool yourself, and you are the easiest person to fool.”    A common mistake is to confuse familiarity with understanding. Deep fluency takes a lot of work. If you want to test your understanding of something or learn something new, try this approach.    “It’s not a competency if you don’t know the edge of it.” Charlie munger    Warren Buffett understands sticking to what you understand rather than chasing what’s new and exciting. He writes:     If we have a strength, it is in recognizing when we are well within our cycle of competence and when we are approaching the perimeter. Predicting the long term economics of companies that operate in fast-changing industries is simply far beyond our perimeter. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "Swing for Success: Mastering Your Circle of Competence with Ted Williams’ Winning Strategy",
					"article_url": "https://fs.blog/make-better-decisions/",
					"content": "If others claim predictive skills in those industriesand seem to have claims validated by the behaviour of the stock market we neither envy not emulate them. Instead, we just stick with what we understand. If we stray, we will have done so inadvertently, not because we got restless and substituted hope for rationality.       Unlike Williams, Buffett can’t be called “out” on strikes if he resists pitches that are barely in the strike zone. He can, quite literally, wait for the perfect pitchlooking at thousands of different investments before finding one that is just right.     If straying from our core competence decreases our success rate, what can we do to improve our odds?    When you are operating outside of your area of understanding, focusing on positioning rather than predicting is crucial. Two ways to achieve this are by increasing the margin of safety and ensuring circumstances don’t force us into a bad decision. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "Swing for Success: Mastering Your Circle of Competence with Ted Williams’ Winning Strategy",
					"article_url": "https://fs.blog/make-better-decisions/",
					"content": "By learning from Ted Williams and understanding our Circle of Competence, we can make better decisions and increase our odds of success in various domains.",
					"content_token": 28,
					"embedding": []
				}
			]
		},
		{
			"title": "Understanding and Diagnosing Problems",
			"url": "https://fs.blog/understanding-and-diagnosing-problems/",
			"content": "We all know one, the Monday morning quarterback. They walk into the meeting room primed and ready for action. Ready that is, to apply the knowledge they know now to decisions of the past. And too often we’re defenseless. The outcome by now is likely apparent to everyone. “When a decision goes awry,” writes Albert Bernstein in his book Dinosaur Brains, “we tend to focus on the people who made it, rather than on the decision itself. Our assumption, which is really unwarranted, is that good people make good decisions, and vice versa.” The point is to focus on what was known at the time. And consider, in light of that, was it a reasonable decision? Good decisions don’t always have a good outcome, just as bad decisions don’t always have bad outcomes. It’s scary but a lot of otherwise smart people are unable to distinguish the difference. This image from our rethink conference on decision making helps us understand what’s going on.  It’s easy to shine the spotlight on the outcome. It doesn’t involve a lot of thinking either and it certainly isn’t going to help you understand or diagnose problems. It’s harder, yet profitable, to think back and evaluate the merits of a particular decision based on what was known at the time. Was it a good decision with a bad outcome? But usually, the only information we have about how and why decisions were made is the self-serving memories of the people in the room. “We have very little vocabulary for talking about internal thought processes,” writes James March, “Decisions feel as if they jump fully grown from one’s head.” This is where having a good decisionprocess comes in. Keeping a decision journals is also helpful. Maybe executives in responsible positions should be required to keep logs, as sea captains do. After each decision, a manager would list his or her reasons for having made it and record how it turned out. If you have a journal, you can pull it out and see, in light of the facts and assumptions at the time, whether the best decision possible was made and if there was, in fact, a mistake. If there really was a mistake, you can look at your decision process and determine what went wrong and how to avoid it in the future. Don’t hide mistakes behind vagueness but, equally important, stay away from the blamecredit mentality because it undermines understanding. And understanding is the key to getting better. One way to reinforce good decisions is to document the assumptions at the time the decision is made in a decision journal. Read the ultimate guide to making smart decisions next. ",
			"tokens": 562,
			"chunks": [
				{
					"article_title": "Understanding and Diagnosing Problems",
					"article_url": "https://fs.blog/understanding-and-diagnosing-problems/",
					"content": "We all know one, the Monday morning quarterback. They walk into the meeting room primed and ready for action. Ready that is, to apply the knowledge they know now to decisions of the past. And too often we’re defenseless. The outcome by now is likely apparent to everyone. “When a decision goes awry,” writes Albert Bernstein in his book Dinosaur Brains, “we tend to focus on the people who made it, rather than on the decision itself. Our assumption, which is really unwarranted, is that good people make good decisions, and vice versa.” The point is to focus on what was known at the time. And consider, in light of that, was it a reasonable decision? Good decisions don’t always have a good outcome, just as bad decisions don’t always have bad outcomes. It’s scary but a lot of otherwise smart people are unable to distinguish the difference. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "Understanding and Diagnosing Problems",
					"article_url": "https://fs.blog/understanding-and-diagnosing-problems/",
					"content": "This image from our rethink conference on decision making helps us understand what’s going on.  It’s easy to shine the spotlight on the outcome. It doesn’t involve a lot of thinking either and it certainly isn’t going to help you understand or diagnose problems. It’s harder, yet profitable, to think back and evaluate the merits of a particular decision based on what was known at the time. Was it a good decision with a bad outcome? But usually, the only information we have about how and why decisions were made is the self-serving memories of the people in the room. “We have very little vocabulary for talking about internal thought processes,” writes James March, “Decisions feel as if they jump fully grown from one’s head.” This is where having a good decisionprocess comes in. Keeping a decision journals is also helpful. ",
					"content_token": 187,
					"embedding": []
				},
				{
					"article_title": "Understanding and Diagnosing Problems",
					"article_url": "https://fs.blog/understanding-and-diagnosing-problems/",
					"content": "Maybe executives in responsible positions should be required to keep logs, as sea captains do. After each decision, a manager would list his or her reasons for having made it and record how it turned out. If you have a journal, you can pull it out and see, in light of the facts and assumptions at the time, whether the best decision possible was made and if there was, in fact, a mistake. If there really was a mistake, you can look at your decision process and determine what went wrong and how to avoid it in the future. Don’t hide mistakes behind vagueness but, equally important, stay away from the blamecredit mentality because it undermines understanding. And understanding is the key to getting better. One way to reinforce good decisions is to document the assumptions at the time the decision is made in a decision journal. Read the ultimate guide to making smart decisions next.",
					"content_token": 180,
					"embedding": []
				}
			]
		},
		{
			"title": "The Munger Two Step",
			"url": "https://fs.blog/munger-two-step/",
			"content": "A simple and easy approach to decision making that prevents us from being manipulated.  Understand the forces at play. Understand how your subconscious might be leading you astray.   While most of us make decisions daily, few of us have a useful framework for thinking that protects us when making decisions. We’re going to explore Munger’s two-step process for making effective decisions and reducing human misjudgment. In A Lesson on Elementary Worldly Wisdom, Charlie Munger offers a simple two-step filter for making effective decisions: Personally, I’ve gotten so that I now use a kind of two-track analysis. First, what are the factors that really govern the interests involved, rationally considered? And second, what are the subconscious influences where the brain at a subconscious level is automatically doing these things-which by and large are useful, but which often misfunction. One approach is rationality-the way you’d work out a bridge problem: by evaluating the real interests, the real probabilities and so forth. And the other is to evaluate the psychological factors that cause subconscious conclusions-many of which are wrong. Let’s take a closer look. 1. The Forces at Play The key to the first step is knowing what you know and what you don’t know. You need to understand your circle of competence. It’s just as important to know what you don’t know as it is to know what you know. If you know what you don’t know, you might still have to make a decision, but your approaches for making that decision will change. For example, if you’re forced to make a decision in an area that you know is well outside your circle of competence, one tool you can use is inversion. While there are millions of factors that go into decisions, there will always be a few variables and factors that will carry the bulk of the weight. If you’re operating within your circle of competence, it should be relatively easy to figure out the relevant variables and forces at play. I can’t tell you the relevant variables. There is no magic formula. To make consistently good decisions, you need to develop a deep fluency in the area in which you are making decisions, and you need to pull in the big ideas from multiple disciplines to make sure you’re exercising good judgment. 2. The Psychological Factors There are many causes of human misjudgment, including over-confidence. These are the subtle ways that your mind might be leading you astray at a subconscious level. Your subconscious mind is larger than your conscious mind, and yet we rarely pay attention to how we might be tricking ourselves. One way to mislead yourself, for instance, is to make decisions based on a small sample size and extrapolate the results to a larger population. Another way we fool ourselves is to remain committed to something we’ve said in the past. We might rely on an authority figure or default to what everyone else is doing. You get the idea. Usually, when we have extreme success or failure, there are four or five factors working in the same direction. The same goes for psychology. The more human misjudgment factors there are working against us, the more likely we are to make an ill-informed decision.     ",
			"tokens": 683,
			"chunks": [
				{
					"article_title": "The Munger Two Step",
					"article_url": "https://fs.blog/munger-two-step/",
					"content": "A simple and easy approach to decision making that prevents us from being manipulated.  Understand the forces at play. Understand how your subconscious might be leading you astray.   While most of us make decisions daily, few of us have a useful framework for thinking that protects us when making decisions. We’re going to explore Munger’s two-step process for making effective decisions and reducing human misjudgment. In A Lesson on Elementary Worldly Wisdom, Charlie Munger offers a simple two-step filter for making effective decisions: Personally, I’ve gotten so that I now use a kind of two-track analysis. First, what are the factors that really govern the interests involved, rationally considered? And second, what are the subconscious influences where the brain at a subconscious level is automatically doing these things-which by and large are useful, but which often misfunction. ",
					"content_token": 185,
					"embedding": []
				},
				{
					"article_title": "The Munger Two Step",
					"article_url": "https://fs.blog/munger-two-step/",
					"content": "One approach is rationality-the way you’d work out a bridge problem: by evaluating the real interests, the real probabilities and so forth. And the other is to evaluate the psychological factors that cause subconscious conclusions-many of which are wrong. Let’s take a closer look. 1. The Forces at Play The key to the first step is knowing what you know and what you don’t know. You need to understand your circle of competence. It’s just as important to know what you don’t know as it is to know what you know. If you know what you don’t know, you might still have to make a decision, but your approaches for making that decision will change. For example, if you’re forced to make a decision in an area that you know is well outside your circle of competence, one tool you can use is inversion. ",
					"content_token": 187,
					"embedding": []
				},
				{
					"article_title": "The Munger Two Step",
					"article_url": "https://fs.blog/munger-two-step/",
					"content": "While there are millions of factors that go into decisions, there will always be a few variables and factors that will carry the bulk of the weight. If you’re operating within your circle of competence, it should be relatively easy to figure out the relevant variables and forces at play. I can’t tell you the relevant variables. There is no magic formula. To make consistently good decisions, you need to develop a deep fluency in the area in which you are making decisions, and you need to pull in the big ideas from multiple disciplines to make sure you’re exercising good judgment. 2. The Psychological Factors There are many causes of human misjudgment, including over-confidence. These are the subtle ways that your mind might be leading you astray at a subconscious level. ",
					"content_token": 161,
					"embedding": []
				},
				{
					"article_title": "The Munger Two Step",
					"article_url": "https://fs.blog/munger-two-step/",
					"content": "Your subconscious mind is larger than your conscious mind, and yet we rarely pay attention to how we might be tricking ourselves. One way to mislead yourself, for instance, is to make decisions based on a small sample size and extrapolate the results to a larger population. Another way we fool ourselves is to remain committed to something we’ve said in the past. We might rely on an authority figure or default to what everyone else is doing. You get the idea. Usually, when we have extreme success or failure, there are four or five factors working in the same direction. The same goes for psychology. The more human misjudgment factors there are working against us, the more likely we are to make an ill-informed decision.",
					"content_token": 151,
					"embedding": []
				}
			]
		},
		{
			"title": "A Decision-Making Magic Trick",
			"url": "https://fs.blog/a-decision-making-magic-trick/",
			"content": "Two important nuggets from an interview with Chip Heath, co-author of Decisive more here, on improving our ability to make better decisions: A decision-making magic trick The closest thing to a decision-making magic trick that I’ve found is the question, “What would you advise your best friend to do if they were in your situation?” So often when I ask that question, people blurt out an answer and their eyes get wide. They’re shocked at how easy it is when you just imagine you’re advising someone else. This time isn’t so different businesses make decisions about mergers and acquisitions that are hundreds of millions of dollars, and to the senior leader it seems like, “Well this is a different situation than the last acquisition we made.” And yet in that room making the decision is a set of people who have probably seen a dozen acquisitions, but they don’t take the time to do even the equivalent of the three-out-of-five-stars rating that we would get from Amazon.com. The kind of decisions that senior people make always present themselves as though they are completely different than anything else. Big decisions are subtle in a way because they all seem to come one at a time. The advantage of smaller decisions is we realize we are in a repeated situation where we’re going to see the same thing a lot. Yet lots of big decisions end up having that property as well. If we take the time to move our mental spotlight around, we can always find other decisions that are similar to this one. We think the chief financial officer we’re trying to hire is in a unique position in the company, and that this is a unique position in time with unique demands. But the fact is, we’ve made other senior hires and we know how that process goes. Stepping back and taking in the broader context is just as useful for senior leaders as it is for the frontline worker who’s making a decision on the 35th mortgage application or the 75th customer complaint. ",
			"tokens": 428,
			"chunks": [
				{
					"article_title": "A Decision-Making Magic Trick",
					"article_url": "https://fs.blog/a-decision-making-magic-trick/",
					"content": "Two important nuggets from an interview with Chip Heath, co-author of Decisive more here, on improving our ability to make better decisions: A decision-making magic trick The closest thing to a decision-making magic trick that I’ve found is the question, “What would you advise your best friend to do if they were in your situation?” So often when I ask that question, people blurt out an answer and their eyes get wide. They’re shocked at how easy it is when you just imagine you’re advising someone else. ",
					"content_token": 118,
					"embedding": []
				},
				{
					"article_title": "A Decision-Making Magic Trick",
					"article_url": "https://fs.blog/a-decision-making-magic-trick/",
					"content": "This time isn’t so different businesses make decisions about mergers and acquisitions that are hundreds of millions of dollars, and to the senior leader it seems like, “Well this is a different situation than the last acquisition we made.” And yet in that room making the decision is a set of people who have probably seen a dozen acquisitions, but they don’t take the time to do even the equivalent of the three-out-of-five-stars rating that we would get from Amazon.com. The kind of decisions that senior people make always present themselves as though they are completely different than anything else. Big decisions are subtle in a way because they all seem to come one at a time. The advantage of smaller decisions is we realize we are in a repeated situation where we’re going to see the same thing a lot. Yet lots of big decisions end up having that property as well. ",
					"content_token": 187,
					"embedding": []
				},
				{
					"article_title": "A Decision-Making Magic Trick",
					"article_url": "https://fs.blog/a-decision-making-magic-trick/",
					"content": "If we take the time to move our mental spotlight around, we can always find other decisions that are similar to this one. We think the chief financial officer we’re trying to hire is in a unique position in the company, and that this is a unique position in time with unique demands. But the fact is, we’ve made other senior hires and we know how that process goes. Stepping back and taking in the broader context is just as useful for senior leaders as it is for the frontline worker who’s making a decision on the 35th mortgage application or the 75th customer complaint.",
					"content_token": 124,
					"embedding": []
				}
			]
		},
		{
			"title": "Decision Making Psychology with Rory Sutherland",
			"url": "https://fs.blog/decision-making-psychology-with-rory-sutherland/",
			"content": "Below are three excerpts from a great interview with Rory Sutherland on decision making psychology. Understanding Human Behavior That attempt to model economic behaviour as though it were Newtonian physics was responsible for many past mistakes. This is closer to weather forecasting than to conventional physics as a science. But it is still a science and can still make progress like a science. And the great news is that we are starting from such a low base. If our ability to understand and predict human behaviour only improves by a few percent a decade, the benefits will be immense. And even a tiny reduction in misdirected effort by abandoning daft, ineffectual sunk-cost-plagued endeavours such as the war on drugs or, at a more modest level, badly conceived choice-architectures in a new range of cars all can be economically transformative. The Physical Fallacy The problem we all face is “The physical fallacy”. All of us, even those the social sciences, have an innate bias where we are happier fixing problems with stuff, rather than with psychological solutions – building faster trains rather than putting wifi on existing trains, to use my oft cited example. But as Benjamin Franklin no mean decision scientist himself remarked “There are two ways of being happy: We must either diminish our wants or augment our means – either may do. The result is the same and it is for each man to decide for himself and to do that which happens to be easier.” There is no reason to prefer one solution over another simply because it involves solid matter rather than grey matter. This is an interesting area where the advertising industry and the environmental movement rarely seen as natural bedfellows sometimes find common ground. Intangible value is the best kind of value – since the materials needed to create it are not in short supply. Marketing and Advertising If you need to understand why marketing and advertising and reputation and brands are important to the functioning of markets, Akerlof’s paper “The Market for Lemons” is essential reading. So too is his excellent and underread book “Identity Economics” written with Rachel Kranton. The problem is not with economics as practiced by great economists – it is the unquestioning adherence to the dumber assumptions of Basic Economics 101 as unthinkingly absorbed by the product of a thousand business schools. You are particularly made aware of the pernicious influence of bad economics if you work in advertising. Even when advertising demonstrably works and is highly cost effective, people in finance and in the boards of companies don’t seem to like it very much. Since they have a mental model of the world in which everyone has perfect information, they have of course constructed in their heads a vision of the world in which marketing shouldn’t exist. ",
			"tokens": 562,
			"chunks": [
				{
					"article_title": "Decision Making Psychology with Rory Sutherland",
					"article_url": "https://fs.blog/decision-making-psychology-with-rory-sutherland/",
					"content": "Below are three excerpts from a great interview with Rory Sutherland on decision making psychology. Understanding Human Behavior That attempt to model economic behaviour as though it were Newtonian physics was responsible for many past mistakes. This is closer to weather forecasting than to conventional physics as a science. But it is still a science and can still make progress like a science. And the great news is that we are starting from such a low base. If our ability to understand and predict human behaviour only improves by a few percent a decade, the benefits will be immense. And even a tiny reduction in misdirected effort by abandoning daft, ineffectual sunk-cost-plagued endeavours such as the war on drugs or, at a more modest level, badly conceived choice-architectures in a new range of cars all can be economically transformative. The Physical Fallacy The problem we all face is “The physical fallacy” ",
					"content_token": 184,
					"embedding": []
				},
				{
					"article_title": "Decision Making Psychology with Rory Sutherland",
					"article_url": "https://fs.blog/decision-making-psychology-with-rory-sutherland/",
					"content": "All of us, even those the social sciences, have an innate bias where we are happier fixing problems with stuff, rather than with psychological solutions – building faster trains rather than putting wifi on existing trains, to use my oft cited example. But as Benjamin Franklin no mean decision scientist himself remarked “There are two ways of being happy: We must either diminish our wants or augment our means – either may do. The result is the same and it is for each man to decide for himself and to do that which happens to be easier.” There is no reason to prefer one solution over another simply because it involves solid matter rather than grey matter. This is an interesting area where the advertising industry and the environmental movement rarely seen as natural bedfellows sometimes find common ground. Intangible value is the best kind of value – since the materials needed to create it are not in short supply. ",
					"content_token": 179,
					"embedding": []
				},
				{
					"article_title": "Decision Making Psychology with Rory Sutherland",
					"article_url": "https://fs.blog/decision-making-psychology-with-rory-sutherland/",
					"content": "Marketing and Advertising If you need to understand why marketing and advertising and reputation and brands are important to the functioning of markets, Akerlof’s paper “The Market for Lemons” is essential reading. So too is his excellent and underread book “Identity Economics” written with Rachel Kranton. The problem is not with economics as practiced by great economists – it is the unquestioning adherence to the dumber assumptions of Basic Economics 101 as unthinkingly absorbed by the product of a thousand business schools. You are particularly made aware of the pernicious influence of bad economics if you work in advertising. Even when advertising demonstrably works and is highly cost effective, people in finance and in the boards of companies don’t seem to like it very much. Since they have a mental model of the world in which everyone has perfect information, they have of course constructed in their heads a vision of the world in which marketing shouldn’t exist. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "Decision Making Psychology with Rory Sutherland",
					"article_url": "https://fs.blog/decision-making-psychology-with-rory-sutherland/",
					"content": "",
					"content_token": 0,
					"embedding": []
				}
			]
		},
		{
			"title": "The Four Villains of Decision Making",
			"url": "https://fs.blog/how-to-make-better-choices-in-life-and-work/",
			"content": "You’re probably not as effective at making decisions as you could be. This article explores Chip and Dan Heaths’ new book, Decisive. It’s going to help us make better decisions both as individuals and in groups. But before we get to that, you should think about a tough decision you’re grappling with right now. Having a decision working in your mind as you’re reading this post will help make the advice in here tangible. Ok, let’s dig in. “A remarkable aspect of your mental life is that you are rarely stumped  The normal state of your mind is that you have intuitive feelings and opinions about almost everything that comes your way. You like or dislike people long before you know much about them; you trust or distrust strangers without knowing why; you feel that an enterprise is bound to succeed without analyzing it.”  Daniel Kahneman We’re quick to jump to conclusions because we give too much weight to the information in front of us and we fail to search for new information, which might disprove our thoughts. Nobel Prize winning Psychologist Daniel Kahneman called this tendency “what you see is all there is.” But that’s not the only reason we don’t make good decisions  there are many others. We’re overconfident. We look for information that fits our thoughts and ignore information that doesn’t. We are overly influenced by authority. We choose the short-term over the long-term. Once we’ve made a decision we find it hard to change our mind. In short, our brains are flawed. I could go on. Knowing about these and other biases isn’t enough; it doesn’t help us fix the problem. We need a framework for making decisions. In Decisive, the Heaths introduce a four-step process designed to counteract many biases. In keeping with Kahneman’s visual metaphor, the Heaths refer to the tendency to see only what’s in front of us as a “spotlight” effect. And that, in essence, is the core difficulty of decision making. What’s in the spotlight will rarely be everything we need to make good decisions, but we won’t always remember to shift the light. Most of us rarely use a process for thinking about things. If we do use one it’s likely to be the pros-and-cons list. While better than nothing, this approach is still deeply flawed because it doesn’t really account for biases. The Four Villains of Decision Making  Narrow Framing: “ the tendency to define our choices too narrowly, to see them in binary terms. We ask, “Should I break up with my partner or not?” instead of “What are the ways I could make this relationship better?” Confirmation Bias: “When people have the opportunity to collect information from the world, they are more likely to select information that supports their preexisting attitudes, beliefs, and actions.” We pretend we want the truth, yet all we really want is reassurance. Short-term Emotion: “When we’ve got a difficult decision to make, our feelings churn. We replay the same arguments in our head. We agonize about our circumstances. We change our minds from day to day. If our decision was represented on a spreadsheet, none of the numbers would be changingthere’s no new information being addedbut it doesn’t feel that way in our heads.” Overconfidence: “People think they know more than they do about how the future will unfold.”  The Heaths came up with a process to help us overcome these villains and make better choices. “We can’t deactivate our biases, but  we can counteract them with the right discipline.” The nature of each of the four decision-making villains suggests a strategy for how to defeat it. 1. You encounter a choice. But narrow framing makes you miss options. So  Widen Your Options. How can you expand your set of choices?  2. You analyze your options. But the confirmation bias leads you to gather self-serving information. So  Reality-Test Your Assumptions. How can you get outside your head and collect information you can trust?  3. You make a choice. But short-term emotion will often tempt you to make the wrong one. So  Attain Distance Before Deciding. How can you overcome short-term emotion and conflicted feelings to make better choices?  4. Then you live with it. But you’ll often be overconfident about how the future will unfold. So  Prepare to Be Wrong. How can we plan for an uncertain future so that we give our decisions the best chance to succeed?  They call this WRAP. “At its core, the WRAP model urges you to switch from “auto spotlight” to manual spotlight. Source: Decisive All in all this was a great book. We focus our efforts on analysis. If a decision is wrong the analysis must have been the problem. Not only does this ignore the fact that you can have bad outcomes’ with good decisions but it also places your spotlight on the analysis at the cost of the process by which the decision was made. Read this next: What Matters More in Decisions: Analysis or Process? ",
			"tokens": 1128,
			"chunks": [
				{
					"article_title": "The Four Villains of Decision Making",
					"article_url": "https://fs.blog/how-to-make-better-choices-in-life-and-work/",
					"content": "You’re probably not as effective at making decisions as you could be. This article explores Chip and Dan Heaths’ new book, Decisive. It’s going to help us make better decisions both as individuals and in groups. But before we get to that, you should think about a tough decision you’re grappling with right now. Having a decision working in your mind as you’re reading this post will help make the advice in here tangible. Ok, let’s dig in. “A remarkable aspect of your mental life is that you are rarely stumped  The normal state of your mind is that you have intuitive feelings and opinions about almost everything that comes your way. ",
					"content_token": 146,
					"embedding": []
				},
				{
					"article_title": "The Four Villains of Decision Making",
					"article_url": "https://fs.blog/how-to-make-better-choices-in-life-and-work/",
					"content": "You like or dislike people long before you know much about them; you trust or distrust strangers without knowing why; you feel that an enterprise is bound to succeed without analyzing it.”  Daniel Kahneman We’re quick to jump to conclusions because we give too much weight to the information in front of us and we fail to search for new information, which might disprove our thoughts. Nobel Prize winning Psychologist Daniel Kahneman called this tendency “what you see is all there is.” But that’s not the only reason we don’t make good decisions  there are many others. We’re overconfident. We look for information that fits our thoughts and ignore information that doesn’t. We are overly influenced by authority. We choose the short-term over the long-term. Once we’ve made a decision we find it hard to change our mind. In short, our brains are flawed. I could go on. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "The Four Villains of Decision Making",
					"article_url": "https://fs.blog/how-to-make-better-choices-in-life-and-work/",
					"content": "Knowing about these and other biases isn’t enough; it doesn’t help us fix the problem. We need a framework for making decisions. In Decisive, the Heaths introduce a four-step process designed to counteract many biases. In keeping with Kahneman’s visual metaphor, the Heaths refer to the tendency to see only what’s in front of us as a “spotlight” effect. And that, in essence, is the core difficulty of decision making. What’s in the spotlight will rarely be everything we need to make good decisions, but we won’t always remember to shift the light. Most of us rarely use a process for thinking about things. If we do use one it’s likely to be the pros-and-cons list. While better than nothing, this approach is still deeply flawed because it doesn’t really account for biases. ",
					"content_token": 189,
					"embedding": []
				},
				{
					"article_title": "The Four Villains of Decision Making",
					"article_url": "https://fs.blog/how-to-make-better-choices-in-life-and-work/",
					"content": "The Four Villains of Decision Making  Narrow Framing: “ the tendency to define our choices too narrowly, to see them in binary terms. We ask, “Should I break up with my partner or not?” instead of “What are the ways I could make this relationship better?” Confirmation Bias: “When people have the opportunity to collect information from the world, they are more likely to select information that supports their preexisting attitudes, beliefs, and actions.” We pretend we want the truth, yet all we really want is reassurance. Short-term Emotion: “When we’ve got a difficult decision to make, our feelings churn. We replay the same arguments in our head. We agonize about our circumstances. We change our minds from day to day. ",
					"content_token": 172,
					"embedding": []
				},
				{
					"article_title": "The Four Villains of Decision Making",
					"article_url": "https://fs.blog/how-to-make-better-choices-in-life-and-work/",
					"content": "If our decision was represented on a spreadsheet, none of the numbers would be changingthere’s no new information being addedbut it doesn’t feel that way in our heads.” Overconfidence: “People think they know more than they do about how the future will unfold.”  The Heaths came up with a process to help us overcome these villains and make better choices. “We can’t deactivate our biases, but  we can counteract them with the right discipline.” The nature of each of the four decision-making villains suggests a strategy for how to defeat it. 1. You encounter a choice. But narrow framing makes you miss options. So  Widen Your Options. How can you expand your set of choices?  2. You analyze your options. But the confirmation bias leads you to gather self-serving information. So  Reality-Test Your Assumptions. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "The Four Villains of Decision Making",
					"article_url": "https://fs.blog/how-to-make-better-choices-in-life-and-work/",
					"content": "How can you get outside your head and collect information you can trust?  3. You make a choice. But short-term emotion will often tempt you to make the wrong one. So  Attain Distance Before Deciding. How can you overcome short-term emotion and conflicted feelings to make better choices?  4. Then you live with it. But you’ll often be overconfident about how the future will unfold. So  Prepare to Be Wrong. How can we plan for an uncertain future so that we give our decisions the best chance to succeed?  They call this WRAP. “At its core, the WRAP model urges you to switch from “auto spotlight” to manual spotlight. Source: Decisive All in all this was a great book. We focus our efforts on analysis. If a decision is wrong the analysis must have been the problem. ",
					"content_token": 181,
					"embedding": []
				},
				{
					"article_title": "The Four Villains of Decision Making",
					"article_url": "https://fs.blog/how-to-make-better-choices-in-life-and-work/",
					"content": "Not only does this ignore the fact that you can have bad outcomes’ with good decisions but it also places your spotlight on the analysis at the cost of the process by which the decision was made. Read this next: What Matters More in Decisions: Analysis or Process?",
					"content_token": 55,
					"embedding": []
				}
			]
		},
		{
			"title": "What Matters More in Decisions: Analysis or Process?",
			"url": "https://fs.blog/what-matters-more-in-decisions-analysis-or-process/",
			"content": "We all make decisions. Some of them are large and many of them are small. Few of us understand that the process we use to make those decisions is more important than the analysis we put into the decision.    Think of the last major decision you made. Maybe it was an acquisition, a large purchase, or perhaps it was whether to launch a new product. Odds are three things went into that decision: 1 It probably relied on the insights of a few key executives; 2 it involved some sort of fact gathering and analysis; and 3 it was likely enveloped in some sort of decision processwhether formal or informalthat translated the analysis into a decision. Now how would you rate the quality of your organization’s strategic decisions? If you’re like most executives, the answer wouldn’t be positive: In a recent McKinsey Quarterly survey of 2,207 executives, only 28 percent said that the quality of strategic decisions in their companies was generally good, 60 percent thought that bad decisions were about as frequent as good ones, and the remaining 12 percent thought good decisions were altogether infrequent. How could it be otherwise? Product launches are frequently behind schedule and over budget. Strategic plans often ignore even the anticipated response of competitors. Mergers routinely fail to live up to the promises made in press releases. The persistence of problems across time and organizations, both large and small, indicates that we can make better decisions. “I have no use whatsoever for projections or forecasts. They create an illusion of apparent precision. The more meticulous they are, the more concerned you should be. We never look at projections.”  Warren Buffett The best place to start if we’re trying to improve the quality of our decisions is to look at how organizations make decisions. One interesting thing about bureaucracies is that they develop processes to limit the damage the worst people can do at every level. That is they come up with mechanisms to reduce the impact the worst people can have. Yes, this also limits the positive impact that people can have as well. When it comes to decisions, organizations default to gathering data and analyzing decisions. The widespread belief is that analysis reduces biases. But does it? Is putting your faith in analysis any better than using your gut? What does the evidence say? Is there a better way? Dan Lovallo and Olivier Sibony set to find out. Lovallo is a professor at the University of Sydney and Olivier is a director at McKinsey  Company. Together they studied 1,048 “major” business decisions over five years. The results are surprising. Most business decisions were not made on “gut calls” but rather rigorous analysis. And yet they were poor decisions. In short, most people did the all the legwork we think we’re supposed to do: they delivered large quantities of detailed analysis. Yet this wasn’t enough. “Our research indicates that, contrary to what one might assume, good analysis in the hands of managers who have good judgment won’t naturally yield good decisions.” Projections are put together by people who have an interest in a particular outcome, have a subconscious bias, and its apparent precision makes it fallacious. They remind me of Mark Twain’s saying, A mine is a hole in the ground owned by a liar.’ Projections in America are often a lie, although not an intentional one, but the worst kind because the forecaster often believes them himself.”  Charlie Munger  Lovallo and Sibony didn’t only look at the analysis, they also asked executives about the process used to make decisions. Did they, for example, “explicitly explore and discuss major uncertainties or discuss viewpoints that contradicted the senior leader’s?” So what matters more, process or analysis? After comparing the results they determined that “process mattered more than analysisby a factor of six.” This finding does not mean that analysis is unimportant, as a closer look at the data reveals: almost no decisions in our sample made through a very strong process were backed by very poor analysis. Why? Because one of the things an unbiased decision-making process will do is ferret out poor analysis. The reverse is not true; superb analysis is useless unless the decision process gives it a fair hearing. To illustrate the weakness of how most organizations make decisions, Sibony used an interesting analogy: the legal system. Imagine walking into a courtroom where the trial consists of a prosecutor presenting PowerPoint slides. In 20 pretty compelling charts, he demonstrates why the defendant is guilty. The judge then challenges some of the facts of the presentation, but the prosecutor has a good answer to every objection. So the judge decides, and the accused man is sentenced. That wouldn’t be due process, right? So if you would find this process shocking in a courtroom, why is it acceptable when you make an investment decision? Now of course, this is an oversimplification, but this process is essentially the one most companies follow to make a decision. They have a team arguing only one side of the case. The team has a choice of what points it wants to make and what way it wants to make them. And it falls to the final decision maker to be both the challenger and the ultimate judge. Building a good decision-making process is largely ensuring that these flaws don’t happen. Simply understanding our cognitive biases doesn’t make you immune to them. It’s not enough.  A disciplined decision process is the best place to improve the quality of decisions and guard against common decision-making biases. Still curious? Read the ultimate guide to making smart decisions. ",
			"tokens": 1165,
			"chunks": [
				{
					"article_title": "What Matters More in Decisions: Analysis or Process?",
					"article_url": "https://fs.blog/what-matters-more-in-decisions-analysis-or-process/",
					"content": "We all make decisions. Some of them are large and many of them are small. Few of us understand that the process we use to make those decisions is more important than the analysis we put into the decision.    Think of the last major decision you made. Maybe it was an acquisition, a large purchase, or perhaps it was whether to launch a new product. Odds are three things went into that decision: 1 It probably relied on the insights of a few key executives; 2 it involved some sort of fact gathering and analysis; and 3 it was likely enveloped in some sort of decision processwhether formal or informalthat translated the analysis into a decision. ",
					"content_token": 136,
					"embedding": []
				},
				{
					"article_title": "What Matters More in Decisions: Analysis or Process?",
					"article_url": "https://fs.blog/what-matters-more-in-decisions-analysis-or-process/",
					"content": "Now how would you rate the quality of your organization’s strategic decisions? If you’re like most executives, the answer wouldn’t be positive: In a recent McKinsey Quarterly survey of 2,207 executives, only 28 percent said that the quality of strategic decisions in their companies was generally good, 60 percent thought that bad decisions were about as frequent as good ones, and the remaining 12 percent thought good decisions were altogether infrequent. How could it be otherwise? Product launches are frequently behind schedule and over budget. Strategic plans often ignore even the anticipated response of competitors. Mergers routinely fail to live up to the promises made in press releases. The persistence of problems across time and organizations, both large and small, indicates that we can make better decisions. “I have no use whatsoever for projections or forecasts. They create an illusion of apparent precision. The more meticulous they are, the more concerned you should be. ",
					"content_token": 189,
					"embedding": []
				},
				{
					"article_title": "What Matters More in Decisions: Analysis or Process?",
					"article_url": "https://fs.blog/what-matters-more-in-decisions-analysis-or-process/",
					"content": "We never look at projections.”  Warren Buffett The best place to start if we’re trying to improve the quality of our decisions is to look at how organizations make decisions. One interesting thing about bureaucracies is that they develop processes to limit the damage the worst people can do at every level. That is they come up with mechanisms to reduce the impact the worst people can have. Yes, this also limits the positive impact that people can have as well. When it comes to decisions, organizations default to gathering data and analyzing decisions. The widespread belief is that analysis reduces biases. But does it? Is putting your faith in analysis any better than using your gut? What does the evidence say? Is there a better way? Dan Lovallo and Olivier Sibony set to find out. Lovallo is a professor at the University of Sydney and Olivier is a director at McKinsey  Company. Together they studied 1,048 “major” business decisions over five years. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "What Matters More in Decisions: Analysis or Process?",
					"article_url": "https://fs.blog/what-matters-more-in-decisions-analysis-or-process/",
					"content": "The results are surprising. Most business decisions were not made on “gut calls” but rather rigorous analysis. And yet they were poor decisions. In short, most people did the all the legwork we think we’re supposed to do: they delivered large quantities of detailed analysis. Yet this wasn’t enough. “Our research indicates that, contrary to what one might assume, good analysis in the hands of managers who have good judgment won’t naturally yield good decisions.” Projections are put together by people who have an interest in a particular outcome, have a subconscious bias, and its apparent precision makes it fallacious. ",
					"content_token": 136,
					"embedding": []
				},
				{
					"article_title": "What Matters More in Decisions: Analysis or Process?",
					"article_url": "https://fs.blog/what-matters-more-in-decisions-analysis-or-process/",
					"content": "They remind me of Mark Twain’s saying, A mine is a hole in the ground owned by a liar.’ Projections in America are often a lie, although not an intentional one, but the worst kind because the forecaster often believes them himself.”  Charlie Munger  Lovallo and Sibony didn’t only look at the analysis, they also asked executives about the process used to make decisions. Did they, for example, “explicitly explore and discuss major uncertainties or discuss viewpoints that contradicted the senior leader’s?” So what matters more, process or analysis? After comparing the results they determined that “process mattered more than analysisby a factor of six.” This finding does not mean that analysis is unimportant, as a closer look at the data reveals: almost no decisions in our sample made through a very strong process were backed by very poor analysis. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "What Matters More in Decisions: Analysis or Process?",
					"article_url": "https://fs.blog/what-matters-more-in-decisions-analysis-or-process/",
					"content": "Why? Because one of the things an unbiased decision-making process will do is ferret out poor analysis. The reverse is not true; superb analysis is useless unless the decision process gives it a fair hearing. To illustrate the weakness of how most organizations make decisions, Sibony used an interesting analogy: the legal system. Imagine walking into a courtroom where the trial consists of a prosecutor presenting PowerPoint slides. In 20 pretty compelling charts, he demonstrates why the defendant is guilty. The judge then challenges some of the facts of the presentation, but the prosecutor has a good answer to every objection. So the judge decides, and the accused man is sentenced. That wouldn’t be due process, right? So if you would find this process shocking in a courtroom, why is it acceptable when you make an investment decision? Now of course, this is an oversimplification, but this process is essentially the one most companies follow to make a decision. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "What Matters More in Decisions: Analysis or Process?",
					"article_url": "https://fs.blog/what-matters-more-in-decisions-analysis-or-process/",
					"content": "They have a team arguing only one side of the case. The team has a choice of what points it wants to make and what way it wants to make them. And it falls to the final decision maker to be both the challenger and the ultimate judge. Building a good decision-making process is largely ensuring that these flaws don’t happen. Simply understanding our cognitive biases doesn’t make you immune to them. It’s not enough.  A disciplined decision process is the best place to improve the quality of decisions and guard against common decision-making biases. Still curious? Read the ultimate guide to making smart decisions.",
					"content_token": 129,
					"embedding": []
				}
			]
		},
		{
			"title": "Richard Zeckhauser on Making Better Decisions",
			"url": "https://fs.blog/richard-zeckhauser-decisions/",
			"content": "Richard Zeckhauser, aka Mr. Probability, is a champion Bridge player and the Frank Ramsey professor of political economy at Harvard University. Speaking about Zeckhauser, Charlie Munger, the brilliant business parter of Warren Buffett, said, “The right way to think is the way Zeckhauser plays bridge. It’s just that simple.” In an interview, Zeckhauser offers some insights on the craft of decision making about where to place your priorities and how to distinguish between various priorities. When asked how companies can prevent overpaying for acquisition, Zeckhauser responded: There is this tremendous optimism bias built into acquisitions. Synergies in my experience are frequently overstated. If I were looking at a large merger, I would hire a team in my corporation to present arguments to the board as to why we should not do it. The idea is to have a countervailing team to poke holes in the logic. Organizations have this tremendous tendency to get behind the boss and do what he thinks should be done, but you have to get away from that and motivate people to bring to the table something contrary to what is being said. That bit of wisdom applies to more than just corporate acquisitions. The problem is that people often blindly follow the boss and what she thinks should be done. The Hippo Problem.  The Highest Paid Person’s Opinion carries the day even if they are wrong. They are, after all, the authority figure. Stanley Milgram demonstrated our obedience to authority through a series of experiments. Milgram summarized his most famous experiment in a 1974 article, The Perils of Obedience, writing: I set up a simple experiment at Yale University to test how much pain an ordinary citizen would inflict on another person simply because he was ordered to by an experimental scientist. Stark authority was pitted against the subjects’ participants’ strongest moral imperatives against hurting others, and, with the subjects’ participants’ ears ringing with the screams of the victims, authority won more often than not. The extreme willingness of adults to go to almost any lengths on the command of an authority constitutes the chief finding of the study and the fact most urgently demanding explanation. Ordinary people, simply doing their jobs, and without any particular hostility on their part, can become agents in a terrible destructive process. Moreover, even when the destructive effects of their work become patently clear, and they are asked to carry out actions incompatible with fundamental standards of morality, relatively few people have the resources needed to resist authority Zeckhauser also commented on how we can make better decisions? One part of decision-making is about how to place your priorities. Let me tell you what I said to a group of investment professionals recently. They were making investments and were being introduced to five fund managers. I said, “You have 50 million to invest and you have five potential managers; that does not mean you have to give 10 million to each of these managers. If you really think that manager A is much better, you should probably give him 25m and the others much smaller amounts.” Then, you improve your odds. Here’s another example out of what I see in everyday life. You get 50 e-mails during the day and you answer 30 of them. On the one that you answer the most, you take 3 minutes. In all the others, you take 45 seconds. You should take 25 minutes to answer the one that is important, but you don’t. Once that is pointed out to you, you will say that is really obvious. In other words, you should decide what is really important and make your choices accordingly. The other thing is about distinguishing between various probabilities. I think of making decisions the way I play tennis. I have taken many tennis lessons and my trainer always tells me the same three or four things. Keep your eye on the ball, get into position, swing your racquet back and swing the ball. I pay him 75 to tell me “keep your eye on the ball” and he tells me the same thing over and over again because the natural tendency when you are playing tennis is to take your eye off the ball. The natural tendency when you are thinking about probabilistic situations is to marginalise probabilities  treat 1, 5, 10 and 15 probabilities all as low probabilities. I think it is worth your while before you take a decision to figure out whether it is going to be 1, 5, 10 or 20. And when it is worthwhile and when it is not. But most people don’t bother to do that. I am writing a paper today where we start off talking about President Obama’s assessment of the likelihood that Osama bin Laden was in the hideout where we found him to be. He had a variety of assessments and he eventually concluded well it was 50 likely that we were going to go get him. Now, there is nothing magical about 50. It might be that it is perfectly worthwhile to go and raid that compound if the probability is only 30. And maybe it is not worthwhile even if it is 70. Think about that. But people feel that 50 is magical and they don’t like to do things where they don’t have 50 odds. I know that is not a good idea, so I am willing to make some bets where you say it is 20 likely to work but you get a big pay-off if it works, and only has a small cost if it does not. I will take that gamble. Most successful investments in new companies are where the odds are against you but, if you succeed, you will succeed in a big way. To improve your ability to make better decisions and think probabilistically Zeckhauser recommends reading Thinking, Fast and Slow. If you’re looking for something less mainstream but equally insightful try Max Bazerman’s Judgment in Managerial Decision Making, which has been a favorite of mine for years.  Still curious? Zeckhauser is the author of a fascinating paper: Investing in the Unknown and Unknowable. Interview source: http:business.outlookindia.comarticle.aspx?283878 ",
			"tokens": 1264,
			"chunks": [
				{
					"article_title": "Richard Zeckhauser on Making Better Decisions",
					"article_url": "https://fs.blog/richard-zeckhauser-decisions/",
					"content": "Richard Zeckhauser, aka Mr. Probability, is a champion Bridge player and the Frank Ramsey professor of political economy at Harvard University. Speaking about Zeckhauser, Charlie Munger, the brilliant business parter of Warren Buffett, said, “The right way to think is the way Zeckhauser plays bridge. It’s just that simple.” In an interview, Zeckhauser offers some insights on the craft of decision making about where to place your priorities and how to distinguish between various priorities. When asked how companies can prevent overpaying for acquisition, Zeckhauser responded: There is this tremendous optimism bias built into acquisitions. Synergies in my experience are frequently overstated. If I were looking at a large merger, I would hire a team in my corporation to present arguments to the board as to why we should not do it. The idea is to have a countervailing team to poke holes in the logic. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "Richard Zeckhauser on Making Better Decisions",
					"article_url": "https://fs.blog/richard-zeckhauser-decisions/",
					"content": "Organizations have this tremendous tendency to get behind the boss and do what he thinks should be done, but you have to get away from that and motivate people to bring to the table something contrary to what is being said. That bit of wisdom applies to more than just corporate acquisitions. The problem is that people often blindly follow the boss and what she thinks should be done. The Hippo Problem.  The Highest Paid Person’s Opinion carries the day even if they are wrong. They are, after all, the authority figure. Stanley Milgram demonstrated our obedience to authority through a series of experiments. Milgram summarized his most famous experiment in a 1974 article, The Perils of Obedience, writing: I set up a simple experiment at Yale University to test how much pain an ordinary citizen would inflict on another person simply because he was ordered to by an experimental scientist. ",
					"content_token": 176,
					"embedding": []
				},
				{
					"article_title": "Richard Zeckhauser on Making Better Decisions",
					"article_url": "https://fs.blog/richard-zeckhauser-decisions/",
					"content": "Stark authority was pitted against the subjects’ participants’ strongest moral imperatives against hurting others, and, with the subjects’ participants’ ears ringing with the screams of the victims, authority won more often than not. The extreme willingness of adults to go to almost any lengths on the command of an authority constitutes the chief finding of the study and the fact most urgently demanding explanation. Ordinary people, simply doing their jobs, and without any particular hostility on their part, can become agents in a terrible destructive process. Moreover, even when the destructive effects of their work become patently clear, and they are asked to carry out actions incompatible with fundamental standards of morality, relatively few people have the resources needed to resist authority Zeckhauser also commented on how we can make better decisions? One part of decision-making is about how to place your priorities. Let me tell you what I said to a group of investment professionals recently. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "Richard Zeckhauser on Making Better Decisions",
					"article_url": "https://fs.blog/richard-zeckhauser-decisions/",
					"content": "They were making investments and were being introduced to five fund managers. I said, “You have 50 million to invest and you have five potential managers; that does not mean you have to give 10 million to each of these managers. If you really think that manager A is much better, you should probably give him 25m and the others much smaller amounts.” Then, you improve your odds. Here’s another example out of what I see in everyday life. You get 50 e-mails during the day and you answer 30 of them. On the one that you answer the most, you take 3 minutes. In all the others, you take 45 seconds. You should take 25 minutes to answer the one that is important, but you don’t. Once that is pointed out to you, you will say that is really obvious. In other words, you should decide what is really important and make your choices accordingly. The other thing is about distinguishing between various probabilities. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "Richard Zeckhauser on Making Better Decisions",
					"article_url": "https://fs.blog/richard-zeckhauser-decisions/",
					"content": "I think of making decisions the way I play tennis. I have taken many tennis lessons and my trainer always tells me the same three or four things. Keep your eye on the ball, get into position, swing your racquet back and swing the ball. I pay him 75 to tell me “keep your eye on the ball” and he tells me the same thing over and over again because the natural tendency when you are playing tennis is to take your eye off the ball. The natural tendency when you are thinking about probabilistic situations is to marginalise probabilities  treat 1, 5, 10 and 15 probabilities all as low probabilities. I think it is worth your while before you take a decision to figure out whether it is going to be 1, 5, 10 or 20. And when it is worthwhile and when it is not. But most people don’t bother to do that. ",
					"content_token": 182,
					"embedding": []
				},
				{
					"article_title": "Richard Zeckhauser on Making Better Decisions",
					"article_url": "https://fs.blog/richard-zeckhauser-decisions/",
					"content": "I am writing a paper today where we start off talking about President Obama’s assessment of the likelihood that Osama bin Laden was in the hideout where we found him to be. He had a variety of assessments and he eventually concluded well it was 50 likely that we were going to go get him. Now, there is nothing magical about 50. It might be that it is perfectly worthwhile to go and raid that compound if the probability is only 30. And maybe it is not worthwhile even if it is 70. Think about that. But people feel that 50 is magical and they don’t like to do things where they don’t have 50 odds. I know that is not a good idea, so I am willing to make some bets where you say it is 20 likely to work but you get a big pay-off if it works, and only has a small cost if it does not. I will take that gamble. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "Richard Zeckhauser on Making Better Decisions",
					"article_url": "https://fs.blog/richard-zeckhauser-decisions/",
					"content": "Most successful investments in new companies are where the odds are against you but, if you succeed, you will succeed in a big way. To improve your ability to make better decisions and think probabilistically Zeckhauser recommends reading Thinking, Fast and Slow. If you’re looking for something less mainstream but equally insightful try Max Bazerman’s Judgment in Managerial Decision Making, which has been a favorite of mine for years.  Still curious? Zeckhauser is the author of a fascinating paper: Investing in the Unknown and Unknowable. Interview source: http:business.outlookindia.comarticle.aspx?283878",
					"content_token": 136,
					"embedding": []
				}
			]
		},
		{
			"title": "Michael Mauboussin: Untangling Skill and Luck in Business, Sports, and Investing",
			"url": "https://fs.blog/untangling-skill-and-luck/",
			"content": "In The Success Equation: Untangling Skill and Luck in Business, Sports, and Investing, Michael Mauboussin goes beyond the general idea that luck is important to outcomes. He explains the type of interactions where luck is important and dives into why we have a difficult time comprehending the role of luck. “The basic challenge,” he writes, “is that we love stories narrative fallacy and have a yearning to understand the relationship between cause and effect. As a result, statistical reasoning is hard, and we start to view the past as something that was inevitable.” Mauboussin goes on to explain how we should untangle skill and luck so we can get a feel for where they fall on the luck-skill continuum. “Where an activity falls on that continuum,” he writes “provides a great deal of insight into how to deal with it.” Skill tends to follow an arc – improving, stagnating, and then ultimately going lower. In activities where the results are independent of one another, simple models effectively explain what we see. But when a past result affects a future result, predicting winners becomes very difficult. The most skillful don’t always win. Source: The Success Equation As a sports fan, I enjoyed the breakdown of the contribution of luck in some professional sports leagues: And something to keep in mind, “the contribution of luck has been rising steadily over time in most sports, which means that the players are all converging on an equal level of skill.” Although, this doesn’t apply to basketball. On automatic decision making, Mauboussin writes: The problem with this sort of automatic decision-making apparatus is that it only works under very specific circumstances. Intuition works when the environment is stable and an individual has the opportunity to spend a great deal of time learning about it. . . . Trouble arises when individuals rely too heavily on their experience in making automatic decisions. When we age, we tend to avoid exerting too much cognitive effort and deliberating extensively over a decision that needs to be made. We gradually come to rely more on rule of thumb. This means that we make poorer choices in environments that are complex and unstable. Organizations also lose skill with age. Probably the best explanation for why companies decline is that they fall prey to organizational rigidities. Companies must balance exploiting profitable markets with exploring new markets. Exploiting known markets requires optimizing processes and executing effectively, and leads to reliable, near-term successes. Exploring unknown markets requires search and experimentation and offers none of the immediate benefits of exploitation. Finding the best balance between exploration and exploitation depends on the rate of change in the environment. When change comes slowly, the balance can tilt toward exploitation. When it comes quickly, an organization must dedicate more resources to exploration, since profits are quickly exhausted. In general, companies tend to lean more on exploitation, which increases efficiency and profits in the short run but makes the company rigid, a state of affairs that only grows worse with age. Similar to aging individuals, companies rely on methods and rules of thumb that worked well in the past rather than embrace novelty. Companies, too, follow an arc of skill. The book is full of tips. Deliberate practice helps develop differentiating skill when only a little luck is involved in the outcome. That is, the larger the impact of skill on the outcome, the more effective deliberate practice becomes. On the other hand, “where luck is rampant,” he writes, “we must think of skill in terms of a process because the results don’t provide clear feedback.” Checklists, are also important because they guide behavior. Sometimes, of course, you want to defend against luck. If you’re a heavy favorite, you want to neutralize the other teams luck, so your aim should be to simplify the game. When you’re the underdog you want to make the game as complex as possible. Effort and strategy can compensate for skill. ",
			"tokens": 825,
			"chunks": [
				{
					"article_title": "Michael Mauboussin: Untangling Skill and Luck in Business, Sports, and Investing",
					"article_url": "https://fs.blog/untangling-skill-and-luck/",
					"content": "In The Success Equation: Untangling Skill and Luck in Business, Sports, and Investing, Michael Mauboussin goes beyond the general idea that luck is important to outcomes. He explains the type of interactions where luck is important and dives into why we have a difficult time comprehending the role of luck. “The basic challenge,” he writes, “is that we love stories narrative fallacy and have a yearning to understand the relationship between cause and effect. As a result, statistical reasoning is hard, and we start to view the past as something that was inevitable.” Mauboussin goes on to explain how we should untangle skill and luck so we can get a feel for where they fall on the luck-skill continuum. ",
					"content_token": 155,
					"embedding": []
				},
				{
					"article_title": "Michael Mauboussin: Untangling Skill and Luck in Business, Sports, and Investing",
					"article_url": "https://fs.blog/untangling-skill-and-luck/",
					"content": "“Where an activity falls on that continuum,” he writes “provides a great deal of insight into how to deal with it.” Skill tends to follow an arc – improving, stagnating, and then ultimately going lower. In activities where the results are independent of one another, simple models effectively explain what we see. But when a past result affects a future result, predicting winners becomes very difficult. The most skillful don’t always win. Source: The Success Equation As a sports fan, I enjoyed the breakdown of the contribution of luck in some professional sports leagues: And something to keep in mind, “the contribution of luck has been rising steadily over time in most sports, which means that the players are all converging on an equal level of skill.” Although, this doesn’t apply to basketball. ",
					"content_token": 175,
					"embedding": []
				},
				{
					"article_title": "Michael Mauboussin: Untangling Skill and Luck in Business, Sports, and Investing",
					"article_url": "https://fs.blog/untangling-skill-and-luck/",
					"content": "On automatic decision making, Mauboussin writes: The problem with this sort of automatic decision-making apparatus is that it only works under very specific circumstances. Intuition works when the environment is stable and an individual has the opportunity to spend a great deal of time learning about it.    Trouble arises when individuals rely too heavily on their experience in making automatic decisions. When we age, we tend to avoid exerting too much cognitive effort and deliberating extensively over a decision that needs to be made. We gradually come to rely more on rule of thumb. This means that we make poorer choices in environments that are complex and unstable. Organizations also lose skill with age. Probably the best explanation for why companies decline is that they fall prey to organizational rigidities. Companies must balance exploiting profitable markets with exploring new markets. Exploiting known markets requires optimizing processes and executing effectively, and leads to reliable, near-term successes. ",
					"content_token": 189,
					"embedding": []
				},
				{
					"article_title": "Michael Mauboussin: Untangling Skill and Luck in Business, Sports, and Investing",
					"article_url": "https://fs.blog/untangling-skill-and-luck/",
					"content": "Exploring unknown markets requires search and experimentation and offers none of the immediate benefits of exploitation. Finding the best balance between exploration and exploitation depends on the rate of change in the environment. When change comes slowly, the balance can tilt toward exploitation. When it comes quickly, an organization must dedicate more resources to exploration, since profits are quickly exhausted. In general, companies tend to lean more on exploitation, which increases efficiency and profits in the short run but makes the company rigid, a state of affairs that only grows worse with age. Similar to aging individuals, companies rely on methods and rules of thumb that worked well in the past rather than embrace novelty. Companies, too, follow an arc of skill. The book is full of tips. Deliberate practice helps develop differentiating skill when only a little luck is involved in the outcome. That is, the larger the impact of skill on the outcome, the more effective deliberate practice becomes. ",
					"content_token": 188,
					"embedding": []
				},
				{
					"article_title": "Michael Mauboussin: Untangling Skill and Luck in Business, Sports, and Investing",
					"article_url": "https://fs.blog/untangling-skill-and-luck/",
					"content": "On the other hand, “where luck is rampant,” he writes, “we must think of skill in terms of a process because the results don’t provide clear feedback.” Checklists, are also important because they guide behavior. Sometimes, of course, you want to defend against luck. If you’re a heavy favorite, you want to neutralize the other teams luck, so your aim should be to simplify the game. When you’re the underdog you want to make the game as complex as possible. Effort and strategy can compensate for skill.",
					"content_token": 121,
					"embedding": []
				}
			]
		},
		{
			"title": "An Ancient Lesson on Taking Responsibility For Decisions",
			"url": "https://fs.blog/philosophy-of-responsibility/",
			"content": "“A decision is responsible,” wrote Charles Frankel, “when the man or group that makes it has to answer for it to those who are directly or indirectly affected by it.” Think about that for a second. How often does that happen today? Not very often. In most organizations people don’t make decisions  committees do. Responsibility is diffused to a group, not the individual. Everyone is insulated from their mistakes. Everyone takes credit for success. The ancients had a way around this. Consider Hammurabi’s Code: If a builder builds a house for a man and does not make its construction firm, and the house which he has built collapses and causes the death of the owner of the house, that builder shall be put to death. While extreme, that is the best risk-management rule ever. If you have the upside, you have to keep the downside. The Roman System The Romans had a similar system. The guy who created the arch stood under it as the scaffolding was removed. And to some extent, we do the same thing today. No one packs your parachute for you. Charlie Munger, the partner of Warren Buffett at Berkshire Hathaway, puts it another way: Another thing that is never discussed any more is my idea of one of the great philosophers of America who was Charlie Frankel. He was mugged to death in due course because, after all, he lived in Manhattan in a different time. Before he was mugged to death, he created this philosophy of responsibility. He said the system is responsible in proportion to the degree that the people who make the decisions bear the consequences. So to Charlie Frankel, you don’t create a loan system where all the people who make the loans promptly dump them on somebody else through lies and twaddle, and they don’t bear the responsibility when the loans are good or bad. To Frankel, that is amoral, that is an irresponsible system. That is like selling an automobile with bad brakes and you know the brakes are bad. You shouldn’t do it. We’ve gotten away from responsibility for our decisions, which allows people to get all the upside and none of the downside. Is it any wonder why things go wrong? How can we implement better decisions in organizations? Make people stand under their own arches. One effective way to implement this is to make the person responsible for a decision sign their name to the decision. Simple and effective but not easy to implement. ",
			"tokens": 517,
			"chunks": [
				{
					"article_title": "An Ancient Lesson on Taking Responsibility For Decisions",
					"article_url": "https://fs.blog/philosophy-of-responsibility/",
					"content": "“A decision is responsible,” wrote Charles Frankel, “when the man or group that makes it has to answer for it to those who are directly or indirectly affected by it.” Think about that for a second. How often does that happen today? Not very often. In most organizations people don’t make decisions  committees do. Responsibility is diffused to a group, not the individual. Everyone is insulated from their mistakes. Everyone takes credit for success. The ancients had a way around this. Consider Hammurabi’s Code: If a builder builds a house for a man and does not make its construction firm, and the house which he has built collapses and causes the death of the owner of the house, that builder shall be put to death. While extreme, that is the best risk-management rule ever. If you have the upside, you have to keep the downside. The Roman System The Romans had a similar system. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "An Ancient Lesson on Taking Responsibility For Decisions",
					"article_url": "https://fs.blog/philosophy-of-responsibility/",
					"content": "The guy who created the arch stood under it as the scaffolding was removed. And to some extent, we do the same thing today. No one packs your parachute for you. Charlie Munger, the partner of Warren Buffett at Berkshire Hathaway, puts it another way: Another thing that is never discussed any more is my idea of one of the great philosophers of America who was Charlie Frankel. He was mugged to death in due course because, after all, he lived in Manhattan in a different time. Before he was mugged to death, he created this philosophy of responsibility. He said the system is responsible in proportion to the degree that the people who make the decisions bear the consequences. So to Charlie Frankel, you don’t create a loan system where all the people who make the loans promptly dump them on somebody else through lies and twaddle, and they don’t bear the responsibility when the loans are good or bad. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "An Ancient Lesson on Taking Responsibility For Decisions",
					"article_url": "https://fs.blog/philosophy-of-responsibility/",
					"content": "To Frankel, that is amoral, that is an irresponsible system. That is like selling an automobile with bad brakes and you know the brakes are bad. You shouldn’t do it. We’ve gotten away from responsibility for our decisions, which allows people to get all the upside and none of the downside. Is it any wonder why things go wrong? How can we implement better decisions in organizations? Make people stand under their own arches. One effective way to implement this is to make the person responsible for a decision sign their name to the decision. Simple and effective but not easy to implement.",
					"content_token": 125,
					"embedding": []
				}
			]
		},
		{
			"title": "Making Smart Choices: 8 Keys to Making Effective Decisions",
			"url": "https://fs.blog/making-smart-choices/",
			"content": "Making decisions is a fundamental life skill. Expecting to make perfect decisions all of the time is unreasonable. When even an ounce of luck is involved, good decisions can have bad outcomes. So our goal should be to raise the odds of making a good decision. The best way to do that is to use a good decision-making process. Smart Choices: A Practical Guide to Making Better Decisions contains an interesting decision-making framework: PrOACT. We have found that even the most complex decision can be analysed and resolved by considering a set of eight elements. The first fiveProblem, Objectives, Alternatives, Consequences, and Tradeoffsconstitute the core of our approach and are applicable to virtually any decision. The acronym for thesePrOACTserves as a reminder that the best approach to decision situations is a proactive one.  The three remaining elementsuncertainty, risk tolerance, and linked decisionshelp clarify decisions in volatile or evolving environments. This framework can help you make better decisions. Of course, sometimes good decisions go wrong. A good decision, however, increases the odds of success. There are eight keys to effective decision making. Work on the right decision problem.  The way you frame your decision at the outset can make all the difference. To choose well, you need to state your decision problems carefully, acknowledging their complexity and avoiding unwarranted assumptions and option-limiting prejudices.  Specify your objectives.  A decision is a means to an end. Ask yourself what you most want to accomplish and which of your interests, values, concerns, fears, and aspirations are most relevant to achieving your goal.  Decisions with multiple objectives cannot be resolved by focusing on any one objective.  Create imaginative alternatives.  Remember: your decision can be no better than your best alternative.  Understand the consequences.  Assessing frankly the consequences of each alternative will help you to identify those that best meet your objectivesall your objectives.  Grapple with your tradeoffs. Because objectives frequently conflict with one another, you’ll need to strike a balance. Some of this must sometimes be sacrifices in favor of some of that.  Clarify your uncertainties. What could happen in the future and how likely is it that it will?  Think hard about your risk tolerance. When decisions involve uncertainties, the desired consequence may not be the one that actually results. A much-deliberated bone marrow transplant may or may not halt cancer.  Consider linked decisions. What you decide today could influence your choices tomorrow, and your goals for tomorrow should influence your choices today. Thus many important decisions are linked over time.  Harvard Professor Max Bazerman, who has written extensively human misjudgment, suggests something very similar to this approach in his book Judgment in Management Decision Making when he explains the anatomy of decisions. Before we can fully understand judgment, we have to identify the components of the decision-making process that require it. Here are the six steps that Bazerman aruges you should take, either implicitly or explicitly, when applying a rational decision-making process. 1. Define the problem. Managers often act without a thorough understanding of the problem to be solved, leading them to solve the wrong problem. Accurate judgment is required to identify and define the problem. Managers often err by a defining the problem in terms of a proposed solution, b missing a bigger problem, or c diagnosing the problem in terms of its symptoms. Your goal should be to solve the problem not just eliminate its temporary symptoms. 2. Identify the criteria. Most decisions require you to accomplish more than one objective. When buying a car, you may want to maximize fuel economy, minimize cost, maximize comfort, and so on. The rational decision maker will identify all relevant criteria in the decision-making process. 3. Weight the criteria. Different criteria will vary in importance to a decision maker. Rational decision makers will know the relative value they place on each of the criteria identified. The value may be specified in dollars, points, or whatever scoring system makes sense. 4. Generate alternatives. The fourth step in the decision-making process requires identification of possible courses of action. Decision makers often spend an inappropriate amount of search time seeking alternatives, thus creating a barrier to effective decision making. An optimal search continues only until the cost of the search outweighs the value of added information. 5. Rate each alternative on each criterion. How well will each of the alternative solutions achieve each of the defined criteria? This is often the most difficult stage of the decision-making process, as it typically requires us to forecast future events. The rational decision maker carefully assesses the potential consequences on each of the identified criteria of selecting each of the alternative solutions. 6. Compute the optimal decision. Ideally, after all of the first five steps have been completed, the process of computing the optimal decision consists of a multiplying the ratings in step 5 by the weight of each criterion, b adding up the weighted ratings across all of the criteria for each alternative, and c choosing the solution with the highest sum of weighted ratings. Rational decision frameworks, such as those suggested above, are a great starting place. On top of that, we need to consider our psychological biases. And keep a decision journal. ",
			"tokens": 1071,
			"chunks": [
				{
					"article_title": "Making Smart Choices: 8 Keys to Making Effective Decisions",
					"article_url": "https://fs.blog/making-smart-choices/",
					"content": "Making decisions is a fundamental life skill. Expecting to make perfect decisions all of the time is unreasonable. When even an ounce of luck is involved, good decisions can have bad outcomes. So our goal should be to raise the odds of making a good decision. The best way to do that is to use a good decision-making process. Smart Choices: A Practical Guide to Making Better Decisions contains an interesting decision-making framework: PrOACT. We have found that even the most complex decision can be analysed and resolved by considering a set of eight elements. The first fiveProblem, Objectives, Alternatives, Consequences, and Tradeoffsconstitute the core of our approach and are applicable to virtually any decision. The acronym for thesePrOACTserves as a reminder that the best approach to decision situations is a proactive one.  The three remaining elementsuncertainty, risk tolerance, and linked decisionshelp clarify decisions in volatile or evolving environments. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "Making Smart Choices: 8 Keys to Making Effective Decisions",
					"article_url": "https://fs.blog/making-smart-choices/",
					"content": "This framework can help you make better decisions. Of course, sometimes good decisions go wrong. A good decision, however, increases the odds of success. There are eight keys to effective decision making. Work on the right decision problem.  The way you frame your decision at the outset can make all the difference. To choose well, you need to state your decision problems carefully, acknowledging their complexity and avoiding unwarranted assumptions and option-limiting prejudices.  Specify your objectives.  A decision is a means to an end. Ask yourself what you most want to accomplish and which of your interests, values, concerns, fears, and aspirations are most relevant to achieving your goal.  Decisions with multiple objectives cannot be resolved by focusing on any one objective.  Create imaginative alternatives.  Remember: your decision can be no better than your best alternative.  Understand the consequences.  Assessing frankly the consequences of each alternative will help you to identify those that best meet your objectivesall your objectives. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "Making Smart Choices: 8 Keys to Making Effective Decisions",
					"article_url": "https://fs.blog/making-smart-choices/",
					"content": " Grapple with your tradeoffs. Because objectives frequently conflict with one another, you’ll need to strike a balance. Some of this must sometimes be sacrifices in favor of some of that.  Clarify your uncertainties. What could happen in the future and how likely is it that it will?  Think hard about your risk tolerance. When decisions involve uncertainties, the desired consequence may not be the one that actually results. A much-deliberated bone marrow transplant may or may not halt cancer.  Consider linked decisions. What you decide today could influence your choices tomorrow, and your goals for tomorrow should influence your choices today. Thus many important decisions are linked over time.  Harvard Professor Max Bazerman, who has written extensively human misjudgment, suggests something very similar to this approach in his book Judgment in Management Decision Making when he explains the anatomy of decisions. ",
					"content_token": 180,
					"embedding": []
				},
				{
					"article_title": "Making Smart Choices: 8 Keys to Making Effective Decisions",
					"article_url": "https://fs.blog/making-smart-choices/",
					"content": "Before we can fully understand judgment, we have to identify the components of the decision-making process that require it. Here are the six steps that Bazerman aruges you should take, either implicitly or explicitly, when applying a rational decision-making process. 1. Define the problem. Managers often act without a thorough understanding of the problem to be solved, leading them to solve the wrong problem. Accurate judgment is required to identify and define the problem. Managers often err by a defining the problem in terms of a proposed solution, b missing a bigger problem, or c diagnosing the problem in terms of its symptoms. Your goal should be to solve the problem not just eliminate its temporary symptoms. 2. Identify the criteria. Most decisions require you to accomplish more than one objective. When buying a car, you may want to maximize fuel economy, minimize cost, maximize comfort, and so on. The rational decision maker will identify all relevant criteria in the decision-making process. ",
					"content_token": 201,
					"embedding": []
				},
				{
					"article_title": "Making Smart Choices: 8 Keys to Making Effective Decisions",
					"article_url": "https://fs.blog/making-smart-choices/",
					"content": "3. Weight the criteria. Different criteria will vary in importance to a decision maker. Rational decision makers will know the relative value they place on each of the criteria identified. The value may be specified in dollars, points, or whatever scoring system makes sense. 4. Generate alternatives. The fourth step in the decision-making process requires identification of possible courses of action. Decision makers often spend an inappropriate amount of search time seeking alternatives, thus creating a barrier to effective decision making. An optimal search continues only until the cost of the search outweighs the value of added information. 5. Rate each alternative on each criterion. How well will each of the alternative solutions achieve each of the defined criteria? This is often the most difficult stage of the decision-making process, as it typically requires us to forecast future events. The rational decision maker carefully assesses the potential consequences on each of the identified criteria of selecting each of the alternative solutions. 6. Compute the optimal decision. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "Making Smart Choices: 8 Keys to Making Effective Decisions",
					"article_url": "https://fs.blog/making-smart-choices/",
					"content": "Ideally, after all of the first five steps have been completed, the process of computing the optimal decision consists of a multiplying the ratings in step 5 by the weight of each criterion, b adding up the weighted ratings across all of the criteria for each alternative, and c choosing the solution with the highest sum of weighted ratings. Rational decision frameworks, such as those suggested above, are a great starting place. On top of that, we need to consider our psychological biases. And keep a decision journal.",
					"content_token": 100,
					"embedding": []
				}
			]
		},
		{
			"title": "Why Bad Things Happen to Good Decisions",
			"url": "https://fs.blog/bad-things-good-decisions/",
			"content": "Good decisions don’t always have a good outcome, just as bad decisions don’t always have bad outcomes. Sometimes bad outcomes happen to good decisions. And sometimes good things happen to bad decisions. Learning to distinguish between when you’re brilliant and lucky is the key to rapid improvement. When other people make decisions with bad outcomes, we tend to focus on the people behind the decision. We can’t seem to shake the belief that good people make good decisions and bad people make bad decisions. It’s easy to think that we would have made a better decision. When our decisions have bad outcomes, we know the outcomes is not all there is to see. Our thoughts and intentions come into play. We can’t see the thoughts and intentions of otherswe only see their actions through a biased lens. We can, however, see our thoughts and intentions. Our bad outcomes happen because we were unlucky. The Decision Outcome Matrix Consider this simple two-by-two decision outcome matrix.  We want to deserve success. Everyone wants to be in the upper left box   a good process that results in a good outcome. The problem is the world doesn’t always comply with our wishes. Following a good process can lead to a bad outcome because of uncertainty. A good process with a bad outcome requires that we remember nothing is for sure. Bad outcomes from a bad process require a choice. If we are delusional and let our ego dominate, we mistakenly see this as bad luck. While we are aware that we had a negative outcome, we are unaware that it resulted from a bad process. In this case, we learn nothing.  We are doomed to repeat our mistakes. More self-reflective people see bad outcomes resulting from bad process as an opportunity to learn as much as we can to avoid repeat failures. Perhaps the worst quadrant to be in it the lower left  a bad process leads to a good outcome. Ignoring the fact that this isn’t repeatable, we convince ourselves that we deserved success. If you can’t recognize when you’ve had dumb luck,’ you’ll never be in a position to correct the way you’re making decisions. Eventually, your luck runs out. Of course, it’s easier to place others into the matrix than ourselves. When it comes to others, we see more of reality because we’re a disconnected observer. When it comes to ourselves, however, we default to ego protection. One of the ways to calibrate your decisions is to use a decision journal. A good decision is known before the outcome. It involves a mental representation of the facts known at the time as well as applied judgment. Good decisions are valuable, but they are more valuable if they are part of a good decision process because a good process allows for feedback about where you can improve. This feedback, in turn, allows you to constantly get better at making decisions. Article Summary:  Good decisions don’t always have a good outcome. Bad decisions don’t always have bad outcomes. Bad outcomes can happen to good decisions. When other people have a bad outcome, we tend to think they made a bad decision. When we have a bad outcome, we tend to focus on intentions. There is a simple 22 matrix to help you see what happened. On one axis is GoodBad Process, on the other is goodbad outcome. A bad process with a good outcome is gambling and winning. This is the most dangerous quadrant. A bad process with a bad outcome is gambling and losing. A good process with a bad outcome needs to be put into perspective. You can calibrate your decisions using a decision journal.  ",
			"tokens": 759,
			"chunks": [
				{
					"article_title": "Why Bad Things Happen to Good Decisions",
					"article_url": "https://fs.blog/bad-things-good-decisions/",
					"content": "Good decisions don’t always have a good outcome, just as bad decisions don’t always have bad outcomes. Sometimes bad outcomes happen to good decisions. And sometimes good things happen to bad decisions. Learning to distinguish between when you’re brilliant and lucky is the key to rapid improvement. When other people make decisions with bad outcomes, we tend to focus on the people behind the decision. We can’t seem to shake the belief that good people make good decisions and bad people make bad decisions. It’s easy to think that we would have made a better decision. When our decisions have bad outcomes, we know the outcomes is not all there is to see. Our thoughts and intentions come into play. We can’t see the thoughts and intentions of otherswe only see their actions through a biased lens. We can, however, see our thoughts and intentions. Our bad outcomes happen because we were unlucky. ",
					"content_token": 190,
					"embedding": []
				},
				{
					"article_title": "Why Bad Things Happen to Good Decisions",
					"article_url": "https://fs.blog/bad-things-good-decisions/",
					"content": "The Decision Outcome Matrix Consider this simple two-by-two decision outcome matrix.  We want to deserve success. Everyone wants to be in the upper left box   a good process that results in a good outcome. The problem is the world doesn’t always comply with our wishes. Following a good process can lead to a bad outcome because of uncertainty. A good process with a bad outcome requires that we remember nothing is for sure. Bad outcomes from a bad process require a choice. If we are delusional and let our ego dominate, we mistakenly see this as bad luck. While we are aware that we had a negative outcome, we are unaware that it resulted from a bad process. In this case, we learn nothing.  We are doomed to repeat our mistakes. More self-reflective people see bad outcomes resulting from bad process as an opportunity to learn as much as we can to avoid repeat failures. ",
					"content_token": 185,
					"embedding": []
				},
				{
					"article_title": "Why Bad Things Happen to Good Decisions",
					"article_url": "https://fs.blog/bad-things-good-decisions/",
					"content": "Perhaps the worst quadrant to be in it the lower left  a bad process leads to a good outcome. Ignoring the fact that this isn’t repeatable, we convince ourselves that we deserved success. If you can’t recognize when you’ve had dumb luck,’ you’ll never be in a position to correct the way you’re making decisions. Eventually, your luck runs out. Of course, it’s easier to place others into the matrix than ourselves. When it comes to others, we see more of reality because we’re a disconnected observer. When it comes to ourselves, however, we default to ego protection. One of the ways to calibrate your decisions is to use a decision journal. A good decision is known before the outcome. It involves a mental representation of the facts known at the time as well as applied judgment. ",
					"content_token": 184,
					"embedding": []
				},
				{
					"article_title": "Why Bad Things Happen to Good Decisions",
					"article_url": "https://fs.blog/bad-things-good-decisions/",
					"content": "Good decisions are valuable, but they are more valuable if they are part of a good decision process because a good process allows for feedback about where you can improve. This feedback, in turn, allows you to constantly get better at making decisions. Article Summary:  Good decisions don’t always have a good outcome. Bad decisions don’t always have bad outcomes. Bad outcomes can happen to good decisions. When other people have a bad outcome, we tend to think they made a bad decision. When we have a bad outcome, we tend to focus on intentions. There is a simple 22 matrix to help you see what happened. On one axis is GoodBad Process, on the other is goodbad outcome. A bad process with a good outcome is gambling and winning. This is the most dangerous quadrant. A bad process with a bad outcome is gambling and losing. A good process with a bad outcome needs to be put into perspective. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "Why Bad Things Happen to Good Decisions",
					"article_url": "https://fs.blog/bad-things-good-decisions/",
					"content": "You can calibrate your decisions using a decision journal.",
					"content_token": 11,
					"embedding": []
				}
			]
		},
		{
			"title": "Michael Mauboussin: Two Tips to Improve The Quality of Your Decisions",
			"url": "https://fs.blog/how-to-improve-the-quality-of-our-decision-making/",
			"content": "Michael Mauboussin, chief investment strategist at Legg Mason and our first interview on the podcast, offers two simple techniques to improve the quality of your decision making: a decision journal and a checklist. 1. Create a decision journal and starting using it.  Many years ago when I first met Danny Kahneman, and Kahneman is one of the preeminent psychologists in the world who won a Nobel Prize for economics in 2002, even though he’s never taught an economics class. When I pose him the question, what is a single thing an investor can do to improve his or her performance, he said almost without hesitation, go down to a local drugstore and buy a very cheap notebook and start keeping track of your decisions. And the specific idea is whenever you’re making a consequential decision, something going in or out of the portfolio, just take a moment to think, write down what you expect to happen, why you expect it to happen and then actually, and this is optional, but probably a great idea, is write down how you feel about the situation, both physically and even emotionally. Just, how do you feel? I feel tired. I feel good, or this stock is really draining me. Whatever you think. The key to doing this is that it prevents something called hindsight bias, which is no matter what happens in the world. We tend to look back on our decision-making process, and we tilt it in a way that looks more favorable to us, right? So we have a bias to explain what has happened. When you’ve got a decision-making journal, it gives you accurate and honest feedback of what you were thinking at that time. And so there can be situations, by the way, you buy a stock and it goes up, but it goes up for reasons very different than what you thought was going to happen. And having that feedback in a way to almost check yourself periodically is extremely valuable. So that’s, I think, a very inexpensive; it’s actually not super time consuming, but a very, very valuable way of giving yourself essential feedback because our minds won’t do it normally. 2. Use a checklist.  Mauboussin: So the best work on this I’ve seen is by Atul Gawande, who is a surgeon in Boston who wrote a book a couple of years ago called The Checklist Manifesto, and one of the points he makes in there is that when you go from field to field, wherever checklists have been used correctly and with fidelity, they’ve been extremely effective in proving outcomes. So we all know none of us would step on an airplane today without the pilot having gone through the checklist. It’s been a big move into medicine, especially for example, in surgery where checklists have really made substantial inroads in reducing infections, for example, and hence mortality, and other areas like construction elsewhere. So the question is, how do you become more systematic in applying what you know? And I’ll just mention one other thing on this. There are two; Gawande talks about two kinds of checklists. By the way, this branch is right out of aviation. One is called a do-confirm checklist, a do-confirm, and that just basically says, Hey, just do your normal analysis the way you’ve always done it and been trained to do that, but stop periodically just to confirm that you’ve covered all the bases. So as an analyst that might say, hey, I’m going to do a really thorough evaluation work. I might look very carefully at return on capital trends. I might study the competitive strategy position. You are just going to do all that stuff, but you’re going to stop every now and then, just to check to make sure you’ve done everything. The second one is called, the second kind of checklist, is called a read-do checklist. This is when you get into a difficult situation, for example you’re a pilot and one of your engines goes out, the redo will guide how you should approach that problem. So you don’t have to think about it so much, you just sort of go through it systematically. And so for an investor that might be hey, what happens when a company misses a quarter? What happens when they have a negative announcement or an executive departure? Sometimes that means sell the stock. Sometimes that means buy more. Sometimes it means do nothing, and a read-do checklist can help guide some of that thinking as well. So it’s really a way to be structured and consistent in your analysis. ",
			"tokens": 964,
			"chunks": [
				{
					"article_title": "Michael Mauboussin: Two Tips to Improve The Quality of Your Decisions",
					"article_url": "https://fs.blog/how-to-improve-the-quality-of-our-decision-making/",
					"content": "Michael Mauboussin, chief investment strategist at Legg Mason and our first interview on the podcast, offers two simple techniques to improve the quality of your decision making: a decision journal and a checklist. 1. Create a decision journal and starting using it.  Many years ago when I first met Danny Kahneman, and Kahneman is one of the preeminent psychologists in the world who won a Nobel Prize for economics in 2002, even though he’s never taught an economics class. When I pose him the question, what is a single thing an investor can do to improve his or her performance, he said almost without hesitation, go down to a local drugstore and buy a very cheap notebook and start keeping track of your decisions. ",
					"content_token": 152,
					"embedding": []
				},
				{
					"article_title": "Michael Mauboussin: Two Tips to Improve The Quality of Your Decisions",
					"article_url": "https://fs.blog/how-to-improve-the-quality-of-our-decision-making/",
					"content": "And the specific idea is whenever you’re making a consequential decision, something going in or out of the portfolio, just take a moment to think, write down what you expect to happen, why you expect it to happen and then actually, and this is optional, but probably a great idea, is write down how you feel about the situation, both physically and even emotionally. Just, how do you feel? I feel tired. I feel good, or this stock is really draining me. Whatever you think. The key to doing this is that it prevents something called hindsight bias, which is no matter what happens in the world. We tend to look back on our decision-making process, and we tilt it in a way that looks more favorable to us, right? So we have a bias to explain what has happened. When you’ve got a decision-making journal, it gives you accurate and honest feedback of what you were thinking at that time. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "Michael Mauboussin: Two Tips to Improve The Quality of Your Decisions",
					"article_url": "https://fs.blog/how-to-improve-the-quality-of-our-decision-making/",
					"content": "And so there can be situations, by the way, you buy a stock and it goes up, but it goes up for reasons very different than what you thought was going to happen. And having that feedback in a way to almost check yourself periodically is extremely valuable. So that’s, I think, a very inexpensive; it’s actually not super time consuming, but a very, very valuable way of giving yourself essential feedback because our minds won’t do it normally. 2. Use a checklist.  Mauboussin: So the best work on this I’ve seen is by Atul Gawande, who is a surgeon in Boston who wrote a book a couple of years ago called The Checklist Manifesto, and one of the points he makes in there is that when you go from field to field, wherever checklists have been used correctly and with fidelity, they’ve been extremely effective in proving outcomes. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "Michael Mauboussin: Two Tips to Improve The Quality of Your Decisions",
					"article_url": "https://fs.blog/how-to-improve-the-quality-of-our-decision-making/",
					"content": "So we all know none of us would step on an airplane today without the pilot having gone through the checklist. It’s been a big move into medicine, especially for example, in surgery where checklists have really made substantial inroads in reducing infections, for example, and hence mortality, and other areas like construction elsewhere. So the question is, how do you become more systematic in applying what you know? And I’ll just mention one other thing on this. There are two; Gawande talks about two kinds of checklists. By the way, this branch is right out of aviation. One is called a do-confirm checklist, a do-confirm, and that just basically says, Hey, just do your normal analysis the way you’ve always done it and been trained to do that, but stop periodically just to confirm that you’ve covered all the bases. ",
					"content_token": 184,
					"embedding": []
				},
				{
					"article_title": "Michael Mauboussin: Two Tips to Improve The Quality of Your Decisions",
					"article_url": "https://fs.blog/how-to-improve-the-quality-of-our-decision-making/",
					"content": "So as an analyst that might say, hey, I’m going to do a really thorough evaluation work. I might look very carefully at return on capital trends. I might study the competitive strategy position. You are just going to do all that stuff, but you’re going to stop every now and then, just to check to make sure you’ve done everything. The second one is called, the second kind of checklist, is called a read-do checklist. This is when you get into a difficult situation, for example you’re a pilot and one of your engines goes out, the redo will guide how you should approach that problem. So you don’t have to think about it so much, you just sort of go through it systematically. And so for an investor that might be hey, what happens when a company misses a quarter? What happens when they have a negative announcement or an executive departure? Sometimes that means sell the stock. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "Michael Mauboussin: Two Tips to Improve The Quality of Your Decisions",
					"article_url": "https://fs.blog/how-to-improve-the-quality-of-our-decision-making/",
					"content": "Sometimes that means buy more. Sometimes it means do nothing, and a read-do checklist can help guide some of that thinking as well. So it’s really a way to be structured and consistent in your analysis.",
					"content_token": 45,
					"embedding": []
				}
			]
		},
		{
			"title": "Benjamin Franklin’s Rule for Making Decisions",
			"url": "https://fs.blog/benjamin-franklins-rule-for-decision-making/",
			"content": "When Charles Darwin set out to marry, he employed a technique pioneered half a century earlier by Ben Franklin. Despite his importance, the prolific Franklin often gave his practical wisdom to many of those who asked.  In the summer of 1772, Franklin received a letter from his friend, the English scientist, Joseph Priestley. Priestley was torn between relinquishing his position as the minister of the fame Unitarian church Mill Hill Chapel in Leeds and accepting a lucrative position as the general assistant to the Earl of Shelburne.  Like many of us faced with such a choice, Priestley was torn and turned to a friend for advice. Rather than simply offering advice on this particular choice, Franklin taught him something much more valuable: how to choose. By giving Priestley the simple mathematics of decision making, Franklin created what is now known as the pros and cons framework.  Franklin writes: In the Affair of so much Importance to you, wherein you ask my Advice, I cannot for want of sufficient Premises, advise you what to determine, but if you please I will tell you how. When these difficult Cases occur, they are difficult chiefly because while we have them under Consideration all the Reasons pro and con are not present to the Mind at the same time; but sometimes one Set present themselves, and at other times another, the first being out of Sight. Hence the various Purposes or Inclinations that alternately prevail, and the Uncertainty that perplexes us. To get over this, my Way is, to divide half a Sheet of Paper by a Line into two Columns, writing over the one Pro, and over the other Con. Then during three or four Days Consideration I put down under the different Heads short Hints of the different Motives that at different Times occur to me for or against the Measure. When I have thus got them all together in one View, I endeavour to estimate their respective Weights; and where I find two, one on each side, that seem equal, I strike them both out: If I find a Reason pro equal to some two Reasons con, I strike out the three. If I judge some two Reasons con equal to some three Reasons pro, I strike out the five; and thus proceeding I find at length where the Ballance lies; and if after a Day or two of farther Consideration nothing new that is of Importance occurs on either side, I come to a Determination accordingly. And tho’ the Weight of Reasons cannot be taken with the Precision of Algebraic Quantities, yet when each is thus considered separately and comparatively, and the whole lies before me, I think I can judge better, and am less likely to take a rash Step; and in fact I have found great Advantage from this kind of Equation, in what may be called Moral or Prudential Algebra. Priestley accepted the position and science never looked back.  ",
			"tokens": 592,
			"chunks": [
				{
					"article_title": "Benjamin Franklin’s Rule for Making Decisions",
					"article_url": "https://fs.blog/benjamin-franklins-rule-for-decision-making/",
					"content": "When Charles Darwin set out to marry, he employed a technique pioneered half a century earlier by Ben Franklin. Despite his importance, the prolific Franklin often gave his practical wisdom to many of those who asked.  In the summer of 1772, Franklin received a letter from his friend, the English scientist, Joseph Priestley. Priestley was torn between relinquishing his position as the minister of the fame Unitarian church Mill Hill Chapel in Leeds and accepting a lucrative position as the general assistant to the Earl of Shelburne.  Like many of us faced with such a choice, Priestley was torn and turned to a friend for advice. Rather than simply offering advice on this particular choice, Franklin taught him something much more valuable: how to choose. By giving Priestley the simple mathematics of decision making, Franklin created what is now known as the pros and cons framework. ",
					"content_token": 174,
					"embedding": []
				},
				{
					"article_title": "Benjamin Franklin’s Rule for Making Decisions",
					"article_url": "https://fs.blog/benjamin-franklins-rule-for-decision-making/",
					"content": " Franklin writes: In the Affair of so much Importance to you, wherein you ask my Advice, I cannot for want of sufficient Premises, advise you what to determine, but if you please I will tell you how. When these difficult Cases occur, they are difficult chiefly because while we have them under Consideration all the Reasons pro and con are not present to the Mind at the same time; but sometimes one Set present themselves, and at other times another, the first being out of Sight. Hence the various Purposes or Inclinations that alternately prevail, and the Uncertainty that perplexes us. To get over this, my Way is, to divide half a Sheet of Paper by a Line into two Columns, writing over the one Pro, and over the other Con. Then during three or four Days Consideration I put down under the different Heads short Hints of the different Motives that at different Times occur to me for or against the Measure. ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "Benjamin Franklin’s Rule for Making Decisions",
					"article_url": "https://fs.blog/benjamin-franklins-rule-for-decision-making/",
					"content": "When I have thus got them all together in one View, I endeavour to estimate their respective Weights; and where I find two, one on each side, that seem equal, I strike them both out: If I find a Reason pro equal to some two Reasons con, I strike out the three. If I judge some two Reasons con equal to some three Reasons pro, I strike out the five; and thus proceeding I find at length where the Ballance lies; and if after a Day or two of farther Consideration nothing new that is of Importance occurs on either side, I come to a Determination accordingly. ",
					"content_token": 126,
					"embedding": []
				},
				{
					"article_title": "Benjamin Franklin’s Rule for Making Decisions",
					"article_url": "https://fs.blog/benjamin-franklins-rule-for-decision-making/",
					"content": "And tho’ the Weight of Reasons cannot be taken with the Precision of Algebraic Quantities, yet when each is thus considered separately and comparatively, and the whole lies before me, I think I can judge better, and am less likely to take a rash Step; and in fact I have found great Advantage from this kind of Equation, in what may be called Moral or Prudential Algebra. Priestley accepted the position and science never looked back.",
					"content_token": 94,
					"embedding": []
				}
			]
		},
		{
			"title": "Can Waiting Help You Make Better Decisions?",
			"url": "https://fs.blog/can-waiting-help-you-make-better-decisions/",
			"content": "Great article in the financial times with the subtitle: Watching the world’s best tennis players at Wimbledon over the next fortnight can help us make better decisions. Here is what I learnt from interviewing more than 100 experts in different fields and working through several hundred recent studies and experiments: given the fast pace of modern life, most of us tend to react too quickly. We don’t, or can’t, take enough time to think about the increasingly complex timing challenges we face. Technology surrounds us, speeding us up. We overreact to its crush every day, both at work and at home.  And One of the most surprising aspects of Lehman’s collapse was that the firm’s leaders had tried so hard to understand the problems associated with their own decision-making. In autumn 2005, Lehman’s senior managers hired a group of experts to teach four dozen top executives how to make better decisions. Max H Bazerman, a chaired professor at Harvard Business School, reviewed cutting-edge decision research. Mahzarin Banaji, a Harvard psychologist, administered custom-designed tests to help the executives understand their biases. Malcolm Gladwell, who had just published Blink, a bestseller about the “first two seconds” of our reactions, gave the capstone lecture. These managers sat for a cutting-edge course on the timing of decisions. Then, they rushed back to their offices and made some of the worst decisions in the history of financial markets. Three years later, their firm was gone. If Lehman had lived until today, its decision-making course would look radically different. The core message of recent research is the opposite of the one Lehman’s executives learnt in 2005: the longer we can wait, the better. And once we have a sense of how long a decision should take, we generally should delay the moment of decision until the last possible instant. If we have an hour, we should wait 59 minutes before responding. If we have a year, we should wait 364 days. Even if we have just half a second, we should wait as long as we possibly can. As the matches at Wimbledon will illustrate, even milliseconds matter. Thinking about the role of delay is a profound and fundamental part of being human. Questions about delay are existential: the amount of time we take to reflect on decisions will define who we are. Is our mission simply to be another animal, responding to whatever stimulations we encounter? Or are we here for something more? Life might be a race against time but it is enriched when we rise above our instincts and stop the clock to process and understand what we are doing and why. A wise decision requires reflection, and reflection requires a pause. If we are limited to just one word of wisdom about decision-making for children born a hundred years from now, people who will have all our advantages and limitations as human beings but will need to navigate an unimaginably faster-paced world than the one we confront now, there is no doubt what that word should be. Wait.    Still curious? Steven Sample talks about waiting as long as possible to make decisions in the excellent Contrarian’s Guide to Leadership. Also check out Wait: The Art and Science of Delay.      ",
			"tokens": 669,
			"chunks": [
				{
					"article_title": "Can Waiting Help You Make Better Decisions?",
					"article_url": "https://fs.blog/can-waiting-help-you-make-better-decisions/",
					"content": "Great article in the financial times with the subtitle: Watching the world’s best tennis players at Wimbledon over the next fortnight can help us make better decisions. Here is what I learnt from interviewing more than 100 experts in different fields and working through several hundred recent studies and experiments: given the fast pace of modern life, most of us tend to react too quickly. We don’t, or can’t, take enough time to think about the increasingly complex timing challenges we face. Technology surrounds us, speeding us up. We overreact to its crush every day, both at work and at home.  And One of the most surprising aspects of Lehman’s collapse was that the firm’s leaders had tried so hard to understand the problems associated with their own decision-making. In autumn 2005, Lehman’s senior managers hired a group of experts to teach four dozen top executives how to make better decisions. ",
					"content_token": 192,
					"embedding": []
				},
				{
					"article_title": "Can Waiting Help You Make Better Decisions?",
					"article_url": "https://fs.blog/can-waiting-help-you-make-better-decisions/",
					"content": "Max H Bazerman, a chaired professor at Harvard Business School, reviewed cutting-edge decision research. Mahzarin Banaji, a Harvard psychologist, administered custom-designed tests to help the executives understand their biases. Malcolm Gladwell, who had just published Blink, a bestseller about the “first two seconds” of our reactions, gave the capstone lecture. These managers sat for a cutting-edge course on the timing of decisions. Then, they rushed back to their offices and made some of the worst decisions in the history of financial markets. Three years later, their firm was gone. If Lehman had lived until today, its decision-making course would look radically different. The core message of recent research is the opposite of the one Lehman’s executives learnt in 2005: the longer we can wait, the better. And once we have a sense of how long a decision should take, we generally should delay the moment of decision until the last possible instant. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "Can Waiting Help You Make Better Decisions?",
					"article_url": "https://fs.blog/can-waiting-help-you-make-better-decisions/",
					"content": "If we have an hour, we should wait 59 minutes before responding. If we have a year, we should wait 364 days. Even if we have just half a second, we should wait as long as we possibly can. As the matches at Wimbledon will illustrate, even milliseconds matter. Thinking about the role of delay is a profound and fundamental part of being human. Questions about delay are existential: the amount of time we take to reflect on decisions will define who we are. Is our mission simply to be another animal, responding to whatever stimulations we encounter? Or are we here for something more? Life might be a race against time but it is enriched when we rise above our instincts and stop the clock to process and understand what we are doing and why. A wise decision requires reflection, and reflection requires a pause. ",
					"content_token": 166,
					"embedding": []
				},
				{
					"article_title": "Can Waiting Help You Make Better Decisions?",
					"article_url": "https://fs.blog/can-waiting-help-you-make-better-decisions/",
					"content": "If we are limited to just one word of wisdom about decision-making for children born a hundred years from now, people who will have all our advantages and limitations as human beings but will need to navigate an unimaginably faster-paced world than the one we confront now, there is no doubt what that word should be. Wait.    Still curious? Steven Sample talks about waiting as long as possible to make decisions in the excellent Contrarian’s Guide to Leadership. Also check out Wait: The Art and Science of Delay.",
					"content_token": 109,
					"embedding": []
				}
			]
		},
		{
			"title": "The Noise Bottleneck: When More Information is Harmful",
			"url": "https://fs.blog/noise-and-signal-nassim-taleb/",
			"content": "When consuming information, we strive for more signal and less noise. The problem is a cognitive illusion: we feel like the more information we consume the more signal we receive. While this is probably true on an absolute basis, Nassim Taleb argues in this excerpt from Antifragile, that it is not true on a relative basis. He calls is the noise bottleneck. Taleb argues that as you consume more data and the ratio of noise to signal increases, the less you know about what’s going on and the more inadvertent trouble you are likely to cause.  The Institutionalization Of Neuroticism Imagine someone of the type we call neurotic in common parlance. He is wiry, looks contorted, and speaks with an uneven voice. His necks moves around when he tries to express himself. When he has a small pimple his first reaction is to assume that it is cancerous, that the cancer is of the lethal type, and that it has already spread. His hypochondria is not just in the medical department: he incurs a small setback in business and reacts as if bankruptcy were both near and certain. In the office, he is tuned to every single possible detail, systematically transforming every molehill into a mountain. The last thing you want in life is to be in the same car with him when stuck in traffic on your way to an important appointment. The expression overreact was designed with him in mind: he does not have reactions, just overreactions. Compare him to someone with the opposite temperament, imperturbable, with the calm under fire that is considered necessary to become a leader, military commander or a mafia godfather. Usually unruffled and immune to small information they can impress you with their self-control in difficult circumstances. For a sample of a composed, call and pondered voice, listen to interview of “Sammy the Bull” Salvatore Gravano who was involved in the murder of nineteen people all competing mobsters. He speaks with minimal effort. In the rare situations when he is angry, unlike with the neurotic fellow, everyone knows it and takes it seriously. The supply of information to which we are exposed under modernity is transforming humans from the equable second fellow to the neurotic first. For the purpose of our discussion, the second fellow only reacts to real information, the first largely to noise. The difference between the two fellows will show us the difference between noise and signal. Noise is what you are supposed to ignore; signal what you need to heed. Indeed, we have been loosely mentioning “noise” earlier in the book; time to be precise about it. In science, noise is a generalization beyond the actual sound to describe random information that is totally useless for any purpose, and that you need to clean up to make sense of what you are listening to. Consider, for examples, elements in an encrypted message that have absolutely no meaning, just randomized letters to confuse the spies, or the hiss you hear on a telephone line and that you try to ignore in order to just focus on the voice of your interlocutor. Noise and Signal If you want to accelerate someone’s death, give him a personal doctor. One can see from the tonsillectomy story that access to data increases intervention as with neuroticism. Rory Sutherland signaled to me that those with a personal doctor on staff should be particularly vulnerable to naive interventionism, hence iatrogenics; doctors need to justify their salaries and prove to themselves that they have some work ethics, something “doing nothing” doesn’t satisfy Editor’s note: the same forces apply to leaders, managers, etc.. Indeed at the time of writing the personal doctor or the late singer Michael Jackson is being sued for something that is equivalent to overintervention-to-stifle-antifragility but it will take the law courts a while before they become familiar with the concept. Conceivably, the same happened to Elvis Prestley. So with overmedicated politicians and heads of state. Likewise those in corporations or in policymaking like Fragilista Greenspan endowed with a sophisticated statistics department and therefore getting a lot of “timely” data are capable of overreacting and mistaking noise for information Greenspan kept an eye on such fluctuations as the sales of vacuum cleaners in Cleveland “to get a precise idea about where the economy is going”, and, of course micromanaged us into chaos. In business and economic decision-making, data causes severe side effects data is now plentiful thanks to connectivity; and the share of spuriousness in the data increases as one gets more immersed into it. A not well discussed property of data: it is toxic in large quantities even in moderate quantities. The previous two chapters showed how you can use and take advantage of noise and randomness; but noise and randomness can also use and take advantage of you, particularly when totally unnatural the data you get on the web or thanks to the media. The more frequently you look at data, the more noise you are disproportionally likely to get rather than the valuable part called the signal; hence the higher the noise to signal ratio. And there is a confusion, that is not psychological at all, but inherent in the data itself. Say you look at information on a yearly basis, for stock prices or the fertilizer sales of your father-in-law’s factory, or inflation numbers in Vladivostock. Assume further that for what you are observing, at the yearly frequency the ratio of signal to noise is about one to one say half noise, half signal it means that about half of changes are real improvements or degradations, the other half comes from randomness. This ratio is what you get from yearly observations. But if you look at the very same data on a daily basis, the composition would change to 95 noise, 5 signal. And if you observe data on an hourly basis, as people immersed in the news and markets price variations do, the split becomes 99.5 noise to .5 signal. That is two hundred times more noise than signal which is why anyone who listens to news except when very, very significant events take place is one step below sucker. There is a biological story with information. I have been repeating that in a natural environment, a stressor is information. So too much information would be too much stress, exceeding the threshold of antifragility. In medicine, we are discovering the healing powers of fasting, as the avoidance of too much hormonal rushes that come with the ingestion of food. Hormones convey information to the different parts of our system and too much of it confuses our biology. Here again, as with the story of the news received at too high a frequency, too much information becomes harmful. And in Chapter x on ethics I will show how too much data particularly when sterile causes statistics to be completely meaningless. Now let’s add the psychological to this: we are not made to understand the point, so we overreact emotionally to noise. The best solution is to only look at very large changes in data or conditions, never small ones. Just as we are not likely to mistake a bear for a stone but likely to mistake a stone for a bear, it is almost impossible for someone rational with a clear, uninfected mind, one who is not drowning in data, to mistake a vital signal, one that matters for his survival, for noise. Significant signals have a way to reach you. In the tonsillectomies, the best filter would have been to only consider the children who are very ill, those with periodically recurring throat inflammation. There was even more noise coming from the media and its glorification of the anecdote. Thanks to it, we are living more and more in virtual reality, separated from the real world, a little bit more every day, while realizing it less and less. Consider that every day, 6,200 persons die in the United States, many of preventable causes. But the media only reports the most anecdotal and sensational cases hurricanes, freak incidents, small plane crashes giving us a more and more distorted map of real risks. In an ancestral environment, the anecdote, the “interesting” is information; no longer today. Likewise, by presenting us with explanations and theories the media induces an illusion of understanding the world. And the understanding of events and risks on the part of members of the press is so retrospective that they would put the security checks after the plane ride, or what the ancients call post bellum auxilium, send troops after the battle. Owing to domain dependence, we forget the need to check our map of the world against reality. So we are living in a more and more fragile world, while thinking it is more and more understandable. To conclude, the best way to mitigate interventionism is to ration the supply of information, as naturalistically as possible. This is hard to accept in the age of the internet. It has been very hard for me to explain that the more data you get, the less you know what’s going on, and the more iatrogenics you will cause.  The noise bottleneck is really a paradox. We think the more information we consume the more signal we’ll consume. Only the mind doesn’t work like that. When the volume of information increases, our ability to comprehend the relevant from the irrelevant becomes compromised. We place too much emphasis on irrelevant data and lose sight of what’s really important. Still Curious? Read The Pot Belly of Ignorance.  Source image via ",
			"tokens": 1967,
			"chunks": [
				{
					"article_title": "The Noise Bottleneck: When More Information is Harmful",
					"article_url": "https://fs.blog/noise-and-signal-nassim-taleb/",
					"content": "When consuming information, we strive for more signal and less noise. The problem is a cognitive illusion: we feel like the more information we consume the more signal we receive. While this is probably true on an absolute basis, Nassim Taleb argues in this excerpt from Antifragile, that it is not true on a relative basis. He calls is the noise bottleneck. Taleb argues that as you consume more data and the ratio of noise to signal increases, the less you know about what’s going on and the more inadvertent trouble you are likely to cause.  The Institutionalization Of Neuroticism Imagine someone of the type we call neurotic in common parlance. He is wiry, looks contorted, and speaks with an uneven voice. His necks moves around when he tries to express himself. ",
					"content_token": 170,
					"embedding": []
				},
				{
					"article_title": "The Noise Bottleneck: When More Information is Harmful",
					"article_url": "https://fs.blog/noise-and-signal-nassim-taleb/",
					"content": "When he has a small pimple his first reaction is to assume that it is cancerous, that the cancer is of the lethal type, and that it has already spread. His hypochondria is not just in the medical department: he incurs a small setback in business and reacts as if bankruptcy were both near and certain. In the office, he is tuned to every single possible detail, systematically transforming every molehill into a mountain. The last thing you want in life is to be in the same car with him when stuck in traffic on your way to an important appointment. The expression overreact was designed with him in mind: he does not have reactions, just overreactions. Compare him to someone with the opposite temperament, imperturbable, with the calm under fire that is considered necessary to become a leader, military commander or a mafia godfather. Usually unruffled and immune to small information they can impress you with their self-control in difficult circumstances. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "The Noise Bottleneck: When More Information is Harmful",
					"article_url": "https://fs.blog/noise-and-signal-nassim-taleb/",
					"content": "For a sample of a composed, call and pondered voice, listen to interview of “Sammy the Bull” Salvatore Gravano who was involved in the murder of nineteen people all competing mobsters. He speaks with minimal effort. In the rare situations when he is angry, unlike with the neurotic fellow, everyone knows it and takes it seriously. The supply of information to which we are exposed under modernity is transforming humans from the equable second fellow to the neurotic first. For the purpose of our discussion, the second fellow only reacts to real information, the first largely to noise. The difference between the two fellows will show us the difference between noise and signal. Noise is what you are supposed to ignore; signal what you need to heed. Indeed, we have been loosely mentioning “noise” earlier in the book; time to be precise about it. ",
					"content_token": 182,
					"embedding": []
				},
				{
					"article_title": "The Noise Bottleneck: When More Information is Harmful",
					"article_url": "https://fs.blog/noise-and-signal-nassim-taleb/",
					"content": "In science, noise is a generalization beyond the actual sound to describe random information that is totally useless for any purpose, and that you need to clean up to make sense of what you are listening to. Consider, for examples, elements in an encrypted message that have absolutely no meaning, just randomized letters to confuse the spies, or the hiss you hear on a telephone line and that you try to ignore in order to just focus on the voice of your interlocutor. Noise and Signal If you want to accelerate someone’s death, give him a personal doctor. One can see from the tonsillectomy story that access to data increases intervention as with neuroticism. ",
					"content_token": 137,
					"embedding": []
				},
				{
					"article_title": "The Noise Bottleneck: When More Information is Harmful",
					"article_url": "https://fs.blog/noise-and-signal-nassim-taleb/",
					"content": "Rory Sutherland signaled to me that those with a personal doctor on staff should be particularly vulnerable to naive interventionism, hence iatrogenics; doctors need to justify their salaries and prove to themselves that they have some work ethics, something “doing nothing” doesn’t satisfy Editor’s note: the same forces apply to leaders, managers, etc. Indeed at the time of writing the personal doctor or the late singer Michael Jackson is being sued for something that is equivalent to overintervention-to-stifle-antifragility but it will take the law courts a while before they become familiar with the concept. Conceivably, the same happened to Elvis Prestley. So with overmedicated politicians and heads of state. ",
					"content_token": 154,
					"embedding": []
				},
				{
					"article_title": "The Noise Bottleneck: When More Information is Harmful",
					"article_url": "https://fs.blog/noise-and-signal-nassim-taleb/",
					"content": "Likewise those in corporations or in policymaking like Fragilista Greenspan endowed with a sophisticated statistics department and therefore getting a lot of “timely” data are capable of overreacting and mistaking noise for information Greenspan kept an eye on such fluctuations as the sales of vacuum cleaners in Cleveland “to get a precise idea about where the economy is going”, and, of course micromanaged us into chaos. In business and economic decision-making, data causes severe side effects data is now plentiful thanks to connectivity; and the share of spuriousness in the data increases as one gets more immersed into it. A not well discussed property of data: it is toxic in large quantities even in moderate quantities. The previous two chapters showed how you can use and take advantage of noise and randomness; but noise and randomness can also use and take advantage of you, particularly when totally unnatural the data you get on the web or thanks to the media. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "The Noise Bottleneck: When More Information is Harmful",
					"article_url": "https://fs.blog/noise-and-signal-nassim-taleb/",
					"content": "The more frequently you look at data, the more noise you are disproportionally likely to get rather than the valuable part called the signal; hence the higher the noise to signal ratio. And there is a confusion, that is not psychological at all, but inherent in the data itself. Say you look at information on a yearly basis, for stock prices or the fertilizer sales of your father-in-law’s factory, or inflation numbers in Vladivostock. Assume further that for what you are observing, at the yearly frequency the ratio of signal to noise is about one to one say half noise, half signal it means that about half of changes are real improvements or degradations, the other half comes from randomness. This ratio is what you get from yearly observations. But if you look at the very same data on a daily basis, the composition would change to 95 noise, 5 signal. ",
					"content_token": 184,
					"embedding": []
				},
				{
					"article_title": "The Noise Bottleneck: When More Information is Harmful",
					"article_url": "https://fs.blog/noise-and-signal-nassim-taleb/",
					"content": "And if you observe data on an hourly basis, as people immersed in the news and markets price variations do, the split becomes 99.5 noise to .5 signal. That is two hundred times more noise than signal which is why anyone who listens to news except when very, very significant events take place is one step below sucker. There is a biological story with information. I have been repeating that in a natural environment, a stressor is information. So too much information would be too much stress, exceeding the threshold of antifragility. In medicine, we are discovering the healing powers of fasting, as the avoidance of too much hormonal rushes that come with the ingestion of food. Hormones convey information to the different parts of our system and too much of it confuses our biology. Here again, as with the story of the news received at too high a frequency, too much information becomes harmful. ",
					"content_token": 183,
					"embedding": []
				},
				{
					"article_title": "The Noise Bottleneck: When More Information is Harmful",
					"article_url": "https://fs.blog/noise-and-signal-nassim-taleb/",
					"content": "And in Chapter x on ethics I will show how too much data particularly when sterile causes statistics to be completely meaningless. Now let’s add the psychological to this: we are not made to understand the point, so we overreact emotionally to noise. The best solution is to only look at very large changes in data or conditions, never small ones. Just as we are not likely to mistake a bear for a stone but likely to mistake a stone for a bear, it is almost impossible for someone rational with a clear, uninfected mind, one who is not drowning in data, to mistake a vital signal, one that matters for his survival, for noise. Significant signals have a way to reach you. In the tonsillectomies, the best filter would have been to only consider the children who are very ill, those with periodically recurring throat inflammation. There was even more noise coming from the media and its glorification of the anecdote. ",
					"content_token": 192,
					"embedding": []
				},
				{
					"article_title": "The Noise Bottleneck: When More Information is Harmful",
					"article_url": "https://fs.blog/noise-and-signal-nassim-taleb/",
					"content": "Thanks to it, we are living more and more in virtual reality, separated from the real world, a little bit more every day, while realizing it less and less. Consider that every day, 6,200 persons die in the United States, many of preventable causes. But the media only reports the most anecdotal and sensational cases hurricanes, freak incidents, small plane crashes giving us a more and more distorted map of real risks. In an ancestral environment, the anecdote, the “interesting” is information; no longer today. Likewise, by presenting us with explanations and theories the media induces an illusion of understanding the world. And the understanding of events and risks on the part of members of the press is so retrospective that they would put the security checks after the plane ride, or what the ancients call post bellum auxilium, send troops after the battle. Owing to domain dependence, we forget the need to check our map of the world against reality. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "The Noise Bottleneck: When More Information is Harmful",
					"article_url": "https://fs.blog/noise-and-signal-nassim-taleb/",
					"content": "So we are living in a more and more fragile world, while thinking it is more and more understandable. To conclude, the best way to mitigate interventionism is to ration the supply of information, as naturalistically as possible. This is hard to accept in the age of the internet. It has been very hard for me to explain that the more data you get, the less you know what’s going on, and the more iatrogenics you will cause.  The noise bottleneck is really a paradox. We think the more information we consume the more signal we’ll consume. Only the mind doesn’t work like that. When the volume of information increases, our ability to comprehend the relevant from the irrelevant becomes compromised. We place too much emphasis on irrelevant data and lose sight of what’s really important. Still Curious? Read The Pot Belly of Ignorance.  Source image via",
					"content_token": 186,
					"embedding": []
				}
			]
		},
		{
			"title": "The Best Books on The Psychology Behind Human Decision Making and Irrationality",
			"url": "https://fs.blog/what-are-the-best-books-on-the-psychology-behind-human-decision-making-and-irrationality/",
			"content": "reader suggestions are at the bottom This is a great way to build your antilibrary. Predictably Irrational by Dan Ariely Mentioned by many others. Outstanding experimentally-driven analysis of human irrationality. Nudge by Richard Thaler and Cass Sunstein Great book that explains the disproportionate impact that initial conditions priming, anchoring, etc. have on our decision making. Stumbling Toward Happiness, by Dan Gilbert Very engaging book, focusing mostly on how we go awry when we try to make decisions based upon our recollection of past events or beliefs about how we will feel in the future. I also really enjoyed Haidt’s Happiness Hypothesis, though it’s less focused on decision making than this book is. Sway: The Irresistable Pull of Irrational Behavior by Ori and Rom Brafman Essentially, a quicker and more anecdotal version of Predictably Irrational. Robert Axelrod’s, The Evolution of Cooperation game theory  cooperative behavior Buyology by Martin Lindstrom The Black Swan by Nassim Nicholas Taleb Fooled by Randomness by Nassim NicholasTaleb Paradox of Choice by Barry Schwartz The Psychology of Human Misjudgment by Charlie Munger The Psychology of Judgment and Decision Making by Scott Plous Checklist Manifesto by Atul Gawande Seeking Wisdom by Peter Bevelin Turning Numbers into Knowledge: Mastering the Art of Problem Solving How to Measure Anything: Finding the Value of “Intangibles” in Business A Whole New Mind by Dan Pink Influence: The Psychology of Persuasion, by Robert Cialdini Thinking, Fast and Slow, by Daniel Kahneman Your Are Not So Smart, David McRaney On Being Certain by Robert Burton A fascinating account of the neuroscience behind the feeling of “rightness” we get when we make decisions. That’s an interesting list. I’d add: Thinking and Deciding by Jonathan Baron, a recommendation from Nassim Taleb. Judgment in Decision Making Smart Choices: A Practical Guide to Making Better Decisions Choices Values  Frames Problem Solving, Decision Making, and Professional Judgment: A Guide for Lawyers and Policymakers Reader suggestions Thanks!. Mistakes Were Made But Not by Me: Why We Justify Foolish Beliefs, Bad Decisions, and Hurtful Acts Why do people dodge responsibility when things fall apart? Why the parade of public figures unable to own up when they screw up? Why the endless marital quarrels over who is right? Why can we see hypocrisy in others but not in ourselves? Are we all liars? Or do we really believe the stories we tell? How We Know What Isn’t So: The Fallibility of Human Reason in Everyday Life When can we trust what we believe – that “teams and players have winning streaks”, that “flattery works”, or that “the more people who agree, the more likely they are to be right” – and when are such beliefs suspect? Thomas Gilovich offers a guide to the fallacy of the obvious in everyday life. Decision Traps: The Ten Barriers to Decision-Making and How to Overcome Them Two experts in business management show how to avoid the ten common pitfalls that ensanre decision makers. The very latest research in the fields of business and psychology has been distilled into practical training methods that will save readers from ever making a bad decision again. The Invisible Gorilla: How Our Intuitions Deceive Us  Reading this book will make you less sure of yourselfand that’s a good thing. The Drunkard’s Walk: How Randomness Rules Our Lives With the born storyteller’s command of narrative and imaginative approach, Leonard Mlodinow vividly demonstrates how our lives are profoundly informed by chance and randomness and how everything from wine ratings and corporate success to school grades and political polls are less reliable than we believe. The Folly of Fools: The Logic of Deceit and Self-Deception in Human Life  In his bold new work, prominent biological theorist Robert Trivers unflinchingly argues that self-deception evolved in the service of deceitthe better to fool others. We do it for biological reasonsin order to help us survive and procreate. From viruses mimicking host behavior to humans misremembering sometimes intentionally the details of a quarrel, science has proven that the deceptive one can always outwit the masses. But we undertake this deception at our own peril. Poor Charlie’s Almanac The Psychology of Intelligence Analysis The Social Animal: The Hidden Sources of Love, Character, and Achievement Brooks turns to the building blocks of human flourishing in a multilayered, profoundly illuminating work grounded in everyday life. Source: Quora ",
			"tokens": 973,
			"chunks": [
				{
					"article_title": "The Best Books on The Psychology Behind Human Decision Making and Irrationality",
					"article_url": "https://fs.blog/what-are-the-best-books-on-the-psychology-behind-human-decision-making-and-irrationality/",
					"content": "reader suggestions are at the bottom This is a great way to build your antilibrary. Predictably Irrational by Dan Ariely Mentioned by many others. Outstanding experimentally-driven analysis of human irrationality. Nudge by Richard Thaler and Cass Sunstein Great book that explains the disproportionate impact that initial conditions priming, anchoring, etc. have on our decision making. Stumbling Toward Happiness, by Dan Gilbert Very engaging book, focusing mostly on how we go awry when we try to make decisions based upon our recollection of past events or beliefs about how we will feel in the future. I also really enjoyed Haidt’s Happiness Hypothesis, though it’s less focused on decision making than this book is. Sway: The Irresistable Pull of Irrational Behavior by Ori and Rom Brafman Essentially, a quicker and more anecdotal version of Predictably Irrational. ",
					"content_token": 188,
					"embedding": []
				},
				{
					"article_title": "The Best Books on The Psychology Behind Human Decision Making and Irrationality",
					"article_url": "https://fs.blog/what-are-the-best-books-on-the-psychology-behind-human-decision-making-and-irrationality/",
					"content": "Robert Axelrod’s, The Evolution of Cooperation game theory  cooperative behavior Buyology by Martin Lindstrom The Black Swan by Nassim Nicholas Taleb Fooled by Randomness by Nassim NicholasTaleb Paradox of Choice by Barry Schwartz The Psychology of Human Misjudgment by Charlie Munger The Psychology of Judgment and Decision Making by Scott Plous Checklist Manifesto by Atul Gawande Seeking Wisdom by Peter Bevelin Turning Numbers into Knowledge: Mastering the Art of Problem Solving How to Measure Anything: Finding the Value of “Intangibles” in Business A Whole New Mind by Dan Pink Influence: The Psychology of Persuasion, by Robert Cialdini Thinking, Fast and Slow, by Daniel Kahneman Your Are Not So Smart, David McRaney On Being Certain by Robert Burton A fascinating account of the neuroscience behind the feeling of “rightness” we get when we make decisions. That’s an interesting list. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "The Best Books on The Psychology Behind Human Decision Making and Irrationality",
					"article_url": "https://fs.blog/what-are-the-best-books-on-the-psychology-behind-human-decision-making-and-irrationality/",
					"content": "I’d add: Thinking and Deciding by Jonathan Baron, a recommendation from Nassim Taleb. Judgment in Decision Making Smart Choices: A Practical Guide to Making Better Decisions Choices Values  Frames Problem Solving, Decision Making, and Professional Judgment: A Guide for Lawyers and Policymakers Reader suggestions Thanks! ",
					"content_token": 67,
					"embedding": []
				},
				{
					"article_title": "The Best Books on The Psychology Behind Human Decision Making and Irrationality",
					"article_url": "https://fs.blog/what-are-the-best-books-on-the-psychology-behind-human-decision-making-and-irrationality/",
					"content": "Mistakes Were Made But Not by Me: Why We Justify Foolish Beliefs, Bad Decisions, and Hurtful Acts Why do people dodge responsibility when things fall apart? Why the parade of public figures unable to own up when they screw up? Why the endless marital quarrels over who is right? Why can we see hypocrisy in others but not in ourselves? Are we all liars? Or do we really believe the stories we tell? How We Know What Isn’t So: The Fallibility of Human Reason in Everyday Life When can we trust what we believe – that “teams and players have winning streaks”, that “flattery works”, or that “the more people who agree, the more likely they are to be right” – and when are such beliefs suspect? Thomas Gilovich offers a guide to the fallacy of the obvious in everyday life. ",
					"content_token": 184,
					"embedding": []
				},
				{
					"article_title": "The Best Books on The Psychology Behind Human Decision Making and Irrationality",
					"article_url": "https://fs.blog/what-are-the-best-books-on-the-psychology-behind-human-decision-making-and-irrationality/",
					"content": "Decision Traps: The Ten Barriers to Decision-Making and How to Overcome Them Two experts in business management show how to avoid the ten common pitfalls that ensanre decision makers. The very latest research in the fields of business and psychology has been distilled into practical training methods that will save readers from ever making a bad decision again. The Invisible Gorilla: How Our Intuitions Deceive Us  Reading this book will make you less sure of yourselfand that’s a good thing. The Drunkard’s Walk: How Randomness Rules Our Lives With the born storyteller’s command of narrative and imaginative approach, Leonard Mlodinow vividly demonstrates how our lives are profoundly informed by chance and randomness and how everything from wine ratings and corporate success to school grades and political polls are less reliable than we believe. ",
					"content_token": 173,
					"embedding": []
				},
				{
					"article_title": "The Best Books on The Psychology Behind Human Decision Making and Irrationality",
					"article_url": "https://fs.blog/what-are-the-best-books-on-the-psychology-behind-human-decision-making-and-irrationality/",
					"content": "The Folly of Fools: The Logic of Deceit and Self-Deception in Human Life  In his bold new work, prominent biological theorist Robert Trivers unflinchingly argues that self-deception evolved in the service of deceitthe better to fool others. We do it for biological reasonsin order to help us survive and procreate. From viruses mimicking host behavior to humans misremembering sometimes intentionally the details of a quarrel, science has proven that the deceptive one can always outwit the masses. But we undertake this deception at our own peril. Poor Charlie’s Almanac The Psychology of Intelligence Analysis The Social Animal: The Hidden Sources of Love, Character, and Achievement Brooks turns to the building blocks of human flourishing in a multilayered, profoundly illuminating work grounded in everyday life. Source: Quora",
					"content_token": 169,
					"embedding": []
				}
			]
		},
		{
			"title": "Gary Klein: Streetlights and Shadows",
			"url": "https://fs.blog/streetlights-and-shadows/",
			"content": "Gary Kleins book Streetlights and Shadows looks at commonly held maxims for decision-making and overturns them, revealing cases where these practices break down. The book is an impressive look at why these problems occur and how we can become more resilient decision makers. Here are ten beliefs that we hold about systems and decision making along with a proposed replacement. 1. Teaching people procedures helps them perform tasks more skillfully. Replacement: In complex situations people will need judgment skills to follow procedures effectively and go beyond them when necessary. 2. Decision biases distort our thinking. Replacement: Decision biases reflect our thinking. Rather than discouraging people from using heuristics, we should help them build expertise so they can use their heuristics more effectively. 2a. Successful decision makers rely on logic and statistics instead of intuition. Replacement: We need to blend systemic analysis and intuition. 3. To make a decision, generate several options and compare them to pick the best one. Replacement: Good decision makers use their experience to recognize effective options and evaluate them through mental simulation. 4. We can reduce uncertainty by gathering more information. Too much information can get in our way. Replacement: In complex environments, what we need isn’t the right information but the right way to understand the information we have. 5. It’s bad to jump to conclusions – wait to see the evidence. Replacement: Speculate, but test your speculations instead of committing to them. 6. To get people to learn, give them feedback on the consequences of their actions. Replacement: We can’t just give feedback; we have to find ways to make it understandable. 7. To make sense of a situation, we draw inferences from the data. Replacement: We make sense of data by fitting them into stories and other frames, but the reverse also happens: our frames determine what counts as data. 8. The starting point for any project is a clear description of the goal. Replacement: When facing wicked problems, we should redefine goals as we try to reach them. 9. Our plans will succeed more often if we identify the biggest risks and then find ways to eliminate them. B: We should cope with risk in complex situations by relying on resilience engineering rather than attempting to identify and prevent risks. 10.Leaders can create common ground by assigning roles and setting ground rules in advance. Replacement: All team members are responsible for continually monitoring common ground for breakdowns and repairing the breakdown when necessary. Buy the book. Source ",
			"tokens": 509,
			"chunks": [
				{
					"article_title": "Gary Klein: Streetlights and Shadows",
					"article_url": "https://fs.blog/streetlights-and-shadows/",
					"content": "Gary Kleins book Streetlights and Shadows looks at commonly held maxims for decision-making and overturns them, revealing cases where these practices break down. The book is an impressive look at why these problems occur and how we can become more resilient decision makers. Here are ten beliefs that we hold about systems and decision making along with a proposed replacement. 1. Teaching people procedures helps them perform tasks more skillfully. Replacement: In complex situations people will need judgment skills to follow procedures effectively and go beyond them when necessary. 2. Decision biases distort our thinking. Replacement: Decision biases reflect our thinking. Rather than discouraging people from using heuristics, we should help them build expertise so they can use their heuristics more effectively. 2a. Successful decision makers rely on logic and statistics instead of intuition. Replacement: We need to blend systemic analysis and intuition. 3. To make a decision, generate several options and compare them to pick the best one. ",
					"content_token": 196,
					"embedding": []
				},
				{
					"article_title": "Gary Klein: Streetlights and Shadows",
					"article_url": "https://fs.blog/streetlights-and-shadows/",
					"content": "Replacement: Good decision makers use their experience to recognize effective options and evaluate them through mental simulation. 4. We can reduce uncertainty by gathering more information. Too much information can get in our way. Replacement: In complex environments, what we need isn’t the right information but the right way to understand the information we have. 5. It’s bad to jump to conclusions – wait to see the evidence. Replacement: Speculate, but test your speculations instead of committing to them. 6. To get people to learn, give them feedback on the consequences of their actions. Replacement: We can’t just give feedback; we have to find ways to make it understandable. 7. To make sense of a situation, we draw inferences from the data. Replacement: We make sense of data by fitting them into stories and other frames, but the reverse also happens: our frames determine what counts as data. 8. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "Gary Klein: Streetlights and Shadows",
					"article_url": "https://fs.blog/streetlights-and-shadows/",
					"content": "The starting point for any project is a clear description of the goal. Replacement: When facing wicked problems, we should redefine goals as we try to reach them. 9. Our plans will succeed more often if we identify the biggest risks and then find ways to eliminate them. B: We should cope with risk in complex situations by relying on resilience engineering rather than attempting to identify and prevent risks. 10.Leaders can create common ground by assigning roles and setting ground rules in advance. Replacement: All team members are responsible for continually monitoring common ground for breakdowns and repairing the breakdown when necessary. Buy the book. Source",
					"content_token": 124,
					"embedding": []
				}
			]
		},
		{
			"title": "The Decision-Making Flaw in Powerful People",
			"url": "https://fs.blog/the-decision-making-flaw-in-powerful-people/",
			"content": "The paper below finds a link between having a sense of power and ignoring the advice of others. The authors argue that power increases confidence, which can lead to an excessive belief in one’s own judgment. In a sense, powerful people think they are right because of their place in the organization, not because of their knowledge.  This, of course, leads to flawed decisions. From StrategyBusiness: Previous research has shown that the quality of decision making declines when people hew too much to their own beliefs and discount too readily the advice of others; outside information helps “average out” the distortions that can result when people give a great deal of weight to their own opinions and first impressions. This paper is among the first to examine whether power  defined as an individual’s “capacity to influence others, stemming in part from his or her control over resources, rewards, or punishments”  reduces or increases a person’s willingness to heed advice.  In addition to confirming the previous experiments’ finding that more powerful people were less likely to take advice and were more likely to have high confidence in their answers, this final experiment showed that high-power participants were less accurate in their answers than low-power participants. By calculating the mean deviation between respondents’ initial estimates and the true answers, the researchers showed that low-power participants came significantly closer in their final estimates to the real tuition numbers because they “averaged” their initial guesses with the input from the advisors. The researchers propose that their findings have troubling implications for organizations  and that power could negatively affect not just advice taking, but also an individual’s approach to seeking help or accepting performance feedback. But because power and confidence are so interrelated, there are ways to mitigate the problem. By “directly addressing the inflated confidence levels of powerful individuals,” the researchers write, “organizations may be able to help people with power take andor seek advice when it is valuable to do so.” For one thing, organizations could formally include advice gathering at the earliest stages of the decision-making process, before powerful individuals have a chance to form their own opinions. Encouraging leaders to refrain from commenting on decisions publicly could also keep them from feeling wedded to a particular point of view. Bottom Line: Powerful people are less likely to take advice from others, in large part because they have high confidence in their own judgment and don’t feel the need to incorporate outside views. By not factoring in others’ advice, however, people in power risk making flawed decisions. Abstract: Incorporating input from others can enhance decision quality, yet often people do not effectively utilize advice. We propose that greater power increases the propensity to discount advice, and that a key mechanism explaining this effect is elevated confidence in one’s judgment. We investigate the relationships across four studies: a field survey where working professionals rated their own power and confidence and were rated by coworkers on their level of advice taking; an advice taking task where power and confidence were self-reported; and two advice taking experiments where power was manipulated. Results consistently showed a negative relationship between power and advice taking, and evidence of mediation through confidence. The fourth study also revealed that higher power participants were less accurate in their final judgments. Power can thus exacerbate the tendency for people to overweight their own initial judgment, such that the most powerful decision makers can also be the least accurate. Source: Kelly E. See, Elizabeth W. Morrison, Naomi B. Rothman, Jack B. Soll, The detrimental effects of power on confidence, advice taking, and accuracy, Organizational Behavior and Human Decision Processes ",
			"tokens": 747,
			"chunks": [
				{
					"article_title": "The Decision-Making Flaw in Powerful People",
					"article_url": "https://fs.blog/the-decision-making-flaw-in-powerful-people/",
					"content": "The paper below finds a link between having a sense of power and ignoring the advice of others. The authors argue that power increases confidence, which can lead to an excessive belief in one’s own judgment. In a sense, powerful people think they are right because of their place in the organization, not because of their knowledge.  This, of course, leads to flawed decisions. From StrategyBusiness: Previous research has shown that the quality of decision making declines when people hew too much to their own beliefs and discount too readily the advice of others; outside information helps “average out” the distortions that can result when people give a great deal of weight to their own opinions and first impressions. This paper is among the first to examine whether power  defined as an individual’s “capacity to influence others, stemming in part from his or her control over resources, rewards, or punishments”  reduces or increases a person’s willingness to heed advice. ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "The Decision-Making Flaw in Powerful People",
					"article_url": "https://fs.blog/the-decision-making-flaw-in-powerful-people/",
					"content": " In addition to confirming the previous experiments’ finding that more powerful people were less likely to take advice and were more likely to have high confidence in their answers, this final experiment showed that high-power participants were less accurate in their answers than low-power participants. By calculating the mean deviation between respondents’ initial estimates and the true answers, the researchers showed that low-power participants came significantly closer in their final estimates to the real tuition numbers because they “averaged” their initial guesses with the input from the advisors. The researchers propose that their findings have troubling implications for organizations  and that power could negatively affect not just advice taking, but also an individual’s approach to seeking help or accepting performance feedback. But because power and confidence are so interrelated, there are ways to mitigate the problem. ",
					"content_token": 166,
					"embedding": []
				},
				{
					"article_title": "The Decision-Making Flaw in Powerful People",
					"article_url": "https://fs.blog/the-decision-making-flaw-in-powerful-people/",
					"content": "By “directly addressing the inflated confidence levels of powerful individuals,” the researchers write, “organizations may be able to help people with power take andor seek advice when it is valuable to do so.” For one thing, organizations could formally include advice gathering at the earliest stages of the decision-making process, before powerful individuals have a chance to form their own opinions. Encouraging leaders to refrain from commenting on decisions publicly could also keep them from feeling wedded to a particular point of view. Bottom Line: Powerful people are less likely to take advice from others, in large part because they have high confidence in their own judgment and don’t feel the need to incorporate outside views. By not factoring in others’ advice, however, people in power risk making flawed decisions. Abstract: Incorporating input from others can enhance decision quality, yet often people do not effectively utilize advice. ",
					"content_token": 188,
					"embedding": []
				},
				{
					"article_title": "The Decision-Making Flaw in Powerful People",
					"article_url": "https://fs.blog/the-decision-making-flaw-in-powerful-people/",
					"content": "We propose that greater power increases the propensity to discount advice, and that a key mechanism explaining this effect is elevated confidence in one’s judgment. We investigate the relationships across four studies: a field survey where working professionals rated their own power and confidence and were rated by coworkers on their level of advice taking; an advice taking task where power and confidence were self-reported; and two advice taking experiments where power was manipulated. Results consistently showed a negative relationship between power and advice taking, and evidence of mediation through confidence. The fourth study also revealed that higher power participants were less accurate in their final judgments. Power can thus exacerbate the tendency for people to overweight their own initial judgment, such that the most powerful decision makers can also be the least accurate. Source: Kelly E. See, Elizabeth W. Morrison, Naomi B. Rothman, Jack B. Soll, The detrimental effects of power on confidence, advice taking, and accuracy, Organizational Behavior and Human Decision Processes",
					"content_token": 196,
					"embedding": []
				}
			]
		},
		{
			"title": "Too Many Decisions",
			"url": "https://fs.blog/do-you-make-too-many-decisions/",
			"content": "The first thing you do in the morning is to make a decision. And those decisions pile up fast. Should I hit snooze? What clothes should I wear? What should I have for breakfast? What combination of choices from Starbucks will make my morning go smoother? You’ve already made more decisions than most of our ancestors would make in a day by the time you arrive at work. Unfortunately  at least as far as the quality of your decisions is concerned  your day is just getting started. Decisions take a lot of mental effort. And that’s a problem. Making choices reduces physical stamina, reduces persistence, reduces willpower, and even encourages procrastination. John Tierney, adapted part of his upcoming book, Willpower: Rediscovering the Greatest Human Strength, for a New York Times Magazine article: Do You Suffer From Decision Fatigue? Our brains are tired of making decisions. This has been coined as “Decision fatigue” and helps explain why, in the words of Tierney, “normally sensible people get angry at colleagues and families, splurge on clothes, buy junk food at the supermarket and can’t resist the dealer’s offer to rustproof their new car.” No matter how rational you are or try to be, you can’t make decision after decision without paying a mental price. “It’s different”, Tierney writes, “from ordinary physical fatigue  you’re not consciously aware of being tired  but you’re low on mental energy.” The more choices you make, the harder they become. To save energy your brain starts to look for shortcuts. One shortcut is to be reckless and act impulsively rather than rationally. The other shortcut is to do nothing, which saves as much energy as possible and often creates bigger problems in the long run. It turns out that glucose is a vital part of willpower. Tierney writes, “Your brain does not stop working when glucose is low. It stops doing some things and starts doing others. It responds more strongly to immediate rewards and plays less attention to long-term prospects.” Glucose explains a lot. For instance, why people with phenomenally strong willpower in the rest of their lives struggle to lose weight. It also explains how someone can resist junk all day but gorge on a bag of chips right before bed. We start the day with a clean slate and the best intentions. It’s fairly easy to resist fatty muffins at breakfast and skip the snickers bar fix after lunch. But each of these decisionsresistancesconsumes glucose and lowers our willpower. Eventually, we need to replenish it. But that requires glucose, which creates a catch-22: We need willpower not to eat but in order to have willpower we need to eat. Tierney continues, “when the brain’s regulatory powers weaken, frustrations seem more irritating than usual. Impulses to eat, drink, spend and say stupid things feel more powerful and alcohol causes self-control to decline furtherego-depleted humans become more likely to get into needless fights over turf.” Although we have no way of knowing, it seems like a fairly safe bet that we make more decisions now than at any point in history. That is, we’re under more decision making strain and we’re starting to show cracks. The internet and our ability to “multitask” isn’t helping, argues Nicolas Carr, author of The Shallows: What the Internet is Doing to Our Brian: “A growing body of scientific evidence suggests that the Net, with its constant distractions and interruptions, is also turning us into scattered and superficial thinkers.” Carr argues that our continuously connected, constantly distracted lives readconstantly making decisions rob us of the opportunity for deep thinking. The kind of thinking that we need to make a lot of decisions. By making thousands of trivial decisions every day, we rob ourselves of the ability to make more difficult contemplative decisions. There are ways to improve our ability to make better decisions. Social psychologist Roy Baumeister has done research showing that people with the best self-control are the ones who structure their lives to conserve willpower. “They don’t,” Tierney suggests, “schedule endless back-to-back meetings. They avoid temptations like all-you-can-eat buffets, and they establish habits that eliminate the mental effort of making choices. Instead of deciding every morning whether or not to force themselves to exercise, they set up regular appointments to work out with a friend. Instead of counting on willpower to remain robust all day, they conserve it so that it’s available for emergencies and important decisions.” Wise advice we should all follow. Organizations should start thinking carefully about how their employees actually end up spending their time and what they “waste” their precious mental energy on. If they’re filling out forms, trudging through a bureaucratic morass, or attending more than a few meetings a day, they’re likely using their mental energy on things that add little value to the organization. Still Curious? John Tierney wrote a book about willpower and decision fatigue, Willpower: Rediscovering the Greatest Human Strength. ",
			"tokens": 1092,
			"chunks": [
				{
					"article_title": "Too Many Decisions",
					"article_url": "https://fs.blog/do-you-make-too-many-decisions/",
					"content": "The first thing you do in the morning is to make a decision. And those decisions pile up fast. Should I hit snooze? What clothes should I wear? What should I have for breakfast? What combination of choices from Starbucks will make my morning go smoother? You’ve already made more decisions than most of our ancestors would make in a day by the time you arrive at work. Unfortunately  at least as far as the quality of your decisions is concerned  your day is just getting started. Decisions take a lot of mental effort. And that’s a problem. Making choices reduces physical stamina, reduces persistence, reduces willpower, and even encourages procrastination. John Tierney, adapted part of his upcoming book, Willpower: Rediscovering the Greatest Human Strength, for a New York Times Magazine article: Do You Suffer From Decision Fatigue? Our brains are tired of making decisions. ",
					"content_token": 186,
					"embedding": []
				},
				{
					"article_title": "Too Many Decisions",
					"article_url": "https://fs.blog/do-you-make-too-many-decisions/",
					"content": "This has been coined as “Decision fatigue” and helps explain why, in the words of Tierney, “normally sensible people get angry at colleagues and families, splurge on clothes, buy junk food at the supermarket and can’t resist the dealer’s offer to rustproof their new car.” No matter how rational you are or try to be, you can’t make decision after decision without paying a mental price. “It’s different”, Tierney writes, “from ordinary physical fatigue  you’re not consciously aware of being tired  but you’re low on mental energy.” The more choices you make, the harder they become. To save energy your brain starts to look for shortcuts. One shortcut is to be reckless and act impulsively rather than rationally. ",
					"content_token": 178,
					"embedding": []
				},
				{
					"article_title": "Too Many Decisions",
					"article_url": "https://fs.blog/do-you-make-too-many-decisions/",
					"content": "The other shortcut is to do nothing, which saves as much energy as possible and often creates bigger problems in the long run. It turns out that glucose is a vital part of willpower. Tierney writes, “Your brain does not stop working when glucose is low. It stops doing some things and starts doing others. It responds more strongly to immediate rewards and plays less attention to long-term prospects.” Glucose explains a lot. For instance, why people with phenomenally strong willpower in the rest of their lives struggle to lose weight. It also explains how someone can resist junk all day but gorge on a bag of chips right before bed. We start the day with a clean slate and the best intentions. It’s fairly easy to resist fatty muffins at breakfast and skip the snickers bar fix after lunch. But each of these decisionsresistancesconsumes glucose and lowers our willpower. Eventually, we need to replenish it. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "Too Many Decisions",
					"article_url": "https://fs.blog/do-you-make-too-many-decisions/",
					"content": "But that requires glucose, which creates a catch-22: We need willpower not to eat but in order to have willpower we need to eat. Tierney continues, “when the brain’s regulatory powers weaken, frustrations seem more irritating than usual. Impulses to eat, drink, spend and say stupid things feel more powerful and alcohol causes self-control to decline furtherego-depleted humans become more likely to get into needless fights over turf.” Although we have no way of knowing, it seems like a fairly safe bet that we make more decisions now than at any point in history. That is, we’re under more decision making strain and we’re starting to show cracks. ",
					"content_token": 147,
					"embedding": []
				},
				{
					"article_title": "Too Many Decisions",
					"article_url": "https://fs.blog/do-you-make-too-many-decisions/",
					"content": "The internet and our ability to “multitask” isn’t helping, argues Nicolas Carr, author of The Shallows: What the Internet is Doing to Our Brian: “A growing body of scientific evidence suggests that the Net, with its constant distractions and interruptions, is also turning us into scattered and superficial thinkers.” Carr argues that our continuously connected, constantly distracted lives readconstantly making decisions rob us of the opportunity for deep thinking. The kind of thinking that we need to make a lot of decisions. By making thousands of trivial decisions every day, we rob ourselves of the ability to make more difficult contemplative decisions. There are ways to improve our ability to make better decisions. Social psychologist Roy Baumeister has done research showing that people with the best self-control are the ones who structure their lives to conserve willpower. “They don’t,” Tierney suggests, “schedule endless back-to-back meetings. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "Too Many Decisions",
					"article_url": "https://fs.blog/do-you-make-too-many-decisions/",
					"content": "They avoid temptations like all-you-can-eat buffets, and they establish habits that eliminate the mental effort of making choices. Instead of deciding every morning whether or not to force themselves to exercise, they set up regular appointments to work out with a friend. Instead of counting on willpower to remain robust all day, they conserve it so that it’s available for emergencies and important decisions.” Wise advice we should all follow. Organizations should start thinking carefully about how their employees actually end up spending their time and what they “waste” their precious mental energy on. If they’re filling out forms, trudging through a bureaucratic morass, or attending more than a few meetings a day, they’re likely using their mental energy on things that add little value to the organization. Still Curious? John Tierney wrote a book about willpower and decision fatigue, Willpower: Rediscovering the Greatest Human Strength.",
					"content_token": 192,
					"embedding": []
				}
			]
		},
		{
			"title": "Promoting People In Organizations",
			"url": "https://fs.blog/promoting-people-in-organizations/",
			"content": "In their 1978 paper Performance Sampling in Social Matches, researchers March and March discussed the implications of performance sampling for understanding careers in organizations. They came to some interesting conclusions with implications for those of us working in organizations. Considerable evidence exists documenting that individuals confronted with problems requiring the estimation of proportions act as though sample size were substantially irrelevant to the reliability of their estimates. We do this in hiring all the time. Yet we know that sample size matters. On how this cognitive bias affects hiring, March and March offer some good insights including the false record effect, the hero effect, the disappointment affect. False Record Effect A group of managers of identical moderate ability will show considerable variation in their performance records in the short run. Some will be found at one end of the distribution and will be viewed as outstanding; others will be at the other end and will be viewed as ineffective. The longer a manager stays in a job, the less the probable difference between the observed record of performance and actual ability. Time on the job increased the expected sample of observations, reduced expected sampling error, and thus reduced the chance that the manager of moderate ability will either be promoted or exit. Hero Effect Within a group of managers of varying abilities, the faster the rate of promotion, the less likely it is to be justified. Performance records are produced by a combination of underlying ability and sampling variation. Managers who have good records are more likely to have high ability than managers who have poor records, but the reliability of the differentiation is small when records are short. Disappointment Effect On the average, new managers will be a disappointment. The performance records by which managers are evaluated are subject to sampling error. Since a manager is promoted to a new job on the basis of a good previous record, the proportion of promoted managers whose past records are better than their abilities will be greater than the proportion whose past records are poorer. As a result, on the average, managers will do less well in their new jobs than they did in their old ones, and observers will come to believe that higher level jobs are more difficult than lower level ones, even if they are not. The present results reinforce the idea that indistinguishability among managers is a joint property of the individuals being evaluated and the process by which they are evaluated. Performance sampling models show how careers may be the consequences of erroneous interpretations of variations in performance produced by equivalent managers. But they also indicate that the same pattern of careers could be the consequence of unreliable evaluation of managers who do, in fact, differ, or of managers who do, in fact, learn over the course of their experience. But hold on a second before you stop promoting new managers who, by definition, have a limited sample size. I’m not sure that sample size alone is the right way to think about this. Consider two people: Manager A and Manager B who are up for promotion. Manager A has 10 years of experience and is an “all-star” that is great performance with little variation in observations. Manager B, on the other hand, has only 5 years of experience but has shown a lot of variance in performance. If you had to hire someone you’d likely pick A. But it’s important not to misinterpret the results of March and March and dig a little deeper. What if we add one more variable to our two managers. Manager A’s job has been “easy” whereas Manager B took a very “tough” assignment. With this in mind, it seems reasonable to conclude that Manager B’s variance in performance could be explained by the difficulty of their task. This could also explain the lack of variance in Manager A’s performance. Some jobs are tougher than others. If you don’t factor in degree-of-difficulty you’re missing something big and sending a message to your workforce that discourages people from taking difficult assignments. The importance of measuring performance over a meaningful sample size is the key to distinguishing between luck and skill. When in doubt go with the person that’s excelled with more variance in difficulty.",
			"tokens": 834,
			"chunks": [
				{
					"article_title": "Promoting People In Organizations",
					"article_url": "https://fs.blog/promoting-people-in-organizations/",
					"content": "In their 1978 paper Performance Sampling in Social Matches, researchers March and March discussed the implications of performance sampling for understanding careers in organizations. They came to some interesting conclusions with implications for those of us working in organizations. Considerable evidence exists documenting that individuals confronted with problems requiring the estimation of proportions act as though sample size were substantially irrelevant to the reliability of their estimates. We do this in hiring all the time. Yet we know that sample size matters. On how this cognitive bias affects hiring, March and March offer some good insights including the false record effect, the hero effect, the disappointment affect. False Record Effect A group of managers of identical moderate ability will show considerable variation in their performance records in the short run. Some will be found at one end of the distribution and will be viewed as outstanding; others will be at the other end and will be viewed as ineffective. The longer a manager stays in a job, the less the probable difference between the observed record of performance and actual ability. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "Promoting People In Organizations",
					"article_url": "https://fs.blog/promoting-people-in-organizations/",
					"content": "Time on the job increased the expected sample of observations, reduced expected sampling error, and thus reduced the chance that the manager of moderate ability will either be promoted or exit. Hero Effect Within a group of managers of varying abilities, the faster the rate of promotion, the less likely it is to be justified. Performance records are produced by a combination of underlying ability and sampling variation. Managers who have good records are more likely to have high ability than managers who have poor records, but the reliability of the differentiation is small when records are short. Disappointment Effect On the average, new managers will be a disappointment. The performance records by which managers are evaluated are subject to sampling error. Since a manager is promoted to a new job on the basis of a good previous record, the proportion of promoted managers whose past records are better than their abilities will be greater than the proportion whose past records are poorer. ",
					"content_token": 180,
					"embedding": []
				},
				{
					"article_title": "Promoting People In Organizations",
					"article_url": "https://fs.blog/promoting-people-in-organizations/",
					"content": "As a result, on the average, managers will do less well in their new jobs than they did in their old ones, and observers will come to believe that higher level jobs are more difficult than lower level ones, even if they are not. The present results reinforce the idea that indistinguishability among managers is a joint property of the individuals being evaluated and the process by which they are evaluated. Performance sampling models show how careers may be the consequences of erroneous interpretations of variations in performance produced by equivalent managers. But they also indicate that the same pattern of careers could be the consequence of unreliable evaluation of managers who do, in fact, differ, or of managers who do, in fact, learn over the course of their experience. But hold on a second before you stop promoting new managers who, by definition, have a limited sample size. I’m not sure that sample size alone is the right way to think about this. ",
					"content_token": 188,
					"embedding": []
				},
				{
					"article_title": "Promoting People In Organizations",
					"article_url": "https://fs.blog/promoting-people-in-organizations/",
					"content": "Consider two people: Manager A and Manager B who are up for promotion. Manager A has 10 years of experience and is an “all-star” that is great performance with little variation in observations. Manager B, on the other hand, has only 5 years of experience but has shown a lot of variance in performance. If you had to hire someone you’d likely pick A. But it’s important not to misinterpret the results of March and March and dig a little deeper. What if we add one more variable to our two managers. Manager A’s job has been “easy” whereas Manager B took a very “tough” assignment. With this in mind, it seems reasonable to conclude that Manager B’s variance in performance could be explained by the difficulty of their task. This could also explain the lack of variance in Manager A’s performance. Some jobs are tougher than others. ",
					"content_token": 194,
					"embedding": []
				},
				{
					"article_title": "Promoting People In Organizations",
					"article_url": "https://fs.blog/promoting-people-in-organizations/",
					"content": "If you don’t factor in degree-of-difficulty you’re missing something big and sending a message to your workforce that discourages people from taking difficult assignments. The importance of measuring performance over a meaningful sample size is the key to distinguishing between luck and skill. When in doubt go with the person that’s excelled with more variance in difficulty.",
					"content_token": 76,
					"embedding": []
				}
			]
		},
		{
			"title": "Just for you: How Scarcity Factors Into Decisions",
			"url": "https://fs.blog/just-for-you-how-scarcity-factors-into-decisions/",
			"content": "Rather than invest the time and effort necessary to ponder the pluses and minuses of most decisions, we tend to rely on quick heuristics to make most decisions. These rules of thumb help us save cognitive processing and navigate a world full of choices. Our tendency to make near-automatic decisions exposes us to exploitation by individuals who understand how heuristics work. In the study below the authors were interested in what role the scarcity principlethe notion that the less available an opportunity appears, the more valuable it becomesplays in decision compliance and heuristics. Previously, there were two main ways that we thought scarcity played a role in compliance situations. First, something, a product for example, can be described as being in short supply or a limited edition. This is why sales often say “while supplies last” which leaves the reader with a slight nudge to purchase right now before missing out. Second, scarcity affects compliance when an opportunity is available for a limited time e.g., “This weekend only.” While these principles don’t ensure that someone will purchase a product, they do increase the odds of a purchase. The authors wanted to test another way that scarcity might factor into our decisions. They hypothesized that we naturally rely on a rule of thumb heuristic that says one should take advantage of a unique opportunity. Specifically, “the rule says that we should take advantage of opportunities that few others have access to. For example, if I believe I can purchase tickets to a play at a low price that is unavailable to most people, I am more likely to buy the tickets than if I believe many people have access to this same price.” We’ve all seen examples of this type of marketing already through “friends and family” and “not available to the public” events. But do they work? The authors certainly think so: individuals are more likely to comply with a request when they believe the request represents a unique opportunity not available to most people. The effect appears to operate independently of a limited supply effect and is not the result of a perceived need to help the requester. Moreover, the effect is found even when the opportunity is determined purely by chance, suggesting that individuals are not responding to a sense that they have somehow earned the opportunity. Rather, the unique opportunity effect appears to be the result of heuristic processing, i.e., people relying on a rule of thumb that says they should grab an opportunity available to few others. Source: Burger, J. M.  Caldwell, D.C., When opportunity knocks: The effect of a perceived unique opportunity on compliance. Group Processes and Intergroup Relations  Abstract: Four studies examined the effect of a perceived unique opportunity on compliance. In all four studies, participants who believed they had an opportunity available to few others were more likely to agree with a request than participants who believed the opportunity was widely available or participants who received no opportunity information. We attribute the effect to a widely held heuristic that one should take advantage of unique opportunities. Study results demonstrated that people respond to a perceived unique opportunity even when supplies are not limited and when the opportunity is the result of pure chance. The results of a mediation analysis supported the interpretation that the perceived uniqueness of the opportunity underlies the effect. ",
			"tokens": 666,
			"chunks": [
				{
					"article_title": "Just for you: How Scarcity Factors Into Decisions",
					"article_url": "https://fs.blog/just-for-you-how-scarcity-factors-into-decisions/",
					"content": "Rather than invest the time and effort necessary to ponder the pluses and minuses of most decisions, we tend to rely on quick heuristics to make most decisions. These rules of thumb help us save cognitive processing and navigate a world full of choices. Our tendency to make near-automatic decisions exposes us to exploitation by individuals who understand how heuristics work. In the study below the authors were interested in what role the scarcity principlethe notion that the less available an opportunity appears, the more valuable it becomesplays in decision compliance and heuristics. Previously, there were two main ways that we thought scarcity played a role in compliance situations. First, something, a product for example, can be described as being in short supply or a limited edition. This is why sales often say “while supplies last” which leaves the reader with a slight nudge to purchase right now before missing out. ",
					"content_token": 182,
					"embedding": []
				},
				{
					"article_title": "Just for you: How Scarcity Factors Into Decisions",
					"article_url": "https://fs.blog/just-for-you-how-scarcity-factors-into-decisions/",
					"content": "Second, scarcity affects compliance when an opportunity is available for a limited time e.g., “This weekend only.” While these principles don’t ensure that someone will purchase a product, they do increase the odds of a purchase. The authors wanted to test another way that scarcity might factor into our decisions. They hypothesized that we naturally rely on a rule of thumb heuristic that says one should take advantage of a unique opportunity. Specifically, “the rule says that we should take advantage of opportunities that few others have access to. For example, if I believe I can purchase tickets to a play at a low price that is unavailable to most people, I am more likely to buy the tickets than if I believe many people have access to this same price.” We’ve all seen examples of this type of marketing already through “friends and family” and “not available to the public” events. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "Just for you: How Scarcity Factors Into Decisions",
					"article_url": "https://fs.blog/just-for-you-how-scarcity-factors-into-decisions/",
					"content": "But do they work? The authors certainly think so: individuals are more likely to comply with a request when they believe the request represents a unique opportunity not available to most people. The effect appears to operate independently of a limited supply effect and is not the result of a perceived need to help the requester. Moreover, the effect is found even when the opportunity is determined purely by chance, suggesting that individuals are not responding to a sense that they have somehow earned the opportunity. Rather, the unique opportunity effect appears to be the result of heuristic processing, i.e., people relying on a rule of thumb that says they should grab an opportunity available to few others. Source: Burger, J. M.  Caldwell, D.C., When opportunity knocks: The effect of a perceived unique opportunity on compliance. Group Processes and Intergroup Relations  Abstract: Four studies examined the effect of a perceived unique opportunity on compliance. ",
					"content_token": 186,
					"embedding": []
				},
				{
					"article_title": "Just for you: How Scarcity Factors Into Decisions",
					"article_url": "https://fs.blog/just-for-you-how-scarcity-factors-into-decisions/",
					"content": "In all four studies, participants who believed they had an opportunity available to few others were more likely to agree with a request than participants who believed the opportunity was widely available or participants who received no opportunity information. We attribute the effect to a widely held heuristic that one should take advantage of unique opportunities. Study results demonstrated that people respond to a perceived unique opportunity even when supplies are not limited and when the opportunity is the result of pure chance. The results of a mediation analysis supported the interpretation that the perceived uniqueness of the opportunity underlies the effect.",
					"content_token": 109,
					"embedding": []
				}
			]
		},
		{
			"title": "A Simple Checklist to Improve Decisions",
			"url": "https://fs.blog/before-you-make-that-big-decision/",
			"content": "We owe thanks to the publishing industry. Their ability to take a concept and fill an entire category with a shotgun approach is the reason that more people are talking about biases. Unfortunately, talk alone will not eliminate them but it is possible to take steps to counteract them. Reducing biases can make a huge difference in the quality of any decision and it is easier than you think. In a recent article for Harvard Business Review, Daniel Kahneman and others describe a simple way to detect bias and minimize its effects in the most common type of decisions people make: determining whether to accept, reject, or pass on a recommendation. The Munger two-step process for making decisions is a more complete framework, but Kahneman’s approach is a good way to help reduce biases in our decision-making. If you’re short on time here is a simple checklist that will get you started on the path towards improving your decisions: Preliminary Questions: Ask yourself  1. Check for Self-interested Biases  Is there any reason to suspect the team making the recommendation of errors motivated by self-interest? Review the proposal with extra care, especially for overoptimism.  2. Check for the Affect Heuristic  Has the team fallen in love with its proposal? Rigorously apply all the quality controls on the checklist.  3. Check for Groupthink  Were there dissenting opinions within the team? Were they explored adequately? Solicit dissenting views, discreetly if necessary. Challenge Questions: Ask the recommenders  4. Check for Saliency Bias  Could the diagnosis be overly influenced by an analogy to a memorable success? Ask for more analogies, and rigorously analyze their similarity to the current situation.  5. Check for Confirmation Bias  Are credible alternatives included along with the recommendation? Request additional options.  6. Check for Availability Bias  If you had to make this decision again in a year’s time, what information would you want, and can you get more of it now? Use checklists of the data needed for each kind of decision.  7. Check for Anchoring Bias  Do you know where the numbers came from? Can there be unsubstantiated numbers? extrapolation from history? a motivation to use a certain anchor? Reanchor with figures generated by other models or benchmarks, and request new analysis.  8. Check for Halo Effect  Is the team assuming that a person, organization, or approach that is successful in one area will be just as successful in another? Eliminate false inferences, and ask the team to seek additional comparable examples.  9. Check for Sunk-Cost Fallacy, Endowment Effect  Are the recommenders overly attached to a history of past decisions? Consider the issue as if you were a new CEO. Evaluation Questions: Ask about the proposal  10. Check for Overconfidence, Planning Fallacy, Optimistic Biases, Competitor Neglect  Is the base case overly optimistic? Have the team build a case taking an outside view; use war games.  11. Check for Disaster Neglect  Is the worst case bad enough? Have the team conduct a premortem: Imagine that the worst has happened, and develop a story about the causes.  12. Check for Loss Aversion  Is the recommending team overly cautious? Realign incentives to share responsibility for the risk or to remove risk.  If you’re looking to dramatically improve your decision making here is a great list of books to get started: Nudge: Improving Decisions About Health, Wealth, and Happiness by Richard H. Thaler and Cass R. Sunstein Think Twice: Harnessing the Power of Counterintuition by Michael J. Mauboussin Think Again: Why Good Leaders Make Bad Decisions and How to Keep It from Happening to You by Sydney Finkelstein, Jo Whitehead, and Andrew Campbell Predictably Irrational: The Hidden Forces That Shape Our Decisions by Dan Ariely Thinking, Fast and Slow by Daniel Kahneman Judgment and Managerial Decision Making by Max Bazerman ",
			"tokens": 833,
			"chunks": [
				{
					"article_title": "A Simple Checklist to Improve Decisions",
					"article_url": "https://fs.blog/before-you-make-that-big-decision/",
					"content": "We owe thanks to the publishing industry. Their ability to take a concept and fill an entire category with a shotgun approach is the reason that more people are talking about biases. Unfortunately, talk alone will not eliminate them but it is possible to take steps to counteract them. Reducing biases can make a huge difference in the quality of any decision and it is easier than you think. In a recent article for Harvard Business Review, Daniel Kahneman and others describe a simple way to detect bias and minimize its effects in the most common type of decisions people make: determining whether to accept, reject, or pass on a recommendation. The Munger two-step process for making decisions is a more complete framework, but Kahneman’s approach is a good way to help reduce biases in our decision-making. If you’re short on time here is a simple checklist that will get you started on the path towards improving your decisions: Preliminary Questions: Ask yourself  1. ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "A Simple Checklist to Improve Decisions",
					"article_url": "https://fs.blog/before-you-make-that-big-decision/",
					"content": "Check for Self-interested Biases  Is there any reason to suspect the team making the recommendation of errors motivated by self-interest? Review the proposal with extra care, especially for overoptimism.  2. Check for the Affect Heuristic  Has the team fallen in love with its proposal? Rigorously apply all the quality controls on the checklist.  3. Check for Groupthink  Were there dissenting opinions within the team? Were they explored adequately? Solicit dissenting views, discreetly if necessary. Challenge Questions: Ask the recommenders  4. Check for Saliency Bias  Could the diagnosis be overly influenced by an analogy to a memorable success? Ask for more analogies, and rigorously analyze their similarity to the current situation.  5. Check for Confirmation Bias  Are credible alternatives included along with the recommendation? Request additional options.  6. ",
					"content_token": 177,
					"embedding": []
				},
				{
					"article_title": "A Simple Checklist to Improve Decisions",
					"article_url": "https://fs.blog/before-you-make-that-big-decision/",
					"content": "Check for Availability Bias  If you had to make this decision again in a year’s time, what information would you want, and can you get more of it now? Use checklists of the data needed for each kind of decision.  7. Check for Anchoring Bias  Do you know where the numbers came from? Can there be unsubstantiated numbers? extrapolation from history? a motivation to use a certain anchor? Reanchor with figures generated by other models or benchmarks, and request new analysis.  8. Check for Halo Effect  Is the team assuming that a person, organization, or approach that is successful in one area will be just as successful in another? Eliminate false inferences, and ask the team to seek additional comparable examples.  9. Check for Sunk-Cost Fallacy, Endowment Effect  Are the recommenders overly attached to a history of past decisions? Consider the issue as if you were a new CEO. ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "A Simple Checklist to Improve Decisions",
					"article_url": "https://fs.blog/before-you-make-that-big-decision/",
					"content": "Evaluation Questions: Ask about the proposal  10. Check for Overconfidence, Planning Fallacy, Optimistic Biases, Competitor Neglect  Is the base case overly optimistic? Have the team build a case taking an outside view; use war games.  11. Check for Disaster Neglect  Is the worst case bad enough? Have the team conduct a premortem: Imagine that the worst has happened, and develop a story about the causes.  12. Check for Loss Aversion  Is the recommending team overly cautious? Realign incentives to share responsibility for the risk or to remove risk.  If you’re looking to dramatically improve your decision making here is a great list of books to get started: Nudge: Improving Decisions About Health, Wealth, and Happiness by Richard H. Thaler and Cass R. Sunstein Think Twice: Harnessing the Power of Counterintuition by Michael J. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "A Simple Checklist to Improve Decisions",
					"article_url": "https://fs.blog/before-you-make-that-big-decision/",
					"content": "Mauboussin Think Again: Why Good Leaders Make Bad Decisions and How to Keep It from Happening to You by Sydney Finkelstein, Jo Whitehead, and Andrew Campbell Predictably Irrational: The Hidden Forces That Shape Our Decisions by Dan Ariely Thinking, Fast and Slow by Daniel Kahneman Judgment and Managerial Decision Making by Max Bazerman",
					"content_token": 74,
					"embedding": []
				}
			]
		},
		{
			"title": "Albert Bernstein on the Dinosaur Brain and How To Make Bad Decisions",
			"url": "https://fs.blog/how-to-make-bad-decisions/",
			"content": "I enjoyed reading Dinosaur Brains: Dealing with All Those Impossible People at Work by Albert Bernstein. Near the end of the book, Bernstein playfully illuminates how too many decisions get made.   Take an idea from some authority figure, maybe your boss, or an author; Tell everyone this idea is the basis for all the change you’re going to make; Do things the way you’ve always done them; If something changes, take credit for it. If something bad happens, point out that this just goes to show that the old way of doing things was better.   Sound familiar? It should. Another approach, let’s call it the more rational approach, might look something like:  Understand the problem, or set a goal; Establish criteria how will you know the problem is solved or you’ve reached your goal; Generate alternatives; Measure alternatives versus criteria and try a few of them; Evaluate; Choose the best solution.  This approach probably won’t get you promoted, but it will increase the odds of making better decisions. ",
			"tokens": 232,
			"chunks": [
				{
					"article_title": "Albert Bernstein on the Dinosaur Brain and How To Make Bad Decisions",
					"article_url": "https://fs.blog/how-to-make-bad-decisions/",
					"content": "I enjoyed reading Dinosaur Brains: Dealing with All Those Impossible People at Work by Albert Bernstein. Near the end of the book, Bernstein playfully illuminates how too many decisions get made.   Take an idea from some authority figure, maybe your boss, or an author; Tell everyone this idea is the basis for all the change you’re going to make; Do things the way you’ve always done them; If something changes, take credit for it. If something bad happens, point out that this just goes to show that the old way of doing things was better.   Sound familiar? It should. ",
					"content_token": 134,
					"embedding": []
				},
				{
					"article_title": "Albert Bernstein on the Dinosaur Brain and How To Make Bad Decisions",
					"article_url": "https://fs.blog/how-to-make-bad-decisions/",
					"content": "Another approach, let’s call it the more rational approach, might look something like:  Understand the problem, or set a goal; Establish criteria how will you know the problem is solved or you’ve reached your goal; Generate alternatives; Measure alternatives versus criteria and try a few of them; Evaluate; Choose the best solution.  This approach probably won’t get you promoted, but it will increase the odds of making better decisions.",
					"content_token": 98,
					"embedding": []
				}
			]
		},
		{
			"title": "The Art and Science of High-Stakes Decisions",
			"url": "https://fs.blog/the-art-and-science-of-high-stakes-decisions/",
			"content": "How can anyone make rational decisions in a world where knowledge is limited, time is pressing, and deep thought is often unattainable? Some decisions are more difficult than others. Yet we’re often forced to make all of our decisions the way we make easy ones: on autopilot.  One particular difficulty we have is with making decisions that help us avoid threats which are low probability, but high stakes. We are least prepared to make the decisions that matter the most. Sure we can pick the right brand of peanut butter with ease. But life offers few opportunities to prepare for the type of decisions which could have catastrophic consequences. The kinds of decisions which could wipe us out if we mess up. Shortly after 911 some well-known academics got together to discuss1how people make choices involving low and ambiguous probability of a high-stakes loss. High-stakes decisions involve two distinctive properties: 1 existence of a possible large loss financial or emotional and 2 the costs to reverse decisions once made are high. More importantly, these professors wanted to determine if prescriptive guidelines for improving decision-making process could be created in an effort to help make better decisions. Whether we’re buying something at the grocery store or making a decision to purchase earthquake insurance, we operate in the same way. The possibility of catastrophic outcomes does little to reduce our reliance on heuristics rules of thumb. These serve us well most of the time, when the cost of an error is low. However, they can often be a poor technique for high-stakes decisions. In order to make better high-stakes decisions, we need a better understanding of why we generally make poor decisions. Here are several causes. Poor understanding of probability. Several studies show that people either utilize probability information insufficiently when it is made available to them or ignore it all together. In one study, 78 of subjects failed to seek out probability information when evaluating between several risky managerial decisions. In the context of high-stakes decisions, the probability of an event causing loss may seem sufficiently low that organizations and individuals consider them not worth worry about. In doing so, they effectively treat the probability of something as zero or close to it. An excessive focus on short time horizons. Many high-stakes decisions are not obvious to the decision-maker. In part, this is because people tend to focus on the immediate consequences and not the long-term consequences. A CEO near retirement has incentives to skimp on insurance to report slightly higher profits before leaving shareholders are unaware of the increased risk and appreciate the increased profits. Governments tend to under-invest in less visible things like infrastructure because they have short election cycles. The long-term consequences of short-term thinking can be disastrous. The focus on short-term decision making is one of the most widely-documented failings of human decision making. People have difficulty considering the future consequences of current actions over long periods of time. Garrett Hardin, the author of Filters against Folly, suggests we look at things through three filters literacy, numeracy, and ecolacy. In ecolacy, the key question is “and then what?” And then what helps us avoid a focus solely on the short-term. Excessive attention to what’s available. Decisions requiring difficult trade-offs between attributes or entailing ambiguity as to what a right answer looks like often leads people to resolve choices by focusing on the information most easily brought to mind. Sometimes things can be difficult to bring to mind. Constant exposure to low-risk events without realization leads to us being less concerned than we probably would warrant it makes these events less available and “proves” our past decisions to ignore low-risk events were right. People refuse to buy flood insurance even when it is heavily subsidized and priced far below an actuarially fair value. Kunreuther et. al. 1993 suggests underreaction to threats of flooding may arise from “the inability of individuals to conceptualize floods that have never occurred Men on flood plains appear to be very much prisoners of their experience Recently experienced floods appear to set an upward bound to the size of loss with which managers believe they ought to be concerned.”Paradoxically, we feel more secure even as the “risk” may have increased. Distortions under stress. Most high-stakes decisions will be made under perceived or real stress. A large number of empirical studies find that stress focuses decision-makers on a selective set of cues when evaluating options and leads to greater reliance on simplifying heuristics. When we’re stressed, we’re less likely to think things through. Over-reliance on social norms. Most individuals have little experience with high-stakes decisions and are highly uncertain about how to resolve them procedural uncertainty. In such casesand combined with stressthe natural course of action is to mimic the behavior of others or follow established social norms. This is based on the psychological desire to fail conventionally. The tendency to prefer the status-quo. What happens when people are presented with difficult choices and no obvious right answer? We tend to prefer making no decision at all, we choose the norm. In high-stakes decisions many options are better than the status-quo and we must make trade-offs. Yet, when faced with decisions that involve life-and-death trade-offs, people frequently remark “I’d rather not think about it.” Failures to learn. Although individuals and organizations are eager to derive intelligence from experience, the inferences stemming from that eagerness are often misguided. The problems lie partly in errors in how people think, but even more so in properties of experience that confound learning from it. Experience may possibly be the best teacher, but it is not a particularly good teacher. As an illustration, one study finds that participants in an earthquake simulation tended to over-invest in mitigation that was normatively ineffective but under-invest when it is normatively effective. The reason was a misinterpretation of feedback; when mitigation was ineffective, respondents attributed the persistence of damage to the fact that they had not invested enough. by contract, when it was effective, they attributed the absence of damage to a belief that earthquakes posted limited damage risk. Gresham’s Law of Decision making. Over time, bad decisions will tend to drive out good decisions in an organization. Improving. What can you do to improve your decision-making? A few things: 1 learn more about judgment and decision making; 2 encourage decision makers to see events through alternative frames, such as gains versus losses and changes in the status-quo; 3 adjust the time frame of decisionswhile the probability of an earthquake at your plant may be 1100 in any given year, the probability over the 25 year life of the plant will be 15; and 4 read Farnam Street! ",
			"tokens": 1392,
			"chunks": [
				{
					"article_title": "The Art and Science of High-Stakes Decisions",
					"article_url": "https://fs.blog/the-art-and-science-of-high-stakes-decisions/",
					"content": "How can anyone make rational decisions in a world where knowledge is limited, time is pressing, and deep thought is often unattainable? Some decisions are more difficult than others. Yet we’re often forced to make all of our decisions the way we make easy ones: on autopilot.  One particular difficulty we have is with making decisions that help us avoid threats which are low probability, but high stakes. We are least prepared to make the decisions that matter the most. Sure we can pick the right brand of peanut butter with ease. But life offers few opportunities to prepare for the type of decisions which could have catastrophic consequences. The kinds of decisions which could wipe us out if we mess up. Shortly after 911 some well-known academics got together to discuss1how people make choices involving low and ambiguous probability of a high-stakes loss. ",
					"content_token": 171,
					"embedding": []
				},
				{
					"article_title": "The Art and Science of High-Stakes Decisions",
					"article_url": "https://fs.blog/the-art-and-science-of-high-stakes-decisions/",
					"content": "High-stakes decisions involve two distinctive properties: 1 existence of a possible large loss financial or emotional and 2 the costs to reverse decisions once made are high. More importantly, these professors wanted to determine if prescriptive guidelines for improving decision-making process could be created in an effort to help make better decisions. Whether we’re buying something at the grocery store or making a decision to purchase earthquake insurance, we operate in the same way. The possibility of catastrophic outcomes does little to reduce our reliance on heuristics rules of thumb. These serve us well most of the time, when the cost of an error is low. However, they can often be a poor technique for high-stakes decisions. In order to make better high-stakes decisions, we need a better understanding of why we generally make poor decisions. Here are several causes. Poor understanding of probability. Several studies show that people either utilize probability information insufficiently when it is made available to them or ignore it all together. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "The Art and Science of High-Stakes Decisions",
					"article_url": "https://fs.blog/the-art-and-science-of-high-stakes-decisions/",
					"content": "In one study, 78 of subjects failed to seek out probability information when evaluating between several risky managerial decisions. In the context of high-stakes decisions, the probability of an event causing loss may seem sufficiently low that organizations and individuals consider them not worth worry about. In doing so, they effectively treat the probability of something as zero or close to it. An excessive focus on short time horizons. Many high-stakes decisions are not obvious to the decision-maker. In part, this is because people tend to focus on the immediate consequences and not the long-term consequences. A CEO near retirement has incentives to skimp on insurance to report slightly higher profits before leaving shareholders are unaware of the increased risk and appreciate the increased profits. Governments tend to under-invest in less visible things like infrastructure because they have short election cycles. The long-term consequences of short-term thinking can be disastrous. ",
					"content_token": 180,
					"embedding": []
				},
				{
					"article_title": "The Art and Science of High-Stakes Decisions",
					"article_url": "https://fs.blog/the-art-and-science-of-high-stakes-decisions/",
					"content": "The focus on short-term decision making is one of the most widely-documented failings of human decision making. People have difficulty considering the future consequences of current actions over long periods of time. Garrett Hardin, the author of Filters against Folly, suggests we look at things through three filters literacy, numeracy, and ecolacy. In ecolacy, the key question is “and then what?” And then what helps us avoid a focus solely on the short-term. Excessive attention to what’s available. Decisions requiring difficult trade-offs between attributes or entailing ambiguity as to what a right answer looks like often leads people to resolve choices by focusing on the information most easily brought to mind. Sometimes things can be difficult to bring to mind. ",
					"content_token": 160,
					"embedding": []
				},
				{
					"article_title": "The Art and Science of High-Stakes Decisions",
					"article_url": "https://fs.blog/the-art-and-science-of-high-stakes-decisions/",
					"content": "Constant exposure to low-risk events without realization leads to us being less concerned than we probably would warrant it makes these events less available and “proves” our past decisions to ignore low-risk events were right. People refuse to buy flood insurance even when it is heavily subsidized and priced far below an actuarially fair value. Kunreuther et. al. 1993 suggests underreaction to threats of flooding may arise from “the inability of individuals to conceptualize floods that have never occurred Men on flood plains appear to be very much prisoners of their experience Recently experienced floods appear to set an upward bound to the size of loss with which managers believe they ought to be concerned.”Paradoxically, we feel more secure even as the “risk” may have increased. Distortions under stress. Most high-stakes decisions will be made under perceived or real stress. ",
					"content_token": 183,
					"embedding": []
				},
				{
					"article_title": "The Art and Science of High-Stakes Decisions",
					"article_url": "https://fs.blog/the-art-and-science-of-high-stakes-decisions/",
					"content": "A large number of empirical studies find that stress focuses decision-makers on a selective set of cues when evaluating options and leads to greater reliance on simplifying heuristics. When we’re stressed, we’re less likely to think things through. Over-reliance on social norms. Most individuals have little experience with high-stakes decisions and are highly uncertain about how to resolve them procedural uncertainty. In such casesand combined with stressthe natural course of action is to mimic the behavior of others or follow established social norms. This is based on the psychological desire to fail conventionally. The tendency to prefer the status-quo. What happens when people are presented with difficult choices and no obvious right answer? We tend to prefer making no decision at all, we choose the norm. In high-stakes decisions many options are better than the status-quo and we must make trade-offs. ",
					"content_token": 185,
					"embedding": []
				},
				{
					"article_title": "The Art and Science of High-Stakes Decisions",
					"article_url": "https://fs.blog/the-art-and-science-of-high-stakes-decisions/",
					"content": "Yet, when faced with decisions that involve life-and-death trade-offs, people frequently remark “I’d rather not think about it.” Failures to learn. Although individuals and organizations are eager to derive intelligence from experience, the inferences stemming from that eagerness are often misguided. The problems lie partly in errors in how people think, but even more so in properties of experience that confound learning from it. Experience may possibly be the best teacher, but it is not a particularly good teacher. As an illustration, one study finds that participants in an earthquake simulation tended to over-invest in mitigation that was normatively ineffective but under-invest when it is normatively effective. The reason was a misinterpretation of feedback; when mitigation was ineffective, respondents attributed the persistence of damage to the fact that they had not invested enough. by contract, when it was effective, they attributed the absence of damage to a belief that earthquakes posted limited damage risk. ",
					"content_token": 197,
					"embedding": []
				},
				{
					"article_title": "The Art and Science of High-Stakes Decisions",
					"article_url": "https://fs.blog/the-art-and-science-of-high-stakes-decisions/",
					"content": "Gresham’s Law of Decision making. Over time, bad decisions will tend to drive out good decisions in an organization. Improving. What can you do to improve your decision-making? A few things: 1 learn more about judgment and decision making; 2 encourage decision makers to see events through alternative frames, such as gains versus losses and changes in the status-quo; 3 adjust the time frame of decisionswhile the probability of an earthquake at your plant may be 1100 in any given year, the probability over the 25 year life of the plant will be 15; and 4 read Farnam Street!",
					"content_token": 124,
					"embedding": []
				}
			]
		},
		{
			"title": "Ethical Breakdowns: Why Good People often Let Bad Things Happen",
			"url": "https://fs.blog/ethical-breakdowns-why-good-people-often-let-bad-things-happen/",
			"content": "When Charlie Munger recommended reading Max Bazerman’s Judgment in Managerial Decision Making I had never hear of the HBS professor. A lot of reading later and I’m a huge fan. In the HBR article below Bazerman covers some of the ground from his new book Blind Spots see my notes. These days, many of us are instructed to make decisions from a business perspective thereby reducing or eliminating the ethical implications of our decisions. The Ford Pinto example below is very telling: Consider an infamous case that, when it broke, had all the earmarks of conscious top-down corruption. The Ford Pinto, a compact car produced during the 1970s, became notorious for its tendency in rear-end collisions to leak fuel and explode into flames. More than two dozen people were killed or injured in Pinto fires before the company issued a recall to correct the problem. Scrutiny of the decision process behind the model’s launch revealed that under intense competition from Volkswagen and other small-car manufacturers, Ford had rushed the Pinto into production. Engineers had discovered the potential danger of ruptured fuel tanks in preproduction crash tests, but the assembly line was ready to go, and the company’s leaders decided to proceed. Many saw the decision as evidence of the callousness, greed, and mendacity of Ford’s leadersin short, their deep unethicality. But looking at their decision through a modern lensone that takes into account a growing understanding of how cognitive biases distort ethical decision makingwe come to a different conclusion. We suspect that few if any of the executives involved in the Pinto decision believed that they were making an unethical choice. Why? Apparently because they thought of it as purely a business decision rather than an ethical one. Taking an approach heralded as rational in most business school curricula, they conducted a formal cost-benefit analysisputting dollar amounts on a redesign, potential lawsuits, and even livesand determined that it would be cheaper to pay off lawsuits than to make the repair. That methodical process colored how they viewed and made their choice. The moral dimension was not part of the equation. Such “ethical fading,” a phenomenon first described by Ann Tenbrunsel and her colleague David Messick, takes ethics out of consideration and even increases unconscious unethical behavior. Continue Reading at HBR. I recommend you purchase Judgment in Managerial Decision Making and Blind Spots. ",
			"tokens": 505,
			"chunks": [
				{
					"article_title": "Ethical Breakdowns: Why Good People often Let Bad Things Happen",
					"article_url": "https://fs.blog/ethical-breakdowns-why-good-people-often-let-bad-things-happen/",
					"content": "When Charlie Munger recommended reading Max Bazerman’s Judgment in Managerial Decision Making I had never hear of the HBS professor. A lot of reading later and I’m a huge fan. In the HBR article below Bazerman covers some of the ground from his new book Blind Spots see my notes. These days, many of us are instructed to make decisions from a business perspective thereby reducing or eliminating the ethical implications of our decisions. The Ford Pinto example below is very telling: Consider an infamous case that, when it broke, had all the earmarks of conscious top-down corruption. The Ford Pinto, a compact car produced during the 1970s, became notorious for its tendency in rear-end collisions to leak fuel and explode into flames. More than two dozen people were killed or injured in Pinto fires before the company issued a recall to correct the problem. ",
					"content_token": 187,
					"embedding": []
				},
				{
					"article_title": "Ethical Breakdowns: Why Good People often Let Bad Things Happen",
					"article_url": "https://fs.blog/ethical-breakdowns-why-good-people-often-let-bad-things-happen/",
					"content": "Scrutiny of the decision process behind the model’s launch revealed that under intense competition from Volkswagen and other small-car manufacturers, Ford had rushed the Pinto into production. Engineers had discovered the potential danger of ruptured fuel tanks in preproduction crash tests, but the assembly line was ready to go, and the company’s leaders decided to proceed. Many saw the decision as evidence of the callousness, greed, and mendacity of Ford’s leadersin short, their deep unethicality. But looking at their decision through a modern lensone that takes into account a growing understanding of how cognitive biases distort ethical decision makingwe come to a different conclusion. We suspect that few if any of the executives involved in the Pinto decision believed that they were making an unethical choice. Why? Apparently because they thought of it as purely a business decision rather than an ethical one. ",
					"content_token": 182,
					"embedding": []
				},
				{
					"article_title": "Ethical Breakdowns: Why Good People often Let Bad Things Happen",
					"article_url": "https://fs.blog/ethical-breakdowns-why-good-people-often-let-bad-things-happen/",
					"content": "Taking an approach heralded as rational in most business school curricula, they conducted a formal cost-benefit analysisputting dollar amounts on a redesign, potential lawsuits, and even livesand determined that it would be cheaper to pay off lawsuits than to make the repair. That methodical process colored how they viewed and made their choice. The moral dimension was not part of the equation. Such “ethical fading,” a phenomenon first described by Ann Tenbrunsel and her colleague David Messick, takes ethics out of consideration and even increases unconscious unethical behavior. Continue Reading at HBR. I recommend you purchase Judgment in Managerial Decision Making and Blind Spots.",
					"content_token": 137,
					"embedding": []
				}
			]
		},
		{
			"title": "Why You Are Not As Ethical As You Think",
			"url": "https://fs.blog/you-are-not-as-ethical-as-you-think/",
			"content": "Ethical infractions are rooted in the intricacies of human psychology rather than integrity. We are wired far more strongly for unethical behavior than for integrity.  Max Bazerman and Ann Tebrusnel’s book: Blind Spots covers the ways in which we overestimate our ability to behave ethically.  Briefly, here are some of our takeaways.  We engage in behavioral forecasting errors. We believe we will behave a certain way in a certain situation. Yet, when actually faced with that situation we behave differently. When we behave in unethical ways, we are experts at deflecting blame and rationalizing our behavior. For instance, a used car salesman may view selling a car that leaks oil as perfectly ethical because the buyer failed to ask. bias from self-interest. People often judge the ethicality of actions based on the outcome outcome bias. We tend to be far more concerned with and show more sympathy when the actions taken affect “identifiable victims”. We may experience motivated blindness when we have an incentive to overlook the consequences of an action. when one party has an interest in overlooking the unethical behavior of another party People who are mentally overloaded are more likely to cheat on a task than those who are not. Why? Because it takes cognitive effort to skip the temptation to cheat. Our brains are designed to make quick decisions. This means they can fail to consider outside influences, such as ethical concerns. We’re also more willing to cheat to avoid a loss than for gain. When making snap decisions, we are especially prone to unconscious bias. The less time we have to think, the more we default to in-group preferences along racial lines. Research shows that most people view their own input into a group, their division’s input to the overall organization, and their firm’s contributions to a strategic alliance to be more important and substantial than reality can sustain. Over-claiming this credit is, at least partly rooted in our bounded ethicality. That is, we exclude important and relevant information from our decisions by placing arbitrary and functional bounds around our definition of a problem normally in a self-serving manner. This is part of the reason we fail to see eye to eye in disagreements  we pay attention to different data. The difference in the way information is processed is often not intentional. Confirmation bias helps our minds absorb information that is in agreement with our beliefs and discount information that may contradict our thoughts. We can’t remember our previous intentions either; How Our Brains Make Memories. Egocentrism is dangerous when playing a Tragedy of the Commons game Social Dilemma such as the one we’re currently playing with debt and the environment as it encourages us to over claim resources. In the end the kindergarten rule of fairness applies: one person cuts the cookie and the other has first pick on which half to eat. In social dilemmas the easiest strategy is to defect. A whole host of societal problems result from our tendency to use an extremely high discount rate regarding the future. One result is that we save far too little for retirement. Over-discounting the future can be immoral too as it robs future generations of opportunities and resources. Compliance programs often include sanctioning systems that attempt to discourage unethical behavior, typically though punishment. Yet these programs often have the reverse effect, encouraging the behavior they are supposed to discourage. Why? In short because it removes the ethical consideration and makes it a business decision. The number of late pick ups at daycares increase when there is a fine. When your informal culture doesn’t line up with your formal culture you have blind spots and employees will follow the informal culture. Of course, we’re overconfident so informing us about our blind spots doesn’t seem to help us make better choices. We tend to believe that while others may fall prey to psychological biases, we don’t. Left to our own devices we dramatically understate the degree to which our own behavior is affected by incentives and situational factors.   Still curious? Check out Blind Spots. This book will help you see how your biases lead to your own immoral actions. And if you’re still curious try: Bounded Ethicality: The Perils of Loss Framing. ",
			"tokens": 874,
			"chunks": [
				{
					"article_title": "Why You Are Not As Ethical As You Think",
					"article_url": "https://fs.blog/you-are-not-as-ethical-as-you-think/",
					"content": "Ethical infractions are rooted in the intricacies of human psychology rather than integrity. We are wired far more strongly for unethical behavior than for integrity.  Max Bazerman and Ann Tebrusnel’s book: Blind Spots covers the ways in which we overestimate our ability to behave ethically.  Briefly, here are some of our takeaways.  We engage in behavioral forecasting errors. We believe we will behave a certain way in a certain situation. Yet, when actually faced with that situation we behave differently. When we behave in unethical ways, we are experts at deflecting blame and rationalizing our behavior. For instance, a used car salesman may view selling a car that leaks oil as perfectly ethical because the buyer failed to ask. bias from self-interest. People often judge the ethicality of actions based on the outcome outcome bias. We tend to be far more concerned with and show more sympathy when the actions taken affect “identifiable victims” ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "Why You Are Not As Ethical As You Think",
					"article_url": "https://fs.blog/you-are-not-as-ethical-as-you-think/",
					"content": "We may experience motivated blindness when we have an incentive to overlook the consequences of an action. when one party has an interest in overlooking the unethical behavior of another party People who are mentally overloaded are more likely to cheat on a task than those who are not. Why? Because it takes cognitive effort to skip the temptation to cheat. Our brains are designed to make quick decisions. This means they can fail to consider outside influences, such as ethical concerns. We’re also more willing to cheat to avoid a loss than for gain. When making snap decisions, we are especially prone to unconscious bias. The less time we have to think, the more we default to in-group preferences along racial lines. Research shows that most people view their own input into a group, their division’s input to the overall organization, and their firm’s contributions to a strategic alliance to be more important and substantial than reality can sustain. ",
					"content_token": 187,
					"embedding": []
				},
				{
					"article_title": "Why You Are Not As Ethical As You Think",
					"article_url": "https://fs.blog/you-are-not-as-ethical-as-you-think/",
					"content": "Over-claiming this credit is, at least partly rooted in our bounded ethicality. That is, we exclude important and relevant information from our decisions by placing arbitrary and functional bounds around our definition of a problem normally in a self-serving manner. This is part of the reason we fail to see eye to eye in disagreements  we pay attention to different data. The difference in the way information is processed is often not intentional. Confirmation bias helps our minds absorb information that is in agreement with our beliefs and discount information that may contradict our thoughts. We can’t remember our previous intentions either; How Our Brains Make Memories. Egocentrism is dangerous when playing a Tragedy of the Commons game Social Dilemma such as the one we’re currently playing with debt and the environment as it encourages us to over claim resources. ",
					"content_token": 175,
					"embedding": []
				},
				{
					"article_title": "Why You Are Not As Ethical As You Think",
					"article_url": "https://fs.blog/you-are-not-as-ethical-as-you-think/",
					"content": "In the end the kindergarten rule of fairness applies: one person cuts the cookie and the other has first pick on which half to eat. In social dilemmas the easiest strategy is to defect. A whole host of societal problems result from our tendency to use an extremely high discount rate regarding the future. One result is that we save far too little for retirement. Over-discounting the future can be immoral too as it robs future generations of opportunities and resources. Compliance programs often include sanctioning systems that attempt to discourage unethical behavior, typically though punishment. Yet these programs often have the reverse effect, encouraging the behavior they are supposed to discourage. Why? In short because it removes the ethical consideration and makes it a business decision. The number of late pick ups at daycares increase when there is a fine. When your informal culture doesn’t line up with your formal culture you have blind spots and employees will follow the informal culture. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "Why You Are Not As Ethical As You Think",
					"article_url": "https://fs.blog/you-are-not-as-ethical-as-you-think/",
					"content": "Of course, we’re overconfident so informing us about our blind spots doesn’t seem to help us make better choices. We tend to believe that while others may fall prey to psychological biases, we don’t. Left to our own devices we dramatically understate the degree to which our own behavior is affected by incentives and situational factors.   Still curious? Check out Blind Spots. This book will help you see how your biases lead to your own immoral actions. And if you’re still curious try: Bounded Ethicality: The Perils of Loss Framing.",
					"content_token": 124,
					"embedding": []
				}
			]
		},
		{
			"title": "Seth Klarman: The Forgotten Lessons of 2008",
			"url": "https://fs.blog/the-forgotten-lessons-of-2008/",
			"content": "In this excerpt from his annual letter, investing great Seth Klarman describes 20 lessons from the financial crisis which, he says, “were either never learned or else were immediately forgotten by most market participants.”    The Forgotten Lessons of 2008 One might have expected that the near-death experience of most investors in 2008 would generate valuable lessons for the future. We all know about the “depression mentality” of our parents and grandparents who lived through the Great Depression. Memories of tough times colored their behavior for more than a generation, leading to limited risk taking and a sustainable base for healthy growth. Yet one year after the 2008 collapse, investors have returned to shockingly speculative behavior. One state investment board recently adopted a plan to leverage its portfolio – specifically its government and high-grade bond holdings – in an amount that could grow to 20 of its assets over the next three years. No one who was paying attention in 2008 would possibly think this is a good idea. Below, we highlight the lessons that we believe could and should have been learned from the turmoil of 2008. Some of them are unique to the 2008 melt- down; others, which could have been drawn from general market observation over the past several decades, were certainly reinforced last year. Shockingly, virtually all of these lessons were either never learned or else were immediately forgotten by most market participants. Twenty Investment Lessons of 2008  Things that have never happened before are bound to occur with some regularity. You must always be prepared for the unexpected, including sudden, sharp downward swings in markets and the economy. Whatever adverse scenario you can contemplate, reality can be far worse. When excesses such as lax lending standards become widespread and persist for some time, people are lulled into a false sense of security, creating an even more dangerous situation. In some cases, excesses migrate beyond regional or national borders, raising the ante for investors and governments. These excesses will eventually end, triggering a crisis at least in proportion to the degree of the excesses. Correlations between asset classes may be surprisingly high when leverage rapidly unwinds. Nowhere does it say that investors should strive to make every last dollar of potential profit; consideration of risk must never take a backseat to return. Conservative positioning entering a crisis is crucial: it enables one to maintain long-term oriented, clear thinking, and to focus on new opportunities while others are distracted or even forced to sell. Portfolio hedges must be in place before a crisis hits. One cannot reliably or affordably increase or replace hedges that are rolling off during a financial crisis. Risk is not inherent in an investment; it is always relative to the price paid. Uncertainty is not the same as risk. Indeed, when great uncertainty – such as in the fall of 2008 – drives securities prices to especially low levels, they often become less risky investments. Do not trust financial market risk models. Reality is always too complex to be accurately modeled. Attention to risk must be a 247365 obsession, with people – not computers – assessing and reassessing the risk environment in real time. Despite the predilection of some analysts to model the financial markets using sophisticated mathematics, the markets are governed by behavioral science, not physical science. Do not accept principal risk while investing short-term cash: the greedy effort to earn a few extra basis points of yield inevitably leads to the incurrence of greater risk, which increases the likelihood of losses and severe illiquidity at precisely the moment when cash is needed to cover expenses, to meet commitments, or to make compelling long-term investments. The latest trade of a security creates a dangerous illusion that its market price approximates its true value. This mirage is especially dangerous during periods of market exuberance. The concept of “private market value” as an anchor to the proper valuation of a business can also be greatly skewed during ebullient times and should always be considered with a healthy degree of skepticism. A broad and flexible investment approach is essential during a crisis. Opportunities can be vast, ephemeral, and dispersed through various sectors and markets. Rigid silos can be an enormous disadvantage at such times. You must buy on the way down. There is far more volume on the way down than on the way back up, and far less competition among buyers. It is almost always better to be too early than too late, but you must be prepared for price markdowns on what you buy. Financial innovation can be highly dangerous, though almost no one will tell you this. New financial products are typically created for sunny days and are almost never stress-tested for stormy weather. Securitization is an area that almost perfectly fits this description; markets for securitized assets such as subprime mortgages completely collapsed in 2008 and have not fully recovered. Ironically, the government is eager to restore the securitization markets back to their pre-collapse stature. Ratings agencies are highly conflicted, unimaginative dupes. They are blissfully unaware of adverse selection and moral hazard. Investors should never trust them. Be sure that you are well compensated for illiquidity – especially illiquidity without control – because it can create particularly high opportunity costs. At equal returns, public investments are generally superior to private investments not only because they are more liquid but also because amidst distress, public markets are more likely than private ones to offer attractive opportunities to average down. Beware leverage in all its forms. Borrowers – individual, corporate, or government – should always match fund their liabilities against the duration of their assets. Borrowers must always remember that capital markets can be extremely fickle, and that it is never safe to assume a maturing loan can be rolled over. Even if you are unleveraged, the leverage employed by others can drive dramatic price and valuation swings; sudden unavailability of leverage in the economy may trigger an economic downturn. Many LBOs are man-made disasters. When the price paid is excessive, the equity portion of an LBO is really an out-of-the-money call option. Many fiduciaries placed large amounts of the capital under their stewardship into such options in 2006 and 2007. Financial stocks are particularly risky. Banking, in particular, is a highly lever- aged, extremely competitive, and challenging business. A major European bank recently announced the goal of achieving a 20 return on equity ROE within several years. Unfortunately, ROE is highly dependent on absolute yields, yield spreads, maintaining adequate loan loss reserves, and the amount of leverage used. What is the bank’s management to do if it cannot readily get to 20? Leverage up? Hold riskier assets? Ignore the risk of loss? In some ways, for a major financial institution even to have a ROE goal is to court disaster. Having clients with a long-term orientation is crucial. Nothing else is as important to the success of an investment firm. When a government official says a problem has been “contained,” pay no attention. The government – the ultimate short- term-oriented player – cannot with- stand much pain in the economy or the financial markets. Bailouts and rescues are likely to occur, though not with sufficient predictability for investors to comfortably take advantage. The government will take enormous risks in such interventions, especially if the expenses can be conveniently deferred to the future. Some of the price-tag is in the form of back- stops and guarantees, whose cost is almost impossible to determine. Almost no one will accept responsibility for his or her role in precipitating a crisis: not leveraged speculators, not willfully blind leaders of financial institutions, and certainly not regulators, government officials, ratings agencies or politicians.  Below, we itemize some of the quite different lessons investors seem to have learned as of late 2009 – false lessons, we believe. To not only learn but also effectively implement investment lessons requires a disciplined, often contrary, and long-term-oriented investment approach. It requires a resolute focus on risk aversion rather than maximizing immediate returns, as well as an understanding of history, a sense of financial market cycles, and, at times, extraordinary patience. False Lessons  There are no long-term lessons – ever. Bad things happen, but really bad things do not. Do buy the dips, especially the lowest quality securities when they come under pressure, because declines will quickly be reversed. There is no amount of bad news that the markets cannot see past. If you’ve just stared into the abyss, quickly forget it: the lessons of history can only hold you back. Excess capacity in people, machines, or property will be quickly absorbed. Markets need not be in sync with one another. Simultaneously, the bond market can be priced for sustained tough times, the equity market for a strong recovery, and gold for high inflation. Such an apparent disconnect is indefinitely sustainable. In a crisis, stocks of financial companies are great investments, because the tide is bound to turn. Massive losses on bad loans and soured investments are irrelevant to value; improving trends and future prospects are what matter, regardless of whether profits will have to be used to cover loan losses and equity shortfalls for years to come. The government can reasonably rely on debt ratings when it forms programs to lend money to buyers of otherwise unattractive debt instruments. The government can indefinitely control both short-term and long-term interest rates. The government can always rescue the markets or interfere with contract law whenever it deems convenient with little or no apparent cost. Investors believe this now and, worse still, the government believes it as well. We are probably doomed to a lasting legacy of government tampering with financial markets and the economy, which is likely to create the mother of all moral hazards. The government is blissfully unaware of the wisdom of Friedrich Hayek: “The curious task of economics is to demonstrate to men how little they really know about what they imagine they can design.”   Still curious? Check out Basically, It’s Over: A Parable About How One Nation Came To Financial Ruin by Charlie Munger. ",
			"tokens": 2050,
			"chunks": [
				{
					"article_title": "Seth Klarman: The Forgotten Lessons of 2008",
					"article_url": "https://fs.blog/the-forgotten-lessons-of-2008/",
					"content": "In this excerpt from his annual letter, investing great Seth Klarman describes 20 lessons from the financial crisis which, he says, “were either never learned or else were immediately forgotten by most market participants.”    The Forgotten Lessons of 2008 One might have expected that the near-death experience of most investors in 2008 would generate valuable lessons for the future. We all know about the “depression mentality” of our parents and grandparents who lived through the Great Depression. Memories of tough times colored their behavior for more than a generation, leading to limited risk taking and a sustainable base for healthy growth. Yet one year after the 2008 collapse, investors have returned to shockingly speculative behavior. One state investment board recently adopted a plan to leverage its portfolio – specifically its government and high-grade bond holdings – in an amount that could grow to 20 of its assets over the next three years. No one who was paying attention in 2008 would possibly think this is a good idea. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "Seth Klarman: The Forgotten Lessons of 2008",
					"article_url": "https://fs.blog/the-forgotten-lessons-of-2008/",
					"content": "Below, we highlight the lessons that we believe could and should have been learned from the turmoil of 2008. Some of them are unique to the 2008 melt- down; others, which could have been drawn from general market observation over the past several decades, were certainly reinforced last year. Shockingly, virtually all of these lessons were either never learned or else were immediately forgotten by most market participants. Twenty Investment Lessons of 2008  Things that have never happened before are bound to occur with some regularity. You must always be prepared for the unexpected, including sudden, sharp downward swings in markets and the economy. Whatever adverse scenario you can contemplate, reality can be far worse. When excesses such as lax lending standards become widespread and persist for some time, people are lulled into a false sense of security, creating an even more dangerous situation. In some cases, excesses migrate beyond regional or national borders, raising the ante for investors and governments. ",
					"content_token": 189,
					"embedding": []
				},
				{
					"article_title": "Seth Klarman: The Forgotten Lessons of 2008",
					"article_url": "https://fs.blog/the-forgotten-lessons-of-2008/",
					"content": "These excesses will eventually end, triggering a crisis at least in proportion to the degree of the excesses. Correlations between asset classes may be surprisingly high when leverage rapidly unwinds. Nowhere does it say that investors should strive to make every last dollar of potential profit; consideration of risk must never take a backseat to return. Conservative positioning entering a crisis is crucial: it enables one to maintain long-term oriented, clear thinking, and to focus on new opportunities while others are distracted or even forced to sell. Portfolio hedges must be in place before a crisis hits. One cannot reliably or affordably increase or replace hedges that are rolling off during a financial crisis. Risk is not inherent in an investment; it is always relative to the price paid. Uncertainty is not the same as risk. Indeed, when great uncertainty – such as in the fall of 2008 – drives securities prices to especially low levels, they often become less risky investments. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "Seth Klarman: The Forgotten Lessons of 2008",
					"article_url": "https://fs.blog/the-forgotten-lessons-of-2008/",
					"content": "Do not trust financial market risk models. Reality is always too complex to be accurately modeled. Attention to risk must be a 247365 obsession, with people – not computers – assessing and reassessing the risk environment in real time. Despite the predilection of some analysts to model the financial markets using sophisticated mathematics, the markets are governed by behavioral science, not physical science. Do not accept principal risk while investing short-term cash: the greedy effort to earn a few extra basis points of yield inevitably leads to the incurrence of greater risk, which increases the likelihood of losses and severe illiquidity at precisely the moment when cash is needed to cover expenses, to meet commitments, or to make compelling long-term investments. The latest trade of a security creates a dangerous illusion that its market price approximates its true value. This mirage is especially dangerous during periods of market exuberance. ",
					"content_token": 179,
					"embedding": []
				},
				{
					"article_title": "Seth Klarman: The Forgotten Lessons of 2008",
					"article_url": "https://fs.blog/the-forgotten-lessons-of-2008/",
					"content": "The concept of “private market value” as an anchor to the proper valuation of a business can also be greatly skewed during ebullient times and should always be considered with a healthy degree of skepticism. A broad and flexible investment approach is essential during a crisis. Opportunities can be vast, ephemeral, and dispersed through various sectors and markets. Rigid silos can be an enormous disadvantage at such times. You must buy on the way down. There is far more volume on the way down than on the way back up, and far less competition among buyers. It is almost always better to be too early than too late, but you must be prepared for price markdowns on what you buy. Financial innovation can be highly dangerous, though almost no one will tell you this. New financial products are typically created for sunny days and are almost never stress-tested for stormy weather. ",
					"content_token": 181,
					"embedding": []
				},
				{
					"article_title": "Seth Klarman: The Forgotten Lessons of 2008",
					"article_url": "https://fs.blog/the-forgotten-lessons-of-2008/",
					"content": "Securitization is an area that almost perfectly fits this description; markets for securitized assets such as subprime mortgages completely collapsed in 2008 and have not fully recovered. Ironically, the government is eager to restore the securitization markets back to their pre-collapse stature. Ratings agencies are highly conflicted, unimaginative dupes. They are blissfully unaware of adverse selection and moral hazard. Investors should never trust them. Be sure that you are well compensated for illiquidity – especially illiquidity without control – because it can create particularly high opportunity costs. At equal returns, public investments are generally superior to private investments not only because they are more liquid but also because amidst distress, public markets are more likely than private ones to offer attractive opportunities to average down. Beware leverage in all its forms. Borrowers – individual, corporate, or government – should always match fund their liabilities against the duration of their assets. ",
					"content_token": 188,
					"embedding": []
				},
				{
					"article_title": "Seth Klarman: The Forgotten Lessons of 2008",
					"article_url": "https://fs.blog/the-forgotten-lessons-of-2008/",
					"content": "Borrowers must always remember that capital markets can be extremely fickle, and that it is never safe to assume a maturing loan can be rolled over. Even if you are unleveraged, the leverage employed by others can drive dramatic price and valuation swings; sudden unavailability of leverage in the economy may trigger an economic downturn. Many LBOs are man-made disasters. When the price paid is excessive, the equity portion of an LBO is really an out-of-the-money call option. Many fiduciaries placed large amounts of the capital under their stewardship into such options in 2006 and 2007. Financial stocks are particularly risky. Banking, in particular, is a highly lever- aged, extremely competitive, and challenging business. A major European bank recently announced the goal of achieving a 20 return on equity ROE within several years. Unfortunately, ROE is highly dependent on absolute yields, yield spreads, maintaining adequate loan loss reserves, and the amount of leverage used. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "Seth Klarman: The Forgotten Lessons of 2008",
					"article_url": "https://fs.blog/the-forgotten-lessons-of-2008/",
					"content": "What is the bank’s management to do if it cannot readily get to 20? Leverage up? Hold riskier assets? Ignore the risk of loss? In some ways, for a major financial institution even to have a ROE goal is to court disaster. Having clients with a long-term orientation is crucial. Nothing else is as important to the success of an investment firm. When a government official says a problem has been “contained,” pay no attention. The government – the ultimate short- term-oriented player – cannot with- stand much pain in the economy or the financial markets. Bailouts and rescues are likely to occur, though not with sufficient predictability for investors to comfortably take advantage. The government will take enormous risks in such interventions, especially if the expenses can be conveniently deferred to the future. Some of the price-tag is in the form of back- stops and guarantees, whose cost is almost impossible to determine. ",
					"content_token": 195,
					"embedding": []
				},
				{
					"article_title": "Seth Klarman: The Forgotten Lessons of 2008",
					"article_url": "https://fs.blog/the-forgotten-lessons-of-2008/",
					"content": "Almost no one will accept responsibility for his or her role in precipitating a crisis: not leveraged speculators, not willfully blind leaders of financial institutions, and certainly not regulators, government officials, ratings agencies or politicians.  Below, we itemize some of the quite different lessons investors seem to have learned as of late 2009 – false lessons, we believe. To not only learn but also effectively implement investment lessons requires a disciplined, often contrary, and long-term-oriented investment approach. It requires a resolute focus on risk aversion rather than maximizing immediate returns, as well as an understanding of history, a sense of financial market cycles, and, at times, extraordinary patience. False Lessons  There are no long-term lessons – ever. Bad things happen, but really bad things do not. Do buy the dips, especially the lowest quality securities when they come under pressure, because declines will quickly be reversed. There is no amount of bad news that the markets cannot see past. ",
					"content_token": 198,
					"embedding": []
				},
				{
					"article_title": "Seth Klarman: The Forgotten Lessons of 2008",
					"article_url": "https://fs.blog/the-forgotten-lessons-of-2008/",
					"content": "If you’ve just stared into the abyss, quickly forget it: the lessons of history can only hold you back. Excess capacity in people, machines, or property will be quickly absorbed. Markets need not be in sync with one another. Simultaneously, the bond market can be priced for sustained tough times, the equity market for a strong recovery, and gold for high inflation. Such an apparent disconnect is indefinitely sustainable. In a crisis, stocks of financial companies are great investments, because the tide is bound to turn. Massive losses on bad loans and soured investments are irrelevant to value; improving trends and future prospects are what matter, regardless of whether profits will have to be used to cover loan losses and equity shortfalls for years to come. The government can reasonably rely on debt ratings when it forms programs to lend money to buyers of otherwise unattractive debt instruments. The government can indefinitely control both short-term and long-term interest rates. ",
					"content_token": 193,
					"embedding": []
				},
				{
					"article_title": "Seth Klarman: The Forgotten Lessons of 2008",
					"article_url": "https://fs.blog/the-forgotten-lessons-of-2008/",
					"content": "The government can always rescue the markets or interfere with contract law whenever it deems convenient with little or no apparent cost. Investors believe this now and, worse still, the government believes it as well. We are probably doomed to a lasting legacy of government tampering with financial markets and the economy, which is likely to create the mother of all moral hazards. The government is blissfully unaware of the wisdom of Friedrich Hayek: “The curious task of economics is to demonstrate to men how little they really know about what they imagine they can design.”   Still curious? Check out Basically, It’s Over: A Parable About How One Nation Came To Financial Ruin by Charlie Munger.",
					"content_token": 142,
					"embedding": []
				}
			]
		},
		{
			"title": "Three Questions to Remove Ego from Decision Making",
			"url": "https://fs.blog/three-questions-to-remove-ego-from-decision-making/",
			"content": "Here are three questions leaders can ask to help make better decisions. 1. How will this decision make things better for the organization? Consider how the decision will affect the organization’s ability to fulfill its mission. Managers who push their teams to achieve “stretch goals” without providing adequate support and resources may be seeking to get noticed by their bosses rather than helping the company serve its customers. Such behavior will have another side effect  talent will exit. The answer to this question must enhance the organization, not simply the resume of the manager. 2. How will this decision affect employees? The business case for your decision should factor in the people quotient and affects on headcount, training, and development. Employees must execute what leaders decide, so if employees perceive that their boss is only doing something to make himself look good, they’ll be reluctant to embrace the change. They may comply, but they may never commit unless they determine the benefit for themselves. 3. How will this decision affect me? When you are involved in a project, it is easy to entangle ego with outcome. Healthy ego is necessary, but when too much ego makes a you blind to obvious problems such as lack of resources, customer disinterest, and employee morale, problems arise. As we have seen with corporate executives in the financial sector, it isn’t positive when personal interest comes before corporate and public interest. So if the answer to this question is more in favor of you rather than the company, the issue may be over-personalized and need more deliberation. ",
			"tokens": 319,
			"chunks": [
				{
					"article_title": "Three Questions to Remove Ego from Decision Making",
					"article_url": "https://fs.blog/three-questions-to-remove-ego-from-decision-making/",
					"content": "Here are three questions leaders can ask to help make better decisions. 1. How will this decision make things better for the organization? Consider how the decision will affect the organization’s ability to fulfill its mission. Managers who push their teams to achieve “stretch goals” without providing adequate support and resources may be seeking to get noticed by their bosses rather than helping the company serve its customers. Such behavior will have another side effect  talent will exit. The answer to this question must enhance the organization, not simply the resume of the manager. 2. How will this decision affect employees? The business case for your decision should factor in the people quotient and affects on headcount, training, and development. Employees must execute what leaders decide, so if employees perceive that their boss is only doing something to make himself look good, they’ll be reluctant to embrace the change. They may comply, but they may never commit unless they determine the benefit for themselves. 3. ",
					"content_token": 200,
					"embedding": []
				},
				{
					"article_title": "Three Questions to Remove Ego from Decision Making",
					"article_url": "https://fs.blog/three-questions-to-remove-ego-from-decision-making/",
					"content": "How will this decision affect me? When you are involved in a project, it is easy to entangle ego with outcome. Healthy ego is necessary, but when too much ego makes a you blind to obvious problems such as lack of resources, customer disinterest, and employee morale, problems arise. As we have seen with corporate executives in the financial sector, it isn’t positive when personal interest comes before corporate and public interest. So if the answer to this question is more in favor of you rather than the company, the issue may be over-personalized and need more deliberation.",
					"content_token": 119,
					"embedding": []
				}
			]
		},
		{
			"title": "The Anatomy of a Decision: An Introduction to Decision Making",
			"url": "https://fs.blog/an-introduction-to-decision-making/",
			"content": "“The only proven way to raise your odds of making a good decision is  to learn to use a good decision-making processone that can  get you the best solution with a minimal  loss of time, energy, money, and composure.”  John Hammond  This is an introduction to decision making. A good decision-making process can literally change the world. Consider the following example from Predictable Surprises: In 1962, when spy planes spotted Soviet missiles in Cuba, U.S. military leaders urged President Kennedy to authorize an immediate attack. Fresh from the bruising failure of the Bay of Pigs, Kennedy instead set up a structured decision-making process to evaluate his options. In a precursor of the Devil’s Advocacy method, Kennedy established two groups each including government officials and outside experts, to develop and evaluate the two main options–attack Cuba or set up a blockade to prevent more missiles from reaching its shores. Based on the groups’ analysis and debate, Kennedy decided to establish a blockade. The Soviets backed down, and nuclear war was averted. Recently available documents suggest that if the United States had invaded Cuba, the consequences would have been catastrophic: Soviet missiles that had not been located by U.S. Intelligence could still have struck several U.S. cities. The concept of a decision-making process can be found in the early history of thinking. Decisions should be the result of rational and deliberate reasoning. Plato argues that human knowledge can be derived based on reason alone using deduction and self-evident propositions. Aristotle formalized logic with logical proofs where someone could reasonably determine if a conclusion was true or false. However, as we will discover, not all decisions are perfectly rational. Often, we let our system one thinking–intuition–make decisions for us. Our intuition is based on long-term memory that has been primarily acquired over the years through learning and allows our mind to process and judge without conscious awareness. System one thinking, however, does not always lead to optimal solutions and often tricks our mind to thinking that consequences and second-order effects are either non-existent or less probable than reality would indicate. In  Predictable Surprises Max Bazerman writes: Rigorous decision analysis combines a systematic assessment of the probabilities of future events with a hard-headed evaluation of the costs and benefits of particular outcomes. As such, it can be an invaluable tool in helping organizations overcome the biases that hinder them in estimating the likelihood of unpleasant events. Decision analysis begins with a clear definition of the decision to be made, followed by an explicit statement of objectives and explicit criteria for assessing the “goodness” of alternative courses of action, by which we mean the net cost or benefit as perceived by the decision-maker. The next steps involve identifying potential courses of action and their consequences. Because these elements often are laid out visually in a decision tree, this technique is known as “decision tree analysis.” Finally, the technique instructs decision-makers to explicitly assess and make trade-offs based on the potential costs and benefits of different courses of action. To conduct a proper decision analysis, leaders must carefully quantify costs and benefits, their tolerance for accepting risk, and the extent of uncertainty associated with different potential outcomes. These assumptions are inherently subjective, but the process of quantification is nonetheless extremely valuable’ it forces participants to express their assumptions and beliefs, thereby making them transparent and subject to challenge and improvement. From Judgment in Management Decision Making by Max Bazerman: The term judgment refers to the cognitive aspects of the decision-making process. To fully understand judgment, we must first identify the components of the decision-making process that require it. Let’s look at six steps you should take, either implicitly or explicitly, when applying a “rational” decision-making process to each scenario. 1. Define the problem. Managers often act without a thorough understanding of the problem to be solved, leading them to solve the wrong problem. Accurate judgment is required to identify and define the problem. Managers often err by a defining the problem in terms of a proposed solution, b missing a bigger problem, or c diagnosing the problem in terms of its symptoms. Your goal should be to solve the problem not just eliminate its temporary symptoms. 2. Identify the criteria. Most decisions require you to accomplish more than one objective. When buying a car, you may want to maximize fuel economy, minimize cost, maximize comfort, and so on. The rational decision maker will identify all relevant criteria in the decision-making process. 3. Weight the criteria. Different criteria will vary in importance to a decision maker. Rational decision makers will know the relative value they place on each of the criteria identified. The value may be specified in dollars, points, or whatever scoring system makes sense. 4. Generate alternatives. The fourth step in the decision-making process requires identification of possible courses of action. Decision makers often spend an inappropriate amount of search time seeking alternatives, thus creating a barrier to effective decision making. An optimal search continues only until the cost of the search outweighs the value of added information. 5. Rate each alternative on each criterion. How well will each of the alternative solutions achieve each of the defined criteria? This is often the most difficult stage of the decision-making process, as it typically requires us to forecast future events. The rational decision maker carefully assesses the potential consequences on each of the identified criteria of selecting each of the alternative solutions. 6. Compute the optimal decision. Ideally, after all of the first five steps have been completed, the process of computing the optimal decision consists of a multiplying the ratings in step 5 by the weight of each criterion, b adding up the weighted ratings across all of the criteria for each alternative, and c choosing the solution with the highest sum of weighted ratings. Hammond, Keeney, and Raiffa suggest 8 steps in their book Smart Choices: 1. Work on the right problem. 2. Identify all criteria. 3. Create imaginative alternatives. 4. Understand the consequences. 5. Grapple with your tradeoffs. 6. Clarify your uncertainties. 7. Think hard about your risk tolerance. 8. Consider linked decisions.    People, however, are not always entirely logical machines. In Judgment in Managerial Decision Making, the distinction between System One and System Two thinking becomes clear: System 1 thinking refers to our intuitive system, which is typically fast, automatic, effortless, implicit, and emotional. We make most decisions in life using System 1 thinking. For instance, we usually decide how to interpret verbal language or visual information automatically and unconsciously. By contrast, System 2 refers to reasoning that is slower, conscious, effortful, explicit, and logical. System 2 thinking can be broken down into 1 define the problem; 2 identify the criteria; 3 weigh the criteria; 4 generate alternatives; 5 rate each alternative on each criterion; 6 compute the optimal decision. In most situations, our system 1 thinking is quite sufficient; it would be impractical, for example, to logically reason through every choice we make while shopping for groceries. But System 2 logic should preferably influence our most important decisions.    When making a decision, we are psychologically influenced either consciously or unconsciously. By exploring these biases and other elementary, worldly wisdom, we hope to make you a better decision-maker. Following a rational decision process can help us focus on outcomes that are low in probability but high in potential costs. Without easily quantifiable costs, we often dismiss low probability events or fall prey to biases. We don’t want to be the fragilista. Even rational decision-making processes like the one presented above make several assumptions. The first assumption is that a rational decision-maker is completely informed which means they know about all the possible options and outcomes. The second major assumption is that the decision-maker does not fall prey to any biases that might impact the rational decision. In researching decision-making processes, it struck us as odd that few people question the information upon which criteria are measured. For instance, if you are purchasing a car and use fuel efficiency as the sole criterion for decision making, you would need to make sure that the cars under consideration were all tested and measured fuel consumption in the same way. This second order of thinking can help you make better decisions. If you want to make better decisions, you should read Judgment in Managerial Decision Making. That is the best book I’ve come across on decision making. If you know of a better one, please send me an email. Stanovich’s book, What Intelligence Tests Miss: The Psychology of Rational Thought, proposes a whole range of cognitive abilities and dispositions independent of intelligence that have at least as much to do with whether we think and behave rationally.   Follow your curiosity to The best books on the psychology behind human decision making and Problem Solving 101. ",
			"tokens": 1815,
			"chunks": [
				{
					"article_title": "The Anatomy of a Decision: An Introduction to Decision Making",
					"article_url": "https://fs.blog/an-introduction-to-decision-making/",
					"content": "“The only proven way to raise your odds of making a good decision is  to learn to use a good decision-making processone that can  get you the best solution with a minimal  loss of time, energy, money, and composure.”  John Hammond  This is an introduction to decision making. A good decision-making process can literally change the world. Consider the following example from Predictable Surprises: In 1962, when spy planes spotted Soviet missiles in Cuba, U.S. military leaders urged President Kennedy to authorize an immediate attack. Fresh from the bruising failure of the Bay of Pigs, Kennedy instead set up a structured decision-making process to evaluate his options. In a precursor of the Devil’s Advocacy method, Kennedy established two groups each including government officials and outside experts, to develop and evaluate the two main options–attack Cuba or set up a blockade to prevent more missiles from reaching its shores. ",
					"content_token": 191,
					"embedding": []
				},
				{
					"article_title": "The Anatomy of a Decision: An Introduction to Decision Making",
					"article_url": "https://fs.blog/an-introduction-to-decision-making/",
					"content": "Based on the groups’ analysis and debate, Kennedy decided to establish a blockade. The Soviets backed down, and nuclear war was averted. Recently available documents suggest that if the United States had invaded Cuba, the consequences would have been catastrophic: Soviet missiles that had not been located by U.S. Intelligence could still have struck several U.S. cities. The concept of a decision-making process can be found in the early history of thinking. Decisions should be the result of rational and deliberate reasoning. Plato argues that human knowledge can be derived based on reason alone using deduction and self-evident propositions. Aristotle formalized logic with logical proofs where someone could reasonably determine if a conclusion was true or false. However, as we will discover, not all decisions are perfectly rational. Often, we let our system one thinking–intuition–make decisions for us. ",
					"content_token": 177,
					"embedding": []
				},
				{
					"article_title": "The Anatomy of a Decision: An Introduction to Decision Making",
					"article_url": "https://fs.blog/an-introduction-to-decision-making/",
					"content": "Our intuition is based on long-term memory that has been primarily acquired over the years through learning and allows our mind to process and judge without conscious awareness. System one thinking, however, does not always lead to optimal solutions and often tricks our mind to thinking that consequences and second-order effects are either non-existent or less probable than reality would indicate. In  Predictable Surprises Max Bazerman writes: Rigorous decision analysis combines a systematic assessment of the probabilities of future events with a hard-headed evaluation of the costs and benefits of particular outcomes. As such, it can be an invaluable tool in helping organizations overcome the biases that hinder them in estimating the likelihood of unpleasant events. Decision analysis begins with a clear definition of the decision to be made, followed by an explicit statement of objectives and explicit criteria for assessing the “goodness” of alternative courses of action, by which we mean the net cost or benefit as perceived by the decision-maker. ",
					"content_token": 194,
					"embedding": []
				},
				{
					"article_title": "The Anatomy of a Decision: An Introduction to Decision Making",
					"article_url": "https://fs.blog/an-introduction-to-decision-making/",
					"content": "The next steps involve identifying potential courses of action and their consequences. Because these elements often are laid out visually in a decision tree, this technique is known as “decision tree analysis.” Finally, the technique instructs decision-makers to explicitly assess and make trade-offs based on the potential costs and benefits of different courses of action. To conduct a proper decision analysis, leaders must carefully quantify costs and benefits, their tolerance for accepting risk, and the extent of uncertainty associated with different potential outcomes. These assumptions are inherently subjective, but the process of quantification is nonetheless extremely valuable’ it forces participants to express their assumptions and beliefs, thereby making them transparent and subject to challenge and improvement. From Judgment in Management Decision Making by Max Bazerman: The term judgment refers to the cognitive aspects of the decision-making process. To fully understand judgment, we must first identify the components of the decision-making process that require it. ",
					"content_token": 189,
					"embedding": []
				},
				{
					"article_title": "The Anatomy of a Decision: An Introduction to Decision Making",
					"article_url": "https://fs.blog/an-introduction-to-decision-making/",
					"content": "Let’s look at six steps you should take, either implicitly or explicitly, when applying a “rational” decision-making process to each scenario. 1. Define the problem. Managers often act without a thorough understanding of the problem to be solved, leading them to solve the wrong problem. Accurate judgment is required to identify and define the problem. Managers often err by a defining the problem in terms of a proposed solution, b missing a bigger problem, or c diagnosing the problem in terms of its symptoms. Your goal should be to solve the problem not just eliminate its temporary symptoms. 2. Identify the criteria. Most decisions require you to accomplish more than one objective. When buying a car, you may want to maximize fuel economy, minimize cost, maximize comfort, and so on. The rational decision maker will identify all relevant criteria in the decision-making process. 3. Weight the criteria. Different criteria will vary in importance to a decision maker. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "The Anatomy of a Decision: An Introduction to Decision Making",
					"article_url": "https://fs.blog/an-introduction-to-decision-making/",
					"content": "Rational decision makers will know the relative value they place on each of the criteria identified. The value may be specified in dollars, points, or whatever scoring system makes sense. 4. Generate alternatives. The fourth step in the decision-making process requires identification of possible courses of action. Decision makers often spend an inappropriate amount of search time seeking alternatives, thus creating a barrier to effective decision making. An optimal search continues only until the cost of the search outweighs the value of added information. 5. Rate each alternative on each criterion. How well will each of the alternative solutions achieve each of the defined criteria? This is often the most difficult stage of the decision-making process, as it typically requires us to forecast future events. The rational decision maker carefully assesses the potential consequences on each of the identified criteria of selecting each of the alternative solutions. 6. Compute the optimal decision. ",
					"content_token": 180,
					"embedding": []
				},
				{
					"article_title": "The Anatomy of a Decision: An Introduction to Decision Making",
					"article_url": "https://fs.blog/an-introduction-to-decision-making/",
					"content": "Ideally, after all of the first five steps have been completed, the process of computing the optimal decision consists of a multiplying the ratings in step 5 by the weight of each criterion, b adding up the weighted ratings across all of the criteria for each alternative, and c choosing the solution with the highest sum of weighted ratings. Hammond, Keeney, and Raiffa suggest 8 steps in their book Smart Choices: 1. Work on the right problem. 2. Identify all criteria. 3. Create imaginative alternatives. 4. Understand the consequences. 5. Grapple with your tradeoffs. 6. Clarify your uncertainties. 7. Think hard about your risk tolerance. 8. Consider linked decisions.    People, however, are not always entirely logical machines. ",
					"content_token": 159,
					"embedding": []
				},
				{
					"article_title": "The Anatomy of a Decision: An Introduction to Decision Making",
					"article_url": "https://fs.blog/an-introduction-to-decision-making/",
					"content": "In Judgment in Managerial Decision Making, the distinction between System One and System Two thinking becomes clear: System 1 thinking refers to our intuitive system, which is typically fast, automatic, effortless, implicit, and emotional. We make most decisions in life using System 1 thinking. For instance, we usually decide how to interpret verbal language or visual information automatically and unconsciously. By contrast, System 2 refers to reasoning that is slower, conscious, effortful, explicit, and logical. System 2 thinking can be broken down into 1 define the problem; 2 identify the criteria; 3 weigh the criteria; 4 generate alternatives; 5 rate each alternative on each criterion; 6 compute the optimal decision. In most situations, our system 1 thinking is quite sufficient; it would be impractical, for example, to logically reason through every choice we make while shopping for groceries. But System 2 logic should preferably influence our most important decisions.    When making a decision, we are psychologically influenced either consciously or unconsciously. ",
					"content_token": 199,
					"embedding": []
				},
				{
					"article_title": "The Anatomy of a Decision: An Introduction to Decision Making",
					"article_url": "https://fs.blog/an-introduction-to-decision-making/",
					"content": "By exploring these biases and other elementary, worldly wisdom, we hope to make you a better decision-maker. Following a rational decision process can help us focus on outcomes that are low in probability but high in potential costs. Without easily quantifiable costs, we often dismiss low probability events or fall prey to biases. We don’t want to be the fragilista. Even rational decision-making processes like the one presented above make several assumptions. The first assumption is that a rational decision-maker is completely informed which means they know about all the possible options and outcomes. The second major assumption is that the decision-maker does not fall prey to any biases that might impact the rational decision. In researching decision-making processes, it struck us as odd that few people question the information upon which criteria are measured. ",
					"content_token": 164,
					"embedding": []
				},
				{
					"article_title": "The Anatomy of a Decision: An Introduction to Decision Making",
					"article_url": "https://fs.blog/an-introduction-to-decision-making/",
					"content": "For instance, if you are purchasing a car and use fuel efficiency as the sole criterion for decision making, you would need to make sure that the cars under consideration were all tested and measured fuel consumption in the same way. This second order of thinking can help you make better decisions. If you want to make better decisions, you should read Judgment in Managerial Decision Making. That is the best book I’ve come across on decision making. If you know of a better one, please send me an email. Stanovich’s book, What Intelligence Tests Miss: The Psychology of Rational Thought, proposes a whole range of cognitive abilities and dispositions independent of intelligence that have at least as much to do with whether we think and behave rationally.   Follow your curiosity to The best books on the psychology behind human decision making and Problem Solving 101.",
					"content_token": 173,
					"embedding": []
				}
			]
		}
	]
}